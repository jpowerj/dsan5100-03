---
title: "Week 13: Non-Parametric Methods"
date: "Thursday, November 16, 2023"
date-format: full
lecnum: 13
categories:
  - "Class Sessions"
subtitle: "*DSAN 5100: Probabilistic Modeling and Statistical Computing*<br>Sections 01-04 (Combined Session)"
author: "Jeff Jacobs"
institute: "<a href='mailto:jj1088@georgetown.edu' target='_blank'>`jj1088@georgetown.edu`</a>"
bibliography: "../_DSAN5100.bib"
execute:
  echo: true
format:
  revealjs:
    cache: false
    footer: "DSAN 5100 Week 13: Non-Parametric Methods"
    output-file: slides.html
    df-print: kable
    code-fold: true
    html-math-method: mathjax
    scrollable: true
    slide-number: true
    section-divs: false
    simplemenu:
      flat: true
      barhtml:
        header: "<div class='menubar'><span style='position: absolute; left: 8; padding-left: 8px;'><a href='./index.html'>&larr; Return to Notes</a></span><ul class='menu'></ul></div>"
      scale: 0.5
    number-sections: false
    footnotes-hover: true
    tbl-cap-location: bottom
    theme: [default, "../_style-slides.scss"]
    revealjs-plugins:
      - simplemenu
    include-in-header:
      text: "<link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css' integrity='sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65' crossorigin='anonymous'><link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.5/font/bootstrap-icons.css'><link href=\"https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined\" rel=\"stylesheet\" />"
  html:
    output-file: index.html
    cache: false
    html-math-method: mathjax
    number-sections: false
    code-fold: true
    footnotes-hover: true
    tbl-cap-location: bottom
---

::: {.content-visible unless-format="revealjs"}

<center>
<a class="h2" href="./slides.html" target="_blank">Open slides in new window &rarr;</a>
</center>

:::

# Schedule {.smaller .small-title .crunch-title data-name="Schedule"}

::: {.hidden}

```{r}
#| label: r-source-globals
source("../_globals.r")
```

{{< include ../_globals-tex.qmd >}}

:::

Today's Planned Schedule:

| | Start | End | Topic | Recording |
|:- |:- |:- |:- |:-:|
| **Lecture** | 12:30pm | 1:30pm | Guest Speaker! Dr. Kerrie Carfagno |  |
| | 1:30pm | 2:00pm | <a href='#non-parametric-analysis'>Non-Parametric Analysis &rarr;</a> | <a href='../recordings/recording-w13-1.html' target='_blank' class='disabled'><i class='bi bi-film'></i></a> |
| **Break!** | 2:00pm | 2:10pm | | |
| | 2:10pm | 3:00pm | <a href="#bias-variance-tradeoff-introduction">Non-Parametric Methods Lab &rarr;</a> | <a href="../recordings/recording-w13-2.html" target="_blank" class='disabled'><i class="bi bi-film"></i></a> |

: {tbl-colwidths="[10,10,10,60,10]"}

# Guest Speaker {data-stack-name="Guest Speaker"}

## Dr. Kerrie Carfagno {.smaller .crunch-title}

```{=html}
<style>
.inline-image {
  margin: 0!important;
  height: 220px;
  float: left;
  margin: 10px !important;
}
</style>
```

::: {.bio-container}

![](images/kerrie-gafagno.webp){.inline-image} Kerrie Carfagno is the **Program Director** for Georgetown's **MS** Program in **Environment and Sustainability Management**.

Dr. Carfagno has taught sustainable business and management communication courses with an emphasis on communication strategy, change management, leadership, ethics, and data visualization for more than 15 years.

Carfagno is particularly interested in the financial and ethical impact of climate change on businesses at the industry, corporate, and societal levels. She focuses on how leaders can effectively communicate climate risk (and opportunity) to increase profitability, resiliency, and sustainability.

She employed these concepts in her global sustainability elective courses and her study abroad courses to Scandinavia in partnership with DIS. Carfagno is also a senior fellow at Generation 180, a non-profit org working to inspire and equip people to take action on clean energy.

:::

# Non-Parametric Analysis {data-stack-name="Non-Parametric Analysis"}

## What Makes It "Non-Parametric"? {.smaller .crunch-images .crunch-title .shift-footnotes-0 .crunch-quarto-layout-panel}

* We've talked about how the Normal distribution is "standard" in multiple senses:
  * **Empirically**: It arises from common processes in nature, like random walks
  * **Theoretically**: It is the maximum-entropy distribution which encodes **only** knowledge of a **mean** $\mu$ and a **variance** $\sigma^2$*
* Then we talked about **estimating** these parameters ($\mu$ and $\sigma^2$) from data: different ways to amalgamate information from an **observed sample** $\mathbf{X} = (X_1, \ldots, X_n)$ to estimate $\mu$ and $\sigma^2$ (unobserved) with **minimal bias and variance**

::: {layout="[1,1]"}

![](images/normal-dist-inference.svg){fig-align="center" width="340"}

::: {#nonparametric-right}

* We therefore **"funnel"** all of the information contained in $\mathbf{X}$ down into estimates of $\mu$ and $\sigma^2$
* But... **what if we're wrong?** What if the DGP is **not** drawing from a Normal distribution?

:::

:::

::: {.aside}

Recall that any other distribution implicitly encodes **additional assumptions**, e.g., that the datapoints lie within some bounded range, or have all nonnegative values, etc.

:::

## What If We're Wrong? {.smaller}

* It is this concern: the fact that **all of our results**, **all of our confidence** about our estimates thus far, come as a result of making **distributional assumptions**
* **Non-parametric** analysis aims to **mitigate** this potential catastrophe, by making **as few distributional assumptions as possible**
* Recall how the parameters of a distribution (by way of its **Moment Generating Function**) determine **all of the information** you could possibly want to know about the distribution:

| Type of Distribution | + | Parameter Values | = | All Possible Info (MGF) |
| - | - | - | - | - |
| Normal $\mathcal{N}(\mu, \sigma^2)$ | + | $\mu = m$, $\sigma^2 = s$ | = | $M_t(X) = \exp[mt + s^2t^2/2]$ |
| Uniform $\mathcal{U}(\alpha,\beta)$ | + | $\alpha = a$, $\beta = b$ | = | $M_t(X) = \frac{e^{tb} - e^{ta}}{t(b-a)}$ |
| Poisson $\mathcal{P}(\lambda)$ | + | $\lambda = \ell$ | = | $M_t(X) = \exp[\ell(e^t - 1)]$ |

: {tbl-colwidths="[30,5,30,5,30]"}

## Avoiding Wrongness Disasters {.smaller .crunch-title .crunch-math .smaller-math .smaller-inline .crunch-ul .crunch-p}

* Instead of trying to estimate **all possible info** about the underlying distribution, we only estimate **one piece of information** that we need to **test a hypothesis**
* Example: for populations $\chi$, $\psi$, if $H_A: \mu_\chi > \mu_\psi$, skip intermediate step of estimating distributions $\mathcal{D}_\chi(\param{\theta})$, $\mathcal{D}_\psi(\param{\theta})$ from samples $\mathbf{X}$, $\mathbf{Y}$!
* Instead, just directly "extract" **greater than** vs. **not greater than** info from $\mathbf{X}$ and $\mathbf{Y}$
* It will help us to define a $\text{Sign}(\cdot)$ function:

$$
\text{Sign}(x) = \begin{cases}\phantom{-}1 &\text{if } x > 0 \\ \phantom{-}0 &\text{if }x = 0 \\ -1 &\text{if }x < 0\end{cases}
$$

* If $\mathbf{X} = (15, 7, 11, 3)$, $\mathbf{Y} = (-3, 4, 1, 4)$, we can compute a "greater-than score":

$$
\begin{align*}
\sum_{i=1}^N \sign(X_i - Y_i) &= \sign(15 - (-3)) + \sign(7-4) + \sign(11-1) + \sign(3-4) \\
&= 1 + 1 + 1 + -1 = 2
\end{align*}
$$

* So long as **slots are comparable** (notice $\mathbf{X}, \mathbf{Y}$ are **ordered**), we can compare this with $0$, our expectation if $\chi = \psi$, **regardless of underlying distributions $\mathcal{D}_\chi, \mathcal{D}_\psi$**.

## Procedure in General {.smaller .crunch-title .crunch-math}

* $\mathbf{X}$: size-$N$ sample from population $\chi$; $\mathbf{Y}$: size-$N$ sample from population $\psi$
* (Rather than estimating $\mathcal{D}_\chi$ from $\mathbf{X}$ and $\mathcal{D}_\psi$ from $\mathbf{Y}$), we directly **pair** datapoints $X_i \in \mathbf{X}$ and $Y_i \in \mathbf{Y}$ and compute the **sign** of their difference:

$$
\text{GT}_i(X_i, Y_i) = \text{Sign}(X_{i} - Y_{i}) = \begin{cases}
\phantom{-}1 &\text{if }X_{i} > Y_{i}, \\
\phantom{-}0 &\text{if }X_{i} = Y_{i}, \\
-1 &\text{if }X_{i} < Y_{i}
\end{cases}
$$

* We can then **sum** each pair's score into an aggregate score:

    $$
    \text{GT}(\mathbf{X}, \mathbf{Y}) = \sum_{i=1}^NGT_i(X_i,Y_i)
    $$

    such that if $\chi$ and $\psi$ are in fact **the same population**, we expect $GT(\mathbf{X}, \mathbf{Y}) = 0$ (positive and negative values of $GT_i$ cancel each other out, for sufficiently large $N$)

* Non-parametric tests which use this value as a **test statistic** are called **Sign tests**
<!-- * Note how I'm leaving it ambiguous how to **aggregate** individual scores $\text{GT}_i(X_i, Y_i)$ into an overall score $\text{GT}(\mathbf{X}, \mathbf{Y})$: this depends on the **context**, e.g., the particular **form** of the hypothesis you're trying to test -->

## What If We *Can't* Pair Observations One-to-One? {.title-08}

* For example, what if samples aren't the same size: $N_X = |\mathbf{X}| \neq N_Y = |\mathbf{Y}|$?
* *Intuition*: If there is no "natural" one-to-one pairing of the observations, we can instead consider **all possible pairs** $(X_{i}, Y_{j}) \in \mathbf{X} \times \mathbf{Y}$
* We can then count how often $X_i > Y_j$, how often $Y_j > X_i$, and compare this to our **expectation** of how often these would occur if $\chi = \psi$ (that is, if $\mathbf{X}$ and $\mathbf{Y}$ were in fact drawn from the **same population**)

<!-- * Another piece of information we could compute is the **rank** of each datapoint with respect to the **combination** of the two datasets:
* If dataset 1 has size $N_1$ and dataset 2 has size $N_2$: The **greatest value across both datasets** has **rank 1**, the **second-greatest** has **rank 2**, and so on, up to the **lowest value across both datasets** having **rank $N_1 + N_2$** -->

## Computational Efficiency

* We could just go ahead with this intuition, checking every pair and seeing how often $X_i > Y_j$ vs. how often $Y_j > X_i$, but this is **computationally expensive** for large samples (requiring $O(N_1N_2)$ comparisons)
* So, let's walk through an example with pairwise comparisons, but try to think of an equivalent yet **sub-quadratic** method for achieving the same results!

## Pairwise Comparison Mode {.smaller .crunch-title .crunch-quarto-layout-panel .crunch-ul}

* Let $\mathbf{X} = \{5, 9, 7\}, \mathbf{Y} = \{7, 6\}$, and consider $X_i > Y_j$ vs. $Y_j > X_i$ for all pairs:
* Give 1 point to $\mathbf{X}$ if $X_i > Y_j$, 1 point to $\mathbf{Y}$ if $Y_j > X_i$, 0.5 points to both if $X_i = Y_j$.

| $X_i$ | $Y_j$ | $>$ | $=$ | $<$ |
|:-:|:-:|:-:|:-:|:-:|
| 5 | 7 |  |  | +1 |
| 5 | 6 |  |  | +1 |
| 9 | 7 | +1 |  |
| 9 | 6 | +1 |  |
| 7 | 7 |  | +0.5 |
| 7 | 6 | +1 |  |
| **Final** | **Score:** | $S_{\mathbf{X}} = 3.5$ | | $S_{\mathbf{Y}} = 2.5$ |

## Ranking Mode {.smaller .crunch-title .crunch-ul .smaller-math .small-inline}

* Now consider the **combined dataset** $\mathbf{Z} = \mathbf{X} \oplus \mathbf{Y} = (5_X, 9_X, 7_X, 7_Y, 6_Y)$
* Let's see what we get when we **rank the values** in $\mathbf{X}$ and $\mathbf{Y}$ separately, then rank the same values within $\mathbf{Z}$, keeping track of whether each number is from $\mathbf{X}$ or $\mathbf{Y}$:

| | | | | | | |
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
| **Values** | $5_X$ | $6_Y$ | $7_X$ | $7_Y$ | $9_X$ | |
| **Rank in $\mathbf{X}$** | $[1]_{X/\mathbf{X}}$ | | $[2]_{X/\mathbf{X}}$ | | $[3]_{X/\mathbf{X}}$ | $\Sigma_{X/\mathbf{X}} = [6]$ |
| **Rank in $\mathbf{Y}$** | | $[1]_{Y/\mathbf{Y}}$ | | $[2]_{Y/\mathbf{Y}}$ | | $\Sigma_{Y/\mathbf{Y}} = [3]$ |
| **Rank in $\mathbf{Z}$** | $[1]_{X/\mathbf{Z}}$ | &nbsp;<br>$[2]_{Y/\mathbf{Z}}$ | $[3.5]_{X/\mathbf{Z}}$ | &nbsp;<br>$[3.5]_{Y/\mathbf{Z}}$ | $[5]_{X/\mathbf{Z}}$ | $\Sigma_{X/\mathbf{Z}} = [9.5]$<br>$\Sigma_{Y/\mathbf{Z}} = [5.5]$ |

* Thus, by **subtracting** single-sample ranks from combined-sample ranks, we obtain:
* $S_{\mathbf{X}} = \Sigma_{X/\mathbf{Z}} - \Sigma_{X/\mathbf{X}} = 9.5 - 6 = 3.5$ 
* $S_{\mathbf{Y}} = \Sigma_{Y/\mathbf{Z}} - \Sigma_{Y/\mathbf{Y}} = 5.5 - 3 = 2.5$ 🤯
* And yet, this runs in $O((N_1+N_2)\log(N_1+N_2)) < O(N_1N_2)$

## Example: 2022 World Cup {.smaller}

* Heights (inches) of Welsh vs. US national football teams ($N = 22$ players total):

| | | | | | | | | | | | | |
| - | - | - | - | - | - | - | - | - | - | - | - | - |
| **Wales** | 78 | 71 | 76 | 75 | 72 | 70 | 68 | 72 | 69 | 73 | 67 | $\overline{X} \approx 71.91$ |
| **USA** | 75 | 68 | 74 | 68 | 68 | 70 | 72 | 67 | 72 | 72 | 70 | $\overline{Y} \approx 70.55$ |

```{r}
#| label: height-hist
#| fig-align: center
#| code-fold: true
library(tidyverse)
us_heights <- tibble(height=c(75, 68, 74, 68, 68, 70, 72, 67, 72, 72, 70))
# Go metric! Oh well
#us_heights <- tibble(height=c(190.5, 172.7, 188, 172.7, 172.7, 177.8, 182.9, 170.2, 182.9, 182.9, 177.8)
mean_us <- mean(us_heights$height)
#print(mean_us)
us_heights <- us_heights |> mutate(Team = "US")
wales_heights <- tibble(height=c(78, 71, 76, 75, 72, 70, 68, 72, 69, 73, 67))
mean_wales <- mean(wales_heights$height)
#print(mean_wales)
mean_df <- tibble(mean_height = c(mean_us, mean_wales), Team = c("US", "Wales"))
wales_heights <- wales_heights |> mutate(Team = "Wales")
players = bind_rows(us_heights, wales_heights)
ggplot(players, aes(x=height, fill=Team)) +
  geom_density(
    alpha=0.3, adjust=4/5
  ) +
  geom_vline(
    data=mean_df,
    aes(xintercept=mean_height, color=Team),
    linetype = "dashed",
    linewidth = g_linewidth
  ) +
  xlim(c(65,80)) +
  dsan_theme("half") +
  scale_fill_manual(values=c(cbPalette[1], cbPalette[2])) +
  labs(
    title = "Empirical Distribution of Team Heights",
    x = "Height (inches)",
    y = "Empirical Density"
  )
```

## Samples $\rightarrow$ Populations {.crunch-code}

* We know that the **sampled** heights of Welsh football players ($\mathbf{X}$) are (on average) greater than the **sampled** heights of US football players ($\mathbf{Y}$).
* But are heights in fact greater among the **population** of Welsh football players ($\chi$), relative to the **population** of US football players ($\psi$)?

## The Non-Parametric Fork in the Road {.smaller}

* Recall: in **parametric tests**, when comparing means, we analyzed the difference in the sample means **relative to their variability** and summarized the sample information in a test statistic: for example, $t = \frac{\overline{X} - \mu_H}{\widehat{\sigma} / \sqrt{N}}$
* We **could** compute this test statistic, but it would **implicitly depend on** an assumption of the underlying DGP: that heights follow a **Normal** distribution.
* Here, instead, we produce a test statistic based on the **ranks**!
* Test statistics should measure how **surprised** we would be if we observed what we observed in a world where the **null hypothesis is true**
* Equivalently, it should be **low** if the observed difference could feasibly have occurred just due to random noise (i.e., if we're looking at noisy data from world where **null hypothesis is true**)
* So, let's think in these terms about the **ranks** of each datapoint, to develop a non-parametric **test statistic** based on the ranks

## Choosing *Non-Parametric* Hypotheses {.crunch-title .title-09}

* The **empirical distributions** from the previous slide, and the **small sample size** ($N_1 = N_2 = 11$), motivate our use of a nonparametric test!
* Assuming $X \sim \mathcal{D}_1$ and $Y \sim \mathcal{D}_2$ (but **not** assuming the **parametric forms** of $\mathcal{D}_1$ or $\mathcal{D}_2$!), we can test:
* $H_0: \Pr(X > Y) = \Pr(Y > X)$
* $H_1: \Pr(X > Y) \neq \Pr(Y > X)$

## Sorting and Ranking Observations {.smaller .crunch-title .crunch-table}

```{=html}
<table class='centered-table table-line-2-3 table-line-4-5' style='border-collapse: collapse; font-size: 16pt;'>
<thead>
<tr>
    <td colspan="2" align="center" style="border-right: 2px solid black; font-size: 20pt !important;">Original Data</td>
    <td colspan="2" align="center" style="border-right: 2px solid black; font-size: 20pt !important;">Sorted Total Samples</td>
    <td colspan="2" align="center" style="font-size: 20pt !important;">Rank</td>
</tr>
<tr>
    <td style='font-size: 18pt !important;'>USA</td>
    <td style="font-size: 18pt !important; border-right: 2px solid black;">Wales</td>
    <td style='font-size: 18pt !important;'>USA</td>
    <td style="font-size: 18pt !important; border-right: 2px solid black;">Wales</td>
    <td style='font-size: 18pt !important;'>USA</td>
    <td style='font-size: 18pt !important;'>Wales</td>
</tr>
</thead>
<tbody>
<tr>
    <td>75</td>
    <td>78</td>
    <td>67</td>
    <td>67</td>
    <td>1.5</td>
    <td>1.5</td>
</tr>
<tr>
    <td>68</td>
    <td>71</td>
    <td>68</td>
    <td rowspan="3" style="vertical-align: middle;">68</td>
    <td style="border-right-width: 0px !important;">4.5</td>
    <td rowspan="3" style="vertical-align: middle; border-left: 0px;">4.5</td>
</tr>
<tr>
    <td>74</td>
    <td>76</td>
    <td>68</td>
    <td style="border-right-width: 0px !important;">4.5</td>
</tr>
<tr>
    <td>68</td>
    <td>75</td>
    <td>68</td>
    <td style="border-right-width: 0px !important;">4.5</td>
</tr>
<tr>
    <td>68</td>
    <td>72</td>
    <td></td>
    <td>69</td>
    <td></td>
    <td>7</td>
</tr>
<tr>
    <td>70</td>
    <td>70</td>
    <td>70</td>
    <td rowspan="2" style="vertical-align: middle;">70</td>
    <td>9</td>
    <td rowspan="2" style="vertical-align: middle;">9</td>
</tr>
<tr>
    <td>72</td>
    <td>68</td>
    <td>70</td>
    <td style="border-right-width: 0px !important;">9</td>
</tr>
<tr>
    <td>67</td>
    <td>72</td>
    <td></td>
    <td>71</td>
    <td></td>
    <td>11</td>
</tr>
<tr>
    <td rowspan="2" style="vertical-align: middle;">72</td>
    <td rowspan="2" style="vertical-align: middle;">69</td>
    <td rowspan="2" style="vertical-align: middle;">72</td>
    <td rowspan="3" style="vertical-align: middle;">72</td>
    <td rowspan="2" style="vertical-align: middle;">14</td>
    <td rowspan="3" style="vertical-align: middle;">14</td>
</tr>
<tr>
</tr>
<tr>
    <td rowspan="2" style="vertical-align: middle;">72</td>
    <td rowspan="2" style="vertical-align: middle;">73</td>
    <td rowspan="2" style="vertical-align: middle;">72</td>
    <td rowspan="2" style="vertical-align: middle;border-right-width: 0px !important;">14</td>
</tr>
<tr>
  <td rowspan="3" style="vertical-align: middle;border-right-width: 2px !important;">72</td>
  <td rowspan="3" style="vertical-align: middle;border-right-width: 0px !important;">14</td>
</tr>
<tr>
    <td rowspan="2" style="vertical-align: middle;">72</td>
    <td rowspan="2" style="vertical-align: middle;">73</td>
    <td rowspan="2" style="vertical-align: middle;">72</td>
    <td rowspan="2" style="vertical-align: middle;border-right-width: 0px !important;">14</td>
</tr>
<tr>
    <td>70</td>
    <td>67</td>
    <td rowspan="3">72</td>
    <td style="border-right-width: 0px !important;">14</td>
</tr>
<tr>
    <td></td>
    <td></td>
    <td></td>
    <td>73</td>
    <td></td>
    <td>17</td>
</tr>
<tr>
    <td></td>
    <td></td>
    <td>74</td>
    <td></td>
    <td>18</td>
    <td></td>
</tr>
<tr>
    <td></td>
    <td></td>
    <td>75</td>
    <td>75</td>
    <td>19.5</td>
    <td>19.5</td>
</tr>
<tr>
    <td></td>
    <td></td>
    <td></td>
    <td>76</td>
    <td></td>
    <td>21</td>
</tr>
<tr>
    <td></td>
    <td></td>
    <td></td>
    <td>78</td>
    <td></td>
    <td>22</td>
</tr>
</tbody>
</table>
```

## Our Rank-Based Test Statistic {.smaller .crunch-title .crunch-ul .crunch-math}

* Sums of ranks relative to the **combined** dataset: $\Sigma_{X/\mathbf{Z}} = 112.5$, $\Sigma_{Y/\mathbf{Z}} = 140.5$.
* And then sum the ranks in each group, relative to the same group... In general, if we have $N$ ranked datapoints (so, datapoints given labels $\{1, 2, \ldots, N\}$), what will the **sum** of these individual ranks be?

$$
\sum_{i=1}^{N}i = \underbrace{\overbrace{(1 + N)}^{N + 1} + \overbrace{(2 + (N-1))}^{N + 1} + \cdots}_{N/2\text{ terms}} = \frac{N(N+1)}{2}
$$

* So, in this case,

$$
\Sigma_{X/\mathbf{X}} = \Sigma_{Y/\mathbf{Y}} = \sum_{i=1}^{11}i = \frac{11(12)}{2} = 66
$$

* Giving us the test statistics

$$
\begin{align*}
U_X &= 112.5 - 66 = 46.5, \; U_Y = 140.5 - 66 = 74.5 \\
U &= \min\{U_X, U_Y\} = \min\{46.5, 74.5\} = 46.5
\end{align*}
$$

## Simulating (One) Null-Hypothesis World {.smaller}

* One simulation looks as follows:

::: {layout="[1,1]"}

```{r}
#| label: null-ranks
library(tidyverse)
N1 <- 11
N2 <- 11
N <- N1 + N2
totalRankSum <- (N * (N+1)) / 2
writeLines(paste0("N1 = ",N1,", N2 = ",N2," => Sum(1...(N1+N2)) = ",totalRankSum))
s_1 <- runif(N1)
df_1 <- tibble(x = s_1, team = "A")
s_2 <- runif(N2)
df_2 <- tibble(x = s_2, team = "B")
df_combined <- bind_rows(df_1, df_2)
df_combined['rank'] <- rank(df_combined$x)
df_combined |> arrange(rank) |> head()
```

```{r}
#| label: null-sums
df_combined |> group_by(team) |> summarize(ranksum = sum(rank)) |> mutate(proportion = ranksum / totalRankSum)
```

:::

## Simulating Many Null-Hypothesis Worlds {.smaller}

* And we can repeat this process (say) 10K times:

::: {layout="[1,2]"}

```{r}
#| label: many-null-sums
simulate_ranksums <- function(N1, N2) {
  N <- N1 + N2
  totalRankSum <- (N * (N+1)) / 2
  s_1 <- runif(N1)
  df_1 <- tibble(x = s_1, team = "A")
  s_2 <- runif(N2)
  df_2 <- tibble(x = s_2, team = "B")
  df_combined <- bind_rows(df_1, df_2)
  df_combined['rank'] <- rank(df_combined$x)
  ranksum_df <- df_combined |> group_by(team) |> summarize(ranksum = sum(rank))
  return(ranksum_df$ranksum)
}
num_sims <- 1000
results <- replicate(num_sims, simulate_ranksums(11,11))
t(results[,0:10])
rowMeans(results)
```

```{r}
#| label: ranksum-sim-plot
ranksum_A <- tibble(ranksum=results[1,], team="A")
ranksum_A_mean <- mean(ranksum_A$ranksum)
ranksum_B <- tibble(ranksum=results[2,], team="B")
ranksum_B_mean <- mean(ranksum_B$ranksum)
mean_df <- tibble(mean_value = c(ranksum_A_mean, ranksum_B_mean), team=c("A","B"))
sim_df <- bind_rows(ranksum_A, ranksum_B)
ggplot(sim_df, aes(x=ranksum, fill=team)) +
  geom_density(linewidth = g_linewidth, alpha=0.2) +
  geom_vline(
    data=mean_df,
    aes(xintercept = mean_value),
    linewidth = g_linewidth
  ) +
  dsan_theme("half") +
  scale_fill_manual(values=c(cbPalette[1], cbPalette[2]))
```

:::

## R Time {.crunch-title .crunch-code .crunch-ul}

```{r}
#| label: mann-whitney
#| code-fold: show
wilcox.test(height ~ Team, data=players, exact = TRUE)
```

* We confirm our computed test statistic of **46.5**, and obtain a p-value of about **0.37**
* Thus, under most confidence levels (like my favorite $\alpha = 0.11$), we **fail to reject** the null hypothesis $\mathcal{H}_0$
* Putting on our Bayes hats, we do **not** increase our degree of belief that height **differs** between the two populations.
