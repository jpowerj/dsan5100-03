[
  {
    "objectID": "w14/slides.html#how-is-non-parametric-different-from-what-weve-been-doing",
    "href": "w14/slides.html#how-is-non-parametric-different-from-what-weve-been-doing",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "How is Non-Parametric Different from What We‚Äôve Been Doing?",
    "text": "How is Non-Parametric Different from What We‚Äôve Been Doing?\n\nStatistical models and hypothesis tests we‚Äôve learned thus far were parametric\nMeaning: Assume population follows this distribution, then estimate population parameters (e.g., \\(\\param{\\mu}\\) and \\(\\param{\\sigma}\\)) using MLE, GMM, etc."
  },
  {
    "objectID": "w14/slides.html#what-makes-it-non-parametric",
    "href": "w14/slides.html#what-makes-it-non-parametric",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "What Makes It ‚ÄúNon-Parametric‚Äù?",
    "text": "What Makes It ‚ÄúNon-Parametric‚Äù?\n\nWe‚Äôve talked about how the Normal distribution is ‚Äústandard‚Äù in multiple senses:\n\nEmpirically: It arises from common processes in nature, like random walks\nTheoretically: It is the maximum-entropy distribution which encodes only1 knowledge of a mean \\(\\mu\\) and a variance \\(\\sigma^2\\)\n\nThen we talked about estimating these parameters (\\(\\param{\\mu}\\) and \\(\\param{\\sigma^2}\\)) from data: different ways to amalgamate information from an observed sample \\(\\mathbf{X} = (X_1, \\ldots, X_n)\\) to estimate (unobserved) \\(\\param{\\mu}\\) and \\(\\param{\\sigma}^2\\) with minimal bias and variance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe therefore ‚Äúfunnel‚Äù all of the information contained in \\(\\mathbf{X}\\) down into estimates of \\(\\param{\\mu}\\) and \\(\\param{\\sigma^2}\\)\nBut‚Ä¶ what if we‚Äôre wrong? What if the DGP is not based on a Normal distribution?\n\n\n\n\nRecall that any other distribution implicitly encodes additional assumptions: bounded range, nonnegative, etc."
  },
  {
    "objectID": "w14/slides.html#what-if-were-wrong",
    "href": "w14/slides.html#what-if-were-wrong",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "What If We‚Äôre Wrong?",
    "text": "What If We‚Äôre Wrong?\n\nIt is this concern: the fact that all of our results, all of our confidence about our estimates thus far, come as a result of making distributional assumptions\nNon-parametric analysis tries to avoid this potential catastrophe by making as few distributional assumptions as possible\nRecall how parameters of a distribution determine all information you could possibly want to know about the distribution (via Moment Generating Function):\n\n\n\n\n\n\n\n\n\n\n\nType of Distribution\n+\nParameter Values\n=\nAll Possible Info (MGF)\n\n\n\n\nNormal \\(~\\mathcal{N}(\\param{\\mu}, \\param{\\sigma^2})\\)\n+\n\\(\\param{\\mu} = m\\), \\(\\param{\\sigma^2} = s^2\\)\n=\n\\(M_t(X) = \\exp[mt + s^2t^2/2]\\)\n\n\nUniform \\(~\\mathcal{U}(\\param{\\alpha},\\param{\\beta})\\)\n+\n\\(\\param{\\alpha} = a\\), \\(\\param{\\beta} = b\\)\n=\n\\(M_t(X) = \\frac{e^{tb} - e^{ta}}{t(b-a)}\\)\n\n\nPoisson \\(~\\text{Pois}(\\param{\\lambda})\\)\n+\n\\(\\param{\\lambda} = \\ell\\)\n=\n\\(M_t(X) = \\exp[\\ell(e^t - 1)]\\)"
  },
  {
    "objectID": "w14/slides.html#sign-test-intuition",
    "href": "w14/slides.html#sign-test-intuition",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Sign Test Intuition",
    "text": "Sign Test Intuition\n\nInstead of trying to estimate all possible info about the underlying distribution, we only estimate one piece of information that we need to test a hypothesis\nExample: for populations \\(\\chi\\), \\(\\psi\\), if \\(H_A: \\mu_\\chi &gt; \\mu_\\psi\\), skip intermediate step of estimating distributions \\(\\mathcal{D}_\\chi(\\param{\\theta})\\), \\(\\mathcal{D}_\\psi(\\param{\\theta})\\) from samples \\(\\mathbf{X}\\), \\(\\mathbf{Y}\\)!\nInstead, just directly ‚Äúextract‚Äù greater than vs.¬†not greater than info from \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) (median \\(m\\) always exists as ‚Äúpivot‚Äù for well-behaved \\(X\\), \\(\\Pr(X &gt; m) = 0.5\\))\nIt will help us to define \\(\\text{Sign}(x) = \\begin{cases}\\phantom{-}1 &\\text{if } x &gt; 0 \\\\ \\phantom{-}0 &\\text{if }x = 0 \\\\ -1 &\\text{if }x &lt; 0\\end{cases}\\)\nIf \\(\\mathbf{X} = (15, 7, 11, 3)\\), \\(\\mathbf{Y} = (-3, 4, 1, 4)\\), we can compute a ‚Äúgreater-than score‚Äù:\n\n\\[\n\\begin{align*}\n\\sum_{i=1}^N \\sign(X_i - Y_i) &= \\sign(15 - (-3)) + \\sign(7-4) + \\sign(11-1) + \\sign(3-4) \\\\\n&= 1 + 1 + 1 + -1 = 2\n\\end{align*}\n\\]\n\nSo long as slots are comparable (notice \\(\\mathbf{X}, \\mathbf{Y}\\) are ordered), we can compare this with \\(0\\), our expectation if \\(\\chi = \\psi\\), regardless of underlying distributions \\(\\mathcal{D}_\\chi, \\mathcal{D}_\\psi\\)."
  },
  {
    "objectID": "w14/slides.html#procedure-in-general",
    "href": "w14/slides.html#procedure-in-general",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Procedure in General",
    "text": "Procedure in General\n\n\\(\\mathbf{X}\\): size-\\(N\\) sample from population \\(\\chi\\); \\(\\mathbf{Y}\\): size-\\(N\\) sample from population \\(\\psi\\)\n(Rather than estimating \\(\\mathcal{D}_\\chi\\) from \\(\\mathbf{X}\\) and \\(\\mathcal{D}_\\psi\\) from \\(\\mathbf{Y}\\)), we directly pair datapoints \\(X_i \\in \\mathbf{X}\\) and \\(Y_i \\in \\mathbf{Y}\\) and compute the sign of their difference:\n\n\\[\n\\text{GT}_i(X_i, Y_i) = \\text{Sign}(X_{i} - Y_{i}) = \\begin{cases}\n\\phantom{-}1 &\\text{if }X_{i} &gt; Y_{i}, \\\\\n\\phantom{-}0 &\\text{if }X_{i} = Y_{i}, \\\\\n-1 &\\text{if }X_{i} &lt; Y_{i}\n\\end{cases}\n\\]\n\nWe can then sum each pair‚Äôs score into an aggregate score:\n\\[\n  \\text{GT}(\\mathbf{X}, \\mathbf{Y}) = \\sum_{i=1}^NGT_i(X_i,Y_i)\n  \\]\nsuch that if \\(\\chi\\) and \\(\\psi\\) are in fact the same population, we expect \\(GT(\\mathbf{X}, \\mathbf{Y}) = 0\\) (positive and negative values of \\(GT_i\\) cancel each other out, for sufficiently large \\(N\\))\nNon-parametric tests which use this value as a test statistic are called Sign tests"
  },
  {
    "objectID": "w14/slides.html#what-if-we-cant-pair-observations-one-to-one",
    "href": "w14/slides.html#what-if-we-cant-pair-observations-one-to-one",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "What If We Can‚Äôt Pair Observations One-to-One?",
    "text": "What If We Can‚Äôt Pair Observations One-to-One?\n\nFor example, what if samples aren‚Äôt the same size: \\(N_X = |\\mathbf{X}| \\neq N_Y = |\\mathbf{Y}|\\)?\nIntuition: If there is no ‚Äúnatural‚Äù one-to-one pairing of the observations, we can instead consider all possible pairs \\((X_{i}, Y_{j}) \\in \\mathbf{X} \\times \\mathbf{Y}\\)\nWe can then count how often \\(X_i &gt; Y_j\\), how often \\(Y_j &gt; X_i\\), and compare this to our expectation of how often these would occur if \\(\\chi = \\psi\\) (that is, if \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) were in fact drawn from the same population)"
  },
  {
    "objectID": "w14/slides.html#computational-efficiency",
    "href": "w14/slides.html#computational-efficiency",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Computational Efficiency",
    "text": "Computational Efficiency\n\nWe could just go ahead with this intuition, checking every pair and seeing how often \\(X_i &gt; Y_j\\) vs.¬†how often \\(Y_j &gt; X_i\\), but this is computationally expensive for large samples (requiring \\(O(N_1N_2)\\) comparisons)\nSo, let‚Äôs walk through an example with pairwise comparisons, but try to think of an equivalent yet sub-quadratic method for achieving the same results!"
  },
  {
    "objectID": "w14/slides.html#pairwise-comparison-mode",
    "href": "w14/slides.html#pairwise-comparison-mode",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Pairwise Comparison Mode",
    "text": "Pairwise Comparison Mode\n\nLet \\(\\mathbf{X} = \\{5, 9, 7\\}, \\mathbf{Y} = \\{7, 6\\}\\), and consider \\(X_i &gt; Y_j\\) vs.¬†\\(Y_j &gt; X_i\\) for all pairs:\nGive 1 point to \\(\\mathbf{X}\\) if \\(X_i &gt; Y_j\\), 1 point to \\(\\mathbf{Y}\\) if \\(Y_j &gt; X_i\\), 0.5 points to both if \\(X_i = Y_j\\).\n\n\n\n\n\n\n\n\n\n\n\n\\(X_i\\)\n\\(Y_j\\)\n\\(&gt;\\)\n\\(=\\)\n\\(&lt;\\)\n\n\n\n\n5\n7\n\n\n+1\n\n\n5\n6\n\n\n+1\n\n\n9\n7\n+1\n\n\n\n\n9\n6\n+1\n\n\n\n\n7\n7\n\n+0.5\n\n\n\n7\n6\n+1\n\n\n\n\nFinal\nScore:\n\\(S_{\\mathbf{X}} = 3.5\\)\n\n\\(S_{\\mathbf{Y}} = 2.5\\)"
  },
  {
    "objectID": "w14/slides.html#ranking-mode",
    "href": "w14/slides.html#ranking-mode",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Ranking Mode",
    "text": "Ranking Mode\n\nNow consider the combined dataset \\(\\mathbf{Z} = \\mathbf{X} \\oplus \\mathbf{Y} = (5_X, 9_X, 7_X, 7_Y, 6_Y)\\)\nLet‚Äôs see what we get when we rank the values in \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) separately, then rank the same values within \\(\\mathbf{Z}\\), keeping track of whether each number is from \\(\\mathbf{X}\\) or \\(\\mathbf{Y}\\):\n\n\n\n\n\n\n\n\n\n\n\n\n\nValues\n\\(5_X\\)\n\\(6_Y\\)\n\\(7_X\\)\n\\(7_Y\\)\n\\(9_X\\)\n\n\n\nRank in \\(\\mathbf{X}\\)\n\\([1]_{X/\\mathbf{X}}\\)\n\n\\([2]_{X/\\mathbf{X}}\\)\n\n\\([3]_{X/\\mathbf{X}}\\)\n\\(\\Sigma_{X/\\mathbf{X}} = [6]\\)\n\n\nRank in \\(\\mathbf{Y}\\)\n\n\\([1]_{Y/\\mathbf{Y}}\\)\n\n\\([2]_{Y/\\mathbf{Y}}\\)\n\n\\(\\Sigma_{Y/\\mathbf{Y}} = [3]\\)\n\n\nRank in \\(\\mathbf{Z}\\)\n\\([1]_{X/\\mathbf{Z}}\\)\n¬†\\([2]_{Y/\\mathbf{Z}}\\)\n\\([3.5]_{X/\\mathbf{Z}}\\)\n¬†\\([3.5]_{Y/\\mathbf{Z}}\\)\n\\([5]_{X/\\mathbf{Z}}\\)\n\\(\\Sigma_{X/\\mathbf{Z}} = [9.5]\\)\\(\\Sigma_{Y/\\mathbf{Z}} = [5.5]\\)\n\n\n\n\nThus, by subtracting single-sample ranks from combined-sample ranks, we obtain:\n\\(S_{\\mathbf{X}} = \\Sigma_{X/\\mathbf{Z}} - \\Sigma_{X/\\mathbf{X}} = 9.5 - 6 = 3.5\\)\n\\(S_{\\mathbf{Y}} = \\Sigma_{Y/\\mathbf{Z}} - \\Sigma_{Y/\\mathbf{Y}} = 5.5 - 3 = 2.5\\) ü§Ø\nAnd yet, this runs in \\(O((N_1+N_2)\\log(N_1+N_2)) &lt; O(N_1N_2)\\)"
  },
  {
    "objectID": "w14/slides.html#example-2022-world-cup",
    "href": "w14/slides.html#example-2022-world-cup",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Example: 2022 World Cup",
    "text": "Example: 2022 World Cup\n\nHeights (inches) of Welsh vs.¬†US national football teams (\\(N = 22\\) players total):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWales\n78\n71\n76\n75\n72\n70\n68\n72\n69\n73\n67\n\\(\\overline{X} \\approx 71.91\\)\n\n\nUSA\n75\n68\n75\n69\n70\n70\n72\n67\n72\n72\n70\n\\(\\overline{Y} \\approx 70.73\\)\n\n\n\n\n\nCode\nlibrary(tidyverse)\n# Manual (via tibble)\n# us_heights &lt;- tibble(height=c(75, 68, 74, 68, 68, 70, 72, 67, 72, 72, 70))\n# corrected\nus_heights &lt;- tibble(height=c(75, 68, 75, 69, 70, 70, 72, 67, 72, 72, 68))\nmean_us &lt;- mean(us_heights$height)\nus_heights &lt;- us_heights |&gt; mutate(Team = \"US\")\nwales_heights &lt;- tibble(height=c(78, 71, 76, 75, 72, 70, 68, 72, 69, 73, 67))\nmean_wales &lt;- mean(wales_heights$height)\n# From csv\n# https://www.fifa.com/en/match-centre/match/17/255711/285063/400235455\nteam_df &lt;- read_csv(\"assets/wc_usa_wales.csv\")\n# team_df |&gt; group_by(team) |&gt; summarize(height_mean = mean(height_in))\nmean_df &lt;- tibble(mean_height = c(mean_us, mean_wales), Team = c(\"US\", \"Wales\"))\nwales_heights &lt;- wales_heights |&gt; mutate(Team = \"Wales\")\nplayers = bind_rows(us_heights, wales_heights)\nggplot(players, aes(x=height, fill=Team)) +\n  geom_density(\n    alpha=0.3, adjust=4/5\n  ) +\n  geom_vline(\n    data=mean_df,\n    aes(xintercept=mean_height, color=Team),\n    linetype = \"dashed\",\n    linewidth = g_linewidth\n  ) +\n  xlim(c(65,80)) +\n  dsan_theme(\"half\") +\n  scale_fill_manual(values=c(cbPalette[1], cbPalette[2])) +\n  labs(\n    title = \"Empirical Distribution of Team Heights\",\n    x = \"Height (inches)\",\n    y = \"Empirical Density\"\n  )"
  },
  {
    "objectID": "w14/slides.html#samples-rightarrow-populations",
    "href": "w14/slides.html#samples-rightarrow-populations",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Samples \\(\\rightarrow\\) Populations",
    "text": "Samples \\(\\rightarrow\\) Populations\n\nWe know that the sampled heights of Welsh football players (\\(\\mathbf{X}\\)) are (on average) greater than the sampled heights of US football players (\\(\\mathbf{Y}\\)).\nBut are heights in fact greater among the population of Welsh football players (\\(\\chi\\)), relative to the population of US football players (\\(\\psi\\))?"
  },
  {
    "objectID": "w14/slides.html#the-non-parametric-fork-in-the-road",
    "href": "w14/slides.html#the-non-parametric-fork-in-the-road",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "The Non-Parametric Fork in the Road",
    "text": "The Non-Parametric Fork in the Road\n\nRecall: in parametric tests, when comparing means, we analyzed the difference in the sample means relative to their variability and summarized the sample information in a test statistic: for example, \\(t = \\frac{\\overline{X} - \\mu_H}{\\widehat{\\sigma} / \\sqrt{N}}\\)\nWe could compute this test statistic, but it would implicitly depend on an assumption of the underlying DGP: that heights follow a Normal distribution.\nHere, instead, we produce a test statistic based on the ranks!\nTest statistics should measure how surprised we would be if we observed what we observed in a world where the null hypothesis is true\nEquivalently, it should be low if the observed difference could feasibly have occurred just due to random noise (i.e., if we‚Äôre looking at noisy data from world where null hypothesis is true)\nSo, let‚Äôs think in these terms about the ranks of each datapoint, to develop a non-parametric test statistic based on the ranks"
  },
  {
    "objectID": "w14/slides.html#choosing-non-parametric-hypotheses",
    "href": "w14/slides.html#choosing-non-parametric-hypotheses",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Choosing Non-Parametric Hypotheses",
    "text": "Choosing Non-Parametric Hypotheses\n\nThe empirical distributions from the previous slide, and the small sample size (\\(N_1 = N_2 = 11\\)), motivate our use of a nonparametric test!\nAssuming \\(X \\sim \\mathcal{D}_1\\) and \\(Y \\sim \\mathcal{D}_2\\) (but not assuming the parametric forms of \\(\\mathcal{D}_1\\) or \\(\\mathcal{D}_2\\)!), we can test:\n\\(H_0: \\Pr(X &gt; Y) = \\Pr(Y &gt; X)\\)\n\\(H_1: \\Pr(X &gt; Y) \\neq \\Pr(Y &gt; X)\\)"
  },
  {
    "objectID": "w14/slides.html#sorting-and-ranking-observations",
    "href": "w14/slides.html#sorting-and-ranking-observations",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Sorting and Ranking Observations",
    "text": "Sorting and Ranking Observations\n\n\n\nOriginal Data\nSorted Total Samples\nRank\n\n\nUSA\nWales\nUSA\nWales\nUSA\nWales\n\n\n\n\n75\n78\n67\n67\n1.5\n1.5\n\n\n68\n71\n68\n68\n4\n4\n\n\n75\n76\n68\n4\n\n\n69\n75\n69\n69\n6.5\n6.5\n\n\n70\n72\n70\n70\n9\n9\n\n\n70\n70\n70\n9\n\n\n72\n68\n\n71\n\n11\n\n\n67\n72\n72\n72\n14\n14\n\n\n\n\n72\n69\n72\n14\n\n\n72\n14\n\n\n72\n73\n72\n14\n\n\n\n\n68\n67\n\n73\n\n17\n\n\n\n\n75\n75\n19\n19\n\n\n\n\n75\n19\n\n\n\n\n\n76\n\n21\n\n\n\n\n\n78\n\n22"
  },
  {
    "objectID": "w14/slides.html#our-rank-based-test-statistic",
    "href": "w14/slides.html#our-rank-based-test-statistic",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Our Rank-Based Test Statistic",
    "text": "Our Rank-Based Test Statistic\n\nSums of ranks relative to the combined dataset: \\(\\Sigma_{X/\\mathbf{Z}} = 112.5\\), \\(\\Sigma_{Y/\\mathbf{Z}} = 140.5\\).\nAnd then sum the ranks in each group, relative to the same group‚Ä¶ In general, if we have \\(N\\) ranked datapoints (so, datapoints given labels \\(\\{1, 2, \\ldots, N\\}\\)), what will the sum of these individual ranks be?\n\n\\[\n\\sum_{i=1}^{N}i = \\underbrace{\\overbrace{(1 + N)}^{N + 1} + \\overbrace{(2 + (N-1))}^{N + 1} + \\cdots}_{N/2\\text{ terms}} = \\frac{N(N+1)}{2}\n\\]\n\nSo, in this case,\n\n\\[\n\\Sigma_{X/\\mathbf{X}} = \\Sigma_{Y/\\mathbf{Y}} = \\sum_{i=1}^{11}i = \\frac{11(12)}{2} = 66\n\\]\n\nGiving us the test statistics\n\n\\[\n\\begin{align*}\nU_X &= 112.5 - 66 = 46.5, \\; U_Y = 140.5 - 66 = 74.5 \\\\\nU &= \\min\\{U_X, U_Y\\} = \\min\\{46.5, 74.5\\} = 46.5\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w14/slides.html#simulating-one-null-hypothesis-world",
    "href": "w14/slides.html#simulating-one-null-hypothesis-world",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Simulating (One) Null-Hypothesis World",
    "text": "Simulating (One) Null-Hypothesis World\nOne simulation:\n\n\n\n\nCode\nset.seed(5100)\nlibrary(tidyverse)\nN1 &lt;- 11\nN2 &lt;- 11\nN &lt;- N1 + N2\ntotalRankSum &lt;- (N * (N+1)) / 2\ns_1 &lt;- runif(N1)\ndf_1 &lt;- tibble(x = s_1, team = \"A\")\ns_2 &lt;- runif(N2)\ndf_2 &lt;- tibble(x = s_2, team = \"B\")\ndf_combined &lt;- bind_rows(df_1, df_2)\ndf_combined['rank'] &lt;- rank(df_combined$x)\nwriteLines(paste0(\"N1 = \",N1,\", N2 = \",N2,\" =&gt; Sum(1...(N1+N2)) = \",totalRankSum))\n\n\nN1 = 11, N2 = 11 =&gt; Sum(1...(N1+N2)) = 253\n\n\nCode\ndf_combined |&gt; arrange(rank) |&gt; head()\n\n\n\n\n\n\nx\nteam\nrank\n\n\n\n\n0.0281644\nB\n1\n\n\n0.0282184\nA\n2\n\n\n0.0730575\nB\n3\n\n\n0.1343398\nB\n4\n\n\n0.1351495\nB\n5\n\n\n0.1858087\nA\n6\n\n\n\n\n\n\n\n\n¬†\n\n‚Üí\n\n\n\nCode\ndf_combined |&gt; group_by(team) |&gt; summarize(ranksum = sum(rank)) |&gt; mutate(proportion = ranksum / totalRankSum)\n\n\n\n\n\n\nteam\nranksum\nproportion\n\n\n\n\nA\n144\n0.56917\n\n\nB\n109\n0.43083"
  },
  {
    "objectID": "w14/slides.html#simulating-many-null-hypothesis-worlds",
    "href": "w14/slides.html#simulating-many-null-hypothesis-worlds",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Simulating Many Null-Hypothesis Worlds",
    "text": "Simulating Many Null-Hypothesis Worlds\nAnd we can repeat this process (say) 10K times:\n\n\n\n\nCode\nsimulate_ranksums &lt;- function(N1, N2) {\n  N &lt;- N1 + N2\n  totalRankSum &lt;- (N * (N+1)) / 2\n  s_1 &lt;- runif(N1)\n  df_1 &lt;- tibble(x = s_1, team = \"A\")\n  s_2 &lt;- runif(N2)\n  df_2 &lt;- tibble(x = s_2, team = \"B\")\n  df_combined &lt;- bind_rows(df_1, df_2)\n  df_combined['rank'] &lt;- rank(df_combined$x)\n  ranksum_df &lt;- df_combined |&gt; group_by(team) |&gt; summarize(ranksum = sum(rank))\n  return(ranksum_df$ranksum)\n}\nnum_sims &lt;- 1000\nresults &lt;- replicate(num_sims, simulate_ranksums(11,11))\nt(results[,0:10])\n\n\n      [,1] [,2]\n [1,]  133  120\n [2,]   98  155\n [3,]  115  138\n [4,]  166   87\n [5,]  137  116\n [6,]  140  113\n [7,]  146  107\n [8,]  157   96\n [9,]  119  134\n[10,]  106  147\n\n\nCode\nrowMeans(results)\n\n\n[1] 126.407 126.593\n\n\n\n\n\nCode\n# Separate ranksums\nranksum_A &lt;- tibble(ranksum=results[1,], team=\"A\")\nranksum_A_mean &lt;- mean(ranksum_A$ranksum)\nranksum_B &lt;- tibble(ranksum=results[2,], team=\"B\")\nranksum_B_mean &lt;- mean(ranksum_B$ranksum)\nsim_df &lt;- bind_rows(ranksum_A, ranksum_B)\n# Means\nmean_df &lt;- tibble(mean_value = c(ranksum_A_mean, ranksum_B_mean), team=c(\"A\",\"B\"))\nmean_center &lt;- (ranksum_A_mean + ranksum_B_mean) / 2\ngen_ranksum_plot &lt;- function(radius=Inf) {\n  ranksum_plot &lt;- ggplot(sim_df, aes(x=ranksum, fill=team)) +\n    geom_density(linewidth = g_linewidth, alpha=0.333) +\n    geom_vline(\n        data=mean_df,\n        aes(xintercept = mean_value, color=team),\n        linewidth = g_linewidth\n    ) +\n    theme_classic(base_size=14) +\n    scale_fill_manual(values=c(cbPalette[1], cbPalette[2]))\n    if (radius != Inf) {\n        ranksum_plot &lt;- ranksum_plot +\n        xlim(mean_center - radius, mean_center + radius)\n    }\n    return(ranksum_plot)\n}\ngen_ranksum_plot()\n\n\n\n\n\n\n\n\n\n\n\nCode\ngen_ranksum_plot(radius=8)"
  },
  {
    "objectID": "w14/slides.html#wilcox.test-in-r",
    "href": "w14/slides.html#wilcox.test-in-r",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "wilcox.test in R",
    "text": "wilcox.test in R\n\n\nCode\nwilcox.test(height ~ Team, data=players, exact = TRUE)\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  height by Team\nW = 48, p-value = 0.4262\nalternative hypothesis: true location shift is not equal to 0\n\n\n\nWe confirm our computed test statistic of 46.5, and obtain a p-value of about 0.37\nThus, under most confidence levels (like my favorite \\(\\alpha = 0.11\\)), we fail to reject the null hypothesis \\(\\mathcal{H}_0\\)\nPutting on our Bayes hats, we do not increase our degree of belief that height differs between the two populations."
  },
  {
    "objectID": "w14/slides.html#procedure",
    "href": "w14/slides.html#procedure",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Procedure",
    "text": "Procedure\n\nPool observations from \\(k\\) samples into one combined sample, keeping track of which sample each observation comes from, then rank lowest to highest.\nTest statistic:\n\n\\[\nH = \\frac{12}{N(N+1)}\\sum_{j=1}^{k}\\frac{R_j^2}{n_j} - 3(N+1)\n\\]\n\nReject \\(\\mathcal{H}_0\\) if \\(H \\geq \\text{critical val}\\)"
  },
  {
    "objectID": "w14/slides.html#kruskal.test-in-r",
    "href": "w14/slides.html#kruskal.test-in-r",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "kruskal.test in R",
    "text": "kruskal.test in R\n\n\nCode\n# kruskal.test(height ~ position, data=players)\n\n\n\n\n\nDSAN 5100-03 W14: Non-Parametric Statistics"
  },
  {
    "objectID": "w14/index.html",
    "href": "w14/index.html",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "",
    "text": "Open slides in new window ‚Üí"
  },
  {
    "objectID": "w14/index.html#how-is-non-parametric-different-from-what-weve-been-doing",
    "href": "w14/index.html#how-is-non-parametric-different-from-what-weve-been-doing",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "How is Non-Parametric Different from What We‚Äôve Been Doing?",
    "text": "How is Non-Parametric Different from What We‚Äôve Been Doing?\n\nStatistical models and hypothesis tests we‚Äôve learned thus far were parametric\nMeaning: Assume population follows this distribution, then estimate population parameters (e.g., \\(\\param{\\mu}\\) and \\(\\param{\\sigma}\\)) using MLE, GMM, etc."
  },
  {
    "objectID": "w14/index.html#what-makes-it-non-parametric",
    "href": "w14/index.html#what-makes-it-non-parametric",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "What Makes It ‚ÄúNon-Parametric‚Äù?",
    "text": "What Makes It ‚ÄúNon-Parametric‚Äù?\n\nWe‚Äôve talked about how the Normal distribution is ‚Äústandard‚Äù in multiple senses:\n\nEmpirically: It arises from common processes in nature, like random walks\nTheoretically: It is the maximum-entropy distribution which encodes only1 knowledge of a mean \\(\\mu\\) and a variance \\(\\sigma^2\\)\n\nThen we talked about estimating these parameters (\\(\\param{\\mu}\\) and \\(\\param{\\sigma^2}\\)) from data: different ways to amalgamate information from an observed sample \\(\\mathbf{X} = (X_1, \\ldots, X_n)\\) to estimate (unobserved) \\(\\param{\\mu}\\) and \\(\\param{\\sigma}^2\\) with minimal bias and variance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe therefore ‚Äúfunnel‚Äù all of the information contained in \\(\\mathbf{X}\\) down into estimates of \\(\\param{\\mu}\\) and \\(\\param{\\sigma^2}\\)\nBut‚Ä¶ what if we‚Äôre wrong? What if the DGP is not based on a Normal distribution?"
  },
  {
    "objectID": "w14/index.html#what-if-were-wrong",
    "href": "w14/index.html#what-if-were-wrong",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "What If We‚Äôre Wrong?",
    "text": "What If We‚Äôre Wrong?\n\nIt is this concern: the fact that all of our results, all of our confidence about our estimates thus far, come as a result of making distributional assumptions\nNon-parametric analysis tries to avoid this potential catastrophe by making as few distributional assumptions as possible\nRecall how parameters of a distribution determine all information you could possibly want to know about the distribution (via Moment Generating Function):\n\n\n\n\n\n\n\n\n\n\n\nType of Distribution\n+\nParameter Values\n=\nAll Possible Info (MGF)\n\n\n\n\nNormal \\(~\\mathcal{N}(\\param{\\mu}, \\param{\\sigma^2})\\)\n+\n\\(\\param{\\mu} = m\\), \\(\\param{\\sigma^2} = s^2\\)\n=\n\\(M_t(X) = \\exp[mt + s^2t^2/2]\\)\n\n\nUniform \\(~\\mathcal{U}(\\param{\\alpha},\\param{\\beta})\\)\n+\n\\(\\param{\\alpha} = a\\), \\(\\param{\\beta} = b\\)\n=\n\\(M_t(X) = \\frac{e^{tb} - e^{ta}}{t(b-a)}\\)\n\n\nPoisson \\(~\\text{Pois}(\\param{\\lambda})\\)\n+\n\\(\\param{\\lambda} = \\ell\\)\n=\n\\(M_t(X) = \\exp[\\ell(e^t - 1)]\\)"
  },
  {
    "objectID": "w14/index.html#sign-test-intuition",
    "href": "w14/index.html#sign-test-intuition",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Sign Test Intuition",
    "text": "Sign Test Intuition\n\nInstead of trying to estimate all possible info about the underlying distribution, we only estimate one piece of information that we need to test a hypothesis\nExample: for populations \\(\\chi\\), \\(\\psi\\), if \\(H_A: \\mu_\\chi &gt; \\mu_\\psi\\), skip intermediate step of estimating distributions \\(\\mathcal{D}_\\chi(\\param{\\theta})\\), \\(\\mathcal{D}_\\psi(\\param{\\theta})\\) from samples \\(\\mathbf{X}\\), \\(\\mathbf{Y}\\)!\nInstead, just directly ‚Äúextract‚Äù greater than vs.¬†not greater than info from \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) (median \\(m\\) always exists as ‚Äúpivot‚Äù for well-behaved \\(X\\), \\(\\Pr(X &gt; m) = 0.5\\))\nIt will help us to define \\(\\text{Sign}(x) = \\begin{cases}\\phantom{-}1 &\\text{if } x &gt; 0 \\\\ \\phantom{-}0 &\\text{if }x = 0 \\\\ -1 &\\text{if }x &lt; 0\\end{cases}\\)\nIf \\(\\mathbf{X} = (15, 7, 11, 3)\\), \\(\\mathbf{Y} = (-3, 4, 1, 4)\\), we can compute a ‚Äúgreater-than score‚Äù:\n\n\\[\n\\begin{align*}\n\\sum_{i=1}^N \\sign(X_i - Y_i) &= \\sign(15 - (-3)) + \\sign(7-4) + \\sign(11-1) + \\sign(3-4) \\\\\n&= 1 + 1 + 1 + -1 = 2\n\\end{align*}\n\\]\n\nSo long as slots are comparable (notice \\(\\mathbf{X}, \\mathbf{Y}\\) are ordered), we can compare this with \\(0\\), our expectation if \\(\\chi = \\psi\\), regardless of underlying distributions \\(\\mathcal{D}_\\chi, \\mathcal{D}_\\psi\\)."
  },
  {
    "objectID": "w14/index.html#procedure-in-general",
    "href": "w14/index.html#procedure-in-general",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Procedure in General",
    "text": "Procedure in General\n\n\\(\\mathbf{X}\\): size-\\(N\\) sample from population \\(\\chi\\); \\(\\mathbf{Y}\\): size-\\(N\\) sample from population \\(\\psi\\)\n(Rather than estimating \\(\\mathcal{D}_\\chi\\) from \\(\\mathbf{X}\\) and \\(\\mathcal{D}_\\psi\\) from \\(\\mathbf{Y}\\)), we directly pair datapoints \\(X_i \\in \\mathbf{X}\\) and \\(Y_i \\in \\mathbf{Y}\\) and compute the sign of their difference:\n\n\\[\n\\text{GT}_i(X_i, Y_i) = \\text{Sign}(X_{i} - Y_{i}) = \\begin{cases}\n\\phantom{-}1 &\\text{if }X_{i} &gt; Y_{i}, \\\\\n\\phantom{-}0 &\\text{if }X_{i} = Y_{i}, \\\\\n-1 &\\text{if }X_{i} &lt; Y_{i}\n\\end{cases}\n\\]\n\nWe can then sum each pair‚Äôs score into an aggregate score:\n\\[\n  \\text{GT}(\\mathbf{X}, \\mathbf{Y}) = \\sum_{i=1}^NGT_i(X_i,Y_i)\n  \\]\nsuch that if \\(\\chi\\) and \\(\\psi\\) are in fact the same population, we expect \\(GT(\\mathbf{X}, \\mathbf{Y}) = 0\\) (positive and negative values of \\(GT_i\\) cancel each other out, for sufficiently large \\(N\\))\nNon-parametric tests which use this value as a test statistic are called Sign tests"
  },
  {
    "objectID": "w14/index.html#what-if-we-cant-pair-observations-one-to-one",
    "href": "w14/index.html#what-if-we-cant-pair-observations-one-to-one",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "What If We Can‚Äôt Pair Observations One-to-One?",
    "text": "What If We Can‚Äôt Pair Observations One-to-One?\n\nFor example, what if samples aren‚Äôt the same size: \\(N_X = |\\mathbf{X}| \\neq N_Y = |\\mathbf{Y}|\\)?\nIntuition: If there is no ‚Äúnatural‚Äù one-to-one pairing of the observations, we can instead consider all possible pairs \\((X_{i}, Y_{j}) \\in \\mathbf{X} \\times \\mathbf{Y}\\)\nWe can then count how often \\(X_i &gt; Y_j\\), how often \\(Y_j &gt; X_i\\), and compare this to our expectation of how often these would occur if \\(\\chi = \\psi\\) (that is, if \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) were in fact drawn from the same population)"
  },
  {
    "objectID": "w14/index.html#computational-efficiency",
    "href": "w14/index.html#computational-efficiency",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Computational Efficiency",
    "text": "Computational Efficiency\n\nWe could just go ahead with this intuition, checking every pair and seeing how often \\(X_i &gt; Y_j\\) vs.¬†how often \\(Y_j &gt; X_i\\), but this is computationally expensive for large samples (requiring \\(O(N_1N_2)\\) comparisons)\nSo, let‚Äôs walk through an example with pairwise comparisons, but try to think of an equivalent yet sub-quadratic method for achieving the same results!"
  },
  {
    "objectID": "w14/index.html#pairwise-comparison-mode",
    "href": "w14/index.html#pairwise-comparison-mode",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Pairwise Comparison Mode",
    "text": "Pairwise Comparison Mode\n\nLet \\(\\mathbf{X} = \\{5, 9, 7\\}, \\mathbf{Y} = \\{7, 6\\}\\), and consider \\(X_i &gt; Y_j\\) vs.¬†\\(Y_j &gt; X_i\\) for all pairs:\nGive 1 point to \\(\\mathbf{X}\\) if \\(X_i &gt; Y_j\\), 1 point to \\(\\mathbf{Y}\\) if \\(Y_j &gt; X_i\\), 0.5 points to both if \\(X_i = Y_j\\).\n\n\n\n\n\n\n\n\n\n\n\n\\(X_i\\)\n\\(Y_j\\)\n\\(&gt;\\)\n\\(=\\)\n\\(&lt;\\)\n\n\n\n\n5\n7\n\n\n+1\n\n\n5\n6\n\n\n+1\n\n\n9\n7\n+1\n\n\n\n\n9\n6\n+1\n\n\n\n\n7\n7\n\n+0.5\n\n\n\n7\n6\n+1\n\n\n\n\nFinal\nScore:\n\\(S_{\\mathbf{X}} = 3.5\\)\n\n\\(S_{\\mathbf{Y}} = 2.5\\)"
  },
  {
    "objectID": "w14/index.html#ranking-mode",
    "href": "w14/index.html#ranking-mode",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Ranking Mode",
    "text": "Ranking Mode\n\nNow consider the combined dataset \\(\\mathbf{Z} = \\mathbf{X} \\oplus \\mathbf{Y} = (5_X, 9_X, 7_X, 7_Y, 6_Y)\\)\nLet‚Äôs see what we get when we rank the values in \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) separately, then rank the same values within \\(\\mathbf{Z}\\), keeping track of whether each number is from \\(\\mathbf{X}\\) or \\(\\mathbf{Y}\\):\n\n\n\n\n\n\n\n\n\n\n\n\n\nValues\n\\(5_X\\)\n\\(6_Y\\)\n\\(7_X\\)\n\\(7_Y\\)\n\\(9_X\\)\n\n\n\nRank in \\(\\mathbf{X}\\)\n\\([1]_{X/\\mathbf{X}}\\)\n\n\\([2]_{X/\\mathbf{X}}\\)\n\n\\([3]_{X/\\mathbf{X}}\\)\n\\(\\Sigma_{X/\\mathbf{X}} = [6]\\)\n\n\nRank in \\(\\mathbf{Y}\\)\n\n\\([1]_{Y/\\mathbf{Y}}\\)\n\n\\([2]_{Y/\\mathbf{Y}}\\)\n\n\\(\\Sigma_{Y/\\mathbf{Y}} = [3]\\)\n\n\nRank in \\(\\mathbf{Z}\\)\n\\([1]_{X/\\mathbf{Z}}\\)\n¬†\\([2]_{Y/\\mathbf{Z}}\\)\n\\([3.5]_{X/\\mathbf{Z}}\\)\n¬†\\([3.5]_{Y/\\mathbf{Z}}\\)\n\\([5]_{X/\\mathbf{Z}}\\)\n\\(\\Sigma_{X/\\mathbf{Z}} = [9.5]\\)\\(\\Sigma_{Y/\\mathbf{Z}} = [5.5]\\)\n\n\n\n\nThus, by subtracting single-sample ranks from combined-sample ranks, we obtain:\n\\(S_{\\mathbf{X}} = \\Sigma_{X/\\mathbf{Z}} - \\Sigma_{X/\\mathbf{X}} = 9.5 - 6 = 3.5\\)\n\\(S_{\\mathbf{Y}} = \\Sigma_{Y/\\mathbf{Z}} - \\Sigma_{Y/\\mathbf{Y}} = 5.5 - 3 = 2.5\\) ü§Ø\nAnd yet, this runs in \\(O((N_1+N_2)\\log(N_1+N_2)) &lt; O(N_1N_2)\\)"
  },
  {
    "objectID": "w14/index.html#example-2022-world-cup",
    "href": "w14/index.html#example-2022-world-cup",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Example: 2022 World Cup",
    "text": "Example: 2022 World Cup\n\nHeights (inches) of Welsh vs.¬†US national football teams (\\(N = 22\\) players total):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWales\n78\n71\n76\n75\n72\n70\n68\n72\n69\n73\n67\n\\(\\overline{X} \\approx 71.91\\)\n\n\nUSA\n75\n68\n75\n69\n70\n70\n72\n67\n72\n72\n70\n\\(\\overline{Y} \\approx 70.73\\)\n\n\n\n\n\nCode\nlibrary(tidyverse)\n# Manual (via tibble)\n# us_heights &lt;- tibble(height=c(75, 68, 74, 68, 68, 70, 72, 67, 72, 72, 70))\n# corrected\nus_heights &lt;- tibble(height=c(75, 68, 75, 69, 70, 70, 72, 67, 72, 72, 68))\nmean_us &lt;- mean(us_heights$height)\nus_heights &lt;- us_heights |&gt; mutate(Team = \"US\")\nwales_heights &lt;- tibble(height=c(78, 71, 76, 75, 72, 70, 68, 72, 69, 73, 67))\nmean_wales &lt;- mean(wales_heights$height)\n# From csv\n# https://www.fifa.com/en/match-centre/match/17/255711/285063/400235455\nteam_df &lt;- read_csv(\"assets/wc_usa_wales.csv\")\n# team_df |&gt; group_by(team) |&gt; summarize(height_mean = mean(height_in))\nmean_df &lt;- tibble(mean_height = c(mean_us, mean_wales), Team = c(\"US\", \"Wales\"))\nwales_heights &lt;- wales_heights |&gt; mutate(Team = \"Wales\")\nplayers = bind_rows(us_heights, wales_heights)\nggplot(players, aes(x=height, fill=Team)) +\n  geom_density(\n    alpha=0.3, adjust=4/5\n  ) +\n  geom_vline(\n    data=mean_df,\n    aes(xintercept=mean_height, color=Team),\n    linetype = \"dashed\",\n    linewidth = g_linewidth\n  ) +\n  xlim(c(65,80)) +\n  dsan_theme(\"half\") +\n  scale_fill_manual(values=c(cbPalette[1], cbPalette[2])) +\n  labs(\n    title = \"Empirical Distribution of Team Heights\",\n    x = \"Height (inches)\",\n    y = \"Empirical Density\"\n  )"
  },
  {
    "objectID": "w14/index.html#samples-rightarrow-populations",
    "href": "w14/index.html#samples-rightarrow-populations",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Samples \\(\\rightarrow\\) Populations",
    "text": "Samples \\(\\rightarrow\\) Populations\n\nWe know that the sampled heights of Welsh football players (\\(\\mathbf{X}\\)) are (on average) greater than the sampled heights of US football players (\\(\\mathbf{Y}\\)).\nBut are heights in fact greater among the population of Welsh football players (\\(\\chi\\)), relative to the population of US football players (\\(\\psi\\))?"
  },
  {
    "objectID": "w14/index.html#the-non-parametric-fork-in-the-road",
    "href": "w14/index.html#the-non-parametric-fork-in-the-road",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "The Non-Parametric Fork in the Road",
    "text": "The Non-Parametric Fork in the Road\n\nRecall: in parametric tests, when comparing means, we analyzed the difference in the sample means relative to their variability and summarized the sample information in a test statistic: for example, \\(t = \\frac{\\overline{X} - \\mu_H}{\\widehat{\\sigma} / \\sqrt{N}}\\)\nWe could compute this test statistic, but it would implicitly depend on an assumption of the underlying DGP: that heights follow a Normal distribution.\nHere, instead, we produce a test statistic based on the ranks!\nTest statistics should measure how surprised we would be if we observed what we observed in a world where the null hypothesis is true\nEquivalently, it should be low if the observed difference could feasibly have occurred just due to random noise (i.e., if we‚Äôre looking at noisy data from world where null hypothesis is true)\nSo, let‚Äôs think in these terms about the ranks of each datapoint, to develop a non-parametric test statistic based on the ranks"
  },
  {
    "objectID": "w14/index.html#choosing-non-parametric-hypotheses",
    "href": "w14/index.html#choosing-non-parametric-hypotheses",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Choosing Non-Parametric Hypotheses",
    "text": "Choosing Non-Parametric Hypotheses\n\nThe empirical distributions from the previous slide, and the small sample size (\\(N_1 = N_2 = 11\\)), motivate our use of a nonparametric test!\nAssuming \\(X \\sim \\mathcal{D}_1\\) and \\(Y \\sim \\mathcal{D}_2\\) (but not assuming the parametric forms of \\(\\mathcal{D}_1\\) or \\(\\mathcal{D}_2\\)!), we can test:\n\\(H_0: \\Pr(X &gt; Y) = \\Pr(Y &gt; X)\\)\n\\(H_1: \\Pr(X &gt; Y) \\neq \\Pr(Y &gt; X)\\)"
  },
  {
    "objectID": "w14/index.html#sorting-and-ranking-observations",
    "href": "w14/index.html#sorting-and-ranking-observations",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Sorting and Ranking Observations",
    "text": "Sorting and Ranking Observations\n\n\n\nOriginal Data\nSorted Total Samples\nRank\n\n\nUSA\nWales\nUSA\nWales\nUSA\nWales\n\n\n\n\n75\n78\n67\n67\n1.5\n1.5\n\n\n68\n71\n68\n68\n4\n4\n\n\n75\n76\n68\n4\n\n\n69\n75\n69\n69\n6.5\n6.5\n\n\n70\n72\n70\n70\n9\n9\n\n\n70\n70\n70\n9\n\n\n72\n68\n\n71\n\n11\n\n\n67\n72\n72\n72\n14\n14\n\n\n\n\n72\n69\n72\n14\n\n\n72\n14\n\n\n72\n73\n72\n14\n\n\n\n\n68\n67\n\n73\n\n17\n\n\n\n\n75\n75\n19\n19\n\n\n\n\n75\n19\n\n\n\n\n\n76\n\n21\n\n\n\n\n\n78\n\n22"
  },
  {
    "objectID": "w14/index.html#our-rank-based-test-statistic",
    "href": "w14/index.html#our-rank-based-test-statistic",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Our Rank-Based Test Statistic",
    "text": "Our Rank-Based Test Statistic\n\nSums of ranks relative to the combined dataset: \\(\\Sigma_{X/\\mathbf{Z}} = 112.5\\), \\(\\Sigma_{Y/\\mathbf{Z}} = 140.5\\).\nAnd then sum the ranks in each group, relative to the same group‚Ä¶ In general, if we have \\(N\\) ranked datapoints (so, datapoints given labels \\(\\{1, 2, \\ldots, N\\}\\)), what will the sum of these individual ranks be?\n\n\\[\n\\sum_{i=1}^{N}i = \\underbrace{\\overbrace{(1 + N)}^{N + 1} + \\overbrace{(2 + (N-1))}^{N + 1} + \\cdots}_{N/2\\text{ terms}} = \\frac{N(N+1)}{2}\n\\]\n\nSo, in this case,\n\n\\[\n\\Sigma_{X/\\mathbf{X}} = \\Sigma_{Y/\\mathbf{Y}} = \\sum_{i=1}^{11}i = \\frac{11(12)}{2} = 66\n\\]\n\nGiving us the test statistics\n\n\\[\n\\begin{align*}\nU_X &= 112.5 - 66 = 46.5, \\; U_Y = 140.5 - 66 = 74.5 \\\\\nU &= \\min\\{U_X, U_Y\\} = \\min\\{46.5, 74.5\\} = 46.5\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w14/index.html#simulating-one-null-hypothesis-world",
    "href": "w14/index.html#simulating-one-null-hypothesis-world",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Simulating (One) Null-Hypothesis World",
    "text": "Simulating (One) Null-Hypothesis World\nOne simulation:\n\n\n\nset.seed(5100)\nlibrary(tidyverse)\nN1 &lt;- 11\nN2 &lt;- 11\nN &lt;- N1 + N2\ntotalRankSum &lt;- (N * (N+1)) / 2\ns_1 &lt;- runif(N1)\ndf_1 &lt;- tibble(x = s_1, team = \"A\")\ns_2 &lt;- runif(N2)\ndf_2 &lt;- tibble(x = s_2, team = \"B\")\ndf_combined &lt;- bind_rows(df_1, df_2)\ndf_combined['rank'] &lt;- rank(df_combined$x)\nwriteLines(paste0(\"N1 = \",N1,\", N2 = \",N2,\" =&gt; Sum(1...(N1+N2)) = \",totalRankSum))\n\nN1 = 11, N2 = 11 =&gt; Sum(1...(N1+N2)) = 253\n\ndf_combined |&gt; arrange(rank) |&gt; head()\n\n\n\n\n\nx\nteam\nrank\n\n\n\n\n0.0281644\nB\n1\n\n\n0.0282184\nA\n2\n\n\n0.0730575\nB\n3\n\n\n0.1343398\nB\n4\n\n\n0.1351495\nB\n5\n\n\n0.1858087\nA\n6\n\n\n\n\n\n\n\n\n¬†\n\n‚Üí\n\n\ndf_combined |&gt; group_by(team) |&gt; summarize(ranksum = sum(rank)) |&gt; mutate(proportion = ranksum / totalRankSum)\n\n\n\n\n\nteam\nranksum\nproportion\n\n\n\n\nA\n144\n0.56917\n\n\nB\n109\n0.43083"
  },
  {
    "objectID": "w14/index.html#simulating-many-null-hypothesis-worlds",
    "href": "w14/index.html#simulating-many-null-hypothesis-worlds",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Simulating Many Null-Hypothesis Worlds",
    "text": "Simulating Many Null-Hypothesis Worlds\nAnd we can repeat this process (say) 10K times:\n\n\n\nsimulate_ranksums &lt;- function(N1, N2) {\n  N &lt;- N1 + N2\n  totalRankSum &lt;- (N * (N+1)) / 2\n  s_1 &lt;- runif(N1)\n  df_1 &lt;- tibble(x = s_1, team = \"A\")\n  s_2 &lt;- runif(N2)\n  df_2 &lt;- tibble(x = s_2, team = \"B\")\n  df_combined &lt;- bind_rows(df_1, df_2)\n  df_combined['rank'] &lt;- rank(df_combined$x)\n  ranksum_df &lt;- df_combined |&gt; group_by(team) |&gt; summarize(ranksum = sum(rank))\n  return(ranksum_df$ranksum)\n}\nnum_sims &lt;- 1000\nresults &lt;- replicate(num_sims, simulate_ranksums(11,11))\nt(results[,0:10])\n\n      [,1] [,2]\n [1,]  133  120\n [2,]   98  155\n [3,]  115  138\n [4,]  166   87\n [5,]  137  116\n [6,]  140  113\n [7,]  146  107\n [8,]  157   96\n [9,]  119  134\n[10,]  106  147\n\nrowMeans(results)\n\n[1] 126.407 126.593\n\n\n\n\n# Separate ranksums\nranksum_A &lt;- tibble(ranksum=results[1,], team=\"A\")\nranksum_A_mean &lt;- mean(ranksum_A$ranksum)\nranksum_B &lt;- tibble(ranksum=results[2,], team=\"B\")\nranksum_B_mean &lt;- mean(ranksum_B$ranksum)\nsim_df &lt;- bind_rows(ranksum_A, ranksum_B)\n# Means\nmean_df &lt;- tibble(mean_value = c(ranksum_A_mean, ranksum_B_mean), team=c(\"A\",\"B\"))\nmean_center &lt;- (ranksum_A_mean + ranksum_B_mean) / 2\ngen_ranksum_plot &lt;- function(radius=Inf) {\n  ranksum_plot &lt;- ggplot(sim_df, aes(x=ranksum, fill=team)) +\n    geom_density(linewidth = g_linewidth, alpha=0.333) +\n    geom_vline(\n        data=mean_df,\n        aes(xintercept = mean_value, color=team),\n        linewidth = g_linewidth\n    ) +\n    theme_classic(base_size=14) +\n    scale_fill_manual(values=c(cbPalette[1], cbPalette[2]))\n    if (radius != Inf) {\n        ranksum_plot &lt;- ranksum_plot +\n        xlim(mean_center - radius, mean_center + radius)\n    }\n    return(ranksum_plot)\n}\ngen_ranksum_plot()\n\n\n\n\n\n\n\n\n\ngen_ranksum_plot(radius=8)"
  },
  {
    "objectID": "w14/index.html#wilcox.test-in-r",
    "href": "w14/index.html#wilcox.test-in-r",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "wilcox.test in R",
    "text": "wilcox.test in R\n\n\nCode\nwilcox.test(height ~ Team, data=players, exact = TRUE)\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  height by Team\nW = 48, p-value = 0.4262\nalternative hypothesis: true location shift is not equal to 0\n\n\n\nWe confirm our computed test statistic of 46.5, and obtain a p-value of about 0.37\nThus, under most confidence levels (like my favorite \\(\\alpha = 0.11\\)), we fail to reject the null hypothesis \\(\\mathcal{H}_0\\)\nPutting on our Bayes hats, we do not increase our degree of belief that height differs between the two populations."
  },
  {
    "objectID": "w14/index.html#procedure",
    "href": "w14/index.html#procedure",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Procedure",
    "text": "Procedure\n\nPool observations from \\(k\\) samples into one combined sample, keeping track of which sample each observation comes from, then rank lowest to highest.\nTest statistic:\n\n\\[\nH = \\frac{12}{N(N+1)}\\sum_{j=1}^{k}\\frac{R_j^2}{n_j} - 3(N+1)\n\\]\n\nReject \\(\\mathcal{H}_0\\) if \\(H \\geq \\text{critical val}\\)"
  },
  {
    "objectID": "w14/index.html#kruskal.test-in-r",
    "href": "w14/index.html#kruskal.test-in-r",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "kruskal.test in R",
    "text": "kruskal.test in R\n\n# kruskal.test(height ~ position, data=players)"
  },
  {
    "objectID": "w14/index.html#footnotes",
    "href": "w14/index.html#footnotes",
    "title": "Week 14: Non-Parametric Statistics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRecall that any other distribution implicitly encodes additional assumptions: bounded range, nonnegative, etc.‚Ü©Ô∏é"
  },
  {
    "objectID": "w12/slides.html#classical-test-1-the-z-test",
    "href": "w12/slides.html#classical-test-1-the-z-test",
    "title": "Week 12: Hypothesis Testing",
    "section": "Classical Test 1: The \\(z\\)-Test",
    "text": "Classical Test 1: The \\(z\\)-Test\n\nNull hypothesis: \\(H_0: \\mu = \\mu_0\\); Test statistic \\(Z = \\frac{\\overline{X} - \\mu_0}{\\sigma / \\sqrt{N}}\\)\n\n\n\n\n\n\n\n\nAlternative Hypothesis\nP-Value Determination\n\n\n\n\n\\(H_A: \\mu &gt; \\mu_0\\)\nArea under the standard normal curve to the right of \\(z\\)\n\n\n\\(H_A: \\mu &lt; \\mu_0\\)\nArea under the standard normal curve to the left of \\(z\\)\n\n\n\\(H_A: \\mu \\neq \\mu_0\\)\n\\(2~ \\cdot\\) (Area under the standard normal curve to the right of \\(|z|\\))\n\n\n\n\nAssumptions: A normal population distribution with known value of \\(\\sigma\\)."
  },
  {
    "objectID": "w12/slides.html#example-1-bird-wingspans",
    "href": "w12/slides.html#example-1-bird-wingspans",
    "title": "Week 12: Hypothesis Testing",
    "section": "Example 1: Bird Wingspans",
    "text": "Example 1: Bird Wingspans\n\nTrying to figure out the population distribution of bird wingspans.\nWe hypothesize \\(\\mu_0 = 120\\text{cm}\\)\nSomehow we know the population variance \\(\\sigma = 20\\text{cm}\\), and we know that bird wingspans form a normal distribution, but we don‚Äôt know the true \\(\\mu\\):\n\n\n\nCode\nlibrary(tidyverse)\nhyp_mu &lt;- 120\nsigma &lt;- 20\nbird_dnorm &lt;- function(x) dnorm(x, mean=hyp_mu, sd=sigma)\nsigma_df &lt;- tribble(\n    ~x,\n    hyp_mu - 3 * sigma,\n    hyp_mu - 2 * sigma,\n    hyp_mu - 1 * sigma,\n    hyp_mu + 1 * sigma,\n    hyp_mu + 2 * sigma,\n    hyp_mu + 3 * sigma\n)\nsigma_df &lt;- sigma_df |&gt; mutate(\n    y = 0,\n    xend = x,\n    yend = bird_dnorm(x)\n)\nplot_rad &lt;- 4 * sigma\nplot_bounds &lt;- c(hyp_mu - plot_rad, hyp_mu + plot_rad)\nbird_plot &lt;- ggplot(data=data.frame(x=plot_bounds), aes(x=x)) +\n  stat_function(fun=bird_dnorm, linewidth=g_linewidth) +\n  geom_vline(aes(xintercept=hyp_mu), linewidth=g_linewidth) +\n  geom_segment(data=sigma_df, aes(x=x, y=y, xend=xend, yend=yend), linewidth=g_linewidth, linetype=\"dashed\") +\n  dsan_theme(\"half\") +\n  labs(\n    title = \"Our Hypothesized Bird Distribution\",\n    x = \"Wingspan Values (m)\",\n    y = \"Probability Density\"\n  )\nbird_plot"
  },
  {
    "objectID": "w12/slides.html#a-wild-sample-appears",
    "href": "w12/slides.html#a-wild-sample-appears",
    "title": "Week 12: Hypothesis Testing",
    "section": "A Wild Sample Appears!",
    "text": "A Wild Sample Appears!\n\nWhile we are pondering, someone runs into the room and tosses us a big crate \\(\\mathbf{X}\\), a random sample of \\(N = 16\\) birds from the population üò∞\nRecovering from the shock, we measure each bird‚Äôs wingspan \\(X_i\\) and find \\(\\overline{X} = 131\\text{cm}\\)\nWhat can we infer about our hypothesized \\(\\mu\\), now that we have a sample statistic \\(\\overline{X}\\)?\nWe cannot just plot \\(\\overline{X} = 131\\) on the hypothesized bird distribution from the previous slide (an easy mistake to make!)\nApples and oranges: the distribution below is a distribution of individual bird wingspans, but \\(\\overline{X}\\) is a mean of 16 bird wingspans\nWhat we can do is: think about what the distribution of sample means from \\(N = 16\\) samples would look like if \\(\\mu = \\mu_0\\)!"
  },
  {
    "objectID": "w12/slides.html#what-would-sample-means-look-like-if-hypothesis-was-true",
    "href": "w12/slides.html#what-would-sample-means-look-like-if-hypothesis-was-true",
    "title": "Week 12: Hypothesis Testing",
    "section": "What Would Sample Means Look Like If Hypothesis Was True?",
    "text": "What Would Sample Means Look Like If Hypothesis Was True?\n\nWhat we know, from asymptotic sample theory, is that \\(Z = \\frac{\\overline{X} - \\mu}{\\sigma / \\sqrt{N}}\\) is approximately standard normal, for sufficiently large values of \\(N\\)!\nSo, let‚Äôs (1) plot this distribution, for a bunch of potential sample means, and then (2) see where our actual observed sample mean lies on this distribution!\nSanity check: let‚Äôs actually simulate taking sample means from 1000 size-16 samples:\n\n\n\nCode\nsimulate_sample_mean &lt;- function(N, mu, sigma) {\n    samples &lt;- rnorm(N, mu, sigma)\n    sample_mean &lt;- mean(samples)\n    return(sample_mean)\n}\nN &lt;- 16\nobs_sample_mean &lt;- 129\nnum_reps &lt;- 10000\nsample_means &lt;- as_tibble(replicate(num_reps, simulate_sample_mean(N, hyp_mu, sigma)))\nasymp_dnorm &lt;- function(x) dnorm((x - hyp_mu)/(sigma / sqrt(N)), 0, 1)\nggplot() +\n  geom_histogram(\n    data=sample_means,\n    aes(x=value, y=5*after_stat(density)),\n    binwidth=1) +\n  stat_function(\n    data=data.frame(x=c(100,140)),\n    aes(x=x, color='asymp'),\n    fun=asymp_dnorm,\n    linewidth = g_linewidth\n  ) +\n  geom_segment(\n    aes(x = obs_sample_mean, xend=obs_sample_mean, y=-Inf, yend=Inf, color='obs'),\n    linewidth = g_linewidth\n  ) +\n  dsan_theme(\"half\") +\n  labs(\n    x = \"Simulated Sample Mean\",\n    y = \"(Empirical) Density\",\n    title = paste0(num_reps,\" Simulated Sample Means, N = 16\")\n  ) +\n  scale_color_manual(values=c('asymp'='black', 'obs'=cbPalette[1]), labels=c('asymp'='Asymptotic\\nDistribution', 'obs'='Observed\\nSample Mean')) +\n  remove_legend_title()"
  },
  {
    "objectID": "w12/slides.html#right-tailed-test",
    "href": "w12/slides.html#right-tailed-test",
    "title": "Week 12: Hypothesis Testing",
    "section": "Right-Tailed Test",
    "text": "Right-Tailed Test\n\nNull hypothesis (in all cases) is \\(H_0: \\mu = \\mu_0\\); Right-tailed test is of alternative hypothesis \\(H_A: \\mu &gt; \\mu_0\\)\nWe reject the null if the observed sample mean \\(\\overline{X} = 131\\) is too unlikely in the world where the null is true: \\(Z(\\overline{X}) \\approx 1.8\\)\nWhat cutoff should we use for ‚Äútoo unlikely‚Äù? (See last week‚Äôs slides‚Ä¶) here we‚Äôll use \\(\\alpha = 0.05\\): \\(\\int_{1.645}^{\\infty}\\varphi(x)dx = 0.05\\), so \\(1.645\\) is our ‚Äúcritical‚Äù (cutoff) value\n\n\n\nCode\nlabel_df_signif_int &lt;- tribble(\n    ~x, ~y, ~label,\n    0.55, 0.04, \"95% Signif.\\nCutoff\"\n)\nsignif_cutoff &lt;- 1.645\nfuncShaded &lt;- function(x, lower_bound, upper_bound){\n    y &lt;- dnorm(x)\n    y[x &lt; lower_bound | x &gt; upper_bound] &lt;- NA\n    return(y)\n}\nfuncShadedIntercept &lt;- function(x) funcShaded(x, int_tstat, Inf)\nfuncShadedSignif &lt;- function(x) funcShaded(x, signif_cutoff, Inf)\ncompute_z_val &lt;- function(x) {\n    return ((x - hyp_mu) / (sigma / sqrt(N)))\n}\nobs_zval &lt;- compute_z_val(obs_sample_mean)\nobs_zval_str &lt;- sprintf(\"%.2f\", obs_zval)\nsample_dnorm &lt;- function(x) dnorm(compute_z_val(x))\nggplot(data=data.frame(x=c(-3,3)), aes(x=x)) +\n  stat_function(fun=dnorm, linewidth=g_linewidth) +\n  #geom_segment(data=sigma_df, aes(x=x, y=y, xend=xend, yend=yend), linewidth=g_linewidth, linetype=\"dashed\") +\n  stat_function(fun = funcShadedSignif, geom = \"area\", fill = \"grey\", alpha = 0.333) +\n  geom_vline(aes(xintercept = signif_cutoff), linewidth=g_linewidth, linetype=\"dashed\") +\n  geom_text(label_df_signif_int, mapping = aes(x = x, y = y, label = label), size = 8) +\n  geom_vline(aes(xintercept = obs_zval, color='sample_mean'), linewidth=g_linewidth) +\n  dsan_theme(\"half\") +\n  labs(\n    title = \"z-Test Distribution\",\n    x = \"z Scores\",\n    y = \"Probability Density\"\n  ) +\n  scale_color_manual(values=c('sample_mean'=cbPalette[1]), labels=c('sample_mean'='Z(Observed Sample Mean)')) +\n  remove_legend_title()\n\n\n\n\nSince \\(Z(\\overline{X}) &gt; 1.645\\), we reject the null hypothesis that this sample mean was generated by a distribution with mean \\(\\mu_0\\)!"
  },
  {
    "objectID": "w12/slides.html#two-tailed-test",
    "href": "w12/slides.html#two-tailed-test",
    "title": "Week 12: Hypothesis Testing",
    "section": "Two-Tailed Test",
    "text": "Two-Tailed Test\n\nNull hypothesis (in all cases) is \\(H_0: \\mu = \\mu_0\\); Two-tailed test is of alternative hypothesis \\(H_A: \\mu \\neq \\mu_0\\) (the actual logical negation of the null hypothesis‚Ä¶)\nReject the null if observed sample mean \\(\\overline{X} = 131\\) is too unlikely in null world\nWhat cutoff should we use for ‚Äútoo unlikely‚Äù? Here we‚Äôll use \\(\\alpha = 0.05\\), but for a two tailed test we find \\(\\int_{-\\infty}^{-1.96}\\varphi(x)dx + \\int_{1.96}^{\\infty}\\varphi(x)dx = 0.05\\), so \\(1.96\\) is our ‚Äúcritical‚Äù (cutoff) value\n\n\n\nCode\nsignif_cutoff &lt;- 1.96\nneg_signif_cutoff &lt;- -signif_cutoff\nlabel_df_signif_int &lt;- tribble(\n    ~x, ~y, ~label,\n    -2.45, 0.18, paste0(\"Left\\nCutoff\\n(\",neg_signif_cutoff,\")\"),\n    2.45, 0.18, paste0(\"Right\\nCutoff\\n(\",signif_cutoff,\")\")\n)\nfuncShaded &lt;- function(x, lower_bound, upper_bound){\n    y &lt;- dnorm(x)\n    y[x &lt; lower_bound | x &gt; upper_bound] &lt;- NA\n    return(y)\n}\nfuncShadedIntercept &lt;- function(x) funcShaded(x, int_tstat, Inf)\nfuncShadedNegSignif &lt;- function(x) funcShaded(x, -Inf, neg_signif_cutoff)\nfuncShadedSignif &lt;- function(x) funcShaded(x, signif_cutoff, Inf)\ncompute_z_val &lt;- function(x) {\n    return ((x - hyp_mu) / (sigma / sqrt(N)))\n}\nobs_zval &lt;- compute_z_val(obs_sample_mean)\nsample_dnorm &lt;- function(x) dnorm(compute_z_val(x))\nggplot(data=data.frame(x=c(-3,3)), aes(x=x)) +\n  stat_function(fun=dnorm, linewidth=g_linewidth) +\n  #geom_segment(data=sigma_df, aes(x=x, y=y, xend=xend, yend=yend), linewidth=g_linewidth, linetype=\"dashed\") +\n  stat_function(fun = funcShadedSignif, geom = \"area\", fill = \"grey\", alpha = 0.333) +\n  stat_function(fun = funcShadedNegSignif, geom = \"area\", fill = \"grey\", alpha = 0.333) +\n  geom_vline(aes(xintercept = neg_signif_cutoff), linewidth=g_linewidth, linetype=\"dashed\") +\n  geom_vline(aes(xintercept = signif_cutoff), linewidth=g_linewidth, linetype=\"dashed\") +\n  geom_text(label_df_signif_int, mapping = aes(x = x, y = y, label = label), size = 8) +\n  geom_vline(aes(xintercept = obs_zval, color='sample_mean'), linewidth=g_linewidth) +\n  dsan_theme(\"half\") +\n  labs(\n    title = \"z-Test Distribution\",\n    x = \"z Scores\",\n    y = \"Probability Density\"\n  ) +\n  scale_color_manual(values=c('sample_mean'=cbPalette[1]), labels=c('sample_mean'='Z(Observed Sample Mean)')) +\n  remove_legend_title()\n\n\n\n\nSince \\(|Z(\\overline{X})| &lt; 1.96\\), we fail to reject the null hypothesis that this sample mean was generated by a distribution with mean \\(\\mu_0\\)!"
  },
  {
    "objectID": "w12/slides.html#errors-in-classical-hypothesis-testing",
    "href": "w12/slides.html#errors-in-classical-hypothesis-testing",
    "title": "Week 12: Hypothesis Testing",
    "section": "Errors in Classical Hypothesis Testing",
    "text": "Errors in Classical Hypothesis Testing\n\nSince we‚Äôre trying to infer something about the population using only a sample, we may make one of the following types of errors:\n\n\n\n\n\n\n\n\nType I Error\nType II Error\n\n\n\n\n\n\n\n\\(H_0\\) is:\n\n\nDecision:\nTrue\nFalse\n\n\n\n\nDo not reject \\(H_0\\)\nCorrect decision\nType II error\n\n\nReject \\(H_0\\)\nType I error\nCorrect decision"
  },
  {
    "objectID": "w12/slides.html#what-is-regression",
    "href": "w12/slides.html#what-is-regression",
    "title": "Week 12: Hypothesis Testing",
    "section": "What Is Regression?",
    "text": "What Is Regression?\n\nIf science is understanding relationships between variables, regression is the most basic but fundamental tool we have to start measuring these relationships\nOften exactly what humans do when we see data!\n\n\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(tibble)\nx_data &lt;- seq(from=0, to=1, by=0.02)\nnum_x &lt;- length(x_data)\ny_data &lt;- x_data + runif(num_x, 0, 0.2)\nreg_df &lt;- tibble(x=x_data, y=y_data)\nggplot(reg_df, aes(x=x, y=y)) +\n  geom_point(size=g_pointsize) +\n  dsan_theme(\"quarter\")\n\n\n\n\n\n\n\n\n\n\n\n\n psychology   psychology   trending_flat \n\n\n\n\n\nCode\nggplot(reg_df, aes(x=x, y=y)) + \n  geom_point(size=g_pointsize) +\n  geom_smooth(method = \"lm\", se = FALSE, color = cbPalette[1], formula = y ~ x, linewidth = g_linewidth*3) +\n  dsan_theme(\"quarter\")"
  },
  {
    "objectID": "w12/slides.html#the-goal",
    "href": "w12/slides.html#the-goal",
    "title": "Week 12: Hypothesis Testing",
    "section": "The Goal",
    "text": "The Goal\n\nWhenever you carry out a regression, keep the goal in the front of your mind:\n\n\n\n\n\n The Goal of Regression\n\n\nFind a line \\(\\widehat{y} = mx + b\\) that best predicts \\(Y\\) for given values of \\(X\\)"
  },
  {
    "objectID": "w12/slides.html#how-do-we-define-best",
    "href": "w12/slides.html#how-do-we-define-best",
    "title": "Week 12: Hypothesis Testing",
    "section": "How Do We Define ‚ÄúBest‚Äù?",
    "text": "How Do We Define ‚ÄúBest‚Äù?\n\nIntuitively, two different ways to measure how well a line fits the data:\n\n\n\n\n\nCode\nset.seed(5100)\nN &lt;- 11\nx &lt;- seq(from = 0, to = 1, by = 1 / (N - 1))\ny &lt;- x + rnorm(N, 0, 0.25)\nmean_y &lt;- mean(y)\nspread &lt;- y - mean_y\ndf &lt;- tibble(x = x, y = y, spread = spread)\nggplot(df, aes(x=x, y=y)) +\n  geom_abline(slope=1, intercept=0, linetype=\"dashed\", color=cbPalette[1], linewidth=g_linewidth*2) +\n  geom_segment(xend=(x+y)/2, yend=(x+y)/2, linewidth=g_linewidth*2, color=cbPalette[2]) +\n  geom_point(size=g_pointsize) +\n  coord_equal() +\n  dsan_theme(\"full\") +\n  labs(\n    title = \"Principal Component Line\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(df, aes(x=x, y=y)) +\n  geom_point(size=g_pointsize) +\n  geom_abline(slope=1, intercept=0, linetype=\"dashed\", color=cbPalette[1], linewidth=g_linewidth*2) +\n  geom_segment(xend=x, yend=x, linewidth=g_linewidth*2, color=cbPalette[2]) +\n  dsan_theme(\"full\") +\n  labs(\n    title = \"Regression Line\"\n  ) +\n  coord_equal()\n\n\n\n\n\n\n\n\n\n\n\n\nOn the difference between these two lines, and why it matters, I cannot recommend Gelman and Hill (2007) enough!"
  },
  {
    "objectID": "w12/slides.html#principal-component-analysis",
    "href": "w12/slides.html#principal-component-analysis",
    "title": "Week 12: Hypothesis Testing",
    "section": "Principal Component Analysis",
    "text": "Principal Component Analysis\n\nPrincipal Component Line allows projecting data onto its dimension of highest variance\nMore simply: PCA can discover meaningful axes in data (unsupervised learning / exploratory data analysis settings)\n\n\n\nCode\nlibrary(readr)\nlibrary(ggplot2)\ngdp_df &lt;- read_csv(\"assets/gdp_pca.csv\")\n\ndist_to_line &lt;- function(x0, y0, a, c) {\n    numer &lt;- abs(a * x0 - y0 + c)\n    denom &lt;- sqrt(a * a + 1)\n    return(numer / denom)\n}\n# Finding PCA line for industrial vs. exports\nx &lt;- gdp_df$industrial\ny &lt;- gdp_df$exports\nlossFn &lt;- function(lineParams, x0, y0) {\n    a &lt;- lineParams[1]\n    c &lt;- lineParams[2]\n    return(sum(dist_to_line(x0, y0, a, c)))\n}\no &lt;- optim(c(0, 0), lossFn, x0 = x, y0 = y)\nggplot(gdp_df, aes(x = industrial, y = exports)) +\n    geom_point(size=g_pointsize/2) +\n    geom_abline(aes(slope = o$par[1], intercept = o$par[2], color=\"pca\"), linewidth=g_linewidth, show.legend = TRUE) +\n    geom_smooth(aes(color=\"lm\"), method = \"lm\", se = FALSE, linewidth=g_linewidth, key_glyph = \"blank\") +\n    scale_color_manual(element_blank(), values=c(\"pca\"=cbPalette[2],\"lm\"=cbPalette[1]), labels=c(\"Regression\",\"PCA\")) +\n    dsan_theme(\"half\") +\n    remove_legend_title() +\n    labs(\n      title = \"PCA Line vs. Regression Line\",\n        x = \"Industrial Production (% of GDP)\",\n        y = \"Exports (% of GDP)\"\n    )\n\n\n\n\nSee here for an amazing blog post using PCA to explore UN voting patterns!"
  },
  {
    "objectID": "w12/slides.html#create-your-own-dimension",
    "href": "w12/slides.html#create-your-own-dimension",
    "title": "Week 12: Hypothesis Testing",
    "section": "Create Your Own Dimension!",
    "text": "Create Your Own Dimension!\n\n\nCode\nggplot(gdp_df, aes(pc1, .fittedPC2)) +\n    geom_point(size = g_pointsize/2) +\n    geom_hline(aes(yintercept=0, color='PCA Line'), linetype='solid', size=g_linesize) +\n    geom_rug(sides = \"b\", linewidth=g_linewidth/1.2, length = unit(0.1, \"npc\"), color=cbPalette[3]) +\n    expand_limits(y=-1.6) +\n    scale_color_manual(element_blank(), values=c(\"PCA Line\"=cbPalette[2])) +\n    dsan_theme(\"full\") +\n    remove_legend_title() +\n    labs(\n      title = \"Exports vs. Industrial Production in Principal Component Space\",\n      x = \"First Principal Component (Dimension of Greatest Variance)\",\n      y = \"Second Principal Component\"\n    )"
  },
  {
    "objectID": "w12/slides.html#and-use-it-for-eda",
    "href": "w12/slides.html#and-use-it-for-eda",
    "title": "Week 12: Hypothesis Testing",
    "section": "And Use It for EDA",
    "text": "And Use It for EDA\n\n\nCode\nlibrary(dplyr)\nlibrary(tidyr)\nplot_df &lt;- gdp_df %&gt;% select(c(country_code, pc1, agriculture, military))\nlong_df &lt;- plot_df %&gt;% pivot_longer(!c(country_code, pc1), names_to = \"var\", values_to = \"val\")\nlong_df &lt;- long_df |&gt; mutate(\n  var = case_match(\n    var,\n    \"agriculture\" ~ \"Agricultural Production\",\n    \"military\" ~ \"Military Spending\"\n  )\n)\nggplot(long_df, aes(x = pc1, y = val, facet = var)) +\n    geom_point() +\n    facet_wrap(vars(var), scales = \"free\") +\n    dsan_theme(\"full\") +\n    labs(\n        x = \"Industrial-Export Dimension\",\n        y = \"% of GDP\"\n    )"
  },
  {
    "objectID": "w12/slides.html#but-in-our-case",
    "href": "w12/slides.html#but-in-our-case",
    "title": "Week 12: Hypothesis Testing",
    "section": "But in Our Case‚Ä¶",
    "text": "But in Our Case‚Ä¶\n\n\\(x\\) and \\(y\\) dimensions already have meaning, and we have a hypothesis about \\(x \\rightarrow y\\)!\n\n\n\n\n\n\n\n\nThe Regression Hypothesis \\(\\mathcal{H}_{\\text{reg}}\\)\n\n\nGiven data \\((X, Y)\\), we estimate \\(\\widehat{y} = \\widehat{\\beta_0} + \\widehat{\\beta_1}x\\), hypothesizing that:\n\nStarting from \\(y = \\widehat{\\beta_0}\\) when \\(x = 0\\) (the intercept),\nAn increase of \\(x\\) by 1 unit is associated with an increase of \\(y\\) by \\(\\widehat{\\beta_1}\\) units (the coefficient)\n\n\n\n\n\n\nWe want to measure how well our line predicts \\(y\\) for any given \\(x\\) value \\(\\implies\\) vertical distance from regression line"
  },
  {
    "objectID": "w12/slides.html#key-features-of-regression-line",
    "href": "w12/slides.html#key-features-of-regression-line",
    "title": "Week 12: Hypothesis Testing",
    "section": "Key Features of Regression Line",
    "text": "Key Features of Regression Line\n\nRegression line is BLUE: Best Linear Unbiased Estimator\nWhat exactly is it the ‚Äúbest‚Äù linear estimator of?\n\n\\[\n\\widehat{y} = \\underbrace{\\widehat{\\beta_0}}_{\\small\\begin{array}{c}\\text{Predicted} \\\\[-5mm] \\text{intercept}\\end{array}} + \\underbrace{\\widehat{\\beta_1}}_{\\small\\begin{array}{c}\\text{Predicted} \\\\[-4mm] \\text{slope}\\end{array}}\\cdot x\n\\]\nis chosen so that\n\n\\[\n\\theta = \\left(\\widehat{\\beta_0}, \\widehat{\\beta_1}\\right) = \\argmin_{\\beta_0, \\beta_1}\\left[ \\sum_{x_i \\in X} \\left(\\overbrace{\\widehat{y}(x_i)}^{\\small\\text{Predicted }y} - \\overbrace{\\expect{Y \\mid X = x_i}}^{\\small \\text{Avg. }y\\text{ when }x = x_i}\\right)^2 \\right]\n\\]"
  },
  {
    "objectID": "w12/slides.html#regression-in-r",
    "href": "w12/slides.html#regression-in-r",
    "title": "Week 12: Hypothesis Testing",
    "section": "Regression in R",
    "text": "Regression in R\n\n\nCode\nlin_model &lt;- lm(military ~ industrial, data=gdp_df)\nsummary(lin_model)\n\n\n\nCall:\nlm(formula = military ~ industrial, data = gdp_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.3354 -1.0997 -0.3870  0.6081  6.7508 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  0.61969    0.59526   1.041   0.3010  \nindustrial   0.05253    0.02019   2.602   0.0111 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.671 on 79 degrees of freedom\n  (8 observations deleted due to missingness)\nMultiple R-squared:  0.07895,   Adjusted R-squared:  0.06729 \nF-statistic: 6.771 on 1 and 79 DF,  p-value: 0.01106"
  },
  {
    "objectID": "w12/slides.html#lm-syntax",
    "href": "w12/slides.html#lm-syntax",
    "title": "Week 12: Hypothesis Testing",
    "section": "lm Syntax",
    "text": "lm Syntax\nlm(\n  formula = dependent ~ independent + controls,\n  data = my_df\n)"
  },
  {
    "objectID": "w12/slides.html#interpreting-output",
    "href": "w12/slides.html#interpreting-output",
    "title": "Week 12: Hypothesis Testing",
    "section": "Interpreting Output",
    "text": "Interpreting Output\nCall:\nlm(formula = military ~ industrial, data = gdp_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.3354 -1.0997 -0.3870  0.6081  6.7508 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  0.61969    0.59526   1.041   0.3010  \nindustrial   0.05253    0.02019   2.602   0.0111 *\n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nResidual standard error: 1.671 on 79 degrees of freedom\n  (8 observations deleted due to missingness)\nMultiple R-squared:  0.07895,   Adjusted R-squared:  0.06729 \nF-statistic: 6.771 on 1 and 79 DF,  p-value: 0.01106"
  },
  {
    "objectID": "w12/slides.html#zooming-in-coefficients",
    "href": "w12/slides.html#zooming-in-coefficients",
    "title": "Week 12: Hypothesis Testing",
    "section": "Zooming In: Coefficients",
    "text": "Zooming In: Coefficients\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n\n(Intercept)\n0.61969\n0.59526\n1.041\n0.3010\n\n\n\nindustrial\n0.05253\n0.02019\n2.602\n0.0111\n*\n\n\n\n\\(\\widehat{\\beta}\\)\nUncertainty\nTest statistic\nHow extreme is test stat?\nStatistical significance\n\n\n\n\n\\[\n\\widehat{y} \\approx \\class{cb1}{\\overset{\\beta_0}{\\underset{\\small \\pm 0.595}{0.620}}} +  \\class{cb2}{\\overset{\\beta_1}{\\underset{\\small \\pm 0.020}{0.053}}} \\cdot x\n\\]"
  },
  {
    "objectID": "w12/slides.html#zooming-in-significance",
    "href": "w12/slides.html#zooming-in-significance",
    "title": "Week 12: Hypothesis Testing",
    "section": "Zooming In: Significance",
    "text": "Zooming In: Significance\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n\n(Intercept)\n0.61969\n0.59526\n1.041\n0.3010\n\n\n\nindustrial\n0.05253\n0.02019\n2.602\n0.0111\n*\n\n\n\n\\(\\widehat{\\beta}\\)\nUncertainty\nTest statistic\nHow extreme is test stat?\nStatistical significance\n\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\nint_tstat &lt;- 1.041\nint_tstat_str &lt;- sprintf(\"%.02f\", int_tstat)\nlabel_df_int &lt;- tribble(\n    ~x, ~y, ~label,\n    0.25, 0.05, paste0(\"P(t &gt; \",int_tstat_str,\")\\n= 0.3\")\n)\nlabel_df_signif_int &lt;- tribble(\n    ~x, ~y, ~label,\n    2.7, 0.075, \"95% Signif.\\nCutoff\"\n)\nfuncShaded &lt;- function(x, lower_bound, upper_bound){\n    y &lt;- dnorm(x)\n    y[x &lt; lower_bound | x &gt; upper_bound] &lt;- NA\n    return(y)\n}\nfuncShadedIntercept &lt;- function(x) funcShaded(x, int_tstat, Inf)\nfuncShadedSignif &lt;- function(x) funcShaded(x, 1.96, Inf)\nggplot(data=data.frame(x=c(-3,3)), aes(x=x)) +\n  stat_function(fun=dnorm, linewidth=g_linewidth) +\n  geom_vline(aes(xintercept=int_tstat), linewidth=g_linewidth) +\n  geom_vline(aes(xintercept = 1.96), linewidth=g_linewidth, linetype=\"dashed\") +\n  stat_function(fun = funcShadedIntercept, geom = \"area\", fill = cbPalette[1], alpha = 0.5) +\n  stat_function(fun = funcShadedSignif, geom = \"area\", fill = \"grey\", alpha = 0.333) +\n  geom_text(label_df_int, mapping = aes(x = x, y = y, label = label), size = 10) +\n  geom_text(label_df_signif_int, mapping = aes(x = x, y = y, label = label), size = 8) +\n  # Add single additional tick\n  scale_x_continuous(breaks=c(-2, 0, int_tstat, 2), labels=c(\"-2\",\"0\",int_tstat_str,\"2\")) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title = \"t Value for Intercept\",\n    x = \"t\",\n    y = \"Density\"\n  ) +\n  theme(axis.text.x = element_text(colour = c(\"black\", \"black\", cbPalette[1], \"black\")))\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\ncoef_tstat &lt;- 2.602\ncoef_tstat_str &lt;- sprintf(\"%.02f\", coef_tstat)\nlabel_df_coef &lt;- tribble(\n    ~x, ~y, ~label,\n    3.65, 0.06, paste0(\"P(t &gt; \",coef_tstat_str,\")\\n= 0.01\")\n)\nlabel_df_signif_coef &lt;- tribble(\n  ~x, ~y, ~label,\n  1.05, 0.03, \"95% Signif.\\nCutoff\"\n)\nfuncShadedCoef &lt;- function(x) funcShaded(x, coef_tstat, Inf)\nggplot(data=data.frame(x=c(-4,4)), aes(x=x)) +\n  stat_function(fun=dnorm, linewidth=g_linewidth) +\n  geom_vline(aes(xintercept=coef_tstat), linetype=\"solid\", linewidth=g_linewidth) +\n  geom_vline(aes(xintercept=1.96), linetype=\"dashed\", linewidth=g_linewidth) +\n  stat_function(fun = funcShadedCoef, geom = \"area\", fill = cbPalette[2], alpha = 0.5) +\n  stat_function(fun = funcShadedSignif, geom = \"area\", fill = \"grey\", alpha = 0.333) +\n  # Label shaded area\n  geom_text(label_df_coef, mapping = aes(x = x, y = y, label = label), size = 10) +\n  # Label significance cutoff\n  geom_text(label_df_signif_coef, mapping = aes(x = x, y = y, label = label), size = 8) +\n  coord_cartesian(clip = \"off\") +\n  # Add single additional tick\n  scale_x_continuous(breaks=c(-4, -2, 0, 2, coef_tstat, 4), labels=c(\"-4\", \"-2\",\"0\", \"2\", coef_tstat_str,\"4\")) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title = \"t Value for Coefficient\",\n    x = \"t\",\n    y = \"Density\"\n  ) +\n  theme(axis.text.x = element_text(colour = c(\"black\", \"black\", \"black\", \"black\", cbPalette[2], \"black\")))"
  },
  {
    "objectID": "w12/slides.html#the-residual-plot",
    "href": "w12/slides.html#the-residual-plot",
    "title": "Week 12: Hypothesis Testing",
    "section": "The Residual Plot",
    "text": "The Residual Plot\n\n\n\nA key assumption required for OLS: ‚Äúhomoskedasticity‚Äù\nGiven our model \\[\ny_i = \\beta_0 + \\beta_1x_i + \\varepsilon_i\n\\] the errors \\(\\varepsilon_i\\) should not vary systematically with \\(i\\)\nFormally: \\(\\forall i \\left[ \\Var{\\varepsilon_i} = \\sigma^2 \\right]\\)\n\n\n\n\nCode\nlibrary(broom)\ngdp_resid_df &lt;- augment(lin_model)\nggplot(gdp_resid_df, aes(x = .fitted, y = .resid)) +\n    geom_point(size = g_pointsize/2) +\n    geom_hline(yintercept=0, linetype=\"dashed\") +\n    dsan_theme(\"quarter\") +\n    labs(\n      title = \"Residual Plot for Industrial ~ Military\",\n      x = \"Fitted Value\",\n      y = \"Residual\"\n    )\n\n\n\n\n\n\n\n\n\n\n\nCode\nx &lt;- 1:80\nerrors &lt;- rnorm(length(x), 0, x^2/1000)\ny &lt;- x + errors\nhet_model &lt;- lm(y ~ x)\ndf_het &lt;- augment(het_model)\nggplot(df_het, aes(x = .fitted, y = .resid)) +\n    geom_point(size = g_pointsize / 2) +\n    geom_hline(yintercept = 0, linetype = \"dashed\") +\n    dsan_theme(\"quarter\") +\n    labs(\n        title = \"Residual Plot for Heteroskedastic Data\",\n        x = \"Fitted Value\",\n        y = \"Residual\"\n    )"
  },
  {
    "objectID": "w12/slides.html#multiple-linear-regression",
    "href": "w12/slides.html#multiple-linear-regression",
    "title": "Week 12: Hypothesis Testing",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression\n\nNotation: \\(x_{i,j}\\) = value of independent variable \\(j\\) for person/observation \\(i\\)\n\\(M\\) = total number of independent variables\n\n\\[\n\\widehat{y}_i = \\beta_0 + \\beta_1x_{i,1} + \\beta_2x_{i,2} + \\cdots + \\beta_M x_{i,M}\n\\]\n\n\\(\\beta_j\\) interpretation: a one-unit increase in \\(x_{i,j}\\) is associated with a \\(\\beta_j\\) unit increase in \\(y_i\\), holding all other independent variables constant"
  },
  {
    "objectID": "w12/slides.html#the-f-test",
    "href": "w12/slides.html#the-f-test",
    "title": "Week 12: Hypothesis Testing",
    "section": "The \\(F\\)-Test",
    "text": "The \\(F\\)-Test\n\n\\(t\\)-test is to single-variable regression as \\(F\\)-test is to multiple regression\n\\(H_A: (\\beta_1 = 0) \\wedge (\\beta_2 = 0) \\wedge \\cdots \\wedge (\\beta_M = 0)\\)\n\n(‚ÄúGive up, it‚Äôs not worth doing this regression‚Äù)\n\n\\(H_0: (\\beta_1 \\neq 0) \\vee (\\beta_2 \\neq 0) \\vee \\cdots \\vee (\\beta_M \\neq 0)\\)\n\n(‚ÄúYour regression has at least one redeeming quality‚Äù)"
  },
  {
    "objectID": "w12/slides.html#key-insight-from-behavioral-economics",
    "href": "w12/slides.html#key-insight-from-behavioral-economics",
    "title": "Week 12: Hypothesis Testing",
    "section": "Key Insight From Behavioral Economics",
    "text": "Key Insight From Behavioral Economics\n\nData always has an interpretive context\nHumans are not very good at placing data in that context"
  },
  {
    "objectID": "w12/slides.html#observations-vs.-base-rates",
    "href": "w12/slides.html#observations-vs.-base-rates",
    "title": "Week 12: Hypothesis Testing",
    "section": "Observations vs.¬†Base Rates",
    "text": "Observations vs.¬†Base Rates\n\n\n\n\n\n\n\nSteve is very shy and withdrawn, invariably helpful but with very little interest in people or in the world of reality. A meek and tidy soul, he has a need for order and structure, and a passion for detail.\n\n\\(\\Pr(\\text{Steve is a librarian} \\mid \\text{description})?\\)\n\n\n\n\n\nExample from (kahneman_thinking_2011?)"
  },
  {
    "objectID": "w12/slides.html#base-rates",
    "href": "w12/slides.html#base-rates",
    "title": "Week 12: Hypothesis Testing",
    "section": "Base Rates",
    "text": "Base Rates\n\nGlobally: ~350,000 librarians vs.¬†~800 million farmers\n\n\n\nCode\nlibrary(tidyverse)\nnum_librarians &lt;- 350000\nnum_farmers &lt;- 800000000\noccu_df &lt;- tribble(\n    ~Occupation, ~Count,\n    \"Farmer\", num_farmers,\n    \"Librarian\", num_librarians,\n)\n\nggplot(occu_df, aes(x=factor(Occupation, levels=c(\"Librarian\",\"Farmer\")), y=Count, fill=Occupation)) +\n  geom_bar(stat='identity') +\n  dsan_theme() +\n  labs(\n    x = \"Occupation\",\n    y = \"Count\",\n    title = \"Librarians vs. Farmers Globally\"\n  )"
  },
  {
    "objectID": "w12/slides.html#sampling-from-the-globe",
    "href": "w12/slides.html#sampling-from-the-globe",
    "title": "Week 12: Hypothesis Testing",
    "section": "Sampling From The Globe",
    "text": "Sampling From The Globe\n\\[\n\\begin{align*}\n\\Pr(\\text{Librarian}) &= \\frac{350K}{8\\text{ Billion}} \\approx 0.00004375 \\\\\n\\Pr(\\text{Farmer}) &= \\frac{800\\text{ Million}}{8\\text{ Billion}} = 0.1\n\\end{align*}\n\\]\nMeaning, if we sample 1 million people, we would expect:\n\n44 to be librarians\n100,000 to be farmers"
  },
  {
    "objectID": "w12/slides.html#but-still",
    "href": "w12/slides.html#but-still",
    "title": "Week 12: Hypothesis Testing",
    "section": "But Still‚Ä¶",
    "text": "But Still‚Ä¶\n\nLet‚Äôs say you believe that only 1% of farmers have these traits, while 100% of librarians have these traits. Then, within our sample of 1 million, we would expect:\n44 to be librarians with these traits\n1,000 to be farmers with these traits\n\\(\\implies\\) still 22.7 times more likely that Steve is a farmer"
  },
  {
    "objectID": "w12/slides.html#the-math",
    "href": "w12/slides.html#the-math",
    "title": "Week 12: Hypothesis Testing",
    "section": "The Math",
    "text": "The Math\n\\[\n\\begin{align*}\n\\Pr(\\mathcal{H}_L \\mid E) &= \\Pr(\\text{Steve is librarian} \\mid \\text{description}) \\\\\n&= \\frac{\\Pr(\\text{description} \\mid \\text{Steve is librarian})\\Pr(\\text{Steve is librarian})}{\\Pr(\\text{description})} \\\\\n&= \\frac{(1)(0.00004375)}{\\Pr(\\text{description})} = \\frac{0.00004375}{\\Pr(\\text{description})}\n\\end{align*}\n\\]\n\n\\[\n\\begin{align*}\n\\Pr(\\mathcal{H}_F \\mid E) &= \\Pr(\\text{Steve is farmer} \\mid \\text{description}) \\\\\n&= \\frac{\\Pr(\\text{description} \\mid \\text{Steve is farmer})\\Pr(\\text{Steve is farmer})}{\\Pr(\\text{description})} \\\\\n&= \\frac{(0.01)(0.1)}{\\Pr(\\text{description})} = \\frac{0.001}{\\Pr(\\text{description})} \\\\\n\\end{align*}\n\\]\n\n\\[\n\\implies \\frac{\\Pr(\\mathcal{H}_F \\mid E)}{\\Pr(\\mathcal{H}_L \\mid E)} = \\frac{\n    \\frac{0.001}{\\Pr(\\text{description})}\n}{\n    \\frac{0.00004375}{\\Pr(\\text{description})}\n} = \\frac{0.001}{0.00004375} \\approx 23\n\\]"
  },
  {
    "objectID": "w12/slides.html#the-takeaway",
    "href": "w12/slides.html#the-takeaway",
    "title": "Week 12: Hypothesis Testing",
    "section": "The Takeaway",
    "text": "The Takeaway\n\nClassical hypothesis testing, developed in a time before computers or calculators, was an attempt to test hypotheses solely on the basis of the experimental results (then maybe, after the fact, apply a correction to ‚Äúsneak in‚Äù base rates)\nBayesian hypothesis testing, developed in a time when we have computers, explicitly casts results of experiments as weighted averages of prior evidence and newly-acquired evidence!"
  },
  {
    "objectID": "w12/slides.html#differences-vs.-ratios",
    "href": "w12/slides.html#differences-vs.-ratios",
    "title": "Week 12: Hypothesis Testing",
    "section": "Differences vs.¬†Ratios",
    "text": "Differences vs.¬†Ratios\n\nSetting: We have a sample \\(\\mathbf{X}_1\\) taken from a population \\(P_1\\) and a sample \\(\\mathbf{X}_2\\) taken from a population \\(P_2\\).\nWe care about some variable \\(v\\) that we measured as part of our sampling: in particular, we care about \\(\\mu^{(v)}_1\\), the mean of this variable in population 1, and \\(\\mu^{(v)}_2\\), the mean of this variable in population 21\nGoal: Test whether the mean of \\(v\\) in population 1 is equal to the mean of \\(v\\) in population 2. Formally, we test the hypothesis \\(\\mathcal{H}\\):\n\n\\[\n\\mathcal{H}: \\mu_1 = \\mu_2\n\\]\n\nIt is ambiguous what test statistic we should use to check this(!), since\n\\[\n  \\begin{align*}\n  \\mu_1 = \\mu_2 &\\iff \\mu_1 - \\mu_2 = 0 \\\\\n  \\mu_1 = \\mu_2 &\\iff \\frac{\\mu_1}{\\mu_2} = 0\n  \\end{align*}\n  \\]\n(where we assume, for the second equivalence, that \\(\\mu_2 \\neq 0\\))\n\nFrom here onwards I drop the \\((v)\\) superscript for brevity, but remember that we‚Äôre always talking about \\(\\mu^{(v)}_i\\): the population mean of a particular variable \\(v\\) in population \\(i\\)!"
  },
  {
    "objectID": "w12/slides.html#the-difference-in-math",
    "href": "w12/slides.html#the-difference-in-math",
    "title": "Week 12: Hypothesis Testing",
    "section": "The Difference, In Math",
    "text": "The Difference, In Math\n\nCode\nlibrary(tidyverse)\nlibrary(latex2exp)\nmy_const &lt;- function(x) 1\nmy_ratio &lt;- function(x) 1/x\n#data_df &lt;- data_df |&gt; mutate(\n#  z = my_diff(x, y)\n#)\n#print(data_df)\nx_label &lt;- TeX(\"$\\\\mu_2$\")\ntd_title &lt;- TeX(\"Stability of $t_d$\")\ntd_label &lt;- TeX(\"$t'_d(\\\\mu_2)$\")\nbase_plot &lt;- ggplot(data=data.frame(x=c(-5,5)), aes(x=x)) +\n  dsan_theme(\"quarter\") +\n  labs(\n    x = x_label\n  )\ndiff_plot &lt;- base_plot + stat_function(\n    fun = my_const,\n    linewidth = g_linewidth\n  ) + labs(\n    title = td_title,\n    y = td_label\n  )\ndiff_plot\ntr_title &lt;- TeX(\"Stability of $t_r$\")\ntr_label &lt;- TeX(\"$t'_r(\\\\mu_2)$\")\nratio_plot &lt;- base_plot + stat_function(\n    fun = my_ratio,\n    linewidth = g_linewidth\n  ) + labs(\n    title = tr_title,\n    y = tr_label\n  )\nratio_plot\n\n\n\n\n\nOur test statistic is some function \\(t(\\mu_1, \\mu_2)\\).\nLet \\(t_d(\\mu_1, \\mu_2) = \\mu_1 - \\mu_2\\)\nLet \\(t_r(\\mu_1, \\mu_2) = \\frac{\\mu_1}{\\mu_2}\\)\nHow sensitive are these two ways of defining \\(t\\) to changes in the individual terms?\n\\[\n  t'_d(\\mu_2) = \\frac{\\partial t^-(\\mu_1, \\mu_2)}{\\partial \\mu_1} = 1,\n  \\]\nwhereas\n\\[\n  t'_r(\\mu_2) = \\frac{\\partial t^\\div(\\mu_1, \\mu_2)}{\\partial \\mu_1} = \\frac{1}{\\mu_2}\n  \\]"
  },
  {
    "objectID": "w12/slides.html#the-takeaway-1",
    "href": "w12/slides.html#the-takeaway-1",
    "title": "Week 12: Hypothesis Testing",
    "section": "The Takeaway",
    "text": "The Takeaway\n\nIn scenarios where \\(\\mu\\) values are far from zero, both behave similarly\nBut in scenarios where \\(\\mu\\) values are close to zero, need to be careful about using \\(t_r(\\mu_1, \\mu_2) = \\frac{\\mu_1}{\\mu_2}\\)!\nIf \\(\\mu_2\\) could feasibly be zero‚Ä¶ \\(t_r(\\mu_1, \\mu_2) = üíÄüòµüíÄ\\)"
  },
  {
    "objectID": "w12/slides.html#moving-from-known-rightarrow-unknown-sigma",
    "href": "w12/slides.html#moving-from-known-rightarrow-unknown-sigma",
    "title": "Week 12: Hypothesis Testing",
    "section": "Moving From Known \\(\\rightarrow\\) Unknown \\(\\sigma\\)",
    "text": "Moving From Known \\(\\rightarrow\\) Unknown \\(\\sigma\\)\n\nLast week: \\(z\\)-test for scenario where we (somehow) know population variance \\(\\sigma\\)\nThis week: More realistic case where we don‚Äôt know \\(\\sigma\\), so we estimate it from our sample \\(\\mathbf{X}\\): \\(\\widehat{\\sigma^2} = s^2_{\\mathbf{X}}\\)\nThis means we have recursive uncertainty in our estimates!\n\n\\[\n\\begin{align*}\n\\widehat{\\mu}(\\mathbf{X}) = f(\\mathbf{X}) &= \\frac{1}{N}\\sum_{i=1}^{N}X_i \\\\\n\\widehat{\\sigma^2}(\\mathbf{X}) = g(\\mathbf{X}, \\widehat{\\mu}(\\mathbf{X})) &= \\frac{1}{N}\\sum_{i=1}^N (X_i - \\boxed{\\widehat{\\mu}(\\mathbf{X})})^2 \\\\\n&= \\frac{1}{N}\\sum_{i=1}^N\\left(X_i - \\boxed{\\frac{1}{N}\\sum_{j=1}^NX_j}\\right)^2\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w12/slides.html#errors-now-make-our-estimates-exponentially-worse",
    "href": "w12/slides.html#errors-now-make-our-estimates-exponentially-worse",
    "title": "Week 12: Hypothesis Testing",
    "section": "Errors Now Make Our Estimates Exponentially Worse(!)",
    "text": "Errors Now Make Our Estimates Exponentially Worse(!)\n\nImagine that when calculating \\(\\widehat{\\mu} = \\frac{1}{N}\\sum_{i=1}^nX_i\\) (recall that this is an unbiased estimator for \\(\\mu\\)), we accidentally add \\(\\varepsilon\\) to every value \\(X_i\\), so that we instead compute \\(\\widetilde{\\mu} = \\frac{1}{N}\\sum_{i=1}^n(X_i+\\varepsilon) = \\widehat{\\mu} + \\varepsilon\\)\nThis means our estimate of \\(\\mu\\) is now biased by some amount \\(\\varepsilon\\): while \\(\\mathbb{E}[\\widehat{\\mu}] = \\mu\\), \\(\\mathbb{E}[\\widetilde{\\mu}] = \\mu + {\\color{red}\\varepsilon}\\)\nHow does this affect subsequent estimates of the variance \\(\\widehat{\\sigma^2}\\)? Even if we use an unbiased estimator \\(\\widehat{\\sigma^2}\\), so that \\(\\mathbb{E}[\\widehat{\\sigma^2}] = \\sigma^2\\), we get something that looks like the following (sweeping some details under the rug):\n\n\\[\n\\mathbb{E}[\\widehat{\\sigma^2}] = \\cdots = \\sigma^2 + \\mathbb{E}[\\varepsilon^2] - 2\\varepsilon\\mathbb{E}[X_i-\\mu] = \\sigma^2 + {\\color{red}\\varepsilon^2}\n\\]\n\nWhile our estimate of the mean was off by \\({\\color{red}\\varepsilon}\\), our estimate of the variance is off by \\({\\color{red}\\varepsilon^2}\\)!\nTaking square root to obtain the standard deviation \\(\\widehat{\\sigma}\\) doesn‚Äôt ‚Äúfix‚Äù this, either, since \\(\\sqrt{\\sigma^2 + \\varepsilon^2} \\neq \\sigma + \\varepsilon\\) in general (e.g., \\(\\sqrt{2^2 + 3^2} = \\sqrt{4+9} = \\sqrt{13} \\neq 2 + 3 = 5\\))"
  },
  {
    "objectID": "w12/slides.html#z-test-rightarrow-t-test",
    "href": "w12/slides.html#z-test-rightarrow-t-test",
    "title": "Week 12: Hypothesis Testing",
    "section": "\\(z\\)-Test \\(\\rightarrow\\) \\(t\\)-Test",
    "text": "\\(z\\)-Test \\(\\rightarrow\\) \\(t\\)-Test\n\nCode\nlibrary(tidyverse)\nmy_normal &lt;- function(x) dnorm(x)\nmy_st &lt;- function(x) dt(x, 2)\nggplot(data=data.frame(x=c(-3,3)), aes(x=x)) +\n  stat_function(\n    aes(color='norm'),\n    fun=my_normal,\n    linewidth = g_linewidth\n  ) +\n  stat_function(\n    aes(color='st'),\n    fun=my_st,\n    linewidth = g_linewidth\n  ) +\n  dsan_theme(\"half\") +\n  scale_color_manual(\n    \"Distribution\",\n    values=c('norm'=cbPalette[1],'st'=cbPalette[2]),\n    labels=c('norm'=\"Standard Normal\",'st'=\"Student's t (df=2)\")\n  ) +\n  remove_legend_title() +\n  labs(\n    title = \"Standard Normal vs. Student's t Distribution\"\n  )\n\n\n\n\n\nThe Takeaway:\n\n\nWhen we know \\(\\sigma^2\\) but we estimate \\(\\mu\\) from a sample, we represent our uncertainty via test statistic \\(z \\sim \\mathcal{N}(\\widehat{\\mu}, \\sigma^2)\\)\nWhen we estimate both \\(\\mu\\) and \\(\\sigma^2\\) from a sample, we use a test statistic \\(t\\) with a wider ‚ÄúStudent‚Äôs \\(t\\)‚Äù Distribution in place of the Normal Distribution: \\(t \\sim \\mathcal{T}(\\widehat{\\mu}, \\widehat{\\sigma}^2, N)\\)\nAs \\(N \\rightarrow \\infty\\), \\(\\mathcal{T}_N(\\widehat{\\mu},\\widehat{\\sigma}^2,N) \\rightarrow \\mathcal{N}(\\widehat{\\mu},\\widehat{\\sigma}^2)\\)\n\n\n\n\n\n\n\n\nA comparison of the two distributions, showing how the Student‚Äôs t Distribution has greater variance, representing the greater uncertainty when estimating two population parameters instead of just one"
  },
  {
    "objectID": "w12/slides.html#in-r",
    "href": "w12/slides.html#in-r",
    "title": "Week 12: Hypothesis Testing",
    "section": "In R",
    "text": "In R\n\nLet‚Äôs create a tibble containing samples from two populations\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(infer)\nnl_height_mean &lt;- 182.535\nnl_height_sd &lt;- 8\nyemen_height_mean &lt;- 159.887\nyemen_height_sd &lt;- 8\nN &lt;- 100\nnl_sample &lt;- rnorm(N, mean=nl_height_mean, sd = nl_height_sd)\nnl_df &lt;- tibble(height=nl_sample, Country=\"Netherlands\")\nyemen_sample &lt;- rnorm(N, mean=yemen_height_mean, sd = yemen_height_sd)\nyemen_df &lt;- tibble(height=yemen_sample, Country=\"Yemen\")\ndata_df &lt;- bind_rows(nl_df, yemen_df)\nggplot(data_df, aes(x=height, fill=Country)) +\n  geom_density(alpha=0.5) + \n  dsan_theme() +\n  #xlim(150,200) +\n  labs(\n    title = \"Mean Heights: Yemen (N=100) vs. Netherlands (N=100)\",\n    x = \"Height (cm)\",\n    y = \"Sample Probability Density\"\n  ) +\n  scale_fill_manual(\"Country\", values=c('Netherlands'=cbPalette[1], 'Yemen'=cbPalette[2]))\n\n\n\n\n\\(H_0: \\mu_{\\text{NL}} - \\mu_{\\text{Yem}} = 0\\), \\(H_A: \\mu_{\\text{NL}} - \\mu_{\\text{Yem}} &gt; 0\\), \\(t = \\overline{h}_{\\text{NL}} - \\overline{h}_{\\text{Yem}}\\)"
  },
  {
    "objectID": "w12/slides.html#the-infer-package",
    "href": "w12/slides.html#the-infer-package",
    "title": "Week 12: Hypothesis Testing",
    "section": "The infer Package",
    "text": "The infer Package\n\nIt‚Äôs easy to find resources on built-in t.test(), harder to find resources on newer, tidyverse-based t_test()! üòâ\nSyntax is t_test(df, formula, order, alternative)\norder = c(pop1, pop2) \\(\\rightarrow H_0: \\mu_1 - \\mu_2 = 0\\)\nalternative = {\"two-sided\", \"greater\", \"less\"}\nformula slightly trickier, but tldr is:\nvariable you're computing means for ~ variable splitting df into two populations\n\n\n\nCode\ndata_df |&gt; t_test(formula = height ~ Country, order = c(\"Netherlands\", \"Yemen\"), alternative = \"greater\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstatistic\nt_df\np_value\nalternative\nestimate\nlower_ci\nupper_ci\n\n\n\n\n18.7634\n196.2509\n0\ngreater\n20.13126\n18.35813\nInf"
  },
  {
    "objectID": "w12/slides.html#the-chi-squared-test-of-independence",
    "href": "w12/slides.html#the-chi-squared-test-of-independence",
    "title": "Week 12: Hypothesis Testing",
    "section": "The Chi-Squared Test of Independence",
    "text": "The Chi-Squared Test of Independence\n\n\n\n\n\n\n\n\n\n\\(z\\)-Tests and \\(t\\)-Tests\n\n\n\n\n\n\n\nThe Chi-Squared Test"
  },
  {
    "objectID": "w12/slides.html#what-hypothesis-are-we-testing",
    "href": "w12/slides.html#what-hypothesis-are-we-testing",
    "title": "Week 12: Hypothesis Testing",
    "section": "What Hypothesis Are We Testing?",
    "text": "What Hypothesis Are We Testing?\n\n\\(z\\)-Tests and \\(t\\)-Tests might feel a bit weak: they allow us to hypothesize about a single population parameter, which is nice, but throughout the course we have been talking about distributions, not just means or variances!\nThe Chi-Squared Test allows us to hypothesize about distributions: for categorical random variables \\(X_1\\) and \\(X_2\\) we can test the null and alternative hypotheses:\n\n\\[\n\\begin{align*}\nH_0: X_1 \\perp X_2 &\\iff \\Pr(X_1 = v_1 \\mid X_2 = v_2) = \\Pr(X_1 = v_1) \\\\\nH_A: X_1 \\not\\perp X_2 &\\iff \\Pr(X_1 = v_1 \\mid X_2 = v_2) \\neq \\Pr(X_1 = v_1)\n\\end{align*}\n\\]\n\n\\(H_0\\) in words: ‚Äúlearning the value of \\(X_2\\) does not give me any information about the value of \\(X_1\\), and vice-versa‚Äù"
  },
  {
    "objectID": "w12/slides.html#base-notation",
    "href": "w12/slides.html#base-notation",
    "title": "Week 12: Hypothesis Testing",
    "section": "Base Notation",
    "text": "Base Notation\n\n(May seem tedious, but you will be thankful later if you use this notation!)\nLet \\(N\\) be the total number of samples we have in our dataset\nLet \\(K_1\\) be the total number of categories that \\(X_1\\) can take on: formally, \\(K_1 = |\\mathcal{R}_{X_1}|\\).\nSimilarly, let \\(K_2 = |\\mathcal{R}_{X_2}|\\), the cardinality of the support of \\(X_2\\).\nWe will use a lowercase \\(k_{1,i}\\) to represent the \\(i\\)th possible value of \\(X_1\\), (i.e., the \\(i\\)th element of \\(\\mathcal{R}_{X_1}\\)), and \\(k_{2,i}\\) to represent the \\(i\\)th possible value of \\(\\mathcal{R}_{X_2}\\).\n\ne.g., \\(k_{1,1}\\) is the first element of \\(\\mathcal{R}_{X_1}\\), \\(k_{1,2}\\) is the second element of \\(\\mathcal{R}_{X_2}\\), and so on."
  },
  {
    "objectID": "w12/slides.html#joint-and-marginal-frequencies",
    "href": "w12/slides.html#joint-and-marginal-frequencies",
    "title": "Week 12: Hypothesis Testing",
    "section": "Joint and Marginal Frequencies",
    "text": "Joint and Marginal Frequencies\n\nNow we can define the central quantities that the chi-squared test involves: the frequencies (i.e., unnormalized probabilities) of observations with certain (categorical) variable values:\n\\(f_{i,j}\\): The number of observations for which \\(X_1 = k_{1,i}\\) (the \\(i\\)th value that \\(X_1\\) can take on) and \\(X_2 = k_{2,j}\\) (the \\(j\\)th value that \\(X_2\\) can take on).\n\nExample: \\(f_{1,3}\\), represents the number of observations for which \\(X_1 = k_{1,1}\\) and \\(X_2 = k_{2,3}\\).\n\nLet \\(f_{i,\\cdot} = \\sum_{j=1}^{K_2}f_{i,j}\\) be the number of observations for which \\(X_1 = k_{1,i}\\), regardless of the value of \\(X_2\\) (hence we call this the marginal frequency of \\(X_1 = k_{1,i}\\)).\n\n\\(f_{7,\\cdot}\\), for example, represents the number of observations for which \\(X_1 = k_{1,7}\\), regardless of the values of \\(X_2\\) across these observations.\nThis is called ‚Äúdot notation‚Äù, and makes it easy for us to notationally represent which marginal distributions we are talking about.\n\nSimilarly, let \\(f_{\\cdot, j} = \\sum_{i=1}^{K_1}f_{i,j}\\) be the marginal frequency with which songs have \\(V_2 = k_j\\). \\(f_{\\cdot, 2}\\), for example, represents the number of songs for which the valence value is at level 2 (Moderate), regardless of its artist."
  },
  {
    "objectID": "w12/slides.html#we-made-it",
    "href": "w12/slides.html#we-made-it",
    "title": "Week 12: Hypothesis Testing",
    "section": "We Made It",
    "text": "We Made It\n\nWe can finally compute the test statistic for the Chi-Squared Test, \\(Q\\)!\n\n\\[\nQ = \\sum_{k_1=1}^{K_1}\\sum_{k_2=1}^{K_2}\\frac{\\left(f_{k_1,k_2} - \\frac{f_{k_1,\\cdot}f_{\\cdot,k_2}}{N}\\right)^2}{\\frac{f_{k_1,\\cdot}f_{\\cdot, k_2}}{N}}\n\\]\n\nThis test statistic has (by construction) a Chi-Squared Distribution with \\((K_1 - 1)(K_2 - 1)\\) degrees of freedom"
  },
  {
    "objectID": "w12/slides.html#in-r-1",
    "href": "w12/slides.html#in-r-1",
    "title": "Week 12: Hypothesis Testing",
    "section": "In R",
    "text": "In R\nWe can compute this test statistic (somewhat laboriously) in R as follows: first let‚Äôs create variables representing the supports \\(\\mathcal{R}_{X_1}\\) and \\(\\mathcal{R}_{X_2}\\) for our two random variables \\(X_1\\) and \\(X_2\\):\n\n\nCode\n#(L1 &lt;- sort(unique(artist_df$artist_name)))\n#K1 &lt;- length(L1)\n# Here we set this manually, rather than using unique(), so we can obtain a specific ordering that we want\n#(L2 &lt;- c(\"more negative\", \"Moderate\", \"more positive\"))\n#K2 &lt;- length(L2)"
  },
  {
    "objectID": "w12/slides.html#computing-marginal-frequencies",
    "href": "w12/slides.html#computing-marginal-frequencies",
    "title": "Week 12: Hypothesis Testing",
    "section": "Computing Marginal Frequencies",
    "text": "Computing Marginal Frequencies\n\nNext we pre-compute the marginal frequencies for all possible \\(X_1\\) values (all elements of \\(\\mathcal{R}_{X_1}\\)) and then for all possible \\(X_2\\) values (all elements of \\(\\mathcal{R}_{X_2}\\)):\n\n\n\nCode\n1\n\n\n[1] 1"
  },
  {
    "objectID": "w12/slides.html#computing-the-test-statistic",
    "href": "w12/slides.html#computing-the-test-statistic",
    "title": "Week 12: Hypothesis Testing",
    "section": "Computing the Test Statistic",
    "text": "Computing the Test Statistic\n\nFinally, we can compute the individual bin frequencies \\(f_{i,j}\\) in a loop (there are more efficient ways to do this, which we‚Äôd want to adopt instead if our dataset was much larger, for example):\n\n\n\nCode\n# q_sum &lt;- 0\n# for (k1 in 1:K1) {\n#   artist_name_value &lt;- L1[k1]\n#   artist_marginal_freq &lt;- L1_marginal_freqs[k1]\n#   for (k2 in 1:K2) {\n#     valence_value &lt;- L2[k2]\n#     valence_marginal_freq &lt;- L2_marginal_freqs[k2]\n#     print(paste0(\"(\",artist_name_value,\", \",valence_value,\")\"))\n#     # Compute the frequency in this bin\n#     bin_df &lt;- artist_df |&gt; filter(artist_name == artist_name_value & valence_C == valence_value)\n#     print(nrow(bin_df))\n#     # And now, since we precomputed the marginal frequencies, we have everything we need!\n#     joint_freq &lt;- nrow(bin_df)\n#     marginal_ratio &lt;- (artist_marginal_freq * valence_marginal_freq) / N\n#     numer &lt;- (joint_freq - marginal_ratio)^2\n#     denom &lt;- marginal_ratio\n#     cur_q_val &lt;- numer / denom\n#     q_sum &lt;- q_sum + cur_q_val\n#   }\n# }\n\n# q_sum"
  },
  {
    "objectID": "w12/slides.html#interpretation",
    "href": "w12/slides.html#interpretation",
    "title": "Week 12: Hypothesis Testing",
    "section": "Interpretation",
    "text": "Interpretation\n\nSince we know this test statistic \\(Q\\) follows (asymptotically/approximately) a chi-squared distribution with \\((K_1 - 1)(K_2 - 1)\\) degrees of freedom, we can compute the probability of obtaining a test statistic value this high or higher (14.162598), using R‚Äôs built-in dchisq() function:\n\n\n\nCode\n#(test_df &lt;- (K1 - 1) * (K2 - 2))\n#dchisq(q_sum, test_df)"
  },
  {
    "objectID": "w12/slides.html#drawing-conclusions-in-classical-world",
    "href": "w12/slides.html#drawing-conclusions-in-classical-world",
    "title": "Week 12: Hypothesis Testing",
    "section": "Drawing Conclusions in Classical World",
    "text": "Drawing Conclusions in Classical World\nAnd so, finally: this tells us that under the null hypothesis that artist_name and valence_C represent draws from independent random variables, the likelihood of obtaining our dataset, or a dataset with a more extreme test statistic, is about 0.00042, or 0.042%.\nTherefore, if we are evaluating our hypothesis at the 5% confidence level (or 1% or even 0.1%, because this is a very low probability value/percentage), we conclude that we should reject the null hypothesis that artist name and valence are independent. Therefore (switching from a frequentist to a Bayesian interpretation, mercifully), we increase our degree of belief in the hypothesis that the valence of a song does depend upon the artist making the song."
  },
  {
    "objectID": "w12/slides.html#drawing-conclusions-in-modern-bayesian-world",
    "href": "w12/slides.html#drawing-conclusions-in-modern-bayesian-world",
    "title": "Week 12: Hypothesis Testing",
    "section": "Drawing Conclusions in Modern (Bayesian) World",
    "text": "Drawing Conclusions in Modern (Bayesian) World\nThis technical conclusion (which focuses only on the results of the statistical hypothesis test), combined with the Bayesian interpretation at the end, lets us say something about ‚Äúwhat we‚Äôve learned‚Äù about music:\n\nOur Bayesian prior on the null hypothesis, \\(\\Pr(H_0) = \\Pr(V \\perp A)\\), was probably quite small: before performing this analysis, we probably did not think that these two variables are independent, since we know that some artists tend to make more sad songs, while other artists tend to make more happy songs (though there are obviously exceptions: bands that tend to make a mix of sad and happy songs).\nThen we performed the analysis, and failed to reject the hypothesis that these two variables are independent.\nTherefore, our Bayesian posterior on \\(\\Pr(V \\perp A)\\) should be slightly lower: If our prior probability on \\(H_0\\) was some value \\(p\\), our posterior probability now that we‚Äôve performed the study and failed to reject the null hypothesis should be \\(p - \\varepsilon\\), for some appropriate value \\(\\varepsilon\\) representing the relative balance between (our view of) the veracity of the prior vs.¬†the veracity of the test we performed.\nTo make it concrete: if we previously believed that \\(p = \\Pr(H_0) = 0.1\\), perhaps now we can update our beliefs such that \\(p = \\Pr(H_0) = 0.05\\). This would represent the case where we lend equal credence in our prior and in our experiement, since then\n\n\\[\np_{post} = \\frac{1}{2}\\Pr(H_0) + \\frac{1}{2}\\text{Test Result} = \\frac{1}{2}(0.1) + \\frac{1}{2}(0) = 0.05.\n\\]"
  },
  {
    "objectID": "w12/slides.html#references",
    "href": "w12/slides.html#references",
    "title": "Week 12: Hypothesis Testing",
    "section": "References",
    "text": "References\n\n\nGelman, Andrew, and Jennifer Hill. 2007. Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge University Press.\n\n\n\n\n\nDSAN 5100-03 W12: Hypothesis Testing"
  },
  {
    "objectID": "w12/index.html",
    "href": "w12/index.html",
    "title": "Week 12: Hypothesis Testing",
    "section": "",
    "text": "Open slides in new window ‚Üí",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#classical-test-1-the-z-test",
    "href": "w12/index.html#classical-test-1-the-z-test",
    "title": "Week 12: Hypothesis Testing",
    "section": "Classical Test 1: The \\(z\\)-Test",
    "text": "Classical Test 1: The \\(z\\)-Test\n\nNull hypothesis: \\(H_0: \\mu = \\mu_0\\); Test statistic \\(Z = \\frac{\\overline{X} - \\mu_0}{\\sigma / \\sqrt{N}}\\)\n\n\n\n\n\n\n\n\nAlternative Hypothesis\nP-Value Determination\n\n\n\n\n\\(H_A: \\mu &gt; \\mu_0\\)\nArea under the standard normal curve to the right of \\(z\\)\n\n\n\\(H_A: \\mu &lt; \\mu_0\\)\nArea under the standard normal curve to the left of \\(z\\)\n\n\n\\(H_A: \\mu \\neq \\mu_0\\)\n\\(2~ \\cdot\\) (Area under the standard normal curve to the right of \\(|z|\\))\n\n\n\n\nAssumptions: A normal population distribution with known value of \\(\\sigma\\).",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#example-1-bird-wingspans",
    "href": "w12/index.html#example-1-bird-wingspans",
    "title": "Week 12: Hypothesis Testing",
    "section": "Example 1: Bird Wingspans",
    "text": "Example 1: Bird Wingspans\n\nTrying to figure out the population distribution of bird wingspans.\nWe hypothesize \\(\\mu_0 = 120\\text{cm}\\)\nSomehow we know the population variance \\(\\sigma = 20\\text{cm}\\), and we know that bird wingspans form a normal distribution, but we don‚Äôt know the true \\(\\mu\\):\n\n\nlibrary(tidyverse)\nhyp_mu &lt;- 120\nsigma &lt;- 20\nbird_dnorm &lt;- function(x) dnorm(x, mean=hyp_mu, sd=sigma)\nsigma_df &lt;- tribble(\n    ~x,\n    hyp_mu - 3 * sigma,\n    hyp_mu - 2 * sigma,\n    hyp_mu - 1 * sigma,\n    hyp_mu + 1 * sigma,\n    hyp_mu + 2 * sigma,\n    hyp_mu + 3 * sigma\n)\nsigma_df &lt;- sigma_df |&gt; mutate(\n    y = 0,\n    xend = x,\n    yend = bird_dnorm(x)\n)\nplot_rad &lt;- 4 * sigma\nplot_bounds &lt;- c(hyp_mu - plot_rad, hyp_mu + plot_rad)\nbird_plot &lt;- ggplot(data=data.frame(x=plot_bounds), aes(x=x)) +\n  stat_function(fun=bird_dnorm, linewidth=g_linewidth) +\n  geom_vline(aes(xintercept=hyp_mu), linewidth=g_linewidth) +\n  geom_segment(data=sigma_df, aes(x=x, y=y, xend=xend, yend=yend), linewidth=g_linewidth, linetype=\"dashed\") +\n  dsan_theme(\"half\") +\n  labs(\n    title = \"Our Hypothesized Bird Distribution\",\n    x = \"Wingspan Values (m)\",\n    y = \"Probability Density\"\n  )\nbird_plot",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#a-wild-sample-appears",
    "href": "w12/index.html#a-wild-sample-appears",
    "title": "Week 12: Hypothesis Testing",
    "section": "A Wild Sample Appears!",
    "text": "A Wild Sample Appears!\n\nWhile we are pondering, someone runs into the room and tosses us a big crate \\(\\mathbf{X}\\), a random sample of \\(N = 16\\) birds from the population üò∞\nRecovering from the shock, we measure each bird‚Äôs wingspan \\(X_i\\) and find \\(\\overline{X} = 131\\text{cm}\\)\nWhat can we infer about our hypothesized \\(\\mu\\), now that we have a sample statistic \\(\\overline{X}\\)?\nWe cannot just plot \\(\\overline{X} = 131\\) on the hypothesized bird distribution from the previous slide (an easy mistake to make!)\nApples and oranges: the distribution below is a distribution of individual bird wingspans, but \\(\\overline{X}\\) is a mean of 16 bird wingspans\nWhat we can do is: think about what the distribution of sample means from \\(N = 16\\) samples would look like if \\(\\mu = \\mu_0\\)!",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#what-would-sample-means-look-like-if-hypothesis-was-true",
    "href": "w12/index.html#what-would-sample-means-look-like-if-hypothesis-was-true",
    "title": "Week 12: Hypothesis Testing",
    "section": "What Would Sample Means Look Like If Hypothesis Was True?",
    "text": "What Would Sample Means Look Like If Hypothesis Was True?\n\nWhat we know, from asymptotic sample theory, is that \\(Z = \\frac{\\overline{X} - \\mu}{\\sigma / \\sqrt{N}}\\) is approximately standard normal, for sufficiently large values of \\(N\\)!\nSo, let‚Äôs (1) plot this distribution, for a bunch of potential sample means, and then (2) see where our actual observed sample mean lies on this distribution!\nSanity check: let‚Äôs actually simulate taking sample means from 1000 size-16 samples:\n\n\nsimulate_sample_mean &lt;- function(N, mu, sigma) {\n    samples &lt;- rnorm(N, mu, sigma)\n    sample_mean &lt;- mean(samples)\n    return(sample_mean)\n}\nN &lt;- 16\nobs_sample_mean &lt;- 129\nnum_reps &lt;- 10000\nsample_means &lt;- as_tibble(replicate(num_reps, simulate_sample_mean(N, hyp_mu, sigma)))\nasymp_dnorm &lt;- function(x) dnorm((x - hyp_mu)/(sigma / sqrt(N)), 0, 1)\nggplot() +\n  geom_histogram(\n    data=sample_means,\n    aes(x=value, y=5*after_stat(density)),\n    binwidth=1) +\n  stat_function(\n    data=data.frame(x=c(100,140)),\n    aes(x=x, color='asymp'),\n    fun=asymp_dnorm,\n    linewidth = g_linewidth\n  ) +\n  geom_segment(\n    aes(x = obs_sample_mean, xend=obs_sample_mean, y=-Inf, yend=Inf, color='obs'),\n    linewidth = g_linewidth\n  ) +\n  dsan_theme(\"half\") +\n  labs(\n    x = \"Simulated Sample Mean\",\n    y = \"(Empirical) Density\",\n    title = paste0(num_reps,\" Simulated Sample Means, N = 16\")\n  ) +\n  scale_color_manual(values=c('asymp'='black', 'obs'=cbPalette[1]), labels=c('asymp'='Asymptotic\\nDistribution', 'obs'='Observed\\nSample Mean')) +\n  remove_legend_title()",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#right-tailed-test",
    "href": "w12/index.html#right-tailed-test",
    "title": "Week 12: Hypothesis Testing",
    "section": "Right-Tailed Test",
    "text": "Right-Tailed Test\n\nNull hypothesis (in all cases) is \\(H_0: \\mu = \\mu_0\\); Right-tailed test is of alternative hypothesis \\(H_A: \\mu &gt; \\mu_0\\)\nWe reject the null if the observed sample mean \\(\\overline{X} = 131\\) is too unlikely in the world where the null is true: \\(Z(\\overline{X}) \\approx 1.8\\)\nWhat cutoff should we use for ‚Äútoo unlikely‚Äù? (See last week‚Äôs slides‚Ä¶) here we‚Äôll use \\(\\alpha = 0.05\\): \\(\\int_{1.645}^{\\infty}\\varphi(x)dx = 0.05\\), so \\(1.645\\) is our ‚Äúcritical‚Äù (cutoff) value\n\n\nlabel_df_signif_int &lt;- tribble(\n    ~x, ~y, ~label,\n    0.55, 0.04, \"95% Signif.\\nCutoff\"\n)\nsignif_cutoff &lt;- 1.645\nfuncShaded &lt;- function(x, lower_bound, upper_bound){\n    y &lt;- dnorm(x)\n    y[x &lt; lower_bound | x &gt; upper_bound] &lt;- NA\n    return(y)\n}\nfuncShadedIntercept &lt;- function(x) funcShaded(x, int_tstat, Inf)\nfuncShadedSignif &lt;- function(x) funcShaded(x, signif_cutoff, Inf)\ncompute_z_val &lt;- function(x) {\n    return ((x - hyp_mu) / (sigma / sqrt(N)))\n}\nobs_zval &lt;- compute_z_val(obs_sample_mean)\nobs_zval_str &lt;- sprintf(\"%.2f\", obs_zval)\nsample_dnorm &lt;- function(x) dnorm(compute_z_val(x))\nggplot(data=data.frame(x=c(-3,3)), aes(x=x)) +\n  stat_function(fun=dnorm, linewidth=g_linewidth) +\n  #geom_segment(data=sigma_df, aes(x=x, y=y, xend=xend, yend=yend), linewidth=g_linewidth, linetype=\"dashed\") +\n  stat_function(fun = funcShadedSignif, geom = \"area\", fill = \"grey\", alpha = 0.333) +\n  geom_vline(aes(xintercept = signif_cutoff), linewidth=g_linewidth, linetype=\"dashed\") +\n  geom_text(label_df_signif_int, mapping = aes(x = x, y = y, label = label), size = 8) +\n  geom_vline(aes(xintercept = obs_zval, color='sample_mean'), linewidth=g_linewidth) +\n  dsan_theme(\"half\") +\n  labs(\n    title = \"z-Test Distribution\",\n    x = \"z Scores\",\n    y = \"Probability Density\"\n  ) +\n  scale_color_manual(values=c('sample_mean'=cbPalette[1]), labels=c('sample_mean'='Z(Observed Sample Mean)')) +\n  remove_legend_title()\n\n\n\n\n\n\n\n\n\nSince \\(Z(\\overline{X}) &gt; 1.645\\), we reject the null hypothesis that this sample mean was generated by a distribution with mean \\(\\mu_0\\)!",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#two-tailed-test",
    "href": "w12/index.html#two-tailed-test",
    "title": "Week 12: Hypothesis Testing",
    "section": "Two-Tailed Test",
    "text": "Two-Tailed Test\n\nNull hypothesis (in all cases) is \\(H_0: \\mu = \\mu_0\\); Two-tailed test is of alternative hypothesis \\(H_A: \\mu \\neq \\mu_0\\) (the actual logical negation of the null hypothesis‚Ä¶)\nReject the null if observed sample mean \\(\\overline{X} = 131\\) is too unlikely in null world\nWhat cutoff should we use for ‚Äútoo unlikely‚Äù? Here we‚Äôll use \\(\\alpha = 0.05\\), but for a two tailed test we find \\(\\int_{-\\infty}^{-1.96}\\varphi(x)dx + \\int_{1.96}^{\\infty}\\varphi(x)dx = 0.05\\), so \\(1.96\\) is our ‚Äúcritical‚Äù (cutoff) value\n\n\nsignif_cutoff &lt;- 1.96\nneg_signif_cutoff &lt;- -signif_cutoff\nlabel_df_signif_int &lt;- tribble(\n    ~x, ~y, ~label,\n    -2.45, 0.18, paste0(\"Left\\nCutoff\\n(\",neg_signif_cutoff,\")\"),\n    2.45, 0.18, paste0(\"Right\\nCutoff\\n(\",signif_cutoff,\")\")\n)\nfuncShaded &lt;- function(x, lower_bound, upper_bound){\n    y &lt;- dnorm(x)\n    y[x &lt; lower_bound | x &gt; upper_bound] &lt;- NA\n    return(y)\n}\nfuncShadedIntercept &lt;- function(x) funcShaded(x, int_tstat, Inf)\nfuncShadedNegSignif &lt;- function(x) funcShaded(x, -Inf, neg_signif_cutoff)\nfuncShadedSignif &lt;- function(x) funcShaded(x, signif_cutoff, Inf)\ncompute_z_val &lt;- function(x) {\n    return ((x - hyp_mu) / (sigma / sqrt(N)))\n}\nobs_zval &lt;- compute_z_val(obs_sample_mean)\nsample_dnorm &lt;- function(x) dnorm(compute_z_val(x))\nggplot(data=data.frame(x=c(-3,3)), aes(x=x)) +\n  stat_function(fun=dnorm, linewidth=g_linewidth) +\n  #geom_segment(data=sigma_df, aes(x=x, y=y, xend=xend, yend=yend), linewidth=g_linewidth, linetype=\"dashed\") +\n  stat_function(fun = funcShadedSignif, geom = \"area\", fill = \"grey\", alpha = 0.333) +\n  stat_function(fun = funcShadedNegSignif, geom = \"area\", fill = \"grey\", alpha = 0.333) +\n  geom_vline(aes(xintercept = neg_signif_cutoff), linewidth=g_linewidth, linetype=\"dashed\") +\n  geom_vline(aes(xintercept = signif_cutoff), linewidth=g_linewidth, linetype=\"dashed\") +\n  geom_text(label_df_signif_int, mapping = aes(x = x, y = y, label = label), size = 8) +\n  geom_vline(aes(xintercept = obs_zval, color='sample_mean'), linewidth=g_linewidth) +\n  dsan_theme(\"half\") +\n  labs(\n    title = \"z-Test Distribution\",\n    x = \"z Scores\",\n    y = \"Probability Density\"\n  ) +\n  scale_color_manual(values=c('sample_mean'=cbPalette[1]), labels=c('sample_mean'='Z(Observed Sample Mean)')) +\n  remove_legend_title()\n\n\n\n\n\n\n\n\n\nSince \\(|Z(\\overline{X})| &lt; 1.96\\), we fail to reject the null hypothesis that this sample mean was generated by a distribution with mean \\(\\mu_0\\)!",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#errors-in-classical-hypothesis-testing",
    "href": "w12/index.html#errors-in-classical-hypothesis-testing",
    "title": "Week 12: Hypothesis Testing",
    "section": "Errors in Classical Hypothesis Testing",
    "text": "Errors in Classical Hypothesis Testing\n\nSince we‚Äôre trying to infer something about the population using only a sample, we may make one of the following types of errors:\n\n\n\n\n\n\n\n\nType I Error\nType II Error\n\n\n\n\n\n\n\n\\(H_0\\) is:\n\n\nDecision:\nTrue\nFalse\n\n\n\n\nDo not reject \\(H_0\\)\nCorrect decision\nType II error\n\n\nReject \\(H_0\\)\nType I error\nCorrect decision",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#what-is-regression",
    "href": "w12/index.html#what-is-regression",
    "title": "Week 12: Hypothesis Testing",
    "section": "What Is Regression?",
    "text": "What Is Regression?\n\nIf science is understanding relationships between variables, regression is the most basic but fundamental tool we have to start measuring these relationships\nOften exactly what humans do when we see data!\n\n\n\n\nlibrary(ggplot2)\nlibrary(tibble)\nx_data &lt;- seq(from=0, to=1, by=0.02)\nnum_x &lt;- length(x_data)\ny_data &lt;- x_data + runif(num_x, 0, 0.2)\nreg_df &lt;- tibble(x=x_data, y=y_data)\nggplot(reg_df, aes(x=x, y=y)) +\n  geom_point(size=g_pointsize) +\n  dsan_theme(\"quarter\")\n\n\n\n\n\n\n\n\n\n\n\n psychology   psychology   trending_flat \n\n\n\n\nggplot(reg_df, aes(x=x, y=y)) + \n  geom_point(size=g_pointsize) +\n  geom_smooth(method = \"lm\", se = FALSE, color = cbPalette[1], formula = y ~ x, linewidth = g_linewidth*3) +\n  dsan_theme(\"quarter\")",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#the-goal",
    "href": "w12/index.html#the-goal",
    "title": "Week 12: Hypothesis Testing",
    "section": "The Goal",
    "text": "The Goal\n\nWhenever you carry out a regression, keep the goal in the front of your mind:\n\n\n\n\n\n\n\n The Goal of Regression\n\n\n\nFind a line \\(\\widehat{y} = mx + b\\) that best predicts \\(Y\\) for given values of \\(X\\)",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#how-do-we-define-best",
    "href": "w12/index.html#how-do-we-define-best",
    "title": "Week 12: Hypothesis Testing",
    "section": "How Do We Define ‚ÄúBest‚Äù?",
    "text": "How Do We Define ‚ÄúBest‚Äù?\n\nIntuitively, two different ways to measure how well a line fits the data:\n\n\n\n\nset.seed(5100)\nN &lt;- 11\nx &lt;- seq(from = 0, to = 1, by = 1 / (N - 1))\ny &lt;- x + rnorm(N, 0, 0.25)\nmean_y &lt;- mean(y)\nspread &lt;- y - mean_y\ndf &lt;- tibble(x = x, y = y, spread = spread)\nggplot(df, aes(x=x, y=y)) +\n  geom_abline(slope=1, intercept=0, linetype=\"dashed\", color=cbPalette[1], linewidth=g_linewidth*2) +\n  geom_segment(xend=(x+y)/2, yend=(x+y)/2, linewidth=g_linewidth*2, color=cbPalette[2]) +\n  geom_point(size=g_pointsize) +\n  coord_equal() +\n  dsan_theme(\"full\") +\n  labs(\n    title = \"Principal Component Line\"\n  )\n\n\n\n\n\n\n\n\n\n\nggplot(df, aes(x=x, y=y)) +\n  geom_point(size=g_pointsize) +\n  geom_abline(slope=1, intercept=0, linetype=\"dashed\", color=cbPalette[1], linewidth=g_linewidth*2) +\n  geom_segment(xend=x, yend=x, linewidth=g_linewidth*2, color=cbPalette[2]) +\n  dsan_theme(\"full\") +\n  labs(\n    title = \"Regression Line\"\n  ) +\n  coord_equal()\n\n\n\n\n\n\n\n\n\n\n\n\nOn the difference between these two lines, and why it matters, I cannot recommend Gelman and Hill (2007) enough!",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#principal-component-analysis",
    "href": "w12/index.html#principal-component-analysis",
    "title": "Week 12: Hypothesis Testing",
    "section": "Principal Component Analysis",
    "text": "Principal Component Analysis\n\nPrincipal Component Line allows projecting data onto its dimension of highest variance\nMore simply: PCA can discover meaningful axes in data (unsupervised learning / exploratory data analysis settings)\n\n\nlibrary(readr)\nlibrary(ggplot2)\ngdp_df &lt;- read_csv(\"assets/gdp_pca.csv\")\n\ndist_to_line &lt;- function(x0, y0, a, c) {\n    numer &lt;- abs(a * x0 - y0 + c)\n    denom &lt;- sqrt(a * a + 1)\n    return(numer / denom)\n}\n# Finding PCA line for industrial vs. exports\nx &lt;- gdp_df$industrial\ny &lt;- gdp_df$exports\nlossFn &lt;- function(lineParams, x0, y0) {\n    a &lt;- lineParams[1]\n    c &lt;- lineParams[2]\n    return(sum(dist_to_line(x0, y0, a, c)))\n}\no &lt;- optim(c(0, 0), lossFn, x0 = x, y0 = y)\nggplot(gdp_df, aes(x = industrial, y = exports)) +\n    geom_point(size=g_pointsize/2) +\n    geom_abline(aes(slope = o$par[1], intercept = o$par[2], color=\"pca\"), linewidth=g_linewidth, show.legend = TRUE) +\n    geom_smooth(aes(color=\"lm\"), method = \"lm\", se = FALSE, linewidth=g_linewidth, key_glyph = \"blank\") +\n    scale_color_manual(element_blank(), values=c(\"pca\"=cbPalette[2],\"lm\"=cbPalette[1]), labels=c(\"Regression\",\"PCA\")) +\n    dsan_theme(\"half\") +\n    remove_legend_title() +\n    labs(\n      title = \"PCA Line vs. Regression Line\",\n        x = \"Industrial Production (% of GDP)\",\n        y = \"Exports (% of GDP)\"\n    )\n\n\n\n\n\n\n\n\n\nSee here for an amazing blog post using PCA to explore UN voting patterns!",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#create-your-own-dimension",
    "href": "w12/index.html#create-your-own-dimension",
    "title": "Week 12: Hypothesis Testing",
    "section": "Create Your Own Dimension!",
    "text": "Create Your Own Dimension!\n\nggplot(gdp_df, aes(pc1, .fittedPC2)) +\n    geom_point(size = g_pointsize/2) +\n    geom_hline(aes(yintercept=0, color='PCA Line'), linetype='solid', size=g_linesize) +\n    geom_rug(sides = \"b\", linewidth=g_linewidth/1.2, length = unit(0.1, \"npc\"), color=cbPalette[3]) +\n    expand_limits(y=-1.6) +\n    scale_color_manual(element_blank(), values=c(\"PCA Line\"=cbPalette[2])) +\n    dsan_theme(\"full\") +\n    remove_legend_title() +\n    labs(\n      title = \"Exports vs. Industrial Production in Principal Component Space\",\n      x = \"First Principal Component (Dimension of Greatest Variance)\",\n      y = \"Second Principal Component\"\n    )",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#and-use-it-for-eda",
    "href": "w12/index.html#and-use-it-for-eda",
    "title": "Week 12: Hypothesis Testing",
    "section": "And Use It for EDA",
    "text": "And Use It for EDA\n\nlibrary(dplyr)\nlibrary(tidyr)\nplot_df &lt;- gdp_df %&gt;% select(c(country_code, pc1, agriculture, military))\nlong_df &lt;- plot_df %&gt;% pivot_longer(!c(country_code, pc1), names_to = \"var\", values_to = \"val\")\nlong_df &lt;- long_df |&gt; mutate(\n  var = case_match(\n    var,\n    \"agriculture\" ~ \"Agricultural Production\",\n    \"military\" ~ \"Military Spending\"\n  )\n)\nggplot(long_df, aes(x = pc1, y = val, facet = var)) +\n    geom_point() +\n    facet_wrap(vars(var), scales = \"free\") +\n    dsan_theme(\"full\") +\n    labs(\n        x = \"Industrial-Export Dimension\",\n        y = \"% of GDP\"\n    )",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#but-in-our-case",
    "href": "w12/index.html#but-in-our-case",
    "title": "Week 12: Hypothesis Testing",
    "section": "But in Our Case‚Ä¶",
    "text": "But in Our Case‚Ä¶\n\n\\(x\\) and \\(y\\) dimensions already have meaning, and we have a hypothesis about \\(x \\rightarrow y\\)!\n\n\n\n\n\n\n\nThe Regression Hypothesis \\(\\mathcal{H}_{\\text{reg}}\\)\n\n\n\nGiven data \\((X, Y)\\), we estimate \\(\\widehat{y} = \\widehat{\\beta_0} + \\widehat{\\beta_1}x\\), hypothesizing that:\n\nStarting from \\(y = \\widehat{\\beta_0}\\) when \\(x = 0\\) (the intercept),\nAn increase of \\(x\\) by 1 unit is associated with an increase of \\(y\\) by \\(\\widehat{\\beta_1}\\) units (the coefficient)\n\n\n\n\nWe want to measure how well our line predicts \\(y\\) for any given \\(x\\) value \\(\\implies\\) vertical distance from regression line",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#key-features-of-regression-line",
    "href": "w12/index.html#key-features-of-regression-line",
    "title": "Week 12: Hypothesis Testing",
    "section": "Key Features of Regression Line",
    "text": "Key Features of Regression Line\n\nRegression line is BLUE: Best Linear Unbiased Estimator\nWhat exactly is it the ‚Äúbest‚Äù linear estimator of?\n\n\\[\n\\widehat{y} = \\underbrace{\\widehat{\\beta_0}}_{\\small\\begin{array}{c}\\text{Predicted} \\\\[-5mm] \\text{intercept}\\end{array}} + \\underbrace{\\widehat{\\beta_1}}_{\\small\\begin{array}{c}\\text{Predicted} \\\\[-4mm] \\text{slope}\\end{array}}\\cdot x\n\\]\nis chosen so that\n\n\\[\n\\theta = \\left(\\widehat{\\beta_0}, \\widehat{\\beta_1}\\right) = \\argmin_{\\beta_0, \\beta_1}\\left[ \\sum_{x_i \\in X} \\left(\\overbrace{\\widehat{y}(x_i)}^{\\small\\text{Predicted }y} - \\overbrace{\\expect{Y \\mid X = x_i}}^{\\small \\text{Avg. }y\\text{ when }x = x_i}\\right)^2 \\right]\n\\]",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#regression-in-r",
    "href": "w12/index.html#regression-in-r",
    "title": "Week 12: Hypothesis Testing",
    "section": "Regression in R",
    "text": "Regression in R\n\nlin_model &lt;- lm(military ~ industrial, data=gdp_df)\nsummary(lin_model)\n\n\nCall:\nlm(formula = military ~ industrial, data = gdp_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.3354 -1.0997 -0.3870  0.6081  6.7508 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  0.61969    0.59526   1.041   0.3010  \nindustrial   0.05253    0.02019   2.602   0.0111 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.671 on 79 degrees of freedom\n  (8 observations deleted due to missingness)\nMultiple R-squared:  0.07895,   Adjusted R-squared:  0.06729 \nF-statistic: 6.771 on 1 and 79 DF,  p-value: 0.01106",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#lm-syntax",
    "href": "w12/index.html#lm-syntax",
    "title": "Week 12: Hypothesis Testing",
    "section": "lm Syntax",
    "text": "lm Syntax\nlm(\n  formula = dependent ~ independent + controls,\n  data = my_df\n)",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#interpreting-output",
    "href": "w12/index.html#interpreting-output",
    "title": "Week 12: Hypothesis Testing",
    "section": "Interpreting Output",
    "text": "Interpreting Output\nCall:\nlm(formula = military ~ industrial, data = gdp_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.3354 -1.0997 -0.3870  0.6081  6.7508 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  0.61969    0.59526   1.041   0.3010  \nindustrial   0.05253    0.02019   2.602   0.0111 *\n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nResidual standard error: 1.671 on 79 degrees of freedom\n  (8 observations deleted due to missingness)\nMultiple R-squared:  0.07895,   Adjusted R-squared:  0.06729 \nF-statistic: 6.771 on 1 and 79 DF,  p-value: 0.01106",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#zooming-in-coefficients",
    "href": "w12/index.html#zooming-in-coefficients",
    "title": "Week 12: Hypothesis Testing",
    "section": "Zooming In: Coefficients",
    "text": "Zooming In: Coefficients\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n\n(Intercept)\n0.61969\n0.59526\n1.041\n0.3010\n\n\n\nindustrial\n0.05253\n0.02019\n2.602\n0.0111\n*\n\n\n\n\\(\\widehat{\\beta}\\)\nUncertainty\nTest statistic\nHow extreme is test stat?\nStatistical significance\n\n\n\n\n\\[\n\\widehat{y} \\approx \\class{cb1}{\\overset{\\beta_0}{\\underset{\\small \\pm 0.595}{0.620}}} +  \\class{cb2}{\\overset{\\beta_1}{\\underset{\\small \\pm 0.020}{0.053}}} \\cdot x\n\\]",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#zooming-in-significance",
    "href": "w12/index.html#zooming-in-significance",
    "title": "Week 12: Hypothesis Testing",
    "section": "Zooming In: Significance",
    "text": "Zooming In: Significance\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n\n(Intercept)\n0.61969\n0.59526\n1.041\n0.3010\n\n\n\nindustrial\n0.05253\n0.02019\n2.602\n0.0111\n*\n\n\n\n\\(\\widehat{\\beta}\\)\nUncertainty\nTest statistic\nHow extreme is test stat?\nStatistical significance\n\n\n\n\n\n\n\nlibrary(ggplot2)\nint_tstat &lt;- 1.041\nint_tstat_str &lt;- sprintf(\"%.02f\", int_tstat)\nlabel_df_int &lt;- tribble(\n    ~x, ~y, ~label,\n    0.25, 0.05, paste0(\"P(t &gt; \",int_tstat_str,\")\\n= 0.3\")\n)\nlabel_df_signif_int &lt;- tribble(\n    ~x, ~y, ~label,\n    2.7, 0.075, \"95% Signif.\\nCutoff\"\n)\nfuncShaded &lt;- function(x, lower_bound, upper_bound){\n    y &lt;- dnorm(x)\n    y[x &lt; lower_bound | x &gt; upper_bound] &lt;- NA\n    return(y)\n}\nfuncShadedIntercept &lt;- function(x) funcShaded(x, int_tstat, Inf)\nfuncShadedSignif &lt;- function(x) funcShaded(x, 1.96, Inf)\nggplot(data=data.frame(x=c(-3,3)), aes(x=x)) +\n  stat_function(fun=dnorm, linewidth=g_linewidth) +\n  geom_vline(aes(xintercept=int_tstat), linewidth=g_linewidth) +\n  geom_vline(aes(xintercept = 1.96), linewidth=g_linewidth, linetype=\"dashed\") +\n  stat_function(fun = funcShadedIntercept, geom = \"area\", fill = cbPalette[1], alpha = 0.5) +\n  stat_function(fun = funcShadedSignif, geom = \"area\", fill = \"grey\", alpha = 0.333) +\n  geom_text(label_df_int, mapping = aes(x = x, y = y, label = label), size = 10) +\n  geom_text(label_df_signif_int, mapping = aes(x = x, y = y, label = label), size = 8) +\n  # Add single additional tick\n  scale_x_continuous(breaks=c(-2, 0, int_tstat, 2), labels=c(\"-2\",\"0\",int_tstat_str,\"2\")) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title = \"t Value for Intercept\",\n    x = \"t\",\n    y = \"Density\"\n  ) +\n  theme(axis.text.x = element_text(colour = c(\"black\", \"black\", cbPalette[1], \"black\")))\n\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\ncoef_tstat &lt;- 2.602\ncoef_tstat_str &lt;- sprintf(\"%.02f\", coef_tstat)\nlabel_df_coef &lt;- tribble(\n    ~x, ~y, ~label,\n    3.65, 0.06, paste0(\"P(t &gt; \",coef_tstat_str,\")\\n= 0.01\")\n)\nlabel_df_signif_coef &lt;- tribble(\n  ~x, ~y, ~label,\n  1.05, 0.03, \"95% Signif.\\nCutoff\"\n)\nfuncShadedCoef &lt;- function(x) funcShaded(x, coef_tstat, Inf)\nggplot(data=data.frame(x=c(-4,4)), aes(x=x)) +\n  stat_function(fun=dnorm, linewidth=g_linewidth) +\n  geom_vline(aes(xintercept=coef_tstat), linetype=\"solid\", linewidth=g_linewidth) +\n  geom_vline(aes(xintercept=1.96), linetype=\"dashed\", linewidth=g_linewidth) +\n  stat_function(fun = funcShadedCoef, geom = \"area\", fill = cbPalette[2], alpha = 0.5) +\n  stat_function(fun = funcShadedSignif, geom = \"area\", fill = \"grey\", alpha = 0.333) +\n  # Label shaded area\n  geom_text(label_df_coef, mapping = aes(x = x, y = y, label = label), size = 10) +\n  # Label significance cutoff\n  geom_text(label_df_signif_coef, mapping = aes(x = x, y = y, label = label), size = 8) +\n  coord_cartesian(clip = \"off\") +\n  # Add single additional tick\n  scale_x_continuous(breaks=c(-4, -2, 0, 2, coef_tstat, 4), labels=c(\"-4\", \"-2\",\"0\", \"2\", coef_tstat_str,\"4\")) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title = \"t Value for Coefficient\",\n    x = \"t\",\n    y = \"Density\"\n  ) +\n  theme(axis.text.x = element_text(colour = c(\"black\", \"black\", \"black\", \"black\", cbPalette[2], \"black\")))",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#the-residual-plot",
    "href": "w12/index.html#the-residual-plot",
    "title": "Week 12: Hypothesis Testing",
    "section": "The Residual Plot",
    "text": "The Residual Plot\n\n\n\nA key assumption required for OLS: ‚Äúhomoskedasticity‚Äù\nGiven our model \\[\ny_i = \\beta_0 + \\beta_1x_i + \\varepsilon_i\n\\] the errors \\(\\varepsilon_i\\) should not vary systematically with \\(i\\)\nFormally: \\(\\forall i \\left[ \\Var{\\varepsilon_i} = \\sigma^2 \\right]\\)\n\n\n\nlibrary(broom)\ngdp_resid_df &lt;- augment(lin_model)\nggplot(gdp_resid_df, aes(x = .fitted, y = .resid)) +\n    geom_point(size = g_pointsize/2) +\n    geom_hline(yintercept=0, linetype=\"dashed\") +\n    dsan_theme(\"quarter\") +\n    labs(\n      title = \"Residual Plot for Industrial ~ Military\",\n      x = \"Fitted Value\",\n      y = \"Residual\"\n    )\n\n\n\n\n\n\n\n\n\nx &lt;- 1:80\nerrors &lt;- rnorm(length(x), 0, x^2/1000)\ny &lt;- x + errors\nhet_model &lt;- lm(y ~ x)\ndf_het &lt;- augment(het_model)\nggplot(df_het, aes(x = .fitted, y = .resid)) +\n    geom_point(size = g_pointsize / 2) +\n    geom_hline(yintercept = 0, linetype = \"dashed\") +\n    dsan_theme(\"quarter\") +\n    labs(\n        title = \"Residual Plot for Heteroskedastic Data\",\n        x = \"Fitted Value\",\n        y = \"Residual\"\n    )",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#multiple-linear-regression",
    "href": "w12/index.html#multiple-linear-regression",
    "title": "Week 12: Hypothesis Testing",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression\n\nNotation: \\(x_{i,j}\\) = value of independent variable \\(j\\) for person/observation \\(i\\)\n\\(M\\) = total number of independent variables\n\n\\[\n\\widehat{y}_i = \\beta_0 + \\beta_1x_{i,1} + \\beta_2x_{i,2} + \\cdots + \\beta_M x_{i,M}\n\\]\n\n\\(\\beta_j\\) interpretation: a one-unit increase in \\(x_{i,j}\\) is associated with a \\(\\beta_j\\) unit increase in \\(y_i\\), holding all other independent variables constant",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#the-f-test",
    "href": "w12/index.html#the-f-test",
    "title": "Week 12: Hypothesis Testing",
    "section": "The \\(F\\)-Test",
    "text": "The \\(F\\)-Test\n\n\\(t\\)-test is to single-variable regression as \\(F\\)-test is to multiple regression\n\\(H_A: (\\beta_1 = 0) \\wedge (\\beta_2 = 0) \\wedge \\cdots \\wedge (\\beta_M = 0)\\)\n\n(‚ÄúGive up, it‚Äôs not worth doing this regression‚Äù)\n\n\\(H_0: (\\beta_1 \\neq 0) \\vee (\\beta_2 \\neq 0) \\vee \\cdots \\vee (\\beta_M \\neq 0)\\)\n\n(‚ÄúYour regression has at least one redeeming quality‚Äù)",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#key-insight-from-behavioral-economics",
    "href": "w12/index.html#key-insight-from-behavioral-economics",
    "title": "Week 12: Hypothesis Testing",
    "section": "Key Insight From Behavioral Economics",
    "text": "Key Insight From Behavioral Economics\n\nData always has an interpretive context\nHumans are not very good at placing data in that context",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#observations-vs.-base-rates",
    "href": "w12/index.html#observations-vs.-base-rates",
    "title": "Week 12: Hypothesis Testing",
    "section": "Observations vs.¬†Base Rates",
    "text": "Observations vs.¬†Base Rates\n\n\n\n\n\n\n\nSteve is very shy and withdrawn, invariably helpful but with very little interest in people or in the world of reality. A meek and tidy soul, he has a need for order and structure, and a passion for detail.\n\n\\(\\Pr(\\text{Steve is a librarian} \\mid \\text{description})?\\)\n\n\n\n\n\nExample from (kahneman_thinking_2011?)",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#base-rates",
    "href": "w12/index.html#base-rates",
    "title": "Week 12: Hypothesis Testing",
    "section": "Base Rates",
    "text": "Base Rates\n\nGlobally: ~350,000 librarians vs.¬†~800 million farmers\n\n\nlibrary(tidyverse)\nnum_librarians &lt;- 350000\nnum_farmers &lt;- 800000000\noccu_df &lt;- tribble(\n    ~Occupation, ~Count,\n    \"Farmer\", num_farmers,\n    \"Librarian\", num_librarians,\n)\n\nggplot(occu_df, aes(x=factor(Occupation, levels=c(\"Librarian\",\"Farmer\")), y=Count, fill=Occupation)) +\n  geom_bar(stat='identity') +\n  dsan_theme() +\n  labs(\n    x = \"Occupation\",\n    y = \"Count\",\n    title = \"Librarians vs. Farmers Globally\"\n  )",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#sampling-from-the-globe",
    "href": "w12/index.html#sampling-from-the-globe",
    "title": "Week 12: Hypothesis Testing",
    "section": "Sampling From The Globe",
    "text": "Sampling From The Globe\n\\[\n\\begin{align*}\n\\Pr(\\text{Librarian}) &= \\frac{350K}{8\\text{ Billion}} \\approx 0.00004375 \\\\\n\\Pr(\\text{Farmer}) &= \\frac{800\\text{ Million}}{8\\text{ Billion}} = 0.1\n\\end{align*}\n\\]\nMeaning, if we sample 1 million people, we would expect:\n\n44 to be librarians\n100,000 to be farmers",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#but-still",
    "href": "w12/index.html#but-still",
    "title": "Week 12: Hypothesis Testing",
    "section": "But Still‚Ä¶",
    "text": "But Still‚Ä¶\n\nLet‚Äôs say you believe that only 1% of farmers have these traits, while 100% of librarians have these traits. Then, within our sample of 1 million, we would expect:\n44 to be librarians with these traits\n1,000 to be farmers with these traits\n\\(\\implies\\) still 22.7 times more likely that Steve is a farmer",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#the-math",
    "href": "w12/index.html#the-math",
    "title": "Week 12: Hypothesis Testing",
    "section": "The Math",
    "text": "The Math\n\\[\n\\begin{align*}\n\\Pr(\\mathcal{H}_L \\mid E) &= \\Pr(\\text{Steve is librarian} \\mid \\text{description}) \\\\\n&= \\frac{\\Pr(\\text{description} \\mid \\text{Steve is librarian})\\Pr(\\text{Steve is librarian})}{\\Pr(\\text{description})} \\\\\n&= \\frac{(1)(0.00004375)}{\\Pr(\\text{description})} = \\frac{0.00004375}{\\Pr(\\text{description})}\n\\end{align*}\n\\]\n\n\\[\n\\begin{align*}\n\\Pr(\\mathcal{H}_F \\mid E) &= \\Pr(\\text{Steve is farmer} \\mid \\text{description}) \\\\\n&= \\frac{\\Pr(\\text{description} \\mid \\text{Steve is farmer})\\Pr(\\text{Steve is farmer})}{\\Pr(\\text{description})} \\\\\n&= \\frac{(0.01)(0.1)}{\\Pr(\\text{description})} = \\frac{0.001}{\\Pr(\\text{description})} \\\\\n\\end{align*}\n\\]\n\n\\[\n\\implies \\frac{\\Pr(\\mathcal{H}_F \\mid E)}{\\Pr(\\mathcal{H}_L \\mid E)} = \\frac{\n    \\frac{0.001}{\\Pr(\\text{description})}\n}{\n    \\frac{0.00004375}{\\Pr(\\text{description})}\n} = \\frac{0.001}{0.00004375} \\approx 23\n\\]",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#the-takeaway",
    "href": "w12/index.html#the-takeaway",
    "title": "Week 12: Hypothesis Testing",
    "section": "The Takeaway",
    "text": "The Takeaway\n\nClassical hypothesis testing, developed in a time before computers or calculators, was an attempt to test hypotheses solely on the basis of the experimental results (then maybe, after the fact, apply a correction to ‚Äúsneak in‚Äù base rates)\nBayesian hypothesis testing, developed in a time when we have computers, explicitly casts results of experiments as weighted averages of prior evidence and newly-acquired evidence!",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#differences-vs.-ratios",
    "href": "w12/index.html#differences-vs.-ratios",
    "title": "Week 12: Hypothesis Testing",
    "section": "Differences vs.¬†Ratios",
    "text": "Differences vs.¬†Ratios\n\nSetting: We have a sample \\(\\mathbf{X}_1\\) taken from a population \\(P_1\\) and a sample \\(\\mathbf{X}_2\\) taken from a population \\(P_2\\).\nWe care about some variable \\(v\\) that we measured as part of our sampling: in particular, we care about \\(\\mu^{(v)}_1\\), the mean of this variable in population 1, and \\(\\mu^{(v)}_2\\), the mean of this variable in population 21\nGoal: Test whether the mean of \\(v\\) in population 1 is equal to the mean of \\(v\\) in population 2. Formally, we test the hypothesis \\(\\mathcal{H}\\):\n\n\\[\n\\mathcal{H}: \\mu_1 = \\mu_2\n\\]\n\nIt is ambiguous what test statistic we should use to check this(!), since\n\\[\n  \\begin{align*}\n  \\mu_1 = \\mu_2 &\\iff \\mu_1 - \\mu_2 = 0 \\\\\n  \\mu_1 = \\mu_2 &\\iff \\frac{\\mu_1}{\\mu_2} = 0\n  \\end{align*}\n  \\]\n(where we assume, for the second equivalence, that \\(\\mu_2 \\neq 0\\))",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#the-difference-in-math",
    "href": "w12/index.html#the-difference-in-math",
    "title": "Week 12: Hypothesis Testing",
    "section": "The Difference, In Math",
    "text": "The Difference, In Math\nlibrary(tidyverse)\nlibrary(latex2exp)\nmy_const &lt;- function(x) 1\nmy_ratio &lt;- function(x) 1/x\n#data_df &lt;- data_df |&gt; mutate(\n#  z = my_diff(x, y)\n#)\n#print(data_df)\nx_label &lt;- TeX(\"$\\\\mu_2$\")\ntd_title &lt;- TeX(\"Stability of $t_d$\")\ntd_label &lt;- TeX(\"$t'_d(\\\\mu_2)$\")\nbase_plot &lt;- ggplot(data=data.frame(x=c(-5,5)), aes(x=x)) +\n  dsan_theme(\"quarter\") +\n  labs(\n    x = x_label\n  )\ndiff_plot &lt;- base_plot + stat_function(\n    fun = my_const,\n    linewidth = g_linewidth\n  ) + labs(\n    title = td_title,\n    y = td_label\n  )\ndiff_plot\ntr_title &lt;- TeX(\"Stability of $t_r$\")\ntr_label &lt;- TeX(\"$t'_r(\\\\mu_2)$\")\nratio_plot &lt;- base_plot + stat_function(\n    fun = my_ratio,\n    linewidth = g_linewidth\n  ) + labs(\n    title = tr_title,\n    y = tr_label\n  )\nratio_plot\n\n\n\n\nOur test statistic is some function \\(t(\\mu_1, \\mu_2)\\).\nLet \\(t_d(\\mu_1, \\mu_2) = \\mu_1 - \\mu_2\\)\nLet \\(t_r(\\mu_1, \\mu_2) = \\frac{\\mu_1}{\\mu_2}\\)\nHow sensitive are these two ways of defining \\(t\\) to changes in the individual terms?\n\\[\n  t'_d(\\mu_2) = \\frac{\\partial t^-(\\mu_1, \\mu_2)}{\\partial \\mu_1} = 1,\n  \\]\nwhereas\n\\[\n  t'_r(\\mu_2) = \\frac{\\partial t^\\div(\\mu_1, \\mu_2)}{\\partial \\mu_1} = \\frac{1}{\\mu_2}\n  \\]",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#the-takeaway-1",
    "href": "w12/index.html#the-takeaway-1",
    "title": "Week 12: Hypothesis Testing",
    "section": "The Takeaway",
    "text": "The Takeaway\n\nIn scenarios where \\(\\mu\\) values are far from zero, both behave similarly\nBut in scenarios where \\(\\mu\\) values are close to zero, need to be careful about using \\(t_r(\\mu_1, \\mu_2) = \\frac{\\mu_1}{\\mu_2}\\)!\nIf \\(\\mu_2\\) could feasibly be zero‚Ä¶ \\(t_r(\\mu_1, \\mu_2) = üíÄüòµüíÄ\\)",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#moving-from-known-rightarrow-unknown-sigma",
    "href": "w12/index.html#moving-from-known-rightarrow-unknown-sigma",
    "title": "Week 12: Hypothesis Testing",
    "section": "Moving From Known \\(\\rightarrow\\) Unknown \\(\\sigma\\)",
    "text": "Moving From Known \\(\\rightarrow\\) Unknown \\(\\sigma\\)\n\nLast week: \\(z\\)-test for scenario where we (somehow) know population variance \\(\\sigma\\)\nThis week: More realistic case where we don‚Äôt know \\(\\sigma\\), so we estimate it from our sample \\(\\mathbf{X}\\): \\(\\widehat{\\sigma^2} = s^2_{\\mathbf{X}}\\)\nThis means we have recursive uncertainty in our estimates!\n\n\\[\n\\begin{align*}\n\\widehat{\\mu}(\\mathbf{X}) = f(\\mathbf{X}) &= \\frac{1}{N}\\sum_{i=1}^{N}X_i \\\\\n\\widehat{\\sigma^2}(\\mathbf{X}) = g(\\mathbf{X}, \\widehat{\\mu}(\\mathbf{X})) &= \\frac{1}{N}\\sum_{i=1}^N (X_i - \\boxed{\\widehat{\\mu}(\\mathbf{X})})^2 \\\\\n&= \\frac{1}{N}\\sum_{i=1}^N\\left(X_i - \\boxed{\\frac{1}{N}\\sum_{j=1}^NX_j}\\right)^2\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#errors-now-make-our-estimates-exponentially-worse",
    "href": "w12/index.html#errors-now-make-our-estimates-exponentially-worse",
    "title": "Week 12: Hypothesis Testing",
    "section": "Errors Now Make Our Estimates Exponentially Worse(!)",
    "text": "Errors Now Make Our Estimates Exponentially Worse(!)\n\nImagine that when calculating \\(\\widehat{\\mu} = \\frac{1}{N}\\sum_{i=1}^nX_i\\) (recall that this is an unbiased estimator for \\(\\mu\\)), we accidentally add \\(\\varepsilon\\) to every value \\(X_i\\), so that we instead compute \\(\\widetilde{\\mu} = \\frac{1}{N}\\sum_{i=1}^n(X_i+\\varepsilon) = \\widehat{\\mu} + \\varepsilon\\)\nThis means our estimate of \\(\\mu\\) is now biased by some amount \\(\\varepsilon\\): while \\(\\mathbb{E}[\\widehat{\\mu}] = \\mu\\), \\(\\mathbb{E}[\\widetilde{\\mu}] = \\mu + {\\color{red}\\varepsilon}\\)\nHow does this affect subsequent estimates of the variance \\(\\widehat{\\sigma^2}\\)? Even if we use an unbiased estimator \\(\\widehat{\\sigma^2}\\), so that \\(\\mathbb{E}[\\widehat{\\sigma^2}] = \\sigma^2\\), we get something that looks like the following (sweeping some details under the rug):\n\n\\[\n\\mathbb{E}[\\widehat{\\sigma^2}] = \\cdots = \\sigma^2 + \\mathbb{E}[\\varepsilon^2] - 2\\varepsilon\\mathbb{E}[X_i-\\mu] = \\sigma^2 + {\\color{red}\\varepsilon^2}\n\\]\n\nWhile our estimate of the mean was off by \\({\\color{red}\\varepsilon}\\), our estimate of the variance is off by \\({\\color{red}\\varepsilon^2}\\)!\nTaking square root to obtain the standard deviation \\(\\widehat{\\sigma}\\) doesn‚Äôt ‚Äúfix‚Äù this, either, since \\(\\sqrt{\\sigma^2 + \\varepsilon^2} \\neq \\sigma + \\varepsilon\\) in general (e.g., \\(\\sqrt{2^2 + 3^2} = \\sqrt{4+9} = \\sqrt{13} \\neq 2 + 3 = 5\\))",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#z-test-rightarrow-t-test",
    "href": "w12/index.html#z-test-rightarrow-t-test",
    "title": "Week 12: Hypothesis Testing",
    "section": "\\(z\\)-Test \\(\\rightarrow\\) \\(t\\)-Test",
    "text": "\\(z\\)-Test \\(\\rightarrow\\) \\(t\\)-Test\nlibrary(tidyverse)\nmy_normal &lt;- function(x) dnorm(x)\nmy_st &lt;- function(x) dt(x, 2)\nggplot(data=data.frame(x=c(-3,3)), aes(x=x)) +\n  stat_function(\n    aes(color='norm'),\n    fun=my_normal,\n    linewidth = g_linewidth\n  ) +\n  stat_function(\n    aes(color='st'),\n    fun=my_st,\n    linewidth = g_linewidth\n  ) +\n  dsan_theme(\"half\") +\n  scale_color_manual(\n    \"Distribution\",\n    values=c('norm'=cbPalette[1],'st'=cbPalette[2]),\n    labels=c('norm'=\"Standard Normal\",'st'=\"Student's t (df=2)\")\n  ) +\n  remove_legend_title() +\n  labs(\n    title = \"Standard Normal vs. Student's t Distribution\"\n  )\n\n\n\n\nThe Takeaway:\n\n\nWhen we know \\(\\sigma^2\\) but we estimate \\(\\mu\\) from a sample, we represent our uncertainty via test statistic \\(z \\sim \\mathcal{N}(\\widehat{\\mu}, \\sigma^2)\\)\nWhen we estimate both \\(\\mu\\) and \\(\\sigma^2\\) from a sample, we use a test statistic \\(t\\) with a wider ‚ÄúStudent‚Äôs \\(t\\)‚Äù Distribution in place of the Normal Distribution: \\(t \\sim \\mathcal{T}(\\widehat{\\mu}, \\widehat{\\sigma}^2, N)\\)\nAs \\(N \\rightarrow \\infty\\), \\(\\mathcal{T}_N(\\widehat{\\mu},\\widehat{\\sigma}^2,N) \\rightarrow \\mathcal{N}(\\widehat{\\mu},\\widehat{\\sigma}^2)\\)\n\n\n\n\n\n\n\n\nA comparison of the two distributions, showing how the Student‚Äôs t Distribution has greater variance, representing the greater uncertainty when estimating two population parameters instead of just one",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#in-r",
    "href": "w12/index.html#in-r",
    "title": "Week 12: Hypothesis Testing",
    "section": "In R",
    "text": "In R\n\nLet‚Äôs create a tibble containing samples from two populations\n\n\nlibrary(tidyverse)\nlibrary(infer)\nnl_height_mean &lt;- 182.535\nnl_height_sd &lt;- 8\nyemen_height_mean &lt;- 159.887\nyemen_height_sd &lt;- 8\nN &lt;- 100\nnl_sample &lt;- rnorm(N, mean=nl_height_mean, sd = nl_height_sd)\nnl_df &lt;- tibble(height=nl_sample, Country=\"Netherlands\")\nyemen_sample &lt;- rnorm(N, mean=yemen_height_mean, sd = yemen_height_sd)\nyemen_df &lt;- tibble(height=yemen_sample, Country=\"Yemen\")\ndata_df &lt;- bind_rows(nl_df, yemen_df)\nggplot(data_df, aes(x=height, fill=Country)) +\n  geom_density(alpha=0.5) + \n  dsan_theme() +\n  #xlim(150,200) +\n  labs(\n    title = \"Mean Heights: Yemen (N=100) vs. Netherlands (N=100)\",\n    x = \"Height (cm)\",\n    y = \"Sample Probability Density\"\n  ) +\n  scale_fill_manual(\"Country\", values=c('Netherlands'=cbPalette[1], 'Yemen'=cbPalette[2]))\n\n\n\n\n\n\n\n\n\n\\(H_0: \\mu_{\\text{NL}} - \\mu_{\\text{Yem}} = 0\\), \\(H_A: \\mu_{\\text{NL}} - \\mu_{\\text{Yem}} &gt; 0\\), \\(t = \\overline{h}_{\\text{NL}} - \\overline{h}_{\\text{Yem}}\\)",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#the-infer-package",
    "href": "w12/index.html#the-infer-package",
    "title": "Week 12: Hypothesis Testing",
    "section": "The infer Package",
    "text": "The infer Package\n\nIt‚Äôs easy to find resources on built-in t.test(), harder to find resources on newer, tidyverse-based t_test()! üòâ\nSyntax is t_test(df, formula, order, alternative)\norder = c(pop1, pop2) \\(\\rightarrow H_0: \\mu_1 - \\mu_2 = 0\\)\nalternative = {\"two-sided\", \"greater\", \"less\"}\nformula slightly trickier, but tldr is:\nvariable you're computing means for ~ variable splitting df into two populations\n\n\n\nCode\ndata_df |&gt; t_test(formula = height ~ Country, order = c(\"Netherlands\", \"Yemen\"), alternative = \"greater\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstatistic\nt_df\np_value\nalternative\nestimate\nlower_ci\nupper_ci\n\n\n\n\n18.7634\n196.2509\n0\ngreater\n20.13126\n18.35813\nInf",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#the-chi-squared-test-of-independence",
    "href": "w12/index.html#the-chi-squared-test-of-independence",
    "title": "Week 12: Hypothesis Testing",
    "section": "The Chi-Squared Test of Independence",
    "text": "The Chi-Squared Test of Independence\n\n\n\n\n\n\n\n\n\n\\(z\\)-Tests and \\(t\\)-Tests\n\n\n\n\n\n\n\nThe Chi-Squared Test",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#what-hypothesis-are-we-testing",
    "href": "w12/index.html#what-hypothesis-are-we-testing",
    "title": "Week 12: Hypothesis Testing",
    "section": "What Hypothesis Are We Testing?",
    "text": "What Hypothesis Are We Testing?\n\n\\(z\\)-Tests and \\(t\\)-Tests might feel a bit weak: they allow us to hypothesize about a single population parameter, which is nice, but throughout the course we have been talking about distributions, not just means or variances!\nThe Chi-Squared Test allows us to hypothesize about distributions: for categorical random variables \\(X_1\\) and \\(X_2\\) we can test the null and alternative hypotheses:\n\n\\[\n\\begin{align*}\nH_0: X_1 \\perp X_2 &\\iff \\Pr(X_1 = v_1 \\mid X_2 = v_2) = \\Pr(X_1 = v_1) \\\\\nH_A: X_1 \\not\\perp X_2 &\\iff \\Pr(X_1 = v_1 \\mid X_2 = v_2) \\neq \\Pr(X_1 = v_1)\n\\end{align*}\n\\]\n\n\\(H_0\\) in words: ‚Äúlearning the value of \\(X_2\\) does not give me any information about the value of \\(X_1\\), and vice-versa‚Äù",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#base-notation",
    "href": "w12/index.html#base-notation",
    "title": "Week 12: Hypothesis Testing",
    "section": "Base Notation",
    "text": "Base Notation\n\n(May seem tedious, but you will be thankful later if you use this notation!)\nLet \\(N\\) be the total number of samples we have in our dataset\nLet \\(K_1\\) be the total number of categories that \\(X_1\\) can take on: formally, \\(K_1 = |\\mathcal{R}_{X_1}|\\).\nSimilarly, let \\(K_2 = |\\mathcal{R}_{X_2}|\\), the cardinality of the support of \\(X_2\\).\nWe will use a lowercase \\(k_{1,i}\\) to represent the \\(i\\)th possible value of \\(X_1\\), (i.e., the \\(i\\)th element of \\(\\mathcal{R}_{X_1}\\)), and \\(k_{2,i}\\) to represent the \\(i\\)th possible value of \\(\\mathcal{R}_{X_2}\\).\n\ne.g., \\(k_{1,1}\\) is the first element of \\(\\mathcal{R}_{X_1}\\), \\(k_{1,2}\\) is the second element of \\(\\mathcal{R}_{X_2}\\), and so on.",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#joint-and-marginal-frequencies",
    "href": "w12/index.html#joint-and-marginal-frequencies",
    "title": "Week 12: Hypothesis Testing",
    "section": "Joint and Marginal Frequencies",
    "text": "Joint and Marginal Frequencies\n\nNow we can define the central quantities that the chi-squared test involves: the frequencies (i.e., unnormalized probabilities) of observations with certain (categorical) variable values:\n\\(f_{i,j}\\): The number of observations for which \\(X_1 = k_{1,i}\\) (the \\(i\\)th value that \\(X_1\\) can take on) and \\(X_2 = k_{2,j}\\) (the \\(j\\)th value that \\(X_2\\) can take on).\n\nExample: \\(f_{1,3}\\), represents the number of observations for which \\(X_1 = k_{1,1}\\) and \\(X_2 = k_{2,3}\\).\n\nLet \\(f_{i,\\cdot} = \\sum_{j=1}^{K_2}f_{i,j}\\) be the number of observations for which \\(X_1 = k_{1,i}\\), regardless of the value of \\(X_2\\) (hence we call this the marginal frequency of \\(X_1 = k_{1,i}\\)).\n\n\\(f_{7,\\cdot}\\), for example, represents the number of observations for which \\(X_1 = k_{1,7}\\), regardless of the values of \\(X_2\\) across these observations.\nThis is called ‚Äúdot notation‚Äù, and makes it easy for us to notationally represent which marginal distributions we are talking about.\n\nSimilarly, let \\(f_{\\cdot, j} = \\sum_{i=1}^{K_1}f_{i,j}\\) be the marginal frequency with which songs have \\(V_2 = k_j\\). \\(f_{\\cdot, 2}\\), for example, represents the number of songs for which the valence value is at level 2 (Moderate), regardless of its artist.",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#we-made-it",
    "href": "w12/index.html#we-made-it",
    "title": "Week 12: Hypothesis Testing",
    "section": "We Made It",
    "text": "We Made It\n\nWe can finally compute the test statistic for the Chi-Squared Test, \\(Q\\)!\n\n\\[\nQ = \\sum_{k_1=1}^{K_1}\\sum_{k_2=1}^{K_2}\\frac{\\left(f_{k_1,k_2} - \\frac{f_{k_1,\\cdot}f_{\\cdot,k_2}}{N}\\right)^2}{\\frac{f_{k_1,\\cdot}f_{\\cdot, k_2}}{N}}\n\\]\n\nThis test statistic has (by construction) a Chi-Squared Distribution with \\((K_1 - 1)(K_2 - 1)\\) degrees of freedom",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#in-r-1",
    "href": "w12/index.html#in-r-1",
    "title": "Week 12: Hypothesis Testing",
    "section": "In R",
    "text": "In R\nWe can compute this test statistic (somewhat laboriously) in R as follows: first let‚Äôs create variables representing the supports \\(\\mathcal{R}_{X_1}\\) and \\(\\mathcal{R}_{X_2}\\) for our two random variables \\(X_1\\) and \\(X_2\\):\n\n#(L1 &lt;- sort(unique(artist_df$artist_name)))\n#K1 &lt;- length(L1)\n# Here we set this manually, rather than using unique(), so we can obtain a specific ordering that we want\n#(L2 &lt;- c(\"more negative\", \"Moderate\", \"more positive\"))\n#K2 &lt;- length(L2)",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#computing-marginal-frequencies",
    "href": "w12/index.html#computing-marginal-frequencies",
    "title": "Week 12: Hypothesis Testing",
    "section": "Computing Marginal Frequencies",
    "text": "Computing Marginal Frequencies\n\nNext we pre-compute the marginal frequencies for all possible \\(X_1\\) values (all elements of \\(\\mathcal{R}_{X_1}\\)) and then for all possible \\(X_2\\) values (all elements of \\(\\mathcal{R}_{X_2}\\)):\n\n\n1\n\n[1] 1",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#computing-the-test-statistic",
    "href": "w12/index.html#computing-the-test-statistic",
    "title": "Week 12: Hypothesis Testing",
    "section": "Computing the Test Statistic",
    "text": "Computing the Test Statistic\n\nFinally, we can compute the individual bin frequencies \\(f_{i,j}\\) in a loop (there are more efficient ways to do this, which we‚Äôd want to adopt instead if our dataset was much larger, for example):\n\n\n# q_sum &lt;- 0\n# for (k1 in 1:K1) {\n#   artist_name_value &lt;- L1[k1]\n#   artist_marginal_freq &lt;- L1_marginal_freqs[k1]\n#   for (k2 in 1:K2) {\n#     valence_value &lt;- L2[k2]\n#     valence_marginal_freq &lt;- L2_marginal_freqs[k2]\n#     print(paste0(\"(\",artist_name_value,\", \",valence_value,\")\"))\n#     # Compute the frequency in this bin\n#     bin_df &lt;- artist_df |&gt; filter(artist_name == artist_name_value & valence_C == valence_value)\n#     print(nrow(bin_df))\n#     # And now, since we precomputed the marginal frequencies, we have everything we need!\n#     joint_freq &lt;- nrow(bin_df)\n#     marginal_ratio &lt;- (artist_marginal_freq * valence_marginal_freq) / N\n#     numer &lt;- (joint_freq - marginal_ratio)^2\n#     denom &lt;- marginal_ratio\n#     cur_q_val &lt;- numer / denom\n#     q_sum &lt;- q_sum + cur_q_val\n#   }\n# }\n\n# q_sum",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#interpretation",
    "href": "w12/index.html#interpretation",
    "title": "Week 12: Hypothesis Testing",
    "section": "Interpretation",
    "text": "Interpretation\n\nSince we know this test statistic \\(Q\\) follows (asymptotically/approximately) a chi-squared distribution with \\((K_1 - 1)(K_2 - 1)\\) degrees of freedom, we can compute the probability of obtaining a test statistic value this high or higher (14.162598), using R‚Äôs built-in dchisq() function:\n\n\n#(test_df &lt;- (K1 - 1) * (K2 - 2))\n#dchisq(q_sum, test_df)",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#drawing-conclusions-in-classical-world",
    "href": "w12/index.html#drawing-conclusions-in-classical-world",
    "title": "Week 12: Hypothesis Testing",
    "section": "Drawing Conclusions in Classical World",
    "text": "Drawing Conclusions in Classical World\nAnd so, finally: this tells us that under the null hypothesis that artist_name and valence_C represent draws from independent random variables, the likelihood of obtaining our dataset, or a dataset with a more extreme test statistic, is about 0.00042, or 0.042%.\nTherefore, if we are evaluating our hypothesis at the 5% confidence level (or 1% or even 0.1%, because this is a very low probability value/percentage), we conclude that we should reject the null hypothesis that artist name and valence are independent. Therefore (switching from a frequentist to a Bayesian interpretation, mercifully), we increase our degree of belief in the hypothesis that the valence of a song does depend upon the artist making the song.",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#drawing-conclusions-in-modern-bayesian-world",
    "href": "w12/index.html#drawing-conclusions-in-modern-bayesian-world",
    "title": "Week 12: Hypothesis Testing",
    "section": "Drawing Conclusions in Modern (Bayesian) World",
    "text": "Drawing Conclusions in Modern (Bayesian) World\nThis technical conclusion (which focuses only on the results of the statistical hypothesis test), combined with the Bayesian interpretation at the end, lets us say something about ‚Äúwhat we‚Äôve learned‚Äù about music:\n\nOur Bayesian prior on the null hypothesis, \\(\\Pr(H_0) = \\Pr(V \\perp A)\\), was probably quite small: before performing this analysis, we probably did not think that these two variables are independent, since we know that some artists tend to make more sad songs, while other artists tend to make more happy songs (though there are obviously exceptions: bands that tend to make a mix of sad and happy songs).\nThen we performed the analysis, and failed to reject the hypothesis that these two variables are independent.\nTherefore, our Bayesian posterior on \\(\\Pr(V \\perp A)\\) should be slightly lower: If our prior probability on \\(H_0\\) was some value \\(p\\), our posterior probability now that we‚Äôve performed the study and failed to reject the null hypothesis should be \\(p - \\varepsilon\\), for some appropriate value \\(\\varepsilon\\) representing the relative balance between (our view of) the veracity of the prior vs.¬†the veracity of the test we performed.\nTo make it concrete: if we previously believed that \\(p = \\Pr(H_0) = 0.1\\), perhaps now we can update our beliefs such that \\(p = \\Pr(H_0) = 0.05\\). This would represent the case where we lend equal credence in our prior and in our experiement, since then\n\n\\[\np_{post} = \\frac{1}{2}\\Pr(H_0) + \\frac{1}{2}\\text{Test Result} = \\frac{1}{2}(0.1) + \\frac{1}{2}(0) = 0.05.\n\\]",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#references",
    "href": "w12/index.html#references",
    "title": "Week 12: Hypothesis Testing",
    "section": "References",
    "text": "References\n\n\nGelman, Andrew, and Jennifer Hill. 2007. Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge University Press.",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#footnotes",
    "href": "w12/index.html#footnotes",
    "title": "Week 12: Hypothesis Testing",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFrom here onwards I drop the \\((v)\\) superscript for brevity, but remember that we‚Äôre always talking about \\(\\mu^{(v)}_i\\): the population mean of a particular variable \\(v\\) in population \\(i\\)!‚Ü©Ô∏é",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w01/index.html",
    "href": "w01/index.html",
    "title": "Week 1: Welcome to DSAN 5100!",
    "section": "",
    "text": "(Week 1 of DSAN 5100 was a joint session across all individual sections, taught on Zoom.)\n\n\n\n\n\n\nToday‚Äôs Links\n\n\n\n\nWeek 1 Slides\nWeek 1 Lecture Recording",
    "crumbs": [
      "Week 1: Aug 30"
    ]
  },
  {
    "objectID": "extra-videos/index.html",
    "href": "extra-videos/index.html",
    "title": "Extra Videos",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Last Updated - Oldest\n        \n         \n          Last Updated - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nLast Updated\n\n\n\n\n\n\nCorrected Bayes‚Äô Theorem Example (W03.1)\n\n\nFriday Sep 8, 2023\n\n\n\n\nStatistics Fundamentals (W02.5)\n\n\nTuesday Sep 5, 2023\n\n\n\n\nProbability Fundamentals (W02.4)\n\n\nMonday Sep 4, 2023\n\n\n\n\nCombinatorics (W02.3)\n\n\nSunday Sep 3, 2023\n\n\n\n\nReview (W02.2)\n\n\nSaturday Sep 2, 2023\n\n\n\n\nAbout Me (W02.1)\n\n\nFriday Sep 1, 2023\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Extra Videos"
    ]
  },
  {
    "objectID": "w07/slides.html#frequency-tables",
    "href": "w07/slides.html#frequency-tables",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Frequency Tables",
    "text": "Frequency Tables\n\n\n\n\n\n\n\nWhat does this tell us on its own (before computing proportions in our heads) that is useful for probability?\nAnswer: Not very much!\nBut, if we can find the overall total, then it would tell us a lot (everything we need to know)!\n\n\n\n\n\n\nTable¬†1: A frequency table of HS students (\\(G\\) = grade, \\(H\\) = honors status)This tells us, e.g., there are 5 honors students in grade 10\n\n\n\n¬†\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\\(G = 11\\)\n6\n4\n\n\n\\(G = 12\\)\n7\n1\n\n\n\n\n\n\n\n\n\n\nA frequency table where each row corresponds to a grade in a certain senior high school, each column corresponds to honor-student-status (\\(H=1\\) represents honors, \\(H=0\\) represents non-honors), and each cell contains the number of students in that grade with that honors-status"
  },
  {
    "objectID": "w07/slides.html#why-do-we-need-the-total",
    "href": "w07/slides.html#why-do-we-need-the-total",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Why Do We Need The Total?",
    "text": "Why Do We Need The Total?\n\nQ1: Someone asks the probability that a randomly-selected student will be an honor student in 11th grade.\nQ2: Someone asks what proportion of students are honors\nQ3: Someone asks what % of 12th grade are honors\n\nQ1, for example, is asking us for \\(\\Pr(G = 11, H = 1)\\), a question we can answer if we know the joint distribution \\(f_{G,H}(v_G, v_H)\\)."
  },
  {
    "objectID": "w07/slides.html#back-to-the-na√Øve-definition",
    "href": "w07/slides.html#back-to-the-na√Øve-definition",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Back to the Na√Øve Definition",
    "text": "Back to the Na√Øve Definition\nUsing our na√Øve definition of probability, we can compute this probability using the frequencies in the table as\n\\[\n\\Pr(G = 11, H = 1) = \\frac{\\#(G = 11, H = 1)}{\\#\\text{ Students Total}}\n\\]\nPlugging in the values from Table¬†1, we obtain the answer:\n\\[\n\\Pr(G = 11, H = 1) = \\frac{4}{33} \\approx 0.121\n\\]"
  },
  {
    "objectID": "w07/slides.html#frequency-table-rightarrow-probability-table",
    "href": "w07/slides.html#frequency-table-rightarrow-probability-table",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Frequency Table \\(\\rightarrow\\) Probability Table",
    "text": "Frequency Table \\(\\rightarrow\\) Probability Table\n\nWhen we divide by 33, we are normalizing the counts, producing probabilities (normalized counts)\nBy normalizing all cells in the table, we convert our frequency table into a probability table"
  },
  {
    "objectID": "w07/slides.html#computing-overall-total-by-column",
    "href": "w07/slides.html#computing-overall-total-by-column",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Computing Overall Total by Column",
    "text": "Computing Overall Total by Column\nWe could compute the total by summing columns, then summing over our individual column totals to get 33:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\n\\(G = 11\\)\n6\n4\n\n\n\n\\(G = 12\\)\n7\n1\n\n\n\nTotal\n23\n10\n33"
  },
  {
    "objectID": "w07/slides.html#computing-overall-total-by-row",
    "href": "w07/slides.html#computing-overall-total-by-row",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Computing Overall Total by Row",
    "text": "Computing Overall Total by Row\nOr, we could compute the total by summing rows, then summing over our individual row totals to get 33:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\n\\(G = 10\\)\n10\n5\n15\n\n\n\n\\(G = 11\\)\n6\n4\n10\n\n\n\n\\(G = 12\\)\n7\n1\n8\n\n\n\nTotal\n\n\n33"
  },
  {
    "objectID": "w07/slides.html#bringing-both-methods-together",
    "href": "w07/slides.html#bringing-both-methods-together",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Bringing Both Methods Together",
    "text": "Bringing Both Methods Together\n\n\n\nTable¬†2: The same frequency table as in Table¬†1, but now with row and column totals representing marginal frequencies\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\n\\(G = 10\\)\n10\n5\n15\n\n\n\n\\(G = 11\\)\n6\n4\n10\n\n\n\n\\(G = 12\\)\n7\n1\n8\n\n\n\nTotal\n23\n10\n33"
  },
  {
    "objectID": "w07/slides.html#frequencies-to-probabilities",
    "href": "w07/slides.html#frequencies-to-probabilities",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Frequencies to Probabilities",
    "text": "Frequencies to Probabilities\n\n\n\n\n\n\n\nNow (before we think about row/column totals) let‚Äôs use overall total (33) to convert counts into probabilities:\n\n\n\n\n\n\nTable¬†3: Table from prev slide with all values normalized (divided by the total number of obs)\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{5}{33}\\)\n\\(\\frac{15}{33}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{33}\\)\n\\(\\frac{4}{33}\\)\n\\(\\frac{10}{33}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{33}\\)\n\\(\\frac{1}{33}\\)\n\\(\\frac{8}{33}\\)\n\n\nTotal\n\\(\\frac{23}{33}\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{33}{33}\\)"
  },
  {
    "objectID": "w07/slides.html#one-table-three-distributions",
    "href": "w07/slides.html#one-table-three-distributions",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "One Table, Three Distributions!",
    "text": "One Table, Three Distributions!\nNow that we have normalized counts, different pieces of this table give different probability distributions:\n\n\n\nJoint Distribution \\(f_{G,H}(v_G, v_H)\\): Look at value in row \\(v_G\\), col \\(v_H\\)\nMarginal Distributions\n\n\\(f_G(v_G)\\): Look at total for row \\(v_G\\)\n\\(f_H(v_H)\\): Look at total for column \\(v_H\\)\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{5}{33}\\)\n\\(\\frac{15}{33}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{33}\\)\n\\(\\frac{4}{33}\\)\n\\(\\frac{10}{33}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{33}\\)\n\\(\\frac{1}{33}\\)\n\\(\\frac{8}{33}\\)\n\n\nTotal\n\\(\\frac{23}{33}\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{33}{33}\\)"
  },
  {
    "objectID": "w07/slides.html#summary-joint-rightarrow-marginal",
    "href": "w07/slides.html#summary-joint-rightarrow-marginal",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Summary: Joint \\(\\rightarrow\\) Marginal",
    "text": "Summary: Joint \\(\\rightarrow\\) Marginal\n\nNote how marginal distributions were obtained by summing the joint distribution over a particular dimension:\nSumming each column (\\(H = 0\\) and \\(H = 1\\)) produced marginal distribution of \\(H\\):\n\n\n\n\n\n\n\n\n\n\n\\(\\Pr(H = 0, G = 10)\\)\n\n\n+\n\\(\\Pr(H = 0, G = 11)\\)\n\n\n+\n\\(\\Pr(H = 0, G = 12)\\)\n\n\n=\n\\(\\Pr(H = 0)\\)\n\n\n\n\n\n\n\n\n\n\\(\\Pr(H = 1, G = 10)\\)\n\n\n+\n\\(\\Pr(H = 1, G = 11)\\)\n\n\n+\n\\(\\Pr(H = 1, G = 12)\\)\n\n\n=\n\\(\\Pr(H = 1)\\)\n\n\n\n\n\n\nSumming each row (\\(G = 10\\), \\(G = 11\\), \\(G = 12\\)) produced marginal distribution of \\(G\\):\n\n\n\n\n\\(\\Pr(G = 10, H = 0)\\)\n+\n\\(\\Pr(G = 10, H = 1)\\)\n=\n\\(\\Pr(G = 10)\\)\n\n\n\\(\\Pr(G = 11, H = 0)\\)\n+\n\\(\\Pr(G = 11, H = 1)\\)\n=\n\\(\\Pr(G = 11)\\)\n\n\n\\(\\Pr(G = 12, H = 0)\\)\n+\n\\(\\Pr(G = 12, H = 1)\\)\n=\n\\(\\Pr(G = 12)\\)"
  },
  {
    "objectID": "w07/slides.html#whats-missing-conditional-distributions",
    "href": "w07/slides.html#whats-missing-conditional-distributions",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "What‚Äôs Missing? Conditional Distributions",
    "text": "What‚Äôs Missing? Conditional Distributions\n\nConditional distribution does not represent a sum but a slice: we consider e.g.¬†one particular row or one particular column of the table.\nüö®Warningüö®! unlike in joint and marginal cases, when computing conditional distributions we have to renormalize, since we are ‚Äúentering world‚Äù where we only consider subsets of the table where condition is met!\nRecall slide about how all distributions are conditional distributions:\n\n\n\n\n\\(\\Pr(G = 10, H = 1)\\)\n\n\\[\n\\begin{align*}\n= &\\Pr(G = 10, H = 1 \\mid \\Omega) \\\\[0.6em]\n= &\\frac{\\#(G = 10, H = 1, \\Omega)}{\\#\\text{ Total }(\\Omega)\\text{ ‚úÖ}}\n\\end{align*}\n\\]\n\n\n\\(\\Pr(G = 10)\\)\n\n\\[\n\\begin{align*}\n= &\\Pr(G = 10 \\mid \\Omega) \\\\[0.6em]\n= &\\frac{\\#(G = 10, \\Omega)}{\\#\\text{ Total }(\\Omega)\\text{ ‚úÖ}}\n\\end{align*}\n\\]\n\n\n\\(\\Pr(G = 10 \\mid H = 1)\\)\n\n\\[\n\\begin{align*}\n= &\\frac{\\Pr(G = 10, H = 1)}{\\Pr(H = 1)} \\\\[0.6em]\n= &\\frac{\\#(G = 10, H = 1)}{\\#(H = 1)\\text{ üò≥}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w07/slides.html#conditional-distributions-from-columns",
    "href": "w07/slides.html#conditional-distributions-from-columns",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Conditional Distributions from Columns",
    "text": "Conditional Distributions from Columns\nLet‚Äôs extract just the \\(H = 1\\) column:\n\n\n\n\n\n\n\n\n\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n5\n\n\n\\(G = 11\\)\n4\n\n\n\\(G = 12\\)\n1\n\n\nTotal\n10\n\n\n\n\n\n\n\n\n\n\n\n\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{5}{10}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{4}{10}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{1}{10}\\)\n\n\nTotal\n\\(\\frac{10}{10}\\)\n\n\n\n\n\n\nBefore, 10 was a particular marginal frequency of interest; now 10 is just a total that we use to renormalize"
  },
  {
    "objectID": "w07/slides.html#conditional-distributions-from-rows",
    "href": "w07/slides.html#conditional-distributions-from-rows",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Conditional Distributions from Rows",
    "text": "Conditional Distributions from Rows\nLet‚Äôs extract just the \\(G = 10\\) row:\n\n\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n5\n10\n15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{5}{15}\\)\n\\(\\frac{10}{15}\\)\n\\(\\frac{15}{15}\\)\n\n\n\n\n\n\nBefore, 15 was a particular marginal frequency of interest; now 15 is just a total that we use to renormalize"
  },
  {
    "objectID": "w07/slides.html#discrete-world-summary",
    "href": "w07/slides.html#discrete-world-summary",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Discrete World Summary",
    "text": "Discrete World Summary\nWe now have the link between three types of distributions derived from our table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistribution Type\nHow Many?\nExample Value\n\n\n\n\nJoint Distribution\n1\n\\(\\Pr(G = 11, H = 1)\\)\\(= \\frac{4}{33}\\)\n\n\nMarginal Distributions\n2\n\\(\\Pr(H = 1) = \\frac{10}{33}\\)\n\n\nConditional Distributions\n6\n\\(\\Pr(G = 10 \\mid H = 1)\\)\\(= \\frac{5}{10}\\)\n\n\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{5}{33}\\)\n\\(\\frac{15}{33}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{33}\\)\n\\(\\frac{4}{33}\\)\n\\(\\frac{10}{33}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{33}\\)\n\\(\\frac{1}{33}\\)\n\\(\\frac{8}{33}\\)\n\n\nTotal\n\\(\\frac{23}{33}\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{33}{33}\\)\n\n\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{23}\\)\n\\(\\frac{5}{10}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{23}\\)\n\\(\\frac{4}{10}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{23}\\)\n\\(\\frac{1}{10}\\)\n\n\nTotal\n\\(\\frac{23}{23}\\)\n\\(\\frac{10}{10}\\)"
  },
  {
    "objectID": "w07/slides.html#working-backwards",
    "href": "w07/slides.html#working-backwards",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Working Backwards",
    "text": "Working Backwards\n\nHere we started from the joint distribution and derived marginal and conditional distributions\nSame intuition, plus math, lets us go in opposite direction: given marginal and conditional distributions, can derive joint distribution, since (conditional prob defn):\n\n\n\n\n\n\n\n\n\n\\(\\Pr(A \\mid B)\\)\n\\(=\\)\n\\(\\Pr(A, B)\\)\n\n\n\\(\\Pr(B)\\)\n\n\n\n\n\\[\n\\iff\n\\]\n\n\n\n\n\\(\\Pr(A,B)\\)\n\\(=\\)\n\\(\\Pr(A \\mid B)\\)\n\\(\\cdot\\)\n\\(\\Pr(B)\\)\n\n\n\n\n\n\nfrom which we can see that if we know the conditional distribution \\(\\Pr(B \\mid A)\\) and the marginal distribution \\(\\Pr(A)\\), we can combine these (via multiplication) to obtain the joint distribution \\(\\Pr(B,A)\\)."
  },
  {
    "objectID": "w07/slides.html#moving-to-continuous-world",
    "href": "w07/slides.html#moving-to-continuous-world",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Moving to Continuous World",
    "text": "Moving to Continuous World\n\nIntuitions from discrete world do translate into good intuitions for continuous world, in this case!\nCan ‚Äúmove‚Äù discrete table into continuous space like Riemann sums ‚Äúmove‚Äù discrete sums into integrals:"
  },
  {
    "objectID": "w07/slides.html#smoothing-our-example",
    "href": "w07/slides.html#smoothing-our-example",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "‚ÄúSmoothing‚Äù Our Example",
    "text": "‚ÄúSmoothing‚Äù Our Example\n\nInstead of discrete \\(G\\) with \\(\\mathcal{R}_G = \\{10, 11, 12\\}\\), we have a continuous \\(G\\) with \\(\\mathcal{R}_G = [10,12] \\subset \\mathbb{R}\\) (‚Äúprogress‚Äù through senior HS)\nInstead of discrete \\(H\\) with \\(\\mathcal{R}_H = \\{0, 1\\}\\), now we keep track of continuous ‚Äúhonors spectrum‚Äù \\(H\\) with \\(\\mathcal{R}_H = [0, 1] \\subset \\mathbb{R}\\)\nA student near the beginning of 10th grade who is towards the ‚Äúhigh end‚Äù of the ‚Äúhonors spectrum‚Äù: (\\(G = 10.03\\) and \\(H = 0.95\\))"
  },
  {
    "objectID": "w07/slides.html#smoothing-our-tables",
    "href": "w07/slides.html#smoothing-our-tables",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "‚ÄúSmoothing‚Äù Our Tables",
    "text": "‚ÄúSmoothing‚Äù Our Tables\n\nSums become integrals\nRe-normalization (ensuring that probability mass values sum to 1) becomes ensuring that probability density values integrate to 1.\nWhat comes in place of frequency table?\nAnswer in theory: Joint pdf\nAnswer in practice: Depends on the context üò¨"
  },
  {
    "objectID": "w07/slides.html#continuous-joint-pdfs",
    "href": "w07/slides.html#continuous-joint-pdfs",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Continuous Joint pdfs",
    "text": "Continuous Joint pdfs\n\nThe volume of this Hershey Kiss is exactly \\(1\\)\nIntegrating over a region \\(C\\) gives us\n\n\\[\n\\frac{\\text{Volume}(\\{(X,Y) \\mid (X,Y) \\in C\\})}{\\text{Volume}(\\text{Hershey Kiss})} = \\Pr((X,Y) \\in C)\n\\]\n\nFigure 3.11 from (degroot_probability_2013?)"
  },
  {
    "objectID": "w07/slides.html#conditional-pdfs",
    "href": "w07/slides.html#conditional-pdfs",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Conditional pdfs",
    "text": "Conditional pdfs\n\nNow, if we learn that \\(Y = y_0\\), can take ‚Äúslice‚Äù at \\(y = y_0\\)\nTotal area of this slice is not \\(1\\), so \\(f_{X,Y}(x, y_0)\\) is not a valid pdf\nDividing by total area of slice would generate a valid pdf. What is this area? \\(f_X(y_0)\\)\n\\(\\implies\\) \\(f_{X \\mid Y = y_0}(x \\mid y_0) = \\frac{f_{X,Y}(x, y_0)}{f_X(y_0)}\\) is valid (conditional) pdf\n\n\nFigure 3.20 from (degroot_probability_2013?)"
  },
  {
    "objectID": "w07/slides.html#working-backwards-redux",
    "href": "w07/slides.html#working-backwards-redux",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Working Backwards Redux",
    "text": "Working Backwards Redux\n\nWhile in discrete world we could easily provide a table, in continuous world we often/usually have to work backwards; we may just be given:\n\\(G \\sim \\mathcal{U}(10, 12)\\)\n\\(H \\sim \\ddot{\\mathcal{N}}(\\mu = 0.5, \\sigma = 0.1, a = 0, b = 1)\\), and\n\\(G \\perp H\\) (so \\(\\Pr(G \\mid H) = \\Pr(G), \\Pr(H \\mid G) = \\Pr(H)\\))\n(i.e., marginal distributions = conditional distributions)."
  },
  {
    "objectID": "w07/slides.html#the-marginal-pdfs-of-g-and-h",
    "href": "w07/slides.html#the-marginal-pdfs-of-g-and-h",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Marginal pdfs of \\(G\\) and \\(H\\)",
    "text": "The Marginal pdfs of \\(G\\) and \\(H\\)\n\nSince we know \\(G \\sim \\mathcal{U}(10,12)\\), we know (or we could look up) that \\(G\\) has pdf\n\n\\[\nf_G(v_G) = \\frac{1}{12 - 10} = \\frac{1}{2}.\n\\]\n\n\\(H\\) has a slightly fancier distribution, the truncated normal distribution, but nonetheless a pdf we can derive from (a) knowing the pdf of the normal distribution and (b) knowing what we‚Äôve just talked about regarding conditional distributions"
  },
  {
    "objectID": "w07/slides.html#the-truncated-normal-distribution",
    "href": "w07/slides.html#the-truncated-normal-distribution",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Truncated Normal Distribution",
    "text": "The Truncated Normal Distribution\n\n\\(\\ddot{\\mathcal{N}}\\) may look scary, but \\(X \\sim \\ddot{\\mathcal{N}}(\\mu, \\sigma, a, b)\\) just means that \\(X\\) can be ‚Äúconstructed from scratch‚Äù (similar to Problem 1 on the Lab 5 Assignment) as\n\n\\[\nX \\sim \\mathcal{N}(\\mu, \\sigma) \\implies [X \\mid a &lt; X &lt; b] \\sim \\ddot{\\mathcal{N}}(\\mu, \\sigma, a, b)\n\\]\n\nAdapted from simstudy package documentation"
  },
  {
    "objectID": "w07/slides.html#the-truncated-normal-pdf",
    "href": "w07/slides.html#the-truncated-normal-pdf",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Truncated Normal pdf",
    "text": "The Truncated Normal pdf\n\nSince we see a conditioning bar on the previous slide, we can infer what the pdf of this conditional distribution would look like. If \\(X \\sim \\ddot{\\mathcal{N}}(\\mu, \\sigma, a, b)\\), then \\(X\\) has pdf\n\n\\[\nf_X(v) = \\frac{\\frac{1}{\\sigma}\\varphi\\left(\\frac{v_H-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{b-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right)} \\approx \\frac{\\Pr(X = v, a &lt; X &lt; b)}{\\Pr(a &lt; X &lt; b)}\n\\]\n\n\\(\\varphi\\) is the pdf of \\(\\mathcal{N}(0,1)\\)\n\\(\\Phi\\) is the CDF of \\(\\mathcal{N}(0,1)\\)\n\n\n\n(note the consistent usage of lowercase letters to describe pdfs and capital letters to describe CDFs, even in Greek!)"
  },
  {
    "objectID": "w07/slides.html#back-to-working-backwards",
    "href": "w07/slides.html#back-to-working-backwards",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Back to Working Backwards",
    "text": "Back to Working Backwards\n\nBy the definition of independence, we can obtain joint pdf \\(f_{G,H}(v_G, v_H)\\) by multiplying the marginal pdf \\(f_G(v_G)\\) and marginal pdf \\(f_H(v_H)\\):\n\n\\[\n\\begin{align*}\nf_{G,H}(v_G, v_H) &= f_G(v_G) \\cdot f_H(v_H) \\\\\n&= \\frac{\\frac{1}{2\\sigma}\\varphi\\left(\\frac{v_H-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{b-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right)}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w07/slides.html#moving-forwards-again",
    "href": "w07/slides.html#moving-forwards-again",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Moving Forwards Again",
    "text": "Moving Forwards Again\n\nWe‚Äôve arrived at the case we had in discrete world, where we know the joint distribution!\nWe can integrate wherever we took sums in the discrete case to obtain marginal pdfs:\n\n\\[\n\\begin{align*}\nf_G(v_G) &= \\int_{0}^{1}f_{G,H}(v_G,v_H)\\mathrm{d}v_H = \\frac{1}{2}, \\\\\nf_H(v_H) &= \\int_{10}^{12}f_{G,H}(v_G, v_H)\\mathrm{d}v_G = \\frac{\\frac{1}{\\sigma}\\varphi\\left(\\frac{v_H-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{b-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right)}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w07/slides.html#conditional-distributions-in-continuous-world",
    "href": "w07/slides.html#conditional-distributions-in-continuous-world",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Conditional Distributions in Continuous World",
    "text": "Conditional Distributions in Continuous World\nAnd we can compute conditional pdfs by renormalizing so that the denominator is no longer the integral of the distribution over all its possible values (hence just the number \\(1\\)) but a ratio of joint distribution to marginal distribution values like the following:\n\\[\nf_{H \\mid G}(v_H | v_G) = \\frac{f_{G,H}(v_G, v_H)}{f_G(v_G)}.\n\\]"
  },
  {
    "objectID": "w07/slides.html#you-dont-have-to-stare-helplessly-at-scary-math",
    "href": "w07/slides.html#you-dont-have-to-stare-helplessly-at-scary-math",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "You Don‚Äôt Have To Stare Helplessly At Scary Math!",
    "text": "You Don‚Äôt Have To Stare Helplessly At Scary Math!\n\nTry to link the continuous equations back to their simpler discrete forms\nWork with the discrete forms to develop intuition, then\nConvert sums back into integrals once you‚Äôre ready"
  },
  {
    "objectID": "w07/slides.html#a-concrete-strategy",
    "href": "w07/slides.html#a-concrete-strategy",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "A Concrete Strategy",
    "text": "A Concrete Strategy\n\nStart by discretizing (‚Äúbinning‚Äù) the possible values of a continuous RV to obtain a discrete RV:\n\nSplit \\([10,12]\\) into three equal-length bins, \\([0,1]\\) into two equal-length bins\nSimulate \\((G, H)\\) pairs, sort into bins, plot joint / marginal / conditional distributions of binned data\n\nAs you make bins thinner and thinner‚Ä¶"
  },
  {
    "objectID": "w07/slides.html#the-multinoulli-distribution",
    "href": "w07/slides.html#the-multinoulli-distribution",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Multinoulli Distribution",
    "text": "The Multinoulli Distribution\n\nThis may seem like a weird/contrived distribution, but it‚Äôs perfect for building intuition, as your first \\(N\\)-dimensional distribution (\\(N &gt; 2\\))\n\\(\\mathbf{X}\\) is a six-dimensional Vector-Valued RV, so that\n\\[\n  \\mathbf{X} = (X_1, X_2, X_3, X_4, X_5, X_6),\n  \\]\nwhere \\(\\mathcal{R}_{X_1} = \\{0, 1\\}, \\mathcal{R}_{X_2} = \\{0, 1\\}, \\ldots, \\mathcal{R}_{X_6} = \\{0, 1\\}\\)\nBut, \\(X_1, X_2, \\ldots, X_6\\) are not independent! In fact, they are so dependent that if one has the value \\(1\\), the rest must have value \\(0\\), so that we can infer the support of \\(\\mathbf{X}\\):\n\\[\n  \\begin{align*}\n  \\mathcal{R}_{\\mathbf{X}} = \\{ &(1,0,0,0,0,0),(0,1,0,0,0,0),(0,0,1,0,0,0), \\\\\n  &(0,0,0,1,0,0),(0,0,0,0,1,0),(0,0,0,0,0,1)\\}\n  \\end{align*}\n  \\]\nLastly, need to define the probability that \\(\\mathbf{X}\\) takes on any of these values. Let‚Äôs say \\(\\Pr(\\mathbf{X} = \\mathbf{v}) = \\frac{1}{6}\\) for all \\(\\mathbf{v} \\in \\mathcal{R}_{\\mathbf{X}}\\). Do we see the structure behind this contrived case?\n(For math major friends, there is an isomorphism afoot‚Ä¶ For the rest, it‚Äôs an extremely inefficient way to model outcomes from rolling a fair die)"
  },
  {
    "objectID": "w07/slides.html#the-multivariate-normal-distribution",
    "href": "w07/slides.html#the-multivariate-normal-distribution",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Multivariate Normal Distribution",
    "text": "The Multivariate Normal Distribution\n\nWe‚Äôve already seen the matrix notation for writing the parameters of this distribution: \\(\\mathbf{X}_{[k \\times 1]} \\sim \\mathcal{N}_k(\\boldsymbol\\mu_{[k \\times 1]}, \\Sigma_{[k \\times k]})\\)\nNow we get to crack open the matrix notation for writing its pdf:\n\n\\[\nf_\\mathbf{X}(\\mathbf{v}_{[k \\times 1]}) = \\underbrace{\\left(\\frac{1}{\\sqrt{2\\pi}}\\right)^k \\frac{1}{\\sqrt{\\det(\\Sigma)}}}_{\\text{Normalizing constants}} \\exp\\left(-\\frac{1}{2}\\underbrace{(\\mathbf{v} - \\boldsymbol\\mu)^\\top \\Sigma^{-1} (\\mathbf{v} - \\boldsymbol\\mu)}_{\\text{Quadratic form}}\\right)\n\\]\n\nTry to squint your eyes while looking at the above, and compare with the pdf we‚Äôve seen for 1D \\(\\mathcal{N}(\\mu,\\sigma)\\) (W05) and the structure you‚Äôve seen for 2D \\(\\Sigma\\) (W06):\n\n\n\n\n\n\n\n\\[\nf_X(v) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\bigexp{-\\frac{1}{2}\\left(\\frac{v - \\mu}{\\sigma}\\right)^2}\n\\]\n\n\n\\[\n\\begin{align*}\n\\mathbf{\\Sigma} &= \\begin{bmatrix}\\sigma_1^2 & \\rho\\sigma_1\\sigma_2 \\\\ \\rho\\sigma_2\\sigma_1 & \\sigma_2^2\\end{bmatrix} \\\\[0.1em]\n\\implies \\det(\\Sigma) &= \\sigma_1^2\\sigma_2^2 - \\rho^2\\sigma_1^2\\sigma_2^2 \\\\\n&= \\sigma_1^2\\sigma_2^2(1-\\rho^2)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w07/slides.html#quadratic-forms",
    "href": "w07/slides.html#quadratic-forms",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Quadratic Forms",
    "text": "Quadratic Forms\n\nQuadratic forms will seem scary until someone forces you to write out the matrix multiplication!\nStart with the 1D case: \\(\\mathbf{v} = [v_1]\\), \\(\\boldsymbol\\mu = [\\mu_1]\\), \\(\\Sigma = [\\sigma^2]\\). Then\n\n\\[\n(\\mathbf{v} - \\boldsymbol\\mu)^\\top \\Sigma^{-1} (\\mathbf{v - \\boldsymbol\\mu}) = (v_1 - \\mu_1)\\frac{1}{\\sigma^2}(v_1 - \\mu_1) = \\left(\\frac{v_1-\\mu_1}{\\sigma}\\right)^2.\n\\]"
  },
  {
    "objectID": "w07/slides.html#the-2d-case",
    "href": "w07/slides.html#the-2d-case",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The 2D Case",
    "text": "The 2D Case\n\nLet \\(\\mathbf{v} = \\left[\\begin{smallmatrix}v_1 \\\\ v_2\\end{smallmatrix}\\right]\\), \\(\\boldsymbol\\mu = \\left[ \\begin{smallmatrix}\\mu_1 \\\\ \\mu_2 \\end{smallmatrix}\\right]\\), \\(\\Sigma\\) as in previous slide. Then \\(\\mathbf{v} - \\boldsymbol\\mu = \\left[ \\begin{smallmatrix} v_1 - \\mu_1 \\\\ v_2 - \\mu_2 \\end{smallmatrix} \\right]\\).\nUsing what we know about \\(2 \\times 2\\) matrix inversion,\n\n\\[\n\\Sigma^{-1} = \\frac{1}{\\det(\\Sigma)}\\left[ \\begin{smallmatrix} \\sigma_2^2 & -\\rho \\sigma_2\\sigma_1 \\\\ -\\rho \\sigma_1\\sigma_2 & \\sigma_1^2\\end{smallmatrix} \\right] = \\frac{1}{\\sigma_1^2\\sigma_2^2(1-\\rho^2)}\\left[ \\begin{smallmatrix} \\sigma_2^2 & -\\rho \\sigma_2\\sigma_1 \\\\ -\\rho \\sigma_1\\sigma_2 & \\sigma_1^2\\end{smallmatrix} \\right]\n\\]\n\nSo we can write everything as just a bunch of matrix multiplications:\n\n\\[\n\\begin{align*}\n&(\\mathbf{v} - \\boldsymbol\\mu)^\\top \\Sigma^{-1} (\\mathbf{v - \\boldsymbol\\mu}) = \\frac{1}{\\sigma_1^2\\sigma_2^2(1-\\rho^2)}\\begin{bmatrix}v_1 - \\mu_1 & v_2 - \\mu_2\\end{bmatrix} \\cdot \\begin{bmatrix} \\sigma_2^2 & -\\rho \\sigma_2\\sigma_1 \\\\ -\\rho \\sigma_1\\sigma_2 & \\sigma_1^2\\end{bmatrix} \\cdot \\begin{bmatrix}v_1 - \\mu_1 \\\\ v_2 - \\mu_2\\end{bmatrix} \\\\\n&= \\frac{1}{\\sigma_1^2\\sigma_2^2(1-\\rho^2)}\\begin{bmatrix}(v_1-\\mu_1)\\sigma_2^2 - (v_2-\\mu_2)\\rho\\sigma_1\\sigma_2 & (v_2-\\mu_2)\\sigma_1^2 - (v_1-\\mu_1)\\rho\\sigma_2\\sigma_1 \\end{bmatrix}\\cdot \\begin{bmatrix}v_1 - \\mu_1 \\\\ v_2 - \\mu_2\\end{bmatrix} \\\\\n&= \\frac{1}{\\sigma_1^2\\sigma_2^2(1-\\rho^2)}\\left( (v_1-\\mu_1)^2\\sigma_2^2 - (v_1-\\mu_1)(v_1-\\mu_2)\\sigma_1\\sigma_2 + (v_2-\\mu_2)^2\\sigma_1^2 - (v_1-\\mu_1)(v_2-\\mu_2)\\sigma_2\\sigma_1 \\right) \\\\\n&= \\boxed{\\frac{1}{1-\\rho^2}\\left( \\left(\\frac{v_1-\\mu_1}{\\sigma_1}\\right)^2 + \\left(\\frac{v_2-\\mu_2}{\\sigma_2}\\right)^2 - 2\\rho\\frac{(v_1-\\mu_1)(v_2-\\mu_2)}{\\sigma_1\\sigma_2} \\right)}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w07/slides.html#the-2d-case-in-its-final-form",
    "href": "w07/slides.html#the-2d-case-in-its-final-form",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The 2D Case In Its FINAL FORM",
    "text": "The 2D Case In Its FINAL FORM\n\\[\nf_{\\mathbf{X}}(\\mathbf{v}) = C\\bigexp{-\\frac{1}{2}\\frac{1}{1-\\rho^2}\\left( \\left(\\frac{v_1-\\mu_1}{\\sigma_1}\\right)^2 + \\left(\\frac{v_2-\\mu_2}{\\sigma_2}\\right)^2 - 2\\rho\\frac{(v_1-\\mu_1)(v_2-\\mu_2)}{\\sigma_1\\sigma_2} \\right)}\n\\]\nwhere\n\\[\nC = \\frac{1}{2\\pi\\sigma_1\\sigma_2\\sqrt{1-\\rho^2}}.\n\\]"
  },
  {
    "objectID": "w07/slides.html#references",
    "href": "w07/slides.html#references",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nDSAN 5100-03 W07: Joint, Marginal, Conditional Distributions"
  },
  {
    "objectID": "w07/index.html",
    "href": "w07/index.html",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "",
    "text": "Open slides in new window ‚Üí",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#frequency-tables",
    "href": "w07/index.html#frequency-tables",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Frequency Tables",
    "text": "Frequency Tables\n\n\n\n\n\n\n\nWhat does this tell us on its own (before computing proportions in our heads) that is useful for probability?\nAnswer: Not very much!\nBut, if we can find the overall total, then it would tell us a lot (everything we need to know)!\n\n\n\n\n\n\nTable¬†1: A frequency table of HS students (\\(G\\) = grade, \\(H\\) = honors status)This tells us, e.g., there are 5 honors students in grade 10\n\n\n\n¬†\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\\(G = 11\\)\n6\n4\n\n\n\\(G = 12\\)\n7\n1\n\n\n\n\n\n\n\n\n\n\nA frequency table where each row corresponds to a grade in a certain senior high school, each column corresponds to honor-student-status (\\(H=1\\) represents honors, \\(H=0\\) represents non-honors), and each cell contains the number of students in that grade with that honors-status",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#why-do-we-need-the-total",
    "href": "w07/index.html#why-do-we-need-the-total",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Why Do We Need The Total?",
    "text": "Why Do We Need The Total?\n\nQ1: Someone asks the probability that a randomly-selected student will be an honor student in 11th grade.\nQ2: Someone asks what proportion of students are honors\nQ3: Someone asks what % of 12th grade are honors\n\nQ1, for example, is asking us for \\(\\Pr(G = 11, H = 1)\\), a question we can answer if we know the joint distribution \\(f_{G,H}(v_G, v_H)\\).",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#back-to-the-na√Øve-definition",
    "href": "w07/index.html#back-to-the-na√Øve-definition",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Back to the Na√Øve Definition",
    "text": "Back to the Na√Øve Definition\nUsing our na√Øve definition of probability, we can compute this probability using the frequencies in the table as\n\\[\n\\Pr(G = 11, H = 1) = \\frac{\\#(G = 11, H = 1)}{\\#\\text{ Students Total}}\n\\]\nPlugging in the values from Table¬†1, we obtain the answer:\n\\[\n\\Pr(G = 11, H = 1) = \\frac{4}{33} \\approx 0.121\n\\]",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#frequency-table-rightarrow-probability-table",
    "href": "w07/index.html#frequency-table-rightarrow-probability-table",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Frequency Table \\(\\rightarrow\\) Probability Table",
    "text": "Frequency Table \\(\\rightarrow\\) Probability Table\n\nWhen we divide by 33, we are normalizing the counts, producing probabilities (normalized counts)\nBy normalizing all cells in the table, we convert our frequency table into a probability table",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#computing-overall-total-by-column",
    "href": "w07/index.html#computing-overall-total-by-column",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Computing Overall Total by Column",
    "text": "Computing Overall Total by Column\nWe could compute the total by summing columns, then summing over our individual column totals to get 33:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\n\\(G = 11\\)\n6\n4\n\n\n\n\\(G = 12\\)\n7\n1\n\n\n\nTotal\n23\n10\n33",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#computing-overall-total-by-row",
    "href": "w07/index.html#computing-overall-total-by-row",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Computing Overall Total by Row",
    "text": "Computing Overall Total by Row\nOr, we could compute the total by summing rows, then summing over our individual row totals to get 33:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\n\\(G = 10\\)\n10\n5\n15\n\n\n\n\\(G = 11\\)\n6\n4\n10\n\n\n\n\\(G = 12\\)\n7\n1\n8\n\n\n\nTotal\n\n\n33",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#bringing-both-methods-together",
    "href": "w07/index.html#bringing-both-methods-together",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Bringing Both Methods Together",
    "text": "Bringing Both Methods Together\n\n\n\nTable¬†2: The same frequency table as in Table¬†1, but now with row and column totals representing marginal frequencies\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\n\\(G = 10\\)\n10\n5\n15\n\n\n\n\\(G = 11\\)\n6\n4\n10\n\n\n\n\\(G = 12\\)\n7\n1\n8\n\n\n\nTotal\n23\n10\n33",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#frequencies-to-probabilities",
    "href": "w07/index.html#frequencies-to-probabilities",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Frequencies to Probabilities",
    "text": "Frequencies to Probabilities\n\n\n\n\n\n\n\nNow (before we think about row/column totals) let‚Äôs use overall total (33) to convert counts into probabilities:\n\n\n\n\n\n\nTable¬†3: Table from prev slide with all values normalized (divided by the total number of obs)\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{5}{33}\\)\n\\(\\frac{15}{33}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{33}\\)\n\\(\\frac{4}{33}\\)\n\\(\\frac{10}{33}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{33}\\)\n\\(\\frac{1}{33}\\)\n\\(\\frac{8}{33}\\)\n\n\nTotal\n\\(\\frac{23}{33}\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{33}{33}\\)",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#one-table-three-distributions",
    "href": "w07/index.html#one-table-three-distributions",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "One Table, Three Distributions!",
    "text": "One Table, Three Distributions!\nNow that we have normalized counts, different pieces of this table give different probability distributions:\n\n\n\nJoint Distribution \\(f_{G,H}(v_G, v_H)\\): Look at value in row \\(v_G\\), col \\(v_H\\)\nMarginal Distributions\n\n\\(f_G(v_G)\\): Look at total for row \\(v_G\\)\n\\(f_H(v_H)\\): Look at total for column \\(v_H\\)\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{5}{33}\\)\n\\(\\frac{15}{33}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{33}\\)\n\\(\\frac{4}{33}\\)\n\\(\\frac{10}{33}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{33}\\)\n\\(\\frac{1}{33}\\)\n\\(\\frac{8}{33}\\)\n\n\nTotal\n\\(\\frac{23}{33}\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{33}{33}\\)",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#summary-joint-rightarrow-marginal",
    "href": "w07/index.html#summary-joint-rightarrow-marginal",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Summary: Joint \\(\\rightarrow\\) Marginal",
    "text": "Summary: Joint \\(\\rightarrow\\) Marginal\n\nNote how marginal distributions were obtained by summing the joint distribution over a particular dimension:\nSumming each column (\\(H = 0\\) and \\(H = 1\\)) produced marginal distribution of \\(H\\):\n\n\n\n\n\n\n\n\n\n\n\\(\\Pr(H = 0, G = 10)\\)\n\n\n+\n\\(\\Pr(H = 0, G = 11)\\)\n\n\n+\n\\(\\Pr(H = 0, G = 12)\\)\n\n\n=\n\\(\\Pr(H = 0)\\)\n\n\n\n\n\n\n\n\n\n\\(\\Pr(H = 1, G = 10)\\)\n\n\n+\n\\(\\Pr(H = 1, G = 11)\\)\n\n\n+\n\\(\\Pr(H = 1, G = 12)\\)\n\n\n=\n\\(\\Pr(H = 1)\\)\n\n\n\n\n\n\nSumming each row (\\(G = 10\\), \\(G = 11\\), \\(G = 12\\)) produced marginal distribution of \\(G\\):\n\n\n\n\n\\(\\Pr(G = 10, H = 0)\\)\n+\n\\(\\Pr(G = 10, H = 1)\\)\n=\n\\(\\Pr(G = 10)\\)\n\n\n\\(\\Pr(G = 11, H = 0)\\)\n+\n\\(\\Pr(G = 11, H = 1)\\)\n=\n\\(\\Pr(G = 11)\\)\n\n\n\\(\\Pr(G = 12, H = 0)\\)\n+\n\\(\\Pr(G = 12, H = 1)\\)\n=\n\\(\\Pr(G = 12)\\)",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#whats-missing-conditional-distributions",
    "href": "w07/index.html#whats-missing-conditional-distributions",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "What‚Äôs Missing? Conditional Distributions",
    "text": "What‚Äôs Missing? Conditional Distributions\n\nConditional distribution does not represent a sum but a slice: we consider e.g.¬†one particular row or one particular column of the table.\nüö®Warningüö®! unlike in joint and marginal cases, when computing conditional distributions we have to renormalize, since we are ‚Äúentering world‚Äù where we only consider subsets of the table where condition is met!\nRecall slide about how all distributions are conditional distributions:\n\n\n\n\n\\(\\Pr(G = 10, H = 1)\\)\n\n\\[\n\\begin{align*}\n= &\\Pr(G = 10, H = 1 \\mid \\Omega) \\\\[0.6em]\n= &\\frac{\\#(G = 10, H = 1, \\Omega)}{\\#\\text{ Total }(\\Omega)\\text{ ‚úÖ}}\n\\end{align*}\n\\]\n\n\n\\(\\Pr(G = 10)\\)\n\n\\[\n\\begin{align*}\n= &\\Pr(G = 10 \\mid \\Omega) \\\\[0.6em]\n= &\\frac{\\#(G = 10, \\Omega)}{\\#\\text{ Total }(\\Omega)\\text{ ‚úÖ}}\n\\end{align*}\n\\]\n\n\n\\(\\Pr(G = 10 \\mid H = 1)\\)\n\n\\[\n\\begin{align*}\n= &\\frac{\\Pr(G = 10, H = 1)}{\\Pr(H = 1)} \\\\[0.6em]\n= &\\frac{\\#(G = 10, H = 1)}{\\#(H = 1)\\text{ üò≥}}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#conditional-distributions-from-columns",
    "href": "w07/index.html#conditional-distributions-from-columns",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Conditional Distributions from Columns",
    "text": "Conditional Distributions from Columns\nLet‚Äôs extract just the \\(H = 1\\) column:\n\n\n\n\n\n\n\n\n\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n5\n\n\n\\(G = 11\\)\n4\n\n\n\\(G = 12\\)\n1\n\n\nTotal\n10\n\n\n\n\n\n\n\n\n\n\n\n\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{5}{10}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{4}{10}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{1}{10}\\)\n\n\nTotal\n\\(\\frac{10}{10}\\)\n\n\n\n\n\n\nBefore, 10 was a particular marginal frequency of interest; now 10 is just a total that we use to renormalize",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#conditional-distributions-from-rows",
    "href": "w07/index.html#conditional-distributions-from-rows",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Conditional Distributions from Rows",
    "text": "Conditional Distributions from Rows\nLet‚Äôs extract just the \\(G = 10\\) row:\n\n\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n5\n10\n15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{5}{15}\\)\n\\(\\frac{10}{15}\\)\n\\(\\frac{15}{15}\\)\n\n\n\n\n\n\nBefore, 15 was a particular marginal frequency of interest; now 15 is just a total that we use to renormalize",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#discrete-world-summary",
    "href": "w07/index.html#discrete-world-summary",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Discrete World Summary",
    "text": "Discrete World Summary\nWe now have the link between three types of distributions derived from our table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistribution Type\nHow Many?\nExample Value\n\n\n\n\nJoint Distribution\n1\n\\(\\Pr(G = 11, H = 1)\\)\\(= \\frac{4}{33}\\)\n\n\nMarginal Distributions\n2\n\\(\\Pr(H = 1) = \\frac{10}{33}\\)\n\n\nConditional Distributions\n6\n\\(\\Pr(G = 10 \\mid H = 1)\\)\\(= \\frac{5}{10}\\)\n\n\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{5}{33}\\)\n\\(\\frac{15}{33}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{33}\\)\n\\(\\frac{4}{33}\\)\n\\(\\frac{10}{33}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{33}\\)\n\\(\\frac{1}{33}\\)\n\\(\\frac{8}{33}\\)\n\n\nTotal\n\\(\\frac{23}{33}\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{33}{33}\\)\n\n\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{23}\\)\n\\(\\frac{5}{10}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{23}\\)\n\\(\\frac{4}{10}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{23}\\)\n\\(\\frac{1}{10}\\)\n\n\nTotal\n\\(\\frac{23}{23}\\)\n\\(\\frac{10}{10}\\)",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#working-backwards",
    "href": "w07/index.html#working-backwards",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Working Backwards",
    "text": "Working Backwards\n\nHere we started from the joint distribution and derived marginal and conditional distributions\nSame intuition, plus math, lets us go in opposite direction: given marginal and conditional distributions, can derive joint distribution, since (conditional prob defn):\n\n\n\n\n\n\n\n\n\n\\(\\Pr(A \\mid B)\\)\n\\(=\\)\n\\(\\Pr(A, B)\\)\n\n\n\\(\\Pr(B)\\)\n\n\n\n\n\\[\n\\iff\n\\]\n\n\n\n\n\\(\\Pr(A,B)\\)\n\\(=\\)\n\\(\\Pr(A \\mid B)\\)\n\\(\\cdot\\)\n\\(\\Pr(B)\\)\n\n\n\n\n\n\nfrom which we can see that if we know the conditional distribution \\(\\Pr(B \\mid A)\\) and the marginal distribution \\(\\Pr(A)\\), we can combine these (via multiplication) to obtain the joint distribution \\(\\Pr(B,A)\\).",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#moving-to-continuous-world",
    "href": "w07/index.html#moving-to-continuous-world",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Moving to Continuous World",
    "text": "Moving to Continuous World\n\nIntuitions from discrete world do translate into good intuitions for continuous world, in this case!\nCan ‚Äúmove‚Äù discrete table into continuous space like Riemann sums ‚Äúmove‚Äù discrete sums into integrals:",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#smoothing-our-example",
    "href": "w07/index.html#smoothing-our-example",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "‚ÄúSmoothing‚Äù Our Example",
    "text": "‚ÄúSmoothing‚Äù Our Example\n\nInstead of discrete \\(G\\) with \\(\\mathcal{R}_G = \\{10, 11, 12\\}\\), we have a continuous \\(G\\) with \\(\\mathcal{R}_G = [10,12] \\subset \\mathbb{R}\\) (‚Äúprogress‚Äù through senior HS)\nInstead of discrete \\(H\\) with \\(\\mathcal{R}_H = \\{0, 1\\}\\), now we keep track of continuous ‚Äúhonors spectrum‚Äù \\(H\\) with \\(\\mathcal{R}_H = [0, 1] \\subset \\mathbb{R}\\)\nA student near the beginning of 10th grade who is towards the ‚Äúhigh end‚Äù of the ‚Äúhonors spectrum‚Äù: (\\(G = 10.03\\) and \\(H = 0.95\\))",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#smoothing-our-tables",
    "href": "w07/index.html#smoothing-our-tables",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "‚ÄúSmoothing‚Äù Our Tables",
    "text": "‚ÄúSmoothing‚Äù Our Tables\n\nSums become integrals\nRe-normalization (ensuring that probability mass values sum to 1) becomes ensuring that probability density values integrate to 1.\nWhat comes in place of frequency table?\nAnswer in theory: Joint pdf\nAnswer in practice: Depends on the context üò¨",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#continuous-joint-pdfs",
    "href": "w07/index.html#continuous-joint-pdfs",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Continuous Joint pdfs",
    "text": "Continuous Joint pdfs\n\nThe volume of this Hershey Kiss is exactly \\(1\\)\nIntegrating over a region \\(C\\) gives us\n\n\\[\n\\frac{\\text{Volume}(\\{(X,Y) \\mid (X,Y) \\in C\\})}{\\text{Volume}(\\text{Hershey Kiss})} = \\Pr((X,Y) \\in C)\n\\]\n\n\n\nFigure 3.11 from (degroot_probability_2013?)",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#conditional-pdfs",
    "href": "w07/index.html#conditional-pdfs",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Conditional pdfs",
    "text": "Conditional pdfs\n\nNow, if we learn that \\(Y = y_0\\), can take ‚Äúslice‚Äù at \\(y = y_0\\)\nTotal area of this slice is not \\(1\\), so \\(f_{X,Y}(x, y_0)\\) is not a valid pdf\nDividing by total area of slice would generate a valid pdf. What is this area? \\(f_X(y_0)\\)\n\\(\\implies\\) \\(f_{X \\mid Y = y_0}(x \\mid y_0) = \\frac{f_{X,Y}(x, y_0)}{f_X(y_0)}\\) is valid (conditional) pdf\n\n\n\n\nFigure 3.20 from (degroot_probability_2013?)",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#working-backwards-redux",
    "href": "w07/index.html#working-backwards-redux",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Working Backwards Redux",
    "text": "Working Backwards Redux\n\nWhile in discrete world we could easily provide a table, in continuous world we often/usually have to work backwards; we may just be given:\n\\(G \\sim \\mathcal{U}(10, 12)\\)\n\\(H \\sim \\ddot{\\mathcal{N}}(\\mu = 0.5, \\sigma = 0.1, a = 0, b = 1)\\), and\n\\(G \\perp H\\) (so \\(\\Pr(G \\mid H) = \\Pr(G), \\Pr(H \\mid G) = \\Pr(H)\\))\n(i.e., marginal distributions = conditional distributions).",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#the-marginal-pdfs-of-g-and-h",
    "href": "w07/index.html#the-marginal-pdfs-of-g-and-h",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Marginal pdfs of \\(G\\) and \\(H\\)",
    "text": "The Marginal pdfs of \\(G\\) and \\(H\\)\n\nSince we know \\(G \\sim \\mathcal{U}(10,12)\\), we know (or we could look up) that \\(G\\) has pdf\n\n\\[\nf_G(v_G) = \\frac{1}{12 - 10} = \\frac{1}{2}.\n\\]\n\n\\(H\\) has a slightly fancier distribution, the truncated normal distribution, but nonetheless a pdf we can derive from (a) knowing the pdf of the normal distribution and (b) knowing what we‚Äôve just talked about regarding conditional distributions",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#the-truncated-normal-distribution",
    "href": "w07/index.html#the-truncated-normal-distribution",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Truncated Normal Distribution",
    "text": "The Truncated Normal Distribution\n\n\\(\\ddot{\\mathcal{N}}\\) may look scary, but \\(X \\sim \\ddot{\\mathcal{N}}(\\mu, \\sigma, a, b)\\) just means that \\(X\\) can be ‚Äúconstructed from scratch‚Äù (similar to Problem 1 on the Lab 5 Assignment) as\n\n\\[\nX \\sim \\mathcal{N}(\\mu, \\sigma) \\implies [X \\mid a &lt; X &lt; b] \\sim \\ddot{\\mathcal{N}}(\\mu, \\sigma, a, b)\n\\]\n\nrnormt &lt;- function(n, range, mu, s = 1) {\n  \n  # range is a vector of two values\n  \n  F.a &lt;- pnorm(min(range), mean = mu, sd = s)\n  F.b &lt;- pnorm(max(range), mean = mu, sd = s)\n  \n  u &lt;- runif(n, min = F.a, max = F.b)\n  \n  qnorm(u, mean = mu, sd = s)\n  \n}\nlibrary(data.table)\nlibrary(simstudy)\nlibrary(paletteer)\n\ndefC &lt;- defCondition(condition= \"tt == 1\", \n                     formula = \"rnormt(10000, c(-Inf, Inf), mu = 0, s = 3)\")\ndefC &lt;- defCondition(defC, \"tt == 2\", \n                     formula = \"rnormt(10000, c(0, Inf), mu = 0, s = 3)\")\ndefC &lt;- defCondition(defC, \"tt == 3\", \n                     formula = \"rnormt(10000, c(-3, 3.5), mu = 0, s = 3)\")\n\ndd &lt;- genData(30000)\ndd &lt;- trtAssign(dd, nTrt = 3, grpName = \"tt\")\ndd &lt;- addCondition(defC, dd, \"x\")\n\ndd[, tt := factor(tt, \n     labels = c(\"No truncation\", \"Left truncation at 0\", \"Left and right truncation\"))]\n\nggplot(data = dd, aes(x = x, group = tt)) +\n  geom_histogram(aes(fill = tt), alpha = 1, binwidth = .2, boundary = 0) +\n  facet_grid(~tt) +\n  theme(panel.grid = element_blank(),\n        axis.title = element_blank(),\n        legend.position = \"none\") +\n  dsan_theme()\n\n\n\n\nAdapted from simstudy package documentation",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#the-truncated-normal-pdf",
    "href": "w07/index.html#the-truncated-normal-pdf",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Truncated Normal pdf",
    "text": "The Truncated Normal pdf\n\nSince we see a conditioning bar on the previous slide, we can infer what the pdf of this conditional distribution would look like. If \\(X \\sim \\ddot{\\mathcal{N}}(\\mu, \\sigma, a, b)\\), then \\(X\\) has pdf\n\n\\[\nf_X(v) = \\frac{\\frac{1}{\\sigma}\\varphi\\left(\\frac{v_H-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{b-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right)} \\approx \\frac{\\Pr(X = v, a &lt; X &lt; b)}{\\Pr(a &lt; X &lt; b)}\n\\]\n\n\\(\\varphi\\) is the pdf of \\(\\mathcal{N}(0,1)\\)\n\\(\\Phi\\) is the CDF of \\(\\mathcal{N}(0,1)\\)\n\n\n\n(note the consistent usage of lowercase letters to describe pdfs and capital letters to describe CDFs, even in Greek!)",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#back-to-working-backwards",
    "href": "w07/index.html#back-to-working-backwards",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Back to Working Backwards",
    "text": "Back to Working Backwards\n\nBy the definition of independence, we can obtain joint pdf \\(f_{G,H}(v_G, v_H)\\) by multiplying the marginal pdf \\(f_G(v_G)\\) and marginal pdf \\(f_H(v_H)\\):\n\n\\[\n\\begin{align*}\nf_{G,H}(v_G, v_H) &= f_G(v_G) \\cdot f_H(v_H) \\\\\n&= \\frac{\\frac{1}{2\\sigma}\\varphi\\left(\\frac{v_H-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{b-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right)}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#moving-forwards-again",
    "href": "w07/index.html#moving-forwards-again",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Moving Forwards Again",
    "text": "Moving Forwards Again\n\nWe‚Äôve arrived at the case we had in discrete world, where we know the joint distribution!\nWe can integrate wherever we took sums in the discrete case to obtain marginal pdfs:\n\n\\[\n\\begin{align*}\nf_G(v_G) &= \\int_{0}^{1}f_{G,H}(v_G,v_H)\\mathrm{d}v_H = \\frac{1}{2}, \\\\\nf_H(v_H) &= \\int_{10}^{12}f_{G,H}(v_G, v_H)\\mathrm{d}v_G = \\frac{\\frac{1}{\\sigma}\\varphi\\left(\\frac{v_H-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{b-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right)}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#conditional-distributions-in-continuous-world",
    "href": "w07/index.html#conditional-distributions-in-continuous-world",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Conditional Distributions in Continuous World",
    "text": "Conditional Distributions in Continuous World\nAnd we can compute conditional pdfs by renormalizing so that the denominator is no longer the integral of the distribution over all its possible values (hence just the number \\(1\\)) but a ratio of joint distribution to marginal distribution values like the following:\n\\[\nf_{H \\mid G}(v_H | v_G) = \\frac{f_{G,H}(v_G, v_H)}{f_G(v_G)}.\n\\]",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#you-dont-have-to-stare-helplessly-at-scary-math",
    "href": "w07/index.html#you-dont-have-to-stare-helplessly-at-scary-math",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "You Don‚Äôt Have To Stare Helplessly At Scary Math!",
    "text": "You Don‚Äôt Have To Stare Helplessly At Scary Math!\n\nTry to link the continuous equations back to their simpler discrete forms\nWork with the discrete forms to develop intuition, then\nConvert sums back into integrals once you‚Äôre ready",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#a-concrete-strategy",
    "href": "w07/index.html#a-concrete-strategy",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "A Concrete Strategy",
    "text": "A Concrete Strategy\n\nStart by discretizing (‚Äúbinning‚Äù) the possible values of a continuous RV to obtain a discrete RV:\n\nSplit \\([10,12]\\) into three equal-length bins, \\([0,1]\\) into two equal-length bins\nSimulate \\((G, H)\\) pairs, sort into bins, plot joint / marginal / conditional distributions of binned data\n\nAs you make bins thinner and thinner‚Ä¶",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#the-multinoulli-distribution",
    "href": "w07/index.html#the-multinoulli-distribution",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Multinoulli Distribution",
    "text": "The Multinoulli Distribution\n\nThis may seem like a weird/contrived distribution, but it‚Äôs perfect for building intuition, as your first \\(N\\)-dimensional distribution (\\(N &gt; 2\\))\n\\(\\mathbf{X}\\) is a six-dimensional Vector-Valued RV, so that\n\\[\n  \\mathbf{X} = (X_1, X_2, X_3, X_4, X_5, X_6),\n  \\]\nwhere \\(\\mathcal{R}_{X_1} = \\{0, 1\\}, \\mathcal{R}_{X_2} = \\{0, 1\\}, \\ldots, \\mathcal{R}_{X_6} = \\{0, 1\\}\\)\nBut, \\(X_1, X_2, \\ldots, X_6\\) are not independent! In fact, they are so dependent that if one has the value \\(1\\), the rest must have value \\(0\\), so that we can infer the support of \\(\\mathbf{X}\\):\n\\[\n  \\begin{align*}\n  \\mathcal{R}_{\\mathbf{X}} = \\{ &(1,0,0,0,0,0),(0,1,0,0,0,0),(0,0,1,0,0,0), \\\\\n  &(0,0,0,1,0,0),(0,0,0,0,1,0),(0,0,0,0,0,1)\\}\n  \\end{align*}\n  \\]\nLastly, need to define the probability that \\(\\mathbf{X}\\) takes on any of these values. Let‚Äôs say \\(\\Pr(\\mathbf{X} = \\mathbf{v}) = \\frac{1}{6}\\) for all \\(\\mathbf{v} \\in \\mathcal{R}_{\\mathbf{X}}\\). Do we see the structure behind this contrived case?\n(For math major friends, there is an isomorphism afoot‚Ä¶ For the rest, it‚Äôs an extremely inefficient way to model outcomes from rolling a fair die)",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#the-multivariate-normal-distribution",
    "href": "w07/index.html#the-multivariate-normal-distribution",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Multivariate Normal Distribution",
    "text": "The Multivariate Normal Distribution\n\nWe‚Äôve already seen the matrix notation for writing the parameters of this distribution: \\(\\mathbf{X}_{[k \\times 1]} \\sim \\mathcal{N}_k(\\boldsymbol\\mu_{[k \\times 1]}, \\Sigma_{[k \\times k]})\\)\nNow we get to crack open the matrix notation for writing its pdf:\n\n\\[\nf_\\mathbf{X}(\\mathbf{v}_{[k \\times 1]}) = \\underbrace{\\left(\\frac{1}{\\sqrt{2\\pi}}\\right)^k \\frac{1}{\\sqrt{\\det(\\Sigma)}}}_{\\text{Normalizing constants}} \\exp\\left(-\\frac{1}{2}\\underbrace{(\\mathbf{v} - \\boldsymbol\\mu)^\\top \\Sigma^{-1} (\\mathbf{v} - \\boldsymbol\\mu)}_{\\text{Quadratic form}}\\right)\n\\]\n\nTry to squint your eyes while looking at the above, and compare with the pdf we‚Äôve seen for 1D \\(\\mathcal{N}(\\mu,\\sigma)\\) (W05) and the structure you‚Äôve seen for 2D \\(\\Sigma\\) (W06):\n\n\n\n\n\n\n\n\\[\nf_X(v) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\bigexp{-\\frac{1}{2}\\left(\\frac{v - \\mu}{\\sigma}\\right)^2}\n\\]\n\n\n\\[\n\\begin{align*}\n\\mathbf{\\Sigma} &= \\begin{bmatrix}\\sigma_1^2 & \\rho\\sigma_1\\sigma_2 \\\\ \\rho\\sigma_2\\sigma_1 & \\sigma_2^2\\end{bmatrix} \\\\[0.1em]\n\\implies \\det(\\Sigma) &= \\sigma_1^2\\sigma_2^2 - \\rho^2\\sigma_1^2\\sigma_2^2 \\\\\n&= \\sigma_1^2\\sigma_2^2(1-\\rho^2)\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#quadratic-forms",
    "href": "w07/index.html#quadratic-forms",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Quadratic Forms",
    "text": "Quadratic Forms\n\nQuadratic forms will seem scary until someone forces you to write out the matrix multiplication!\nStart with the 1D case: \\(\\mathbf{v} = [v_1]\\), \\(\\boldsymbol\\mu = [\\mu_1]\\), \\(\\Sigma = [\\sigma^2]\\). Then\n\n\\[\n(\\mathbf{v} - \\boldsymbol\\mu)^\\top \\Sigma^{-1} (\\mathbf{v - \\boldsymbol\\mu}) = (v_1 - \\mu_1)\\frac{1}{\\sigma^2}(v_1 - \\mu_1) = \\left(\\frac{v_1-\\mu_1}{\\sigma}\\right)^2.\n\\]",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#the-2d-case",
    "href": "w07/index.html#the-2d-case",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The 2D Case",
    "text": "The 2D Case\n\nLet \\(\\mathbf{v} = \\left[\\begin{smallmatrix}v_1 \\\\ v_2\\end{smallmatrix}\\right]\\), \\(\\boldsymbol\\mu = \\left[ \\begin{smallmatrix}\\mu_1 \\\\ \\mu_2 \\end{smallmatrix}\\right]\\), \\(\\Sigma\\) as in previous slide. Then \\(\\mathbf{v} - \\boldsymbol\\mu = \\left[ \\begin{smallmatrix} v_1 - \\mu_1 \\\\ v_2 - \\mu_2 \\end{smallmatrix} \\right]\\).\nUsing what we know about \\(2 \\times 2\\) matrix inversion,\n\n\\[\n\\Sigma^{-1} = \\frac{1}{\\det(\\Sigma)}\\left[ \\begin{smallmatrix} \\sigma_2^2 & -\\rho \\sigma_2\\sigma_1 \\\\ -\\rho \\sigma_1\\sigma_2 & \\sigma_1^2\\end{smallmatrix} \\right] = \\frac{1}{\\sigma_1^2\\sigma_2^2(1-\\rho^2)}\\left[ \\begin{smallmatrix} \\sigma_2^2 & -\\rho \\sigma_2\\sigma_1 \\\\ -\\rho \\sigma_1\\sigma_2 & \\sigma_1^2\\end{smallmatrix} \\right]\n\\]\n\nSo we can write everything as just a bunch of matrix multiplications:\n\n\\[\n\\begin{align*}\n&(\\mathbf{v} - \\boldsymbol\\mu)^\\top \\Sigma^{-1} (\\mathbf{v - \\boldsymbol\\mu}) = \\frac{1}{\\sigma_1^2\\sigma_2^2(1-\\rho^2)}\\begin{bmatrix}v_1 - \\mu_1 & v_2 - \\mu_2\\end{bmatrix} \\cdot \\begin{bmatrix} \\sigma_2^2 & -\\rho \\sigma_2\\sigma_1 \\\\ -\\rho \\sigma_1\\sigma_2 & \\sigma_1^2\\end{bmatrix} \\cdot \\begin{bmatrix}v_1 - \\mu_1 \\\\ v_2 - \\mu_2\\end{bmatrix} \\\\\n&= \\frac{1}{\\sigma_1^2\\sigma_2^2(1-\\rho^2)}\\begin{bmatrix}(v_1-\\mu_1)\\sigma_2^2 - (v_2-\\mu_2)\\rho\\sigma_1\\sigma_2 & (v_2-\\mu_2)\\sigma_1^2 - (v_1-\\mu_1)\\rho\\sigma_2\\sigma_1 \\end{bmatrix}\\cdot \\begin{bmatrix}v_1 - \\mu_1 \\\\ v_2 - \\mu_2\\end{bmatrix} \\\\\n&= \\frac{1}{\\sigma_1^2\\sigma_2^2(1-\\rho^2)}\\left( (v_1-\\mu_1)^2\\sigma_2^2 - (v_1-\\mu_1)(v_1-\\mu_2)\\sigma_1\\sigma_2 + (v_2-\\mu_2)^2\\sigma_1^2 - (v_1-\\mu_1)(v_2-\\mu_2)\\sigma_2\\sigma_1 \\right) \\\\\n&= \\boxed{\\frac{1}{1-\\rho^2}\\left( \\left(\\frac{v_1-\\mu_1}{\\sigma_1}\\right)^2 + \\left(\\frac{v_2-\\mu_2}{\\sigma_2}\\right)^2 - 2\\rho\\frac{(v_1-\\mu_1)(v_2-\\mu_2)}{\\sigma_1\\sigma_2} \\right)}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#the-2d-case-in-its-final-form",
    "href": "w07/index.html#the-2d-case-in-its-final-form",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The 2D Case In Its FINAL FORM",
    "text": "The 2D Case In Its FINAL FORM\n\\[\nf_{\\mathbf{X}}(\\mathbf{v}) = C\\bigexp{-\\frac{1}{2}\\frac{1}{1-\\rho^2}\\left( \\left(\\frac{v_1-\\mu_1}{\\sigma_1}\\right)^2 + \\left(\\frac{v_2-\\mu_2}{\\sigma_2}\\right)^2 - 2\\rho\\frac{(v_1-\\mu_1)(v_2-\\mu_2)}{\\sigma_1\\sigma_2} \\right)}\n\\]\nwhere\n\\[\nC = \\frac{1}{2\\pi\\sigma_1\\sigma_2\\sqrt{1-\\rho^2}}.\n\\]",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#references",
    "href": "w07/index.html#references",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w10/slides.html#maximum-likelihood-estimation",
    "href": "w10/slides.html#maximum-likelihood-estimation",
    "title": "Week 10: Parameter Estimation",
    "section": "Maximum Likelihood Estimation",
    "text": "Maximum Likelihood Estimation\n\nCreating a model \\(\\mathcal{M}\\) w/parameters \\(\\param{\\theta}\\) means specifying\n\n\\[\n\\mathcal{M} = \\Pr(\\underbrace{x_1, \\ldots, x_n}_{\\text{Observed Data}} \\mid \\underbrace{\\param{\\theta}}_{\\text{Model Parameters}})\n\\]\n\nWhen we view this as a function of \\(\\param{\\theta}\\), given the observed data, we call it the likelihood function \\(\\mathcal{L}_{\\mathcal{M}}(\\param{\\theta} \\mid x_1, \\ldots, x_n)\\)\nRead this as ‚Äúthe likelihood that our model \\(\\mathcal{M}\\), with parameters \\(\\param{\\theta}\\), produced the data \\(x_1, \\ldots, x_n\\)‚Äù"
  },
  {
    "objectID": "w10/slides.html#probability-models-are-generative-models",
    "href": "w10/slides.html#probability-models-are-generative-models",
    "title": "Week 10: Parameter Estimation",
    "section": "Probability Models are Generative Models",
    "text": "Probability Models are Generative Models\n\nA given choice of model parameters \\(\\param{\\theta}\\) can be used to generate simulated datapoints!\nSimple example: \\(X \\sim \\text{Bern}(\\param{p})\\). Just one parameter, \\(\\param{\\theta} = \\{\\param{p}\\}\\)\nWe observe 10 coin flips: 8 heads, 2 tails. Of all possible Bernoulli distributions (parameterized by \\(\\param{p}\\)), which is most likely to generate this data?"
  },
  {
    "objectID": "w10/slides.html#generative-models",
    "href": "w10/slides.html#generative-models",
    "title": "Week 10: Parameter Estimation",
    "section": "Generative Models",
    "text": "Generative Models\n\n\n\nGiven a choice of \\(\\param{\\theta}\\), we can generate simulated datasets (here 10 for each labeled value of \\(\\param{p}\\)), then compute likelihood as proportion of datasets with 8 heads, 2 tails\nFrom plot: (Among these vals) \\(\\param{p} = 0.8\\) is maximum likelihood estimate"
  },
  {
    "objectID": "w10/slides.html#week-10-lab",
    "href": "w10/slides.html#week-10-lab",
    "title": "Week 10: Parameter Estimation",
    "section": "Week 10 Lab!",
    "text": "Week 10 Lab!\n\nLink to Colab"
  },
  {
    "objectID": "w10/slides.html#simulations-rightarrow-math",
    "href": "w10/slides.html#simulations-rightarrow-math",
    "title": "Week 10: Parameter Estimation",
    "section": "Simulations \\(\\rightarrow\\) Math",
    "text": "Simulations \\(\\rightarrow\\) Math\nPrev example was overkill: we can solve for optimal \\(\\param{p}\\) value‚Ä¶\n\\[\n\\begin{align*}\np^* &\\overset{\\phantom{x_i\\text{ indep}}}{=} \\argmax_{\\param{p}} \\mathcal{L}(x_1, \\ldots, x_n \\mid \\param{p}) \\\\\n&\\overset{x_i\\text{ indep}}{=} \\argmax_{\\param{p}} \\mathcal{L}(x_1 \\mid \\param{p})\\mathcal{L}(x_2 \\mid \\param{p}) \\cdots \\mathcal{L}(x_n \\mid \\param{p})\n\\end{align*}\n\\]\n\nWhat are the individual \\(\\mathcal{L}(x_i \\mid \\param{p})\\) terms?\nHow do we maximize the product \\(\\mathcal{L}(x_1 \\mid \\param{p}) \\cdots \\mathcal{L}(x_n \\mid \\param{p})\\)?\n\n\nTime for some Math Magic‚Ä¶"
  },
  {
    "objectID": "w10/slides.html#math-magic-1",
    "href": "w10/slides.html#math-magic-1",
    "title": "Week 10: Parameter Estimation",
    "section": "Math Magic 1",
    "text": "Math Magic 1\n What are the individual \\(\\Pr(x_i \\mid \\param{p})\\) terms?\n\\(X \\sim \\text{Bern}(\\param{p})\\), so\n\\[\n\\begin{align*}\n\\Pr(X = x_i \\mid \\param{p}) &= \\begin{cases}1 - \\param{p} & x_i = 0 \\\\ \\param{p} & x_i = 1\\end{cases} \\; \\leftarrow \\genfrac{}{}{0pt}{}{\\text{ Non-differentiable}}{üò≠} \\\\\n&\\overset{\\text{math}}{\\underset{\\text{magic}}{=}} (1-\\param{p})^{1-x_i}\\param{p}^{x_i} \\; \\leftarrow \\text{ Differentiable! üò≤}\n\\end{align*}\n\\]\nWhy do we need it to be differentiable? Stay tuned‚Ä¶"
  },
  {
    "objectID": "w10/slides.html#math-magic-2",
    "href": "w10/slides.html#math-magic-2",
    "title": "Week 10: Parameter Estimation",
    "section": "Math Magic 2",
    "text": "Math Magic 2\n\n\n\n\n\n\n How do we maximize the product?\n\\[\np^* = \\argmax_{\\param{p}} f(\\param{p}) \\implies f'(p^*) = 0\n\\]\nTo maximize likelihood, we need to find its derivative1, set equal to 0, and solve:\n\n\n\n\n\n\n\\[\n\\begin{align*}\n&\\frac{d}{d\\param{p}}\\lik(x \\mid \\param{p}) = 0 \\iff \\\\\n&\\frac{d}{d\\param{p}}\\left[\\lik(x_1 \\mid \\param{p})\\lik(x_2 \\mid \\param{p})\\cdots \\lik(x_n \\mid \\param{p})\\right] = 0\n\\end{align*}\n\\]\nThat‚Äôs why we used math magic to make \\(\\Pr(x_i \\mid \\param{p})\\) differentiable on prev slide!"
  },
  {
    "objectID": "w10/slides.html#obstacle-products-vs.-sums",
    "href": "w10/slides.html#obstacle-products-vs.-sums",
    "title": "Week 10: Parameter Estimation",
    "section": "Obstacle: Products vs.¬†Sums",
    "text": "Obstacle: Products vs.¬†Sums\n\nFinding \\(\\frac{d}{d\\param{p}}\\left[ \\lik(x_1)\\lik(x_2)\\cdots \\lik(x_n)\\right]\\) is a doozy, even with just \\(n = 2\\) datapoints:\n\n\\[\n\\begin{align*}\n&\\frac{d}{d\\param{p}}\\left[ \\lik(x_1)\\lik(x_2) \\right] = \\left( \\frac{d}{d\\param{p}}\\lik(x_1)\\right) \\cdot \\lik(x_2) + \\lik(x_1)\\cdot \\left( \\frac{d}{d\\param{p}}\\lik(x_2) \\right) \\\\\n&= (1-\\param{p})^{-x_1}\\param{p}^{x_1-1}(x_1-\\param{p})\\cdot (1-\\param{p})^{1-x_2}\\param{p}^{x_2} \\\\\n&+ (1-\\param{p})^{1-x_1}\\param{p}^{x_1} \\cdot (1-\\param{p})^{-x_2}\\param{p}^{x_2-1}(x_2 - \\param{p})\n%&= \\frac{d}{d\\theta}\\left[ (1-p)^{1-x_1}p^{x_1}(1-p)^{1-x_2}p^{x_2} \\right]\n\\end{align*}\n\\]\n\nComplicating factor: \\(\\lik(x_i)\\) terms are all multiplied together, forcing us to use product rule: \\(\\frac{d}{d\\param{p}}\\left[\\lik(x_1)\\lik(x_2)\\right] = \\left(\\frac{d}{d\\param{p}}\\lik(x_1)\\right)\\cdot \\lik(x_2) + \\lik(x_1)\\cdot \\left(\\frac{d}{d\\param{p}}\\lik(x_2)\\right)\\)\nIf we had terms that were added rather than multiplied, we‚Äôd have a much easier time: \\(\\frac{d}{d\\param{p}}\\left[ \\lik(x_1) + \\lik(x_2)\\right] = \\frac{d}{d\\param{p}}\\lik(x_1) + \\frac{d}{d\\param{p}} \\lik(x_2)\\)1\nSo, what math operation do we know that turns multiplications into additions?\n\n\nWe achieve this simplification because the derivative operator is additive: \\(\\frac{d}{dx}\\left[ f(x) + g(x) \\right] = \\frac{d}{dx}f(x) + \\frac{d}{dx}g(x)\\)"
  },
  {
    "objectID": "w10/slides.html#math-magic-3-log-likelihood",
    "href": "w10/slides.html#math-magic-3-log-likelihood",
    "title": "Week 10: Parameter Estimation",
    "section": "Math Magic 3: Log-Likelihood",
    "text": "Math Magic 3: Log-Likelihood\n\\[\n\\log(a\\cdot b) = \\log(a) + \\log(b)\n\\]\nBingo! So, can we maximize \\(\\loglik(x_i) = \\log(\\mathcal{L}(x_i))\\) rather than \\(\\mathcal{L}(x_i)\\)? Bingo again! Because logarithms are monotonic,\n\\[\nx^* = \\argmax_x \\left[ \\log\\left(f(x)\\right) \\right] \\iff x^* = \\argmax_x \\left[ f(x) \\right]\n\\]\nSo, we can just solve\n\\[\np^* = \\argmax_{\\param{p}} \\left[ \\ell(x_1, \\ldots, x_n)\\right]\n\\]"
  },
  {
    "objectID": "w10/slides.html#simplifying",
    "href": "w10/slides.html#simplifying",
    "title": "Week 10: Parameter Estimation",
    "section": "Simplifying",
    "text": "Simplifying\nOur problem simplifies to figuring out\n\\[\n\\begin{align*}\n\\frac{d}{d\\param{p}}\\left[ \\log \\left( \\lik(x_1)\\cdots \\lik(x_n) \\right) \\right] &= \\frac{d}{d\\param{p}}\\left[ \\log \\lik(x_1) + \\log\\lik(x_2) + \\cdots + \\log\\lik(x_n) \\right] \\\\\n&= \\frac{d}{d\\param{p}}\\left[ \\ell(x_1) + \\ell(x_2) + \\cdots + \\ell(x_n) \\right] = \\frac{d}{d\\param{p}}\\left[ \\sum_{i=1}^n \\ell(x_i)\\right]\n\\end{align*}\n\\]\nBut since the derivative is an additive operator, \\(\\frac{d}{d\\param{p}}\\left[ \\sum_{i=1}^n \\ell(x_i) \\right] = \\sum_{i=1}^n \\frac{d}{d\\param{p}}\\left[ \\ell(x_i) \\right]\\), so we just have to compute \\(\\frac{d}{d\\param{p}}\\ell(x_i)\\)! No product rule required (we still need chain rule):\n\\[\n\\begin{align*}\n\\frac{d}{d\\param{p}}\\left[ \\ell(x_i) \\right] &= \\frac{d}{d\\param{p}}\\left[ \\log((1-\\param{p})^{1-x_i}\\param{p}^{x_i}) \\right] = \\frac{d}{d\\param{p}}\\left[(1-x_i)\\log(1-\\param{p}) + x_i\\log(\\param{p})\\right] \\\\\n&= (1-x_i)\\frac{d}{d\\param{p}}\\log(1-\\param{p}) + x_i\\frac{d}{d\\param{p}}\\log(\\param{p}) = -\\frac{1-x_i}{1-\\param{p}} + \\frac{x_i}{\\param{p}} \\\\\n&= \\frac{\\param{p} - x_i}{(\\param{p}-1)\\param{p}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w10/slides.html#maximizing",
    "href": "w10/slides.html#maximizing",
    "title": "Week 10: Parameter Estimation",
    "section": "Maximizing",
    "text": "Maximizing\nNow that we know \\(\\frac{d}{d\\param{p}}\\ell(x_i)\\), we set our log-likelihood equation equal to zero to find the likelihood-maximizing \\(\\param{p}\\) value, \\(p^*\\):\n\\[\n\\begin{align*}\n&\\sum_{i=1}^n\\frac{d}{d\\param{p}}\\ell(x_i) = 0 \\iff \\sum_{i=1}^n \\frac{p^* - x_i}{(p^*-1)p^*} = 0 \\\\\n&\\iff -\\frac{1}{(p^*-1)p^*}\\sum_{i=1}^nx_i - np^* = 0 \\\\\n&\\iff \\sum_{i=1}^nx_i = np^* \\iff \\boxed{p^* = \\frac{\\sum_{i=1}^nx_i}{n}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w10/slides.html#mle-intuition",
    "href": "w10/slides.html#mle-intuition",
    "title": "Week 10: Parameter Estimation",
    "section": "MLE Intuition",
    "text": "MLE Intuition\n\\[\np^* = \\frac{\\sum_{i=1}^nx_i}{n} = \\frac{\\sum_{i=1}^n \\mathbf{1}[x_i = 1]}{n} \\genfrac{}{}{0pt}{}{\\leftarrow \\text{\\# Heads}}{\\leftarrow \\text{\\# Flips }}\n\\]\n\nMLE almost always matches intuition! Example: given data \\(x_1, \\ldots, x_n\\), what Normal distribution best fits this data?\nSame as asking: what parameter settings for \\(\\mathcal{N}(\\param{\\mu}, \\param{\\sigma^2})\\) are most likely to produce \\(x_1, \\ldots, x_n\\)? The answer:\n\n\\[\n\\mu^* = \\frac{\\sum_{i=1}^n x_i}{n} \\; \\; \\; \\sigma^2_* = \\frac{\\sum_{i=1}^n (x_i-\\mu^*)^2}{n}\n\\]"
  },
  {
    "objectID": "w10/slides.html#the-dark-side-of-mle",
    "href": "w10/slides.html#the-dark-side-of-mle",
    "title": "Week 10: Parameter Estimation",
    "section": "The Dark Side of MLE",
    "text": "The Dark Side of MLE\n\nSometimes steers us in the wrong direction!\nConsider values from previous slide, as estimators for population \\(\\mu\\) and \\(\\sigma^2\\): \\(\\mu^*\\) unbiased if \\(\\expect{\\mu^*} = \\mu\\):\n\n\\[\n\\begin{align*}\n\\expect{\\mu^*} &= \\bigexpect{\\frac{\\sum_{i=1}^nx_i}{n}} = \\frac{1}{n}\\sum_{i=1}^n\\expect{x_i} \\\\\n&= \\frac{1}{n}\\sum_{i=1}^n\\mu = \\frac{n\\mu}{n} = \\mu \\; ‚úÖ\n\\end{align*}\n\\]\n\nSo far so good. How about \\(\\sigma^2_*\\)?"
  },
  {
    "objectID": "w10/slides.html#mle-as-biased-estimator",
    "href": "w10/slides.html#mle-as-biased-estimator",
    "title": "Week 10: Parameter Estimation",
    "section": "MLE as Biased Estimator",
    "text": "MLE as Biased Estimator\n\nBefore we think about \\(\\expect{\\sigma^2_*}\\), let‚Äôs rewrite \\(\\sigma^2_*\\):\n\n\\[\n\\begin{align*}\n\\sigma^2_* &= \\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu^*)^2 = \\frac{1}{n}\\sum_{i=1}^n \\left( x_i^2 - 2 \\mu^* x_i + (\\mu^*)^2 \\right) \\\\\n&= \\frac{1}{n}\\sum_{i=1}^nx_i^2 - 2\\mu^*\\underbrace{\\frac{\\sum_{i=1}^nx_i}{n}}_{\\mu^*} + (\\mu^*)^2 = \\frac{1}{n}\\sum_{i=1}^nx_i^2 - (\\mu^*)^2 \\\\\n&= \\frac{1}{n}\\sum_{i=1}^nx_i^2 - (\\mu^*)^2\n\\end{align*}\n\\]\n\nNow we‚Äôre ready to compute \\(\\expect{\\sigma^2_*}\\)!"
  },
  {
    "objectID": "w10/slides.html#computing-mathbbesigma2_",
    "href": "w10/slides.html#computing-mathbbesigma2_",
    "title": "Week 10: Parameter Estimation",
    "section": "Computing \\(\\mathbb{E}[\\sigma^2_*]\\)",
    "text": "Computing \\(\\mathbb{E}[\\sigma^2_*]\\)\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\bigexpect{\\frac{1}{n}\\sum_{i=1}^nx_i^2 - (\\mu^*)^2} = \\frac{1}{n}\\sum_{i=1}^n \\expect{x_i^2} - \\expect{(\\mu^*)^2}\n\\end{align*}\n\\]\n\nWhat do we know about \\(\\expect{x_i^2}\\)? Remember the (alternate) definition of variance: \\(\\Var{X} = \\expect{X^2} - \\left(\\expect{X}\\right)^2\\). Then\n\n\\[\n\\expect{X^2} = \\Var{X} + \\left(\\expect{X}\\right)^2\n\\]\nSo let‚Äôs plug in the right side when we see \\(\\expect{X^2}\\) or \\(\\expect{(\\mu^*)^2}\\):\n\\[\n\\begin{align*}\n\\frac{1}{n}\\sum_{i=1}^n \\expect{x_i^2} - \\expect{(\\mu^*)^2} &= \\frac{1}{n}\\sum_{i=1}^n\\left(\\Var{X} + \\left(\\expect{X}\\right)^2\\right) - \\expect{(\\mu^*)^2} \\\\\n&= (\\sigma^2 + \\mu^2) - \\left(\\Var{\\mu^*} + \\left(\\expect{\\mu^*}\\right)^2\\right)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w10/slides.html#almost-there",
    "href": "w10/slides.html#almost-there",
    "title": "Week 10: Parameter Estimation",
    "section": "Almost There!",
    "text": "Almost There!\nWe know that \\(\\expect{\\mu^*} = \\mu\\), but what is \\(\\Var{\\mu^*}\\)? Remember that \\(\\Var{aX} = a^2\\Var{X}\\)!\n\\[\n\\Var{\\mu^*} = \\bigVar{\\frac{1}{n}\\sum_{i=1}^nx_i} = \\frac{1}{n^2}\\sum_{i=1}^n\\Var{x_i} = \\frac{n\\sigma^2}{n^2} = \\frac{\\sigma^2}{n}\n\\]\nAnd we plug back in to get:\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\sigma^2 + \\mu^2 - \\Var{\\mu^*} - \\left(\\expect{\\mu^*}\\right)^2 \\\\\n&= \\sigma^2 + \\mu^2 - \\frac{\\sigma^2}{n} - \\mu^2 = \\sigma^2 - \\frac{\\sigma^2}{n} \\\\\n&= \\frac{n\\sigma^2 - \\sigma^2}{n} = \\frac{\\sigma^2(n-1)}{n} \\\\\n&= \\color{red}{\\left(\\frac{n-1}{n}\\right)\\sigma^2} \\neq \\sigma^2 \\; üíÄ\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w10/slides.html#why-does-this-happen-handwaving",
    "href": "w10/slides.html#why-does-this-happen-handwaving",
    "title": "Week 10: Parameter Estimation",
    "section": "Why Does This Happen?: Handwaving",
    "text": "Why Does This Happen?: Handwaving\n\nLong story short, we underpredict the population variance because we already used some of the data to compute \\(\\mu^*\\)!\nThis is where the degrees of freedom heuristic comes in:\n\nWhen we construct an estimate \\(e\\), \\(df(e) = n - k_e\\)\n\\(k_e =\\) number of other estimates used to calculate \\(e\\)!"
  },
  {
    "objectID": "w10/slides.html#handwavy-intuition",
    "href": "w10/slides.html#handwavy-intuition",
    "title": "Week 10: Parameter Estimation",
    "section": "Handwavy Intuition",
    "text": "Handwavy Intuition\n\nConsider \\(X_1, X_2 \\sim \\mathcal{N}(0,1)\\): \\(\\mu = 0\\), \\(\\sigma^2 = 1\\).\n\n\\[\n\\expect{\\mu^*} = \\bigexpect{\\frac{X_1 + X_2}{2}} = \\frac{1}{2}\\left(\\expect{X_1} + \\expect{X_2}\\right) = 0 = \\mu \\; ‚úÖ\n\\]\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\frac{1}{2}\\bigexpect{(X_1 - \\mu^*)^2 + (X_2 - \\mu^*)^2} \\\\\n&= \\frac{1}{2}\\bigexpect{\\left(X_1^2 + \\mu^2_* -2\\mu^*X_1\\right) + \\left(X_2^2 + \\mu^2_* - 2X_2\\mu^*\\right)} \\\\\n&= \\frac{1}{2}\\expect{X_1^2 + X_2^2 + 2\\mu_*^2 - 2\\mu^*X_1 - 2\\mu^*X_2} \\\\\n&= \\frac{1}{2}\\left(\\expect{X_1^2} + \\expect{X_2^2} + 2\\expect{\\mu_*^2} - 2\\expect{\\mu^*X_1} - 2\\expect{\\mu^*X_2}\\right) \\\\\n&\\implies \\boxed{\\expect{\\sigma^2_*} = \\frac{1}{2}\\sigma^2}\n\\end{align*}\n\\]\n\nWe‚Äôre off by \\(\\frac{1}{2}\\)! What to do?"
  },
  {
    "objectID": "w10/slides.html#handwavy-solution",
    "href": "w10/slides.html#handwavy-solution",
    "title": "Week 10: Parameter Estimation",
    "section": "Handwavy Solution",
    "text": "Handwavy Solution\n\nWe can account for degrees of freedom, correcting the MLE by a factor of \\(\\frac{n}{df(e^*)}\\)!\n\n\\(e^\\circledast = \\frac{n}{df(e^*)}e^*\\)\n\nEx: Since \\(\\expect{\\sigma_*^2} = \\frac{n-1}{n}\\sigma^2\\), we can instead use \\(\\sigma^2_\\circledast = \\frac{n}{n-1}\\sigma^2_*\\). This gives us:\n\n\\[\n\\expect{\\sigma^2_\\circledast} = \\bigexpect{\\frac{n}{n-1}\\sigma^2_*} = \\frac{n}{n-1}\\frac{n-1}{n}\\sigma^2 = \\color{green}{\\sigma^2} \\; ‚úÖ\n\\]"
  },
  {
    "objectID": "w10/slides.html#st-century-solution",
    "href": "w10/slides.html#st-century-solution",
    "title": "Week 10: Parameter Estimation",
    "section": "21st-Century Solution",
    "text": "21st-Century Solution\n\nBe Bayesian, use priors on parameters (creating hyperparameters)!\nPretend we know \\(\\sigma^2\\), but want to find the ‚Äúbest‚Äù value of \\(\\mu\\):\n\n\\[\n\\begin{array}{rlccc}\nX_1, X_2 \\overset{iid}{\\sim} \\mathcal{N}( &\\hspace{-5mm}\\mu\\hspace{0.5mm}, &\\hspace{-8mm}\\overbrace{\\sigma^2}^{\\large\\text{known}}\\hspace{-2mm}) & & \\\\\n&\\hspace{-4mm}\\downarrow & ~ &\\hspace{-10mm}{\\small\\text{estimate}} & \\hspace{-6mm} & \\hspace{-8mm}{\\small\\text{uncertainty}} \\\\[-5mm]\n&\\hspace{-5mm}\\mu &\\hspace{-5mm}\\sim \\mathcal{N}&\\hspace{-7mm}(\\overbrace{m}&\\hspace{-12mm}, &\\hspace{-16mm}\\overbrace{s})\n\\end{array}\n\\]"
  },
  {
    "objectID": "w10/slides.html#single-datapoint",
    "href": "w10/slides.html#single-datapoint",
    "title": "Week 10: Parameter Estimation",
    "section": "Single Datapoint",
    "text": "Single Datapoint\n\nLet‚Äôs consider the estimate of \\(\\mu\\) from a single datapoint \\(X_i\\). MLE just gives us \\(\\mu^* = X_i\\). How about MAP estimate?\n\n\\[\n\\lik\\left(X_i, \\mu, m, s\\right) \\overset{\\text{factors}}{\\underset{\\text{into}}{=}} P(X_i \\mid \\mu)P(\\mu \\mid m, s)P(m, s)\n\\]\n\nRemembering the pdf of the Normal distribution, we have:\n\n\\[\n\\lik\\left(X_i, \\mu, m, s\\right) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left[-\\frac{(X_i-\\mu)^2}{2\\sigma^2}\\right]\\frac{1}{s\\sqrt{2\\pi}}\\exp\\left[-\\frac{(\\mu - m)^2}{2s^2}\\right]\n\\]\n\nThen, remembering that we can maximize the log-likelihood rather than the likelihood:\n\n\\[\n\\ell(X_i, \\mu, m, s) = \\log\\left[\\frac{1}{\\sigma\\sqrt{2\\pi}}\\right] - \\frac{(X_i-\\mu)^2}{2\\sigma^2} + \\log\\left[\\frac{1}{s\\sqrt{2\\pi}}\\right] - \\frac{(\\mu - m)^2}{2s^2}\n\\]"
  },
  {
    "objectID": "w10/slides.html#taking-the-derivative",
    "href": "w10/slides.html#taking-the-derivative",
    "title": "Week 10: Parameter Estimation",
    "section": "Taking the Derivative",
    "text": "Taking the Derivative\n\nTaking the derivative gives us:\n\n\\[\n\\begin{align*}\n\\frac{\\partial\\ell}{\\partial \\mu} &= \\frac{\\partial}{\\partial\\mu}\\left[ {\\color{red}\\cancel{\\color{black}\\log\\left[\\frac{1}{\\sigma\\sqrt{2\\pi}}\\right]}} - \\frac{(X_i-\\mu)^2}{2\\sigma^2} + {\\color{red}\\cancel{\\color{black}\\log\\left[\\frac{1}{s\\sqrt{2\\pi}}\\right]}} - \\frac{(\\mu - m)^2}{2s^2}\\right] \\\\\n&= - \\frac{1}{2\\sigma^2}\\cdot\\frac{\\partial}{\\partial\\mu}\\left[{\\color{red}\\cancel{\\color{black}X_i^2}} + \\mu^2 - 2X_i\\mu\\right] - \\frac{1}{2s^2}\\cdot\\frac{\\partial}{\\partial\\mu}\\left[\\mu^2 + {\\color{red}\\cancel{\\color{black}m^2}} - 2\\mu m\\right] \\\\\n&= -\\frac{1}{2\\sigma^2}\\cdot (2\\mu -2X_i) - \\frac{1}{2s^2}\\cdot (2\\mu - 2m) = \\frac{X_i-\\mu}{\\sigma^2} + \\frac{m - \\mu}{s^2}\n\\end{align*}\n\\]\n\nAnd we set equal to zero and solve to obtain the MAP estimate:\n\n\\[\n\\begin{align*}\n&\\frac{X_i - \\mu^*}{\\sigma^2} + \\frac{m - \\mu^*}{s^2} = 0 \\iff \\frac{\\mu^*}{\\sigma^2} + \\frac{\\mu^*}{s^2} = \\frac{X_i}{\\sigma^2} + \\frac{m}{s^2} \\iff \\\\\n&\\frac{s^2\\mu^* + \\sigma^2\\mu^*}{\\sigma^2s^2} = \\frac{s^2X_i + \\sigma^2m}{\\sigma^2s^2} \\iff \\mu^*(s^2+\\sigma^2) = s^2X_i + \\sigma^2m \\\\\n&\\iff \\boxed{\\mu^* = \\left(\\frac{s^2}{s^2 + \\sigma^2}\\right)X_i + \\left(\\frac{\\sigma^2}{s^2 + \\sigma^2}\\right)m}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w10/slides.html#the-takeaway",
    "href": "w10/slides.html#the-takeaway",
    "title": "Week 10: Parameter Estimation",
    "section": "The Takeaway",
    "text": "The Takeaway\n\nBayesian approach allows new evidence to be weighed against existing evidence, with statistically principled way to derive these weights:\n\n\\[\n\\begin{array}{ccccc}\n\\Pr_{\\text{post}}(\\mathcal{H}) &\\hspace{-6mm}\\propto &\\hspace{-6mm} \\Pr(X \\mid \\mathcal{H}) &\\hspace{-6mm} \\times &\\hspace{-6mm} \\Pr_{\\text{pre}}(\\mathcal{H}) \\\\\n\\text{Posterior} &\\hspace{-6mm}\\propto &\\hspace{-6mm}\\text{Evidence} &\\hspace{-6mm} \\times &\\hspace{-6mm} \\text{Prior}\n\\end{array}\n\\]"
  },
  {
    "objectID": "w10/slides.html#generalized-method-of-moments-gmm-estimation",
    "href": "w10/slides.html#generalized-method-of-moments-gmm-estimation",
    "title": "Week 10: Parameter Estimation",
    "section": "Generalized Method of Moments (GMM) Estimation",
    "text": "Generalized Method of Moments (GMM) Estimation\n\nRecall that the \\(k\\)th moment of an RV \\(X\\) is \\(\\mu_k = \\expect{X^k}\\)\ne.g., \\(\\mu_1 = \\expect{X}\\), \\(\\mu_2 = \\Var{X} + \\expect{X}^2\\)\nAlso recall (I rambled on about) how the MGF contains all information about a distribution. This means we can estimate distributions from data:\nDefine \\(k\\)th sample moment of \\(\\mathbf{X}_N\\): \\(\\widehat{\\mu}_k = \\frac{1}{N}\\sum_{i=1}^nX_i^k\\). Then:\n\\[\n  \\begin{align*}\n  \\mu_1(\\param{\\theta}) &= \\widehat{\\mu}_1 \\\\\n  \\mu_2(\\param{\\theta}) &= \\widehat{\\mu}_2 \\\\\n  &~\\vdots \\\\\n  \\mu_N(\\param{\\theta}) &= \\widehat{\\mu}_N\n  \\end{align*}\n  \\]\nGives us a system of equations, allowing us to solve for parameters \\(\\param{\\theta}\\) of our distribution!"
  },
  {
    "objectID": "w10/slides.html#intuition",
    "href": "w10/slides.html#intuition",
    "title": "Week 10: Parameter Estimation",
    "section": "Intuition",
    "text": "Intuition\n\n\n\n\n\n\n\n\n\nLow Variance\nHigh Variance\n\n\n\n\nLow Bias\n\n\n\n\nHigh Bias\n\n\n\n\n\n\n\nAdapted from Fortmann-Roe (2012), ‚ÄúUnderstanding the Bias-Variance Tradeoff‚Äù"
  },
  {
    "objectID": "w10/slides.html#components-of-the-error-term",
    "href": "w10/slides.html#components-of-the-error-term",
    "title": "Week 10: Parameter Estimation",
    "section": "Components of the Error Term",
    "text": "Components of the Error Term\n\nWe estimate ‚Äútrue‚Äù DGP \\(Y = f(X)\\) with model \\(\\widehat{f}(X)\\)1, and then we use \\(\\widehat{f}\\) to predict the value of \\(Y\\) for a point \\(x_0\\).\nWhat is our expected error at this point, \\(\\Err(x_0)\\)?\n\n\\[\n\\begin{align*}\n\\Err(x_0) &= \\bigexpect{\\left.(Y ‚àí \\widehat{f}(x_0))^2 \\right| X = x_0} \\\\\n&= \\sigma^2_{\\varepsilon} + \\left( \\bigexpect{\\widehat{f}(x_0)} ‚àí f(x_0) \\right)^2 + \\mathbb{E}\\left[\\widehat{f}(x_0) ‚àí \\bigexpect{\\widehat{f}(x_0)}\\right]^2 \\\\\n&= \\sigma^2_{\\varepsilon} + \\left( \\text{Bias}(\\widehat{f}(x_0)\\right)^2 + \\bigVar{\\widehat{f}(x_0)} \\\\\n&= \\text{Irreducible Error} + \\text{Bias}^2 + \\text{Variance}.\n\\end{align*}\n\\]\nA complication we put aside for now: do the features \\(X\\) we chose in fact causally impact \\(Y\\)? See (hastie_elements_2013?)!"
  },
  {
    "objectID": "w10/slides.html#in-practice",
    "href": "w10/slides.html#in-practice",
    "title": "Week 10: Parameter Estimation",
    "section": "In Practice",
    "text": "In Practice\n\n\nFigure from (tharwat_parameter_2019?)"
  },
  {
    "objectID": "w10/slides.html#appendix-1-derivation-of-mathbbemu_2",
    "href": "w10/slides.html#appendix-1-derivation-of-mathbbemu_2",
    "title": "Week 10: Parameter Estimation",
    "section": "Appendix 1: Derivation of \\(\\mathbb{E}[\\mu_*^2]\\)",
    "text": "Appendix 1: Derivation of \\(\\mathbb{E}[\\mu_*^2]\\)\n\\[\n\\begin{align*}\n\\expect{\\mu_*^2} &= \\bigexpect{\\left(\\frac{X_1 + X_2}{2}\\right)^2} = \\frac{1}{4}\\expect{(X_1+X_2)^2} \\\\\n&= \\frac{1}{4}\\expect{X_1^2 + X_2^2 + 2X_1X_2} = \\frac{1}{4}\\left(\\expect{X_1^2} + \\expect{X_2^2} + 2\\expect{X_1X_2}\\right) \\\\\n&= \\frac{1}{4}\\left(\\Var{X_1} + \\expect{X_1}^2 + \\Var{X_2} + \\expect{X_2}^2 + 2\\expect{X_1X_2}\\right) \\\\\n&= \\frac{1}{4}\\left(2\\sigma^2 + 2\\mu^2 + 2\\expect{X_1X_2}\\right) \\\\\n&= \\frac{1}{2}\\left(\\sigma^2 + \\mu^2 + \\expect{X_1X_2}\\right) \\overset{iid}{=} \\frac{1}{2}\\left(\\sigma^2 + \\mu^2 + \\mu^2\\right) \\\\\n&\\implies \\boxed{\\expect{\\mu^2_*} = \\mu^2 + \\frac{\\sigma^2}{2}} \\; \\; \\left(\\therefore \\; \\expect{\\mu_*^2} \\neq \\mu^2 \\right)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w10/slides.html#appendix-2-derivation-of-mathbbemux_i",
    "href": "w10/slides.html#appendix-2-derivation-of-mathbbemux_i",
    "title": "Week 10: Parameter Estimation",
    "section": "Appendix 2: Derivation of \\(\\mathbb{E}[\\mu^*X_i]\\)",
    "text": "Appendix 2: Derivation of \\(\\mathbb{E}[\\mu^*X_i]\\)\n\\[\n\\begin{align*}\n\\expect{\\mu^*X_1} &= \\bigexpect{\\left(\\frac{X_1 + X_2}{2}\\right)X_1} = \\frac{1}{2}\\expect{X_1^2 + X_1X_2} \\\\\n&= \\frac{1}{2}\\expect{X_1^2} + \\frac{1}{2}\\expect{X_1X_2} = \\frac{1}{2}\\left(\\sigma^2 + \\mu^2\\right) + \\frac{1}{2}\\mu^2 \\\\\n&\\implies \\expect{\\mu^*X_1} = \\mu^2 + \\frac{\\sigma^2}{2}\n\\end{align*}\n\\]\nAnd since \\(X_1\\) was chosen without loss of generality,\n\\[\n\\boxed{\\expect{\\mu^*X_i} = \\mu^2 + \\frac{\\sigma^2}{2}}\n\\]"
  },
  {
    "objectID": "w10/slides.html#appendix-3-derivation-of-mathbbesigma2_",
    "href": "w10/slides.html#appendix-3-derivation-of-mathbbesigma2_",
    "title": "Week 10: Parameter Estimation",
    "section": "Appendix 3: Derivation of \\(\\mathbb{E}[\\sigma^2_*]\\)",
    "text": "Appendix 3: Derivation of \\(\\mathbb{E}[\\sigma^2_*]\\)\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\frac{1}{2}\\bigexpect{(X_1 - \\mu^*)^2 + (X_2 - \\mu^*)^2} \\\\\n&= \\frac{1}{2}\\bigexpect{\\left(X_1^2 + \\mu^2_* -2\\mu^*X_1\\right) + \\left(X_2^2 + \\mu^2_* - 2X_2\\mu^*\\right)} \\\\\n&= \\frac{1}{2}\\expect{X_1^2 + X_2^2 + 2\\mu_*^2 - 2\\mu^*X_1 - 2\\mu^*X_2} \\\\\n&= \\frac{1}{2}\\left(\\expect{X_1^2} + \\expect{X_2^2} + 2\\expect{\\mu_*^2} - 2\\expect{\\mu^*X_1} - 2\\expect{\\mu^*X_2}\\right) \\\\\n&= \\frac{1}{2}\\left( 2\\sigma^2 + 2\\mu^2 + 2\\left(\\mu^2 + \\frac{\\sigma^2}{2}\\right) - 2\\left(\\mu^2 + s/2\\right) - 2\\left(\\mu^2 + s/2\\right) \\right) \\\\\n&= \\sigma^2 + \\mu^2 + \\mu^2 + \\frac{\\sigma^2}{2} - \\mu^2 - \\frac{\\sigma^2}{2} - \\mu^2 - \\frac{\\sigma^2}{2} = \\sigma^2 - \\frac{\\sigma^2}{2} \\\\\n&\\implies \\boxed{\\expect{\\sigma^2_*} = \\frac{1}{2}\\sigma^2}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w10/slides.html#references",
    "href": "w10/slides.html#references",
    "title": "Week 10: Parameter Estimation",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nDSAN 5100-03 W10: Parameter Estimation"
  },
  {
    "objectID": "w10/index.html",
    "href": "w10/index.html",
    "title": "Week 10: Parameter Estimation",
    "section": "",
    "text": "Open slides in new window ‚Üí",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#maximum-likelihood-estimation",
    "href": "w10/index.html#maximum-likelihood-estimation",
    "title": "Week 10: Parameter Estimation",
    "section": "Maximum Likelihood Estimation",
    "text": "Maximum Likelihood Estimation\n\nCreating a model \\(\\mathcal{M}\\) w/parameters \\(\\param{\\theta}\\) means specifying\n\n\\[\n\\mathcal{M} = \\Pr(\\underbrace{x_1, \\ldots, x_n}_{\\text{Observed Data}} \\mid \\underbrace{\\param{\\theta}}_{\\text{Model Parameters}})\n\\]\n\nWhen we view this as a function of \\(\\param{\\theta}\\), given the observed data, we call it the likelihood function \\(\\mathcal{L}_{\\mathcal{M}}(\\param{\\theta} \\mid x_1, \\ldots, x_n)\\)\nRead this as ‚Äúthe likelihood that our model \\(\\mathcal{M}\\), with parameters \\(\\param{\\theta}\\), produced the data \\(x_1, \\ldots, x_n\\)‚Äù",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#probability-models-are-generative-models",
    "href": "w10/index.html#probability-models-are-generative-models",
    "title": "Week 10: Parameter Estimation",
    "section": "Probability Models are Generative Models",
    "text": "Probability Models are Generative Models\n\nA given choice of model parameters \\(\\param{\\theta}\\) can be used to generate simulated datapoints!\nSimple example: \\(X \\sim \\text{Bern}(\\param{p})\\). Just one parameter, \\(\\param{\\theta} = \\{\\param{p}\\}\\)\nWe observe 10 coin flips: 8 heads, 2 tails. Of all possible Bernoulli distributions (parameterized by \\(\\param{p}\\)), which is most likely to generate this data?",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#generative-models",
    "href": "w10/index.html#generative-models",
    "title": "Week 10: Parameter Estimation",
    "section": "Generative Models",
    "text": "Generative Models\n\n\n\nGiven a choice of \\(\\param{\\theta}\\), we can generate simulated datasets (here 10 for each labeled value of \\(\\param{p}\\)), then compute likelihood as proportion of datasets with 8 heads, 2 tails\nFrom plot: (Among these vals) \\(\\param{p} = 0.8\\) is maximum likelihood estimate\n\n\n\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(dplyr)\nset.seed(1948)\nobs_heads &lt;- 8\nnum_flips &lt;- 10\nnum_reps &lt;- 10\np_vals &lt;- c(0.01, 0.2, 0.4, 0.6, 0.8, 0.99)\nobs_matches &lt;- c()\nfor (i in 1:length(p_vals)) {\n  cur_p &lt;- p_vals[i]\n  theta_str &lt;- sprintf(\"%.2f\", cur_p)\n  sim_data &lt;- replicate(\n    num_reps,\n    rbinom(num_flips, 1, cur_p)\n  )\n  #print(sim_data)\n  #data_str &lt;- paste0(sim_data, collapse=\", \")\n  num_heads &lt;- colSums(sim_data)\n  #print(num_heads)\n  num_matches &lt;- sum(num_heads == obs_heads)\n  obs_matches &lt;- c(obs_matches, num_matches)\n  #print(num_matches)\n  #print(num_heads)\n  num_tails &lt;- num_flips - num_heads\n  #print(num_tails)\n  data_strs &lt;- paste0(\"[\",num_heads,\" heads, \",num_tails,\" tails]\")\n  data_str &lt;- paste0(data_strs, collapse=\", \")\n  #writeLines(paste0(\"p = \",theta_str,\": \",data_str))\n}\n#print(obs_matches)\nresult_df &lt;- tibble(p=as.character(p_vals), num_matches=obs_matches)\nresult_df &lt;- result_df %&gt;% mutate(prop_matches = obs_matches / num_reps)\nggplot(result_df, aes(x=p, y=prop_matches)) +\n  geom_bar(stat = 'identity', fill=cb_palette[1]) +\n  dsan_theme(\"quarter\") +\n  # theme(\n  #   axis.title.y = element_text(size = 12)\n  # ) +\n  labs(\n    title = \"Likelihood of data (8 heads, 2 tails) given p\",\n    y = \"Proportion of times (8,2) generated\"\n  )",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#week-10-lab",
    "href": "w10/index.html#week-10-lab",
    "title": "Week 10: Parameter Estimation",
    "section": "Week 10 Lab!",
    "text": "Week 10 Lab!\n\nLink to Colab",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#simulations-rightarrow-math",
    "href": "w10/index.html#simulations-rightarrow-math",
    "title": "Week 10: Parameter Estimation",
    "section": "Simulations \\(\\rightarrow\\) Math",
    "text": "Simulations \\(\\rightarrow\\) Math\nPrev example was overkill: we can solve for optimal \\(\\param{p}\\) value‚Ä¶\n\\[\n\\begin{align*}\np^* &\\overset{\\phantom{x_i\\text{ indep}}}{=} \\argmax_{\\param{p}} \\mathcal{L}(x_1, \\ldots, x_n \\mid \\param{p}) \\\\\n&\\overset{x_i\\text{ indep}}{=} \\argmax_{\\param{p}} \\mathcal{L}(x_1 \\mid \\param{p})\\mathcal{L}(x_2 \\mid \\param{p}) \\cdots \\mathcal{L}(x_n \\mid \\param{p})\n\\end{align*}\n\\]\n\nWhat are the individual \\(\\mathcal{L}(x_i \\mid \\param{p})\\) terms?\nHow do we maximize the product \\(\\mathcal{L}(x_1 \\mid \\param{p}) \\cdots \\mathcal{L}(x_n \\mid \\param{p})\\)?\n\n\nTime for some Math Magic‚Ä¶",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#math-magic-1",
    "href": "w10/index.html#math-magic-1",
    "title": "Week 10: Parameter Estimation",
    "section": "Math Magic 1",
    "text": "Math Magic 1\n What are the individual \\(\\Pr(x_i \\mid \\param{p})\\) terms?\n\\(X \\sim \\text{Bern}(\\param{p})\\), so\n\\[\n\\begin{align*}\n\\Pr(X = x_i \\mid \\param{p}) &= \\begin{cases}1 - \\param{p} & x_i = 0 \\\\ \\param{p} & x_i = 1\\end{cases} \\; \\leftarrow \\genfrac{}{}{0pt}{}{\\text{ Non-differentiable}}{üò≠} \\\\\n&\\overset{\\text{math}}{\\underset{\\text{magic}}{=}} (1-\\param{p})^{1-x_i}\\param{p}^{x_i} \\; \\leftarrow \\text{ Differentiable! üò≤}\n\\end{align*}\n\\]\nWhy do we need it to be differentiable? Stay tuned‚Ä¶",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#math-magic-2",
    "href": "w10/index.html#math-magic-2",
    "title": "Week 10: Parameter Estimation",
    "section": "Math Magic 2",
    "text": "Math Magic 2\n\n\n\n\n\n\n How do we maximize the product?\n\\[\np^* = \\argmax_{\\param{p}} f(\\param{p}) \\implies f'(p^*) = 0\n\\]\nTo maximize likelihood, we need to find its derivative1, set equal to 0, and solve:\n\n\n\n\n\n\n\\[\n\\begin{align*}\n&\\frac{d}{d\\param{p}}\\lik(x \\mid \\param{p}) = 0 \\iff \\\\\n&\\frac{d}{d\\param{p}}\\left[\\lik(x_1 \\mid \\param{p})\\lik(x_2 \\mid \\param{p})\\cdots \\lik(x_n \\mid \\param{p})\\right] = 0\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#obstacle-products-vs.-sums",
    "href": "w10/index.html#obstacle-products-vs.-sums",
    "title": "Week 10: Parameter Estimation",
    "section": "Obstacle: Products vs.¬†Sums",
    "text": "Obstacle: Products vs.¬†Sums\n\nFinding \\(\\frac{d}{d\\param{p}}\\left[ \\lik(x_1)\\lik(x_2)\\cdots \\lik(x_n)\\right]\\) is a doozy, even with just \\(n = 2\\) datapoints:\n\n\\[\n\\begin{align*}\n&\\frac{d}{d\\param{p}}\\left[ \\lik(x_1)\\lik(x_2) \\right] = \\left( \\frac{d}{d\\param{p}}\\lik(x_1)\\right) \\cdot \\lik(x_2) + \\lik(x_1)\\cdot \\left( \\frac{d}{d\\param{p}}\\lik(x_2) \\right) \\\\\n&= (1-\\param{p})^{-x_1}\\param{p}^{x_1-1}(x_1-\\param{p})\\cdot (1-\\param{p})^{1-x_2}\\param{p}^{x_2} \\\\\n&+ (1-\\param{p})^{1-x_1}\\param{p}^{x_1} \\cdot (1-\\param{p})^{-x_2}\\param{p}^{x_2-1}(x_2 - \\param{p})\n%&= \\frac{d}{d\\theta}\\left[ (1-p)^{1-x_1}p^{x_1}(1-p)^{1-x_2}p^{x_2} \\right]\n\\end{align*}\n\\]\n\nComplicating factor: \\(\\lik(x_i)\\) terms are all multiplied together, forcing us to use product rule: \\(\\frac{d}{d\\param{p}}\\left[\\lik(x_1)\\lik(x_2)\\right] = \\left(\\frac{d}{d\\param{p}}\\lik(x_1)\\right)\\cdot \\lik(x_2) + \\lik(x_1)\\cdot \\left(\\frac{d}{d\\param{p}}\\lik(x_2)\\right)\\)\nIf we had terms that were added rather than multiplied, we‚Äôd have a much easier time: \\(\\frac{d}{d\\param{p}}\\left[ \\lik(x_1) + \\lik(x_2)\\right] = \\frac{d}{d\\param{p}}\\lik(x_1) + \\frac{d}{d\\param{p}} \\lik(x_2)\\)2\nSo, what math operation do we know that turns multiplications into additions?",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#math-magic-3-log-likelihood",
    "href": "w10/index.html#math-magic-3-log-likelihood",
    "title": "Week 10: Parameter Estimation",
    "section": "Math Magic 3: Log-Likelihood",
    "text": "Math Magic 3: Log-Likelihood\n\\[\n\\log(a\\cdot b) = \\log(a) + \\log(b)\n\\]\nBingo! So, can we maximize \\(\\loglik(x_i) = \\log(\\mathcal{L}(x_i))\\) rather than \\(\\mathcal{L}(x_i)\\)? Bingo again! Because logarithms are monotonic,\n\\[\nx^* = \\argmax_x \\left[ \\log\\left(f(x)\\right) \\right] \\iff x^* = \\argmax_x \\left[ f(x) \\right]\n\\]\nSo, we can just solve\n\\[\np^* = \\argmax_{\\param{p}} \\left[ \\ell(x_1, \\ldots, x_n)\\right]\n\\]",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#simplifying",
    "href": "w10/index.html#simplifying",
    "title": "Week 10: Parameter Estimation",
    "section": "Simplifying",
    "text": "Simplifying\nOur problem simplifies to figuring out\n\\[\n\\begin{align*}\n\\frac{d}{d\\param{p}}\\left[ \\log \\left( \\lik(x_1)\\cdots \\lik(x_n) \\right) \\right] &= \\frac{d}{d\\param{p}}\\left[ \\log \\lik(x_1) + \\log\\lik(x_2) + \\cdots + \\log\\lik(x_n) \\right] \\\\\n&= \\frac{d}{d\\param{p}}\\left[ \\ell(x_1) + \\ell(x_2) + \\cdots + \\ell(x_n) \\right] = \\frac{d}{d\\param{p}}\\left[ \\sum_{i=1}^n \\ell(x_i)\\right]\n\\end{align*}\n\\]\nBut since the derivative is an additive operator, \\(\\frac{d}{d\\param{p}}\\left[ \\sum_{i=1}^n \\ell(x_i) \\right] = \\sum_{i=1}^n \\frac{d}{d\\param{p}}\\left[ \\ell(x_i) \\right]\\), so we just have to compute \\(\\frac{d}{d\\param{p}}\\ell(x_i)\\)! No product rule required (we still need chain rule):\n\\[\n\\begin{align*}\n\\frac{d}{d\\param{p}}\\left[ \\ell(x_i) \\right] &= \\frac{d}{d\\param{p}}\\left[ \\log((1-\\param{p})^{1-x_i}\\param{p}^{x_i}) \\right] = \\frac{d}{d\\param{p}}\\left[(1-x_i)\\log(1-\\param{p}) + x_i\\log(\\param{p})\\right] \\\\\n&= (1-x_i)\\frac{d}{d\\param{p}}\\log(1-\\param{p}) + x_i\\frac{d}{d\\param{p}}\\log(\\param{p}) = -\\frac{1-x_i}{1-\\param{p}} + \\frac{x_i}{\\param{p}} \\\\\n&= \\frac{\\param{p} - x_i}{(\\param{p}-1)\\param{p}}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#maximizing",
    "href": "w10/index.html#maximizing",
    "title": "Week 10: Parameter Estimation",
    "section": "Maximizing",
    "text": "Maximizing\nNow that we know \\(\\frac{d}{d\\param{p}}\\ell(x_i)\\), we set our log-likelihood equation equal to zero to find the likelihood-maximizing \\(\\param{p}\\) value, \\(p^*\\):\n\\[\n\\begin{align*}\n&\\sum_{i=1}^n\\frac{d}{d\\param{p}}\\ell(x_i) = 0 \\iff \\sum_{i=1}^n \\frac{p^* - x_i}{(p^*-1)p^*} = 0 \\\\\n&\\iff -\\frac{1}{(p^*-1)p^*}\\sum_{i=1}^nx_i - np^* = 0 \\\\\n&\\iff \\sum_{i=1}^nx_i = np^* \\iff \\boxed{p^* = \\frac{\\sum_{i=1}^nx_i}{n}}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#mle-intuition",
    "href": "w10/index.html#mle-intuition",
    "title": "Week 10: Parameter Estimation",
    "section": "MLE Intuition",
    "text": "MLE Intuition\n\\[\np^* = \\frac{\\sum_{i=1}^nx_i}{n} = \\frac{\\sum_{i=1}^n \\mathbf{1}[x_i = 1]}{n} \\genfrac{}{}{0pt}{}{\\leftarrow \\text{\\# Heads}}{\\leftarrow \\text{\\# Flips }}\n\\]\n\nMLE almost always matches intuition! Example: given data \\(x_1, \\ldots, x_n\\), what Normal distribution best fits this data?\nSame as asking: what parameter settings for \\(\\mathcal{N}(\\param{\\mu}, \\param{\\sigma^2})\\) are most likely to produce \\(x_1, \\ldots, x_n\\)? The answer:\n\n\\[\n\\mu^* = \\frac{\\sum_{i=1}^n x_i}{n} \\; \\; \\; \\sigma^2_* = \\frac{\\sum_{i=1}^n (x_i-\\mu^*)^2}{n}\n\\]",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#the-dark-side-of-mle",
    "href": "w10/index.html#the-dark-side-of-mle",
    "title": "Week 10: Parameter Estimation",
    "section": "The Dark Side of MLE",
    "text": "The Dark Side of MLE\n\nSometimes steers us in the wrong direction!\nConsider values from previous slide, as estimators for population \\(\\mu\\) and \\(\\sigma^2\\): \\(\\mu^*\\) unbiased if \\(\\expect{\\mu^*} = \\mu\\):\n\n\\[\n\\begin{align*}\n\\expect{\\mu^*} &= \\bigexpect{\\frac{\\sum_{i=1}^nx_i}{n}} = \\frac{1}{n}\\sum_{i=1}^n\\expect{x_i} \\\\\n&= \\frac{1}{n}\\sum_{i=1}^n\\mu = \\frac{n\\mu}{n} = \\mu \\; ‚úÖ\n\\end{align*}\n\\]\n\nSo far so good. How about \\(\\sigma^2_*\\)?",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#mle-as-biased-estimator",
    "href": "w10/index.html#mle-as-biased-estimator",
    "title": "Week 10: Parameter Estimation",
    "section": "MLE as Biased Estimator",
    "text": "MLE as Biased Estimator\n\nBefore we think about \\(\\expect{\\sigma^2_*}\\), let‚Äôs rewrite \\(\\sigma^2_*\\):\n\n\\[\n\\begin{align*}\n\\sigma^2_* &= \\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu^*)^2 = \\frac{1}{n}\\sum_{i=1}^n \\left( x_i^2 - 2 \\mu^* x_i + (\\mu^*)^2 \\right) \\\\\n&= \\frac{1}{n}\\sum_{i=1}^nx_i^2 - 2\\mu^*\\underbrace{\\frac{\\sum_{i=1}^nx_i}{n}}_{\\mu^*} + (\\mu^*)^2 = \\frac{1}{n}\\sum_{i=1}^nx_i^2 - (\\mu^*)^2 \\\\\n&= \\frac{1}{n}\\sum_{i=1}^nx_i^2 - (\\mu^*)^2\n\\end{align*}\n\\]\n\nNow we‚Äôre ready to compute \\(\\expect{\\sigma^2_*}\\)!",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#computing-mathbbesigma2_",
    "href": "w10/index.html#computing-mathbbesigma2_",
    "title": "Week 10: Parameter Estimation",
    "section": "Computing \\(\\mathbb{E}[\\sigma^2_*]\\)",
    "text": "Computing \\(\\mathbb{E}[\\sigma^2_*]\\)\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\bigexpect{\\frac{1}{n}\\sum_{i=1}^nx_i^2 - (\\mu^*)^2} = \\frac{1}{n}\\sum_{i=1}^n \\expect{x_i^2} - \\expect{(\\mu^*)^2}\n\\end{align*}\n\\]\n\nWhat do we know about \\(\\expect{x_i^2}\\)? Remember the (alternate) definition of variance: \\(\\Var{X} = \\expect{X^2} - \\left(\\expect{X}\\right)^2\\). Then\n\n\\[\n\\expect{X^2} = \\Var{X} + \\left(\\expect{X}\\right)^2\n\\]\nSo let‚Äôs plug in the right side when we see \\(\\expect{X^2}\\) or \\(\\expect{(\\mu^*)^2}\\):\n\\[\n\\begin{align*}\n\\frac{1}{n}\\sum_{i=1}^n \\expect{x_i^2} - \\expect{(\\mu^*)^2} &= \\frac{1}{n}\\sum_{i=1}^n\\left(\\Var{X} + \\left(\\expect{X}\\right)^2\\right) - \\expect{(\\mu^*)^2} \\\\\n&= (\\sigma^2 + \\mu^2) - \\left(\\Var{\\mu^*} + \\left(\\expect{\\mu^*}\\right)^2\\right)\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#almost-there",
    "href": "w10/index.html#almost-there",
    "title": "Week 10: Parameter Estimation",
    "section": "Almost There!",
    "text": "Almost There!\nWe know that \\(\\expect{\\mu^*} = \\mu\\), but what is \\(\\Var{\\mu^*}\\)? Remember that \\(\\Var{aX} = a^2\\Var{X}\\)!\n\\[\n\\Var{\\mu^*} = \\bigVar{\\frac{1}{n}\\sum_{i=1}^nx_i} = \\frac{1}{n^2}\\sum_{i=1}^n\\Var{x_i} = \\frac{n\\sigma^2}{n^2} = \\frac{\\sigma^2}{n}\n\\]\nAnd we plug back in to get:\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\sigma^2 + \\mu^2 - \\Var{\\mu^*} - \\left(\\expect{\\mu^*}\\right)^2 \\\\\n&= \\sigma^2 + \\mu^2 - \\frac{\\sigma^2}{n} - \\mu^2 = \\sigma^2 - \\frac{\\sigma^2}{n} \\\\\n&= \\frac{n\\sigma^2 - \\sigma^2}{n} = \\frac{\\sigma^2(n-1)}{n} \\\\\n&= \\color{red}{\\left(\\frac{n-1}{n}\\right)\\sigma^2} \\neq \\sigma^2 \\; üíÄ\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#why-does-this-happen-handwaving",
    "href": "w10/index.html#why-does-this-happen-handwaving",
    "title": "Week 10: Parameter Estimation",
    "section": "Why Does This Happen?: Handwaving",
    "text": "Why Does This Happen?: Handwaving\n\nLong story short, we underpredict the population variance because we already used some of the data to compute \\(\\mu^*\\)!\nThis is where the degrees of freedom heuristic comes in:\n\nWhen we construct an estimate \\(e\\), \\(df(e) = n - k_e\\)\n\\(k_e =\\) number of other estimates used to calculate \\(e\\)!",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#handwavy-intuition",
    "href": "w10/index.html#handwavy-intuition",
    "title": "Week 10: Parameter Estimation",
    "section": "Handwavy Intuition",
    "text": "Handwavy Intuition\n\nConsider \\(X_1, X_2 \\sim \\mathcal{N}(0,1)\\): \\(\\mu = 0\\), \\(\\sigma^2 = 1\\).\n\n\\[\n\\expect{\\mu^*} = \\bigexpect{\\frac{X_1 + X_2}{2}} = \\frac{1}{2}\\left(\\expect{X_1} + \\expect{X_2}\\right) = 0 = \\mu \\; ‚úÖ\n\\]\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\frac{1}{2}\\bigexpect{(X_1 - \\mu^*)^2 + (X_2 - \\mu^*)^2} \\\\\n&= \\frac{1}{2}\\bigexpect{\\left(X_1^2 + \\mu^2_* -2\\mu^*X_1\\right) + \\left(X_2^2 + \\mu^2_* - 2X_2\\mu^*\\right)} \\\\\n&= \\frac{1}{2}\\expect{X_1^2 + X_2^2 + 2\\mu_*^2 - 2\\mu^*X_1 - 2\\mu^*X_2} \\\\\n&= \\frac{1}{2}\\left(\\expect{X_1^2} + \\expect{X_2^2} + 2\\expect{\\mu_*^2} - 2\\expect{\\mu^*X_1} - 2\\expect{\\mu^*X_2}\\right) \\\\\n&\\implies \\boxed{\\expect{\\sigma^2_*} = \\frac{1}{2}\\sigma^2}\n\\end{align*}\n\\]\n\nWe‚Äôre off by \\(\\frac{1}{2}\\)! What to do?",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#handwavy-solution",
    "href": "w10/index.html#handwavy-solution",
    "title": "Week 10: Parameter Estimation",
    "section": "Handwavy Solution",
    "text": "Handwavy Solution\n\nWe can account for degrees of freedom, correcting the MLE by a factor of \\(\\frac{n}{df(e^*)}\\)!\n\n\\(e^\\circledast = \\frac{n}{df(e^*)}e^*\\)\n\nEx: Since \\(\\expect{\\sigma_*^2} = \\frac{n-1}{n}\\sigma^2\\), we can instead use \\(\\sigma^2_\\circledast = \\frac{n}{n-1}\\sigma^2_*\\). This gives us:\n\n\\[\n\\expect{\\sigma^2_\\circledast} = \\bigexpect{\\frac{n}{n-1}\\sigma^2_*} = \\frac{n}{n-1}\\frac{n-1}{n}\\sigma^2 = \\color{green}{\\sigma^2} \\; ‚úÖ\n\\]",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#st-century-solution",
    "href": "w10/index.html#st-century-solution",
    "title": "Week 10: Parameter Estimation",
    "section": "21st-Century Solution",
    "text": "21st-Century Solution\n\nBe Bayesian, use priors on parameters (creating hyperparameters)!\nPretend we know \\(\\sigma^2\\), but want to find the ‚Äúbest‚Äù value of \\(\\mu\\):\n\n\\[\n\\begin{array}{rlccc}\nX_1, X_2 \\overset{iid}{\\sim} \\mathcal{N}( &\\hspace{-5mm}\\mu\\hspace{0.5mm}, &\\hspace{-8mm}\\overbrace{\\sigma^2}^{\\large\\text{known}}\\hspace{-2mm}) & & \\\\\n&\\hspace{-4mm}\\downarrow & ~ &\\hspace{-10mm}{\\small\\text{estimate}} & \\hspace{-6mm} & \\hspace{-8mm}{\\small\\text{uncertainty}} \\\\[-5mm]\n&\\hspace{-5mm}\\mu &\\hspace{-5mm}\\sim \\mathcal{N}&\\hspace{-7mm}(\\overbrace{m}&\\hspace{-12mm}, &\\hspace{-16mm}\\overbrace{s})\n\\end{array}\n\\]",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#single-datapoint",
    "href": "w10/index.html#single-datapoint",
    "title": "Week 10: Parameter Estimation",
    "section": "Single Datapoint",
    "text": "Single Datapoint\n\nLet‚Äôs consider the estimate of \\(\\mu\\) from a single datapoint \\(X_i\\). MLE just gives us \\(\\mu^* = X_i\\). How about MAP estimate?\n\n\\[\n\\lik\\left(X_i, \\mu, m, s\\right) \\overset{\\text{factors}}{\\underset{\\text{into}}{=}} P(X_i \\mid \\mu)P(\\mu \\mid m, s)P(m, s)\n\\]\n\nRemembering the pdf of the Normal distribution, we have:\n\n\\[\n\\lik\\left(X_i, \\mu, m, s\\right) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left[-\\frac{(X_i-\\mu)^2}{2\\sigma^2}\\right]\\frac{1}{s\\sqrt{2\\pi}}\\exp\\left[-\\frac{(\\mu - m)^2}{2s^2}\\right]\n\\]\n\nThen, remembering that we can maximize the log-likelihood rather than the likelihood:\n\n\\[\n\\ell(X_i, \\mu, m, s) = \\log\\left[\\frac{1}{\\sigma\\sqrt{2\\pi}}\\right] - \\frac{(X_i-\\mu)^2}{2\\sigma^2} + \\log\\left[\\frac{1}{s\\sqrt{2\\pi}}\\right] - \\frac{(\\mu - m)^2}{2s^2}\n\\]",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#taking-the-derivative",
    "href": "w10/index.html#taking-the-derivative",
    "title": "Week 10: Parameter Estimation",
    "section": "Taking the Derivative",
    "text": "Taking the Derivative\n\nTaking the derivative gives us:\n\n\\[\n\\begin{align*}\n\\frac{\\partial\\ell}{\\partial \\mu} &= \\frac{\\partial}{\\partial\\mu}\\left[ {\\color{red}\\cancel{\\color{black}\\log\\left[\\frac{1}{\\sigma\\sqrt{2\\pi}}\\right]}} - \\frac{(X_i-\\mu)^2}{2\\sigma^2} + {\\color{red}\\cancel{\\color{black}\\log\\left[\\frac{1}{s\\sqrt{2\\pi}}\\right]}} - \\frac{(\\mu - m)^2}{2s^2}\\right] \\\\\n&= - \\frac{1}{2\\sigma^2}\\cdot\\frac{\\partial}{\\partial\\mu}\\left[{\\color{red}\\cancel{\\color{black}X_i^2}} + \\mu^2 - 2X_i\\mu\\right] - \\frac{1}{2s^2}\\cdot\\frac{\\partial}{\\partial\\mu}\\left[\\mu^2 + {\\color{red}\\cancel{\\color{black}m^2}} - 2\\mu m\\right] \\\\\n&= -\\frac{1}{2\\sigma^2}\\cdot (2\\mu -2X_i) - \\frac{1}{2s^2}\\cdot (2\\mu - 2m) = \\frac{X_i-\\mu}{\\sigma^2} + \\frac{m - \\mu}{s^2}\n\\end{align*}\n\\]\n\nAnd we set equal to zero and solve to obtain the MAP estimate:\n\n\\[\n\\begin{align*}\n&\\frac{X_i - \\mu^*}{\\sigma^2} + \\frac{m - \\mu^*}{s^2} = 0 \\iff \\frac{\\mu^*}{\\sigma^2} + \\frac{\\mu^*}{s^2} = \\frac{X_i}{\\sigma^2} + \\frac{m}{s^2} \\iff \\\\\n&\\frac{s^2\\mu^* + \\sigma^2\\mu^*}{\\sigma^2s^2} = \\frac{s^2X_i + \\sigma^2m}{\\sigma^2s^2} \\iff \\mu^*(s^2+\\sigma^2) = s^2X_i + \\sigma^2m \\\\\n&\\iff \\boxed{\\mu^* = \\left(\\frac{s^2}{s^2 + \\sigma^2}\\right)X_i + \\left(\\frac{\\sigma^2}{s^2 + \\sigma^2}\\right)m}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#the-takeaway",
    "href": "w10/index.html#the-takeaway",
    "title": "Week 10: Parameter Estimation",
    "section": "The Takeaway",
    "text": "The Takeaway\n\nBayesian approach allows new evidence to be weighed against existing evidence, with statistically principled way to derive these weights:\n\n\\[\n\\begin{array}{ccccc}\n\\Pr_{\\text{post}}(\\mathcal{H}) &\\hspace{-6mm}\\propto &\\hspace{-6mm} \\Pr(X \\mid \\mathcal{H}) &\\hspace{-6mm} \\times &\\hspace{-6mm} \\Pr_{\\text{pre}}(\\mathcal{H}) \\\\\n\\text{Posterior} &\\hspace{-6mm}\\propto &\\hspace{-6mm}\\text{Evidence} &\\hspace{-6mm} \\times &\\hspace{-6mm} \\text{Prior}\n\\end{array}\n\\]",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#generalized-method-of-moments-gmm-estimation",
    "href": "w10/index.html#generalized-method-of-moments-gmm-estimation",
    "title": "Week 10: Parameter Estimation",
    "section": "Generalized Method of Moments (GMM) Estimation",
    "text": "Generalized Method of Moments (GMM) Estimation\n\nRecall that the \\(k\\)th moment of an RV \\(X\\) is \\(\\mu_k = \\expect{X^k}\\)\ne.g., \\(\\mu_1 = \\expect{X}\\), \\(\\mu_2 = \\Var{X} + \\expect{X}^2\\)\nAlso recall (I rambled on about) how the MGF contains all information about a distribution. This means we can estimate distributions from data:\nDefine \\(k\\)th sample moment of \\(\\mathbf{X}_N\\): \\(\\widehat{\\mu}_k = \\frac{1}{N}\\sum_{i=1}^nX_i^k\\). Then:\n\\[\n  \\begin{align*}\n  \\mu_1(\\param{\\theta}) &= \\widehat{\\mu}_1 \\\\\n  \\mu_2(\\param{\\theta}) &= \\widehat{\\mu}_2 \\\\\n  &~\\vdots \\\\\n  \\mu_N(\\param{\\theta}) &= \\widehat{\\mu}_N\n  \\end{align*}\n  \\]\nGives us a system of equations, allowing us to solve for parameters \\(\\param{\\theta}\\) of our distribution!",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#intuition",
    "href": "w10/index.html#intuition",
    "title": "Week 10: Parameter Estimation",
    "section": "Intuition",
    "text": "Intuition\n\n\n\n\n\n\n\n\n\nLow Variance\nHigh Variance\n\n\n\n\nLow Bias\n\n\n\n\nHigh Bias\n\n\n\n\n\n\n\nAdapted from Fortmann-Roe (2012), ‚ÄúUnderstanding the Bias-Variance Tradeoff‚Äù",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#components-of-the-error-term",
    "href": "w10/index.html#components-of-the-error-term",
    "title": "Week 10: Parameter Estimation",
    "section": "Components of the Error Term",
    "text": "Components of the Error Term\n\nWe estimate ‚Äútrue‚Äù DGP \\(Y = f(X)\\) with model \\(\\widehat{f}(X)\\)3, and then we use \\(\\widehat{f}\\) to predict the value of \\(Y\\) for a point \\(x_0\\).\nWhat is our expected error at this point, \\(\\Err(x_0)\\)?\n\n\\[\n\\begin{align*}\n\\Err(x_0) &= \\bigexpect{\\left.(Y ‚àí \\widehat{f}(x_0))^2 \\right| X = x_0} \\\\\n&= \\sigma^2_{\\varepsilon} + \\left( \\bigexpect{\\widehat{f}(x_0)} ‚àí f(x_0) \\right)^2 + \\mathbb{E}\\left[\\widehat{f}(x_0) ‚àí \\bigexpect{\\widehat{f}(x_0)}\\right]^2 \\\\\n&= \\sigma^2_{\\varepsilon} + \\left( \\text{Bias}(\\widehat{f}(x_0)\\right)^2 + \\bigVar{\\widehat{f}(x_0)} \\\\\n&= \\text{Irreducible Error} + \\text{Bias}^2 + \\text{Variance}.\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#in-practice",
    "href": "w10/index.html#in-practice",
    "title": "Week 10: Parameter Estimation",
    "section": "In Practice",
    "text": "In Practice\n\n\n\nFigure from (tharwat_parameter_2019?)",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#appendix-1-derivation-of-mathbbemu_2",
    "href": "w10/index.html#appendix-1-derivation-of-mathbbemu_2",
    "title": "Week 10: Parameter Estimation",
    "section": "Appendix 1: Derivation of \\(\\mathbb{E}[\\mu_*^2]\\)",
    "text": "Appendix 1: Derivation of \\(\\mathbb{E}[\\mu_*^2]\\)\n\\[\n\\begin{align*}\n\\expect{\\mu_*^2} &= \\bigexpect{\\left(\\frac{X_1 + X_2}{2}\\right)^2} = \\frac{1}{4}\\expect{(X_1+X_2)^2} \\\\\n&= \\frac{1}{4}\\expect{X_1^2 + X_2^2 + 2X_1X_2} = \\frac{1}{4}\\left(\\expect{X_1^2} + \\expect{X_2^2} + 2\\expect{X_1X_2}\\right) \\\\\n&= \\frac{1}{4}\\left(\\Var{X_1} + \\expect{X_1}^2 + \\Var{X_2} + \\expect{X_2}^2 + 2\\expect{X_1X_2}\\right) \\\\\n&= \\frac{1}{4}\\left(2\\sigma^2 + 2\\mu^2 + 2\\expect{X_1X_2}\\right) \\\\\n&= \\frac{1}{2}\\left(\\sigma^2 + \\mu^2 + \\expect{X_1X_2}\\right) \\overset{iid}{=} \\frac{1}{2}\\left(\\sigma^2 + \\mu^2 + \\mu^2\\right) \\\\\n&\\implies \\boxed{\\expect{\\mu^2_*} = \\mu^2 + \\frac{\\sigma^2}{2}} \\; \\; \\left(\\therefore \\; \\expect{\\mu_*^2} \\neq \\mu^2 \\right)\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#appendix-2-derivation-of-mathbbemux_i",
    "href": "w10/index.html#appendix-2-derivation-of-mathbbemux_i",
    "title": "Week 10: Parameter Estimation",
    "section": "Appendix 2: Derivation of \\(\\mathbb{E}[\\mu^*X_i]\\)",
    "text": "Appendix 2: Derivation of \\(\\mathbb{E}[\\mu^*X_i]\\)\n\\[\n\\begin{align*}\n\\expect{\\mu^*X_1} &= \\bigexpect{\\left(\\frac{X_1 + X_2}{2}\\right)X_1} = \\frac{1}{2}\\expect{X_1^2 + X_1X_2} \\\\\n&= \\frac{1}{2}\\expect{X_1^2} + \\frac{1}{2}\\expect{X_1X_2} = \\frac{1}{2}\\left(\\sigma^2 + \\mu^2\\right) + \\frac{1}{2}\\mu^2 \\\\\n&\\implies \\expect{\\mu^*X_1} = \\mu^2 + \\frac{\\sigma^2}{2}\n\\end{align*}\n\\]\nAnd since \\(X_1\\) was chosen without loss of generality,\n\\[\n\\boxed{\\expect{\\mu^*X_i} = \\mu^2 + \\frac{\\sigma^2}{2}}\n\\]",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#appendix-3-derivation-of-mathbbesigma2_",
    "href": "w10/index.html#appendix-3-derivation-of-mathbbesigma2_",
    "title": "Week 10: Parameter Estimation",
    "section": "Appendix 3: Derivation of \\(\\mathbb{E}[\\sigma^2_*]\\)",
    "text": "Appendix 3: Derivation of \\(\\mathbb{E}[\\sigma^2_*]\\)\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\frac{1}{2}\\bigexpect{(X_1 - \\mu^*)^2 + (X_2 - \\mu^*)^2} \\\\\n&= \\frac{1}{2}\\bigexpect{\\left(X_1^2 + \\mu^2_* -2\\mu^*X_1\\right) + \\left(X_2^2 + \\mu^2_* - 2X_2\\mu^*\\right)} \\\\\n&= \\frac{1}{2}\\expect{X_1^2 + X_2^2 + 2\\mu_*^2 - 2\\mu^*X_1 - 2\\mu^*X_2} \\\\\n&= \\frac{1}{2}\\left(\\expect{X_1^2} + \\expect{X_2^2} + 2\\expect{\\mu_*^2} - 2\\expect{\\mu^*X_1} - 2\\expect{\\mu^*X_2}\\right) \\\\\n&= \\frac{1}{2}\\left( 2\\sigma^2 + 2\\mu^2 + 2\\left(\\mu^2 + \\frac{\\sigma^2}{2}\\right) - 2\\left(\\mu^2 + s/2\\right) - 2\\left(\\mu^2 + s/2\\right) \\right) \\\\\n&= \\sigma^2 + \\mu^2 + \\mu^2 + \\frac{\\sigma^2}{2} - \\mu^2 - \\frac{\\sigma^2}{2} - \\mu^2 - \\frac{\\sigma^2}{2} = \\sigma^2 - \\frac{\\sigma^2}{2} \\\\\n&\\implies \\boxed{\\expect{\\sigma^2_*} = \\frac{1}{2}\\sigma^2}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#references",
    "href": "w10/index.html#references",
    "title": "Week 10: Parameter Estimation",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#footnotes",
    "href": "w10/index.html#footnotes",
    "title": "Week 10: Parameter Estimation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThat‚Äôs why we used math magic to make \\(\\Pr(x_i \\mid \\param{p})\\) differentiable on prev slide!‚Ü©Ô∏é\nWe achieve this simplification because the derivative operator is additive: \\(\\frac{d}{dx}\\left[ f(x) + g(x) \\right] = \\frac{d}{dx}f(x) + \\frac{d}{dx}g(x)\\)‚Ü©Ô∏é\nA complication we put aside for now: do the features \\(X\\) we chose in fact causally impact \\(Y\\)? See (hastie_elements_2013?)!‚Ü©Ô∏é",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w11/slides.html#generalized-method-of-moments-gmm-estimation",
    "href": "w11/slides.html#generalized-method-of-moments-gmm-estimation",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Generalized Method of Moments (GMM) Estimation",
    "text": "Generalized Method of Moments (GMM) Estimation\n\nRecall that the \\(k\\)th moment of an RV \\(X\\) is \\(\\mu_k = \\expect{X^k}\\)\ne.g., \\(\\mu_1 = \\expect{X}\\), \\(\\mu_2 = \\expect{X^2} = \\Var{X} + \\expect{X}^2\\)\nAlso recall (I rambled on about) how the MGF contains all information about a distribution. This means we can estimate distributions from data:\nDefine \\(k\\)th sample moment of \\(\\mathbf{X}_N\\) to be \\(\\widehat{\\mu}_k = \\frac{1}{N}\\sum_{i=1}^nX_i^k\\). Then the equations\n\\[\n  \\begin{align*}\n  \\mu_1(\\param{\\theta}) &= \\widehat{\\mu}_1 \\\\\n  \\mu_2(\\param{\\theta}) &= \\widehat{\\mu}_2 \\\\\n  &\\vdots \\\\\n  \\mu_N(\\param{\\theta}) &= \\widehat{\\mu}_N\n  \\end{align*}\n  \\]\nGive us a system of equations, allowing us to solve for parameters of our distribution!"
  },
  {
    "objectID": "w11/slides.html#example-bernoulli-distribution",
    "href": "w11/slides.html#example-bernoulli-distribution",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Example: Bernoulli Distribution",
    "text": "Example: Bernoulli Distribution\n\n\\(\\mathbf{X}_N = \\{X_1, X_2, \\ldots, X_n\\} \\iid \\text{Bern}(\\param{p})\\)\nOnly one parameter (\\(\\param{p}\\)), so all of our data can be used solely to generate an estimate of \\(\\param{p}\\)!\n\\(\\mu_1 = \\expect{X_i^1} = p\\), \\(\\widehat{\\mu}_1 = \\frac{1}{N}\\sum_{i=1}^N X_i^1\\)\n\n\\[\n\\mu_1(p) = \\widehat{\\mu}_1 \\iff p = \\frac{1}{N}\\sum_{i=1}^N X_i^1,\n\\]\n\nSolve this system of 1 equation for \\(p\\) to obtain\n\n\\[\n\\underbrace{p^*_{\\text{GMM}}}_{\\mathclap{\\text{Found using algebra}}} = \\frac{1}{N}\\sum_{i=1}^N X_i = \\underbrace{p^*_{\\text{MLE}}}_{\\mathclap{\\text{Found using calculus}}}\n\\]"
  },
  {
    "objectID": "w11/slides.html#method-of-moments-step-by-step",
    "href": "w11/slides.html#method-of-moments-step-by-step",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Method of Moments Step-By-Step",
    "text": "Method of Moments Step-By-Step\n\n\n\n\n\n\n\nSpecify Model: Define a probabilistic model for the distribution of the data.\nIdentify \\(J\\) Parameters of the distribution you‚Äôre trying to estimate: \\(\\param{\\boldsymbol\\theta} = (\\param{\\theta_1}, \\ldots, \\param{\\theta_J})\\)\nCalculate Sample Moments \\(\\widehat{\\boldsymbol\\mu} = (\\widehat{\\mu}_1, \\ldots, \\widehat{\\mu}_J)\\) from observed data.\nSet up Equations: equate population moments \\(\\mu_j\\) (expressed as functions of \\(\\param{\\boldsymbol\\theta}\\)) to their sample counterparts \\(\\widehat{\\mu}_j\\)\nSolve Equations: Solve the system of equations to obtain \\(\\boldsymbol\\theta^*_{\\text{GMM}}\\)\n\n\n\n\nüôå: Applicable to a wide range of distributions.\nüòé: No calculus\nüßê: Other estimators may be more efficient"
  },
  {
    "objectID": "w11/slides.html#intuition",
    "href": "w11/slides.html#intuition",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Intuition",
    "text": "Intuition\n\n\n\n\n\n\n\n\n\nLow Variance\nHigh Variance\n\n\n\n\nLow Bias\n\n\n\n\nHigh Bias\n\n\n\n\n\n\n\nFigure adapted from Fortmann-Roe (2012), ‚ÄúUnderstanding the Bias-Variance Tradeoff‚Äù"
  },
  {
    "objectID": "w11/slides.html#math",
    "href": "w11/slides.html#math",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Math",
    "text": "Math\n\nWe estimate ‚Äútrue‚Äù DGP \\(Y = f(X)\\) with model \\(\\widehat{f}(X)\\)1, and then we use \\(\\widehat{f}\\) to predict the value of \\(Y\\) for a point \\(x_0\\).\nWhat is our expected error at this point, \\(\\Err(x_0)\\)?\n\n\\[\n\\begin{align*}\n\\Err(x_0) &= \\bigexpect{\\left.(Y ‚àí \\widehat{f}(x_0))^2 \\right| X = x_0} \\\\\n&= \\sigma^2_{\\varepsilon} + \\left( \\bigexpect{\\widehat{f}(x_0)} ‚àí f(x_0) \\right)^2 + \\mathbb{E}\\left[\\widehat{f}(x_0) ‚àí \\bigexpect{\\widehat{f}(x_0)}\\right]^2 \\\\\n&= \\sigma^2_{\\varepsilon} + \\left( \\text{Bias}(\\widehat{f}(x_0)\\right)^2 + \\bigVar{\\widehat{f}(x_0)} \\\\\n&= \\text{Irreducible Error} + \\text{Bias}^2 + \\text{Variance}.\n\\end{align*}\n\\]\nIt‚Äôs even more complicated, since we don‚Äôt even know whether the features \\(X\\) we‚Äôve chosen are actually the features in the world that causally affect \\(Y\\), but that‚Äôs for later classes‚Ä¶ Or see (hastie_elements_2013?)!"
  },
  {
    "objectID": "w11/slides.html#in-practice",
    "href": "w11/slides.html#in-practice",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "In Practice",
    "text": "In Practice\n\nFigure from (tharwat_parameter_2019?)"
  },
  {
    "objectID": "w11/slides.html#efficiency",
    "href": "w11/slides.html#efficiency",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Efficiency",
    "text": "Efficiency\n\nIf we were just statisticians, we could stop at bias-variance\nA third consideration, since we‚Äôre also computer scientists, is computational efficiency:\n\n\n\n\n\n Definition: Efficiency\n\n\nif \\(T_1\\) and \\(T_2\\) are both unbiased estimators for the same parameter \\(\\theta\\) (i.e., if \\(\\mathbb{E}[T_1] = \\theta\\) and \\(\\mathbb{E}[T_2] = \\theta\\)), then we can compute their relative efficiency as\n\\[\n\\text{RE}(T_2, T_1) = \\frac{\\Var{T_2}}{\\Var{T_1}},\n\\]\nand then we say that \\(T_2\\) is more efficient than \\(T_1\\) if\n\\[\n\\Var{T_2} &lt; \\Var{T_1} \\iff \\text{RE}(T_2, T_1) &lt; 1.\n\\]"
  },
  {
    "objectID": "w11/slides.html#bootstrap-sampling-1",
    "href": "w11/slides.html#bootstrap-sampling-1",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Bootstrap Sampling",
    "text": "Bootstrap Sampling\n\nBasically a cheat code for squeezing as much information as possible out of your sample\nIntuition: Your model is robust to the extent that it still works for random subsamples of the full dataset"
  },
  {
    "objectID": "w11/slides.html#building-intuition",
    "href": "w11/slides.html#building-intuition",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Building Intuition",
    "text": "Building Intuition\nConsider the following dataset:\n\n\nCode\nx &lt;- seq(from = 0, to = 1, by = 0.1)\nn &lt;- length(x)\neps &lt;- rnorm(n, 0, 0.04)\ny &lt;- x + eps\n# But make one big outlier\nmidpoint &lt;- ceiling((3/4)*n)\ny[midpoint] &lt;- 0\nof_data &lt;- tibble::tibble(x=x, y=y)\n# Linear model\nlin_model &lt;- lm(y ~ x)\n# But now polynomial regression\npoly_model &lt;- lm(y ~ poly(x, degree = 10, raw=TRUE))\nggplot(of_data, aes(x = x, y = y)) +\n    geom_point(size = g_pointsize / 1.5) +\n    dsan_theme(\"full\")"
  },
  {
    "objectID": "w11/slides.html#using-all-observations",
    "href": "w11/slides.html#using-all-observations",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Using All Observations",
    "text": "Using All Observations\nFitting a linear model gives us:\n\n\nCode\nggplot(of_data, aes(x = x, y = y)) +\n    geom_point(size = g_pointsize / 1.5) +\n    geom_smooth(aes(color=\"Linear\"), method = lm, se = FALSE, show.legend=FALSE) +\n    # geom_abline(aes(intercept = 0, slope = 1, color = \"Linear\"), linewidth = 1, show.legend = FALSE) +\n    # stat_smooth(\n    #     method = \"lm\",\n    #     formula = y ~ poly(x, 10, raw = TRUE),\n    #     se = FALSE, aes(color = \"Polynomial\")\n    # ) +\n    dsan_theme(\"full\")\n\n\n\n\n(What‚Äôs wrong with this picture?)"
  },
  {
    "objectID": "w11/slides.html#but-is-it-robust",
    "href": "w11/slides.html#but-is-it-robust",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "But is it Robust?",
    "text": "But is it Robust?\n\n\nCode\n## Part 1: Set up data\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tibble)\n# subsample &lt;- of_data |&gt; sample_n() sample(of_data, size=5)\ngen_subsamples &lt;- function(obs_data, num_subsamples, subsample_size) {\n  #print(subsample_size)\n  subsample_ints &lt;- c()\n  subsample_coefs &lt;- c()\n  for (i in 1:num_subsamples) {\n      cur_subsample &lt;- obs_data |&gt; sample_n(subsample_size, replace = TRUE)\n      cur_lin_model &lt;- lm(y ~ x, data = cur_subsample)\n      cur_int &lt;- cur_lin_model$coefficients[1]\n      subsample_ints &lt;- c(subsample_ints, cur_int)\n      cur_coef &lt;- cur_lin_model$coefficients[2]\n      subsample_coefs &lt;- c(subsample_coefs, cur_coef)\n  }\n  subsample_df &lt;- tibble(intercept = subsample_ints, coef = subsample_coefs)\n  return(subsample_df)\n}\nnum_subsamples &lt;- 50\nsubsample_size &lt;- floor(nrow(of_data) / 2)\nsubsample_df &lt;- gen_subsamples(of_data, num_subsamples, subsample_size)\nfull_model &lt;- lm(y ~ x, data = of_data)\nfull_int &lt;- full_model$coefficients[1]\nfull_coef &lt;- full_model$coefficients[2]\nfull_df &lt;- tibble(intercept=full_int, coef=full_coef)\nmean_df &lt;- tibble(\n    intercept=mean(subsample_df$intercept),\n    coef = mean(subsample_df$coef)\n)\n\n## Part 2: Plot\nggplot(of_data, aes(x = x, y = y)) +\n    geom_point(size=g_pointsize) +\n    # The random lines\n    geom_abline(data = subsample_df, aes(slope = coef, intercept = intercept, color='Subsample Model'), linewidth=g_linewidth, linetype=\"solid\", alpha=0.25) +\n    # The original regression line\n    geom_abline(data=full_df, aes(slope = coef, intercept = intercept, color='Full-Data Model'), linewidth=2*g_linewidth) +\n    # The average of the random lines\n    #geom_abline(data=mean_df, aes(slope = coef, intercept = intercept, color='mean'), linewidth=2*g_linewidth) +\n    labs(\n        title = paste0(\"Linear Models for \", num_subsamples, \" Subsamples of Size n = \", subsample_size),\n        color = element_blank()\n    ) +\n    dsan_theme(\"full\") +\n    theme(\n      legend.title = element_blank(),\n      legend.spacing.y = unit(0, \"mm\")\n    )"
  },
  {
    "objectID": "w11/slides.html#what-a-robust-model-looks-like",
    "href": "w11/slides.html#what-a-robust-model-looks-like",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "What a Robust Model Looks Like",
    "text": "What a Robust Model Looks Like\n\n\nCode\nx &lt;- seq(from = 0, to = 1, by = 0.1)\nn &lt;- length(x)\neps &lt;- rnorm(n, 0, 0.04)\ny &lt;- x + eps\nrobust_data &lt;- tibble(x = x, y = y)\nrobust_sub_df &lt;- gen_subsamples(robust_data, 30, 5)\n#print(robust_sub_df)\nfull_model_robust &lt;- lm(y ~ x, data = robust_data)\nfull_int_robust &lt;- full_model_robust$coefficients[1]\nfull_coef_robust &lt;- full_model_robust$coefficients[2]\nfull_df_robust &lt;- tibble(intercept = full_int_robust, coef = full_coef_robust)\nggplot(robust_data, aes(x = x, y = y)) +\n    geom_point(size=g_pointsize) +\n    # The random lines\n    geom_abline(data = robust_sub_df, aes(slope = coef, intercept = intercept, color='Subsample Model'), linewidth=g_linewidth, linetype=\"solid\", alpha=0.25) +\n    # The original regression line\n    geom_abline(data=full_df_robust, aes(slope = coef, intercept = intercept, color='Full-Data Model'), linewidth=2*g_linewidth) +\n    # The average of the random lines\n    #geom_abline(data=mean_df, aes(slope = coef, intercept = intercept, color='mean'), linewidth=2*g_linewidth) +\n    labs(\n        title = paste0(\"Linear Models for \", num_subsamples, \" Subsamples of Size n = \", subsample_size),\n        color = element_blank()\n    ) +\n    dsan_theme(\"full\") +\n    theme(\n      legend.title = element_blank(),\n      legend.spacing.y = unit(0, \"mm\")\n    )\n\n\n\nHere the model is not ‚Äúmisled‚Äù by outliers"
  },
  {
    "objectID": "w11/slides.html#the-bootstrap-principle",
    "href": "w11/slides.html#the-bootstrap-principle",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "The Bootstrap Principle",
    "text": "The Bootstrap Principle\n\n(This is the cheat code)1 Given a sample \\(X = \\{x_1, \\ldots, x_n\\}\\), we can ‚Äúsqueeze‚Äù more information about out of it by pretending it is the population and sampling from this ‚Äúpopulation‚Äù, with replacement\n\n\\[\n\\begin{align*}\n\\widetilde{X}_1 &= \\{x_2, x_4, x_5, x_7, x_9\\} \\\\\n\\widetilde{X}_2 &= \\{x_2, x_3, x_4, x_7, x_{10}\\} \\\\\n&~\\vdots \\\\\n\\widetilde{X}_{100} &= \\{x_3, x_3, x_7, x_8, x_8\\}\n\\end{align*}\n\\]\nThe fact that this ‚Äújust works‚Äù is similar to the surprising efficacy of the Na√Øve Bayes model (see DSAN 5000!)"
  },
  {
    "objectID": "w11/slides.html#in-pictures",
    "href": "w11/slides.html#in-pictures",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "In Pictures",
    "text": "In Pictures\n\n\nNote in particular how: (a) sampling is done with replacement and (b) the original sample could therefore be replicated exactly in a bootstrap sample (here, \\(\\widetilde{X}_3\\))"
  },
  {
    "objectID": "w11/slides.html#how-well-does-it-work",
    "href": "w11/slides.html#how-well-does-it-work",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "How Well Does it Work?",
    "text": "How Well Does it Work?\nAnswer: Absurdly, unreasonably well.\n\n\nCode\npop &lt;- rnorm(1000000, mean = 3, sd = 1)\n# Sampling 1k times\nrand_samples &lt;- replicate(\n  1000,\n  sample(pop, size=100, replace = FALSE)\n)\nsample_means &lt;- colMeans(rand_samples)\nsample_df &lt;- tibble(est = sample_means, Method = \"1000 Samples\")\n# Sampling 1 time and bootstrapping\nbs_sample &lt;- sample(pop, size = 100, replace = FALSE)\nsubsamples &lt;- replicate(1000, sample(bs_sample, size=100, replace = TRUE))\nbs_means &lt;- colMeans(subsamples)\nbs_df &lt;- tibble(est = bs_means, Method = \"Bootstrap (1 Sample)\")\nresult_df &lt;- bind_rows(sample_df, bs_df)\nsim_dnorm &lt;- function(x) dnorm(x, mean = 3, sd = 1)\nggplot(result_df, aes(x=est, fill=Method)) +\n  dsan_theme(\"full\") +\n  geom_density(alpha=0.2, linewidth=g_linewidth) +\n  geom_vline(aes(xintercept=3, linetype=\"value\"),linewidth=g_linewidth) +\n  scale_linetype_manual(\"\", values=c(\"density\"=\"solid\", \"value\"=\"dashed\"), labels=c(\"Population Mean\", \"testing\")) +\n  theme(\n    legend.title = element_blank(),\n    legend.spacing.y = unit(0, \"mm\")\n  ) +\n  labs(\n    title = \"Bootstrap vs. Multiple Samples\",\n    x = \"Sample / Subsample Means\",\n    y = \"Density\"\n  )\n\n\n\n\n\nCode\nsample_est &lt;- mean(sample_means)\nsample_str &lt;- sprintf(\"%.3f\", sample_est)\nsample_err &lt;- abs(sample_est - 3)\nsample_err_str &lt;- sprintf(\"%.3f\", sample_err)\nsample_output &lt;- paste0(\"1K samples estimate: \", sample_str, \" (abs. err: \", sample_err_str, \")\")\nbs_est &lt;- mean(bs_means)\nbs_str &lt;- sprintf(\"%.3f\", bs_est)\nbs_err &lt;- abs(bs_est - 3)\nbs_err_str &lt;- sprintf(\"%.3f\", bs_err)\nbs_output &lt;- paste0(\"Bootstrap estimate:  \", bs_str, \" (abs. err: \", bs_err_str, \")\")\nwriteLines(paste0(sample_output,\"\\n\",bs_output))\n\n\n1K samples estimate: 3.002 (abs. err: 0.002)\nBootstrap estimate:  3.086 (abs. err: 0.086)"
  },
  {
    "objectID": "w11/slides.html#bootstrapped-confidence-intervals",
    "href": "w11/slides.html#bootstrapped-confidence-intervals",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Bootstrapped ‚ÄúConfidence‚Äù Intervals",
    "text": "Bootstrapped ‚ÄúConfidence‚Äù Intervals\n\nWe get a ‚Äúconfidence‚Äù interval for free!\n\\(\\alpha = 0.05\\)? Just take middle 95% of your bootstrapped estimates!\n\n\n\nCode\nquantile(bs_means, c(0.025, 0.975))\n\n\n    2.5%    97.5% \n2.886234 3.259441 \n\n\n\nEasily interpretable: ‚ÄúAfter repeating this process 1000 times, 95% of the results fell between 2.84 and 3.20‚Äù"
  },
  {
    "objectID": "w11/slides.html#hypothesis-testing-via-bootstrap",
    "href": "w11/slides.html#hypothesis-testing-via-bootstrap",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Hypothesis Testing via Bootstrap",
    "text": "Hypothesis Testing via Bootstrap\n\nNote that our choice to estimate the mean was arbitrary!\nCould just as easily be any chosen test statistic: mean, median, variance, range, 35th percentile, etc.\nHypothesis testing requires choice for test statistic \\(t\\)\n\\(\\mathcal{H}_A\\): Group A taller than Group B\n\\(\\mathcal{H}_0\\): No difference between Group A and Group B heights\n\\(\\mathcal{H}_0 \\iff \\mu_A = \\mu_B \\iff \\underbrace{t = \\mu_A - \\mu_B}_{\\text{Test statistic for }\\mathcal{H}_0} = 0\\)\nBootstrapped test stat, therefore, is just \\(\\widehat{t} = \\widehat{\\mu}_A - \\widehat{\\mu}_B\\)!"
  },
  {
    "objectID": "w11/slides.html#veracity-of-hypothesis-is-relative-to-null-distributions",
    "href": "w11/slides.html#veracity-of-hypothesis-is-relative-to-null-distributions",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Veracity of Hypothesis is Relative to Null Distributions",
    "text": "Veracity of Hypothesis is Relative to Null Distributions\n\nCounterfactual thinking: What would the world look like if the null hypothesis was true? That is, if the relationship of interest did not exist.\nSimulate the test statistic within this null world, say, \\(N = 10000\\) times.\nNow look at how likely/unlikely the observed test statistic is relative to these 10000 null-world-based test statistics."
  },
  {
    "objectID": "w11/slides.html#real-world-example-charter-school-dropout-rates",
    "href": "w11/slides.html#real-world-example-charter-school-dropout-rates",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Real World Example: Charter School Dropout Rates",
    "text": "Real World Example: Charter School Dropout Rates\n\n\n\n\n\n\n\n\n\n(New York City)\nPublic Schools\nCharter Schools\nTotal\n\n\n\n\nEnrolled Students\n\\(N_\\text{pub} \\approx 893000\\)\n\\(N_\\text{ch} \\approx 157000\\)\n\\(N = 1050649\\)\n\n\nYearly Dropouts\n\\(D_\\text{pub} \\approx 24500\\)\n\\(D_\\text{ch} \\approx 16000\\)\n\\(D \\approx 44000\\)\n\n\nYearly Dropout Rate\n\\(R_\\text{pub} \\approx 2.7\\%\\)\n\\(R_\\text{ch} \\approx 10\\%\\)\n\\(R \\approx 4.2\\%\\)\n\n\n\\(\\mathbb{E}[D \\mid R = 4.2\\%]\\)\n\\(\\mathbb{E}[D_\\text{pub}] = 37506\\)\n\\(\\mathbb{E}[D_\\text{ch}] = 6594\\)\n\\(\\mathbb{E}[\\Delta] = 30912\\)\n\n\n\n\nSo, are charter schools systematically pushing lower-performing students out?\nIt depends on how we model the decision to drop out, how we set up our null and alternative hypotheses, and what test statistic we use to evaluate these hypotheses!"
  },
  {
    "objectID": "w11/slides.html#intuition-check-why-do-we-need-to-do-all-this",
    "href": "w11/slides.html#intuition-check-why-do-we-need-to-do-all-this",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Intuition Check: Why Do We Need To Do All This?",
    "text": "Intuition Check: Why Do We Need To Do All This?\n\nDoesn‚Äôt \\(R_\\text{ch} &gt; R_\\text{pub} \\implies\\) charter schools guilty?\nRemember our fair vs.¬†biased coins examples\nLet‚Äôs simulate a fair coin: \\(\\param{p} = \\Pr(\\textsf{H}) = 0.5\\)\n\n\n\nCode\nset.seed(5100)\nlibrary(Rlab)\nnum_flips &lt;- 10\np &lt;- 0.5\ncoin_obs &lt;- rbern(num_flips, p)\ncoin_str &lt;- paste0(coin_obs, collapse=' ')\nnum_heads &lt;- sum(coin_obs)\nwriteLines(paste0(coin_str,\" =&gt; \",num_heads,\" heads\"))\n\n\n1 0 0 0 1 0 0 0 0 1 =&gt; 3 heads\n\n\n\nSeeing 3 heads \\(~\\nimplies \\Pr(\\textsf{H}) = 0.3\\)!"
  },
  {
    "objectID": "w11/slides.html#so-how-can-we-determine-whether-the-coin-is-fair",
    "href": "w11/slides.html#so-how-can-we-determine-whether-the-coin-is-fair",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "So How Can We Determine Whether The Coin Is Fair?",
    "text": "So How Can We Determine Whether The Coin Is Fair?\n\nCode\nlibrary(tidyverse)\nnum_replications &lt;- 1000\ncoin_seqs &lt;- replicate(num_replications, rbern(num_flips, p))\nheads_per_seq &lt;- colSums(coin_seqs)\nheads_df &lt;- tibble(num_heads = heads_per_seq)\nhighlight_3 &lt;- c(rep(\"grey\",2), rep(cbPalette[1],1), rep(\"grey\",7))\nggplot(heads_df, aes(x=factor(num_heads))) +\n  geom_histogram(stat='count', fill=highlight_3) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title=paste0(\"Results From N=\",num_replications,\" 10-Coin-Flip Trials\")\n  )\n\n\n\n\n\nWe have to generate many sequences of coin flips, then look at the distribution of the number of heads in each sequence ‚Üí\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nthree_df &lt;- heads_df |&gt; filter(num_heads == 3)\nnrow(three_df) / nrow(heads_df)\n\n\n\n\n\nNow we can quantify exactly how ‚Äúfishy‚Äù it was to get 3 heads: if the coin was fair, this would happen about 10.7% of the time:\n\n\n\n\n[1] 0.107"
  },
  {
    "objectID": "w11/slides.html#how-fishy-is-too-fishy",
    "href": "w11/slides.html#how-fishy-is-too-fishy",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "How Fishy Is Too Fishy?",
    "text": "How Fishy Is Too Fishy?\n\nThis means, given a context within which we‚Äôre analyzing the data, we can construct a fishiness threshold \\(T\\): then, if \\(\\Pr(\\text{observed outcome}) &lt; T%\\), we can say coin is not fair\nSome journals arbitrarily choose 5% (95% confidence)\nI prefer \\(T = 11\\%\\) (89% confidence), for same reason as anthropologist/statistician Richard McElreath:\n\n\n89 is a prime number, so if someone asks you to justify it, you can stare at them meaningfully and incant, ‚Äúwhy, because it‚Äôs prime, of course!‚Äù That‚Äôs no worse than the conventional justification for 95%. (mcelreath_statistical_2020?)"
  },
  {
    "objectID": "w11/slides.html#our-model-data-generating-process",
    "href": "w11/slides.html#our-model-data-generating-process",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Our Model (Data-Generating Process)",
    "text": "Our Model (Data-Generating Process)\n\nWhat process gives rise to these dropout rates?\nStraightforward model (which we can extend / complicate to include additional factors as needed):\n\nStudent \\(i\\) flips a coin with \\(\\Pr(\\textsf{H}) = \\param{p}\\): if \\(\\textsf{H}\\) student drops out, if \\(\\textsf{T}\\) they stay enrolled\nLet \\(X_i = 1\\) if student \\(i\\) drops out, \\(0\\) otherwise.\n\nThen for school \\(j\\) with \\(N_j\\) students, \\(D_j = \\sum_{i=1}^{N_j}X_i\\) = number of dropouts. Since sum of Bernoulli RVs has Binomial distribution, \\(D_j \\sim \\text{Binom}(N_j, p_j)\\)"
  },
  {
    "objectID": "w11/slides.html#formulatingsimulating-the-null-hypothesis",
    "href": "w11/slides.html#formulatingsimulating-the-null-hypothesis",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Formulating+Simulating the Null Hypothesis",
    "text": "Formulating+Simulating the Null Hypothesis\n\n\\(H_0: p_\\text{ch} = p_\\text{pub} \\iff p_\\text{ch} - p_\\text{pub} = 0\\). There is no difference between the individual-student dropout rate at public schools and the individual-student dropout rate at charter schools\n\\(H_A: p_\\text{pub} &lt; p_\\text{ch} \\iff p_\\text{pub} - p_\\text{ch} &lt; 0\\). There is an underlying difference between the rates at which charter school students and public school students choose to drop out. In this case, the former is greater than the latter\nSo, to simulate null-world, we will simulate public school population and charter school population with the same individual-student dropout rate: \\(\\param{p_\\text{pub}} = \\param{p_\\text{ch}} = \\param{p}\\) then check how often the school-level dropouts \\(D_\\text{pub}\\) and \\(D_\\text{ch}\\) differ by \\(24500 - 16000 = 8500\\) or more"
  },
  {
    "objectID": "w11/slides.html#coding-the-simulation",
    "href": "w11/slides.html#coding-the-simulation",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Coding the Simulation",
    "text": "Coding the Simulation\n\nSimulating a few public-charter pairs:\n\n\n\nCode\n# The true population sizes\nN_ch &lt;- 157000\nN_pub &lt;- 893000\n# We'll use a function to compute num_sims simulations of a school with N_j\n# students, each with dropout probability p\nsimulate_dropouts &lt;- function(num_sims, N_j, p) {\n  return(rbinom(num_sims, N_j, p))\n}\n# We're simulating \"null world\" by generating data\n# on the basis of the assumption p_pub_sim = p_ch_sim\n# So we call the function with the same p for both\n# simulated schools. In this case, we'll use the\n# *overall average* dropout rate across all schools:\n# 4.2% = 0.042\np_sim &lt;- 0.042\n# But we'll write a general function for simulating\n# pairs of schools, whether or not they have the same\n# Pr(dropout):\nsimulate_pair &lt;- function(num_sims, p_ch, p_pub) {\n  D_ch &lt;- simulate_dropouts(num_sims, N_ch, p_ch)\n  D_pub &lt;- simulate_dropouts(num_sims, N_pub, p_pub)\n  sim_df &lt;- tibble(D_ch=D_ch, D_pub=D_pub)\n  return(sim_df)\n}\n# Run the simulation, with the *same* p parameter\n# for both our simulated schools:\nrun_sims_same_p &lt;- function(num_sims, printResults=FALSE) {\n  sim_df &lt;- simulate_pair(num_sims, p_sim, p_sim)\n  # And from these two counts, we can compute the\n  # *test statistic*: in this case, the difference\n  sim_df &lt;- sim_df |&gt; mutate(\n    test_stat = D_pub - D_ch\n  )\n  return(sim_df)\n}\nsmall_sim_df &lt;- run_sims_same_p(3)\nsmall_sim_df\n\n\n\n\n\n\nD_ch\nD_pub\ntest_stat\n\n\n\n\n6528\n37395\n30867\n\n\n6606\n37287\n30681\n\n\n6607\n37469\n30862"
  },
  {
    "objectID": "w11/slides.html#generating-the-null-distribution",
    "href": "w11/slides.html#generating-the-null-distribution",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Generating The Null Distribution",
    "text": "Generating The Null Distribution\n\nThis is the range of values we might expect to see (under our model!) if two schools had the same underlying dropout probabilities\n\\(\\Pr(D_\\text{pub} - D_\\text{ch} = v \\mid H_0) \\propto\\) height of bar at \\(x = v\\):\n\n\n\nCode\nnum_trials &lt;- 10000000\nbw &lt;- 100\nsim_df &lt;- run_sims_same_p(num_trials)\n# And plot the values of our test statistic\nnull_dist_plot &lt;- ggplot(sim_df, aes(x=test_stat)) +\n  geom_histogram(binwidth=bw) +\n  geom_density(\n    aes(y = bw * after_stat(count)),\n    linewidth = g_linewidth,\n    fill = cbPalette[1],\n    alpha = 0.333\n  ) +\n  dsan_theme() +\n  labs(\n    x = \"Test Statistic (D_pub - D_ch)\",\n    y = \"Count\",\n    title = paste0(\"(Public Dropouts - Charter Dropouts), \",format(num_trials,big.mark=' ', scientific=FALSE),\" Simulations\")\n  )\nnull_dist_plot"
  },
  {
    "objectID": "w11/slides.html#how-extreme-is-our-observed-value-relative-to-this-range",
    "href": "w11/slides.html#how-extreme-is-our-observed-value-relative-to-this-range",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "How Extreme Is Our Observed Value Relative To This Range?",
    "text": "How Extreme Is Our Observed Value Relative To This Range?\n\nSame plot, with a vertical (red) line at our observed value:\n\n\n\nCode\nlibrary(scales)\nnull_obs_plot &lt;- ggplot(sim_df, aes(x=test_stat)) +\n  geom_histogram(binwidth=bw) +\n  geom_density(\n    aes(y = (bw/3) * after_stat(count)),\n    linewidth = g_linewidth,\n    fill = cbPalette[1],\n    alpha = 0.333\n  ) +\n  geom_vline(\n    xintercept = 8500,\n    color='red',\n    linewidth = g_linewidth,\n    linetype = 'dashed'\n  ) +\n  scale_x_continuous(breaks=seq(from=5000, to=35000, by=5000), limits=c(5000, 35000)) +\n  scale_y_continuous(labels = label_number(big.mark=' ')) +\n  dsan_theme() +\n  labs(\n    x = \"Test Statistic (D_pub - D_ch)\",\n    y = \"Count\",\n    title = paste0(\"(Public Dropouts - Charter Dropouts), \",format(num_trials,big.mark=' ',scientific=FALSE),\" Simulations\")\n  )\nnull_obs_plot"
  },
  {
    "objectID": "w11/slides.html#drawing-conclusions",
    "href": "w11/slides.html#drawing-conclusions",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Drawing Conclusions",
    "text": "Drawing Conclusions\n\nCode\nmean(sim_df$test_stat)\ncdf_at_val &lt;- function(v) {\n  lt_val_df &lt;- sim_df |&gt; filter(test_stat &lt; v)\n  prop_lt &lt;- nrow(lt_val_df) / nrow(sim_df)\n  return(prop_lt)\n}\nwriteLines(format(cdf_at_val(31000), scientific=FALSE))\nwriteLines(format(cdf_at_val(30500), scientific=FALSE))\ncdf_val &lt;- cdf_at_val(30000)\ncdf_val_fmt &lt;- format(cdf_val, scientific=FALSE)\nlt30k_df &lt;- sim_df |&gt; filter(test_stat &lt; 30000)\nnum_lt30k &lt;- nrow(lt30k_df)\nnum_total &lt;- nrow(sim_df)\nnum_total_fmt &lt;- format(num_total, big.mark=',')\nwriteLines(paste0(cdf_val_fmt,\" = \",num_lt30k,\" / \",num_total_fmt))\nmin(sim_df$test_stat)\n\n\n\n\n\n\\(\\overline{T} = \\overline{D_\\text{pub} - D_\\text{ch}}\\):\n\n\n\n[1] 30911.98\n\n\n\n\\(\\Pr(D_\\text{pub} - D_\\text{ch}) &lt; 31000\\):\n\n\n\n0.6650288\n\n\n\n\\(\\Pr(D_\\text{pub} - D_\\text{ch}) &lt; 30500\\):\n\n\n\n0.0222126\n\n\n\n\n\n\\(\\Pr(D_\\text{pub} - D_\\text{ch}) &lt; 30000\\):\n\n\n\n0.0000037 = 37 / 10,000,000\n\n\n\nIn fact, the lowest value we ever saw, across 10 million simulations, was:\n\n\n\n[1] 29879"
  },
  {
    "objectID": "w11/slides.html#now-you-can-present-your-findings-in-congressional-testimony",
    "href": "w11/slides.html#now-you-can-present-your-findings-in-congressional-testimony",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "(Now You Can Present Your Findings In Congressional Testimony üòâ)",
    "text": "(Now You Can Present Your Findings In Congressional Testimony üòâ)\n\n(From The Guardian, 2016 Feb 21)"
  },
  {
    "objectID": "w11/slides.html#references",
    "href": "w11/slides.html#references",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nDSAN 5100-03 W11: Method of Moments and Bootstrap"
  },
  {
    "objectID": "w11/index.html",
    "href": "w11/index.html",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "",
    "text": "Open slides in new window ‚Üí",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#generalized-method-of-moments-gmm-estimation",
    "href": "w11/index.html#generalized-method-of-moments-gmm-estimation",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Generalized Method of Moments (GMM) Estimation",
    "text": "Generalized Method of Moments (GMM) Estimation\n\nRecall that the \\(k\\)th moment of an RV \\(X\\) is \\(\\mu_k = \\expect{X^k}\\)\ne.g., \\(\\mu_1 = \\expect{X}\\), \\(\\mu_2 = \\expect{X^2} = \\Var{X} + \\expect{X}^2\\)\nAlso recall (I rambled on about) how the MGF contains all information about a distribution. This means we can estimate distributions from data:\nDefine \\(k\\)th sample moment of \\(\\mathbf{X}_N\\) to be \\(\\widehat{\\mu}_k = \\frac{1}{N}\\sum_{i=1}^nX_i^k\\). Then the equations\n\\[\n  \\begin{align*}\n  \\mu_1(\\param{\\theta}) &= \\widehat{\\mu}_1 \\\\\n  \\mu_2(\\param{\\theta}) &= \\widehat{\\mu}_2 \\\\\n  &\\vdots \\\\\n  \\mu_N(\\param{\\theta}) &= \\widehat{\\mu}_N\n  \\end{align*}\n  \\]\nGive us a system of equations, allowing us to solve for parameters of our distribution!",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#example-bernoulli-distribution",
    "href": "w11/index.html#example-bernoulli-distribution",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Example: Bernoulli Distribution",
    "text": "Example: Bernoulli Distribution\n\n\\(\\mathbf{X}_N = \\{X_1, X_2, \\ldots, X_n\\} \\iid \\text{Bern}(\\param{p})\\)\nOnly one parameter (\\(\\param{p}\\)), so all of our data can be used solely to generate an estimate of \\(\\param{p}\\)!\n\\(\\mu_1 = \\expect{X_i^1} = p\\), \\(\\widehat{\\mu}_1 = \\frac{1}{N}\\sum_{i=1}^N X_i^1\\)\n\n\\[\n\\mu_1(p) = \\widehat{\\mu}_1 \\iff p = \\frac{1}{N}\\sum_{i=1}^N X_i^1,\n\\]\n\nSolve this system of 1 equation for \\(p\\) to obtain\n\n\\[\n\\underbrace{p^*_{\\text{GMM}}}_{\\mathclap{\\text{Found using algebra}}} = \\frac{1}{N}\\sum_{i=1}^N X_i = \\underbrace{p^*_{\\text{MLE}}}_{\\mathclap{\\text{Found using calculus}}}\n\\]",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#method-of-moments-step-by-step",
    "href": "w11/index.html#method-of-moments-step-by-step",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Method of Moments Step-By-Step",
    "text": "Method of Moments Step-By-Step\n\n\n\n\n\n\n\nSpecify Model: Define a probabilistic model for the distribution of the data.\nIdentify \\(J\\) Parameters of the distribution you‚Äôre trying to estimate: \\(\\param{\\boldsymbol\\theta} = (\\param{\\theta_1}, \\ldots, \\param{\\theta_J})\\)\nCalculate Sample Moments \\(\\widehat{\\boldsymbol\\mu} = (\\widehat{\\mu}_1, \\ldots, \\widehat{\\mu}_J)\\) from observed data.\nSet up Equations: equate population moments \\(\\mu_j\\) (expressed as functions of \\(\\param{\\boldsymbol\\theta}\\)) to their sample counterparts \\(\\widehat{\\mu}_j\\)\nSolve Equations: Solve the system of equations to obtain \\(\\boldsymbol\\theta^*_{\\text{GMM}}\\)\n\n\n\n\nüôå: Applicable to a wide range of distributions.\nüòé: No calculus\nüßê: Other estimators may be more efficient",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#intuition",
    "href": "w11/index.html#intuition",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Intuition",
    "text": "Intuition\n\n\n\n\n\n\n\n\n\nLow Variance\nHigh Variance\n\n\n\n\nLow Bias\n\n\n\n\nHigh Bias\n\n\n\n\n\n\n\nFigure adapted from Fortmann-Roe (2012), ‚ÄúUnderstanding the Bias-Variance Tradeoff‚Äù",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#math",
    "href": "w11/index.html#math",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Math",
    "text": "Math\n\nWe estimate ‚Äútrue‚Äù DGP \\(Y = f(X)\\) with model \\(\\widehat{f}(X)\\)1, and then we use \\(\\widehat{f}\\) to predict the value of \\(Y\\) for a point \\(x_0\\).\nWhat is our expected error at this point, \\(\\Err(x_0)\\)?\n\n\\[\n\\begin{align*}\n\\Err(x_0) &= \\bigexpect{\\left.(Y ‚àí \\widehat{f}(x_0))^2 \\right| X = x_0} \\\\\n&= \\sigma^2_{\\varepsilon} + \\left( \\bigexpect{\\widehat{f}(x_0)} ‚àí f(x_0) \\right)^2 + \\mathbb{E}\\left[\\widehat{f}(x_0) ‚àí \\bigexpect{\\widehat{f}(x_0)}\\right]^2 \\\\\n&= \\sigma^2_{\\varepsilon} + \\left( \\text{Bias}(\\widehat{f}(x_0)\\right)^2 + \\bigVar{\\widehat{f}(x_0)} \\\\\n&= \\text{Irreducible Error} + \\text{Bias}^2 + \\text{Variance}.\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#in-practice",
    "href": "w11/index.html#in-practice",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "In Practice",
    "text": "In Practice\n\n\n\nFigure from (tharwat_parameter_2019?)",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#efficiency",
    "href": "w11/index.html#efficiency",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Efficiency",
    "text": "Efficiency\n\nIf we were just statisticians, we could stop at bias-variance\nA third consideration, since we‚Äôre also computer scientists, is computational efficiency:\n\n\n\n\n\n\n\n Definition: Efficiency\n\n\n\nif \\(T_1\\) and \\(T_2\\) are both unbiased estimators for the same parameter \\(\\theta\\) (i.e., if \\(\\mathbb{E}[T_1] = \\theta\\) and \\(\\mathbb{E}[T_2] = \\theta\\)), then we can compute their relative efficiency as\n\\[\n\\text{RE}(T_2, T_1) = \\frac{\\Var{T_2}}{\\Var{T_1}},\n\\]\nand then we say that \\(T_2\\) is more efficient than \\(T_1\\) if\n\\[\n\\Var{T_2} &lt; \\Var{T_1} \\iff \\text{RE}(T_2, T_1) &lt; 1.\n\\]",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#bootstrap-sampling-1",
    "href": "w11/index.html#bootstrap-sampling-1",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Bootstrap Sampling",
    "text": "Bootstrap Sampling\n\nBasically a cheat code for squeezing as much information as possible out of your sample\nIntuition: Your model is robust to the extent that it still works for random subsamples of the full dataset",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#building-intuition",
    "href": "w11/index.html#building-intuition",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Building Intuition",
    "text": "Building Intuition\nConsider the following dataset:\n\nx &lt;- seq(from = 0, to = 1, by = 0.1)\nn &lt;- length(x)\neps &lt;- rnorm(n, 0, 0.04)\ny &lt;- x + eps\n# But make one big outlier\nmidpoint &lt;- ceiling((3/4)*n)\ny[midpoint] &lt;- 0\nof_data &lt;- tibble::tibble(x=x, y=y)\n# Linear model\nlin_model &lt;- lm(y ~ x)\n# But now polynomial regression\npoly_model &lt;- lm(y ~ poly(x, degree = 10, raw=TRUE))\nggplot(of_data, aes(x = x, y = y)) +\n    geom_point(size = g_pointsize / 1.5) +\n    dsan_theme(\"full\")",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#using-all-observations",
    "href": "w11/index.html#using-all-observations",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Using All Observations",
    "text": "Using All Observations\nFitting a linear model gives us:\n\nggplot(of_data, aes(x = x, y = y)) +\n    geom_point(size = g_pointsize / 1.5) +\n    geom_smooth(aes(color=\"Linear\"), method = lm, se = FALSE, show.legend=FALSE) +\n    # geom_abline(aes(intercept = 0, slope = 1, color = \"Linear\"), linewidth = 1, show.legend = FALSE) +\n    # stat_smooth(\n    #     method = \"lm\",\n    #     formula = y ~ poly(x, 10, raw = TRUE),\n    #     se = FALSE, aes(color = \"Polynomial\")\n    # ) +\n    dsan_theme(\"full\")\n\n\n\n\n\n\n\n\n\n(What‚Äôs wrong with this picture?)",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#but-is-it-robust",
    "href": "w11/index.html#but-is-it-robust",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "But is it Robust?",
    "text": "But is it Robust?\n\n## Part 1: Set up data\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tibble)\n# subsample &lt;- of_data |&gt; sample_n() sample(of_data, size=5)\ngen_subsamples &lt;- function(obs_data, num_subsamples, subsample_size) {\n  #print(subsample_size)\n  subsample_ints &lt;- c()\n  subsample_coefs &lt;- c()\n  for (i in 1:num_subsamples) {\n      cur_subsample &lt;- obs_data |&gt; sample_n(subsample_size, replace = TRUE)\n      cur_lin_model &lt;- lm(y ~ x, data = cur_subsample)\n      cur_int &lt;- cur_lin_model$coefficients[1]\n      subsample_ints &lt;- c(subsample_ints, cur_int)\n      cur_coef &lt;- cur_lin_model$coefficients[2]\n      subsample_coefs &lt;- c(subsample_coefs, cur_coef)\n  }\n  subsample_df &lt;- tibble(intercept = subsample_ints, coef = subsample_coefs)\n  return(subsample_df)\n}\nnum_subsamples &lt;- 50\nsubsample_size &lt;- floor(nrow(of_data) / 2)\nsubsample_df &lt;- gen_subsamples(of_data, num_subsamples, subsample_size)\nfull_model &lt;- lm(y ~ x, data = of_data)\nfull_int &lt;- full_model$coefficients[1]\nfull_coef &lt;- full_model$coefficients[2]\nfull_df &lt;- tibble(intercept=full_int, coef=full_coef)\nmean_df &lt;- tibble(\n    intercept=mean(subsample_df$intercept),\n    coef = mean(subsample_df$coef)\n)\n\n## Part 2: Plot\nggplot(of_data, aes(x = x, y = y)) +\n    geom_point(size=g_pointsize) +\n    # The random lines\n    geom_abline(data = subsample_df, aes(slope = coef, intercept = intercept, color='Subsample Model'), linewidth=g_linewidth, linetype=\"solid\", alpha=0.25) +\n    # The original regression line\n    geom_abline(data=full_df, aes(slope = coef, intercept = intercept, color='Full-Data Model'), linewidth=2*g_linewidth) +\n    # The average of the random lines\n    #geom_abline(data=mean_df, aes(slope = coef, intercept = intercept, color='mean'), linewidth=2*g_linewidth) +\n    labs(\n        title = paste0(\"Linear Models for \", num_subsamples, \" Subsamples of Size n = \", subsample_size),\n        color = element_blank()\n    ) +\n    dsan_theme(\"full\") +\n    theme(\n      legend.title = element_blank(),\n      legend.spacing.y = unit(0, \"mm\")\n    )",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#what-a-robust-model-looks-like",
    "href": "w11/index.html#what-a-robust-model-looks-like",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "What a Robust Model Looks Like",
    "text": "What a Robust Model Looks Like\n\nx &lt;- seq(from = 0, to = 1, by = 0.1)\nn &lt;- length(x)\neps &lt;- rnorm(n, 0, 0.04)\ny &lt;- x + eps\nrobust_data &lt;- tibble(x = x, y = y)\nrobust_sub_df &lt;- gen_subsamples(robust_data, 30, 5)\n#print(robust_sub_df)\nfull_model_robust &lt;- lm(y ~ x, data = robust_data)\nfull_int_robust &lt;- full_model_robust$coefficients[1]\nfull_coef_robust &lt;- full_model_robust$coefficients[2]\nfull_df_robust &lt;- tibble(intercept = full_int_robust, coef = full_coef_robust)\nggplot(robust_data, aes(x = x, y = y)) +\n    geom_point(size=g_pointsize) +\n    # The random lines\n    geom_abline(data = robust_sub_df, aes(slope = coef, intercept = intercept, color='Subsample Model'), linewidth=g_linewidth, linetype=\"solid\", alpha=0.25) +\n    # The original regression line\n    geom_abline(data=full_df_robust, aes(slope = coef, intercept = intercept, color='Full-Data Model'), linewidth=2*g_linewidth) +\n    # The average of the random lines\n    #geom_abline(data=mean_df, aes(slope = coef, intercept = intercept, color='mean'), linewidth=2*g_linewidth) +\n    labs(\n        title = paste0(\"Linear Models for \", num_subsamples, \" Subsamples of Size n = \", subsample_size),\n        color = element_blank()\n    ) +\n    dsan_theme(\"full\") +\n    theme(\n      legend.title = element_blank(),\n      legend.spacing.y = unit(0, \"mm\")\n    )\n\n\n\n\n\n\n\n\nHere the model is not ‚Äúmisled‚Äù by outliers",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#the-bootstrap-principle",
    "href": "w11/index.html#the-bootstrap-principle",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "The Bootstrap Principle",
    "text": "The Bootstrap Principle\n\n(This is the cheat code)2 Given a sample \\(X = \\{x_1, \\ldots, x_n\\}\\), we can ‚Äúsqueeze‚Äù more information about out of it by pretending it is the population and sampling from this ‚Äúpopulation‚Äù, with replacement\n\n\\[\n\\begin{align*}\n\\widetilde{X}_1 &= \\{x_2, x_4, x_5, x_7, x_9\\} \\\\\n\\widetilde{X}_2 &= \\{x_2, x_3, x_4, x_7, x_{10}\\} \\\\\n&~\\vdots \\\\\n\\widetilde{X}_{100} &= \\{x_3, x_3, x_7, x_8, x_8\\}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#in-pictures",
    "href": "w11/index.html#in-pictures",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "In Pictures",
    "text": "In Pictures\n\n\n\n\n\n\nNote in particular how: (a) sampling is done with replacement and (b) the original sample could therefore be replicated exactly in a bootstrap sample (here, \\(\\widetilde{X}_3\\))",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#how-well-does-it-work",
    "href": "w11/index.html#how-well-does-it-work",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "How Well Does it Work?",
    "text": "How Well Does it Work?\nAnswer: Absurdly, unreasonably well.\n\npop &lt;- rnorm(1000000, mean = 3, sd = 1)\n# Sampling 1k times\nrand_samples &lt;- replicate(\n  1000,\n  sample(pop, size=100, replace = FALSE)\n)\nsample_means &lt;- colMeans(rand_samples)\nsample_df &lt;- tibble(est = sample_means, Method = \"1000 Samples\")\n# Sampling 1 time and bootstrapping\nbs_sample &lt;- sample(pop, size = 100, replace = FALSE)\nsubsamples &lt;- replicate(1000, sample(bs_sample, size=100, replace = TRUE))\nbs_means &lt;- colMeans(subsamples)\nbs_df &lt;- tibble(est = bs_means, Method = \"Bootstrap (1 Sample)\")\nresult_df &lt;- bind_rows(sample_df, bs_df)\nsim_dnorm &lt;- function(x) dnorm(x, mean = 3, sd = 1)\nggplot(result_df, aes(x=est, fill=Method)) +\n  dsan_theme(\"full\") +\n  geom_density(alpha=0.2, linewidth=g_linewidth) +\n  geom_vline(aes(xintercept=3, linetype=\"value\"),linewidth=g_linewidth) +\n  scale_linetype_manual(\"\", values=c(\"density\"=\"solid\", \"value\"=\"dashed\"), labels=c(\"Population Mean\", \"testing\")) +\n  theme(\n    legend.title = element_blank(),\n    legend.spacing.y = unit(0, \"mm\")\n  ) +\n  labs(\n    title = \"Bootstrap vs. Multiple Samples\",\n    x = \"Sample / Subsample Means\",\n    y = \"Density\"\n  )\n\n\n\n\n\n\n\n\n\nsample_est &lt;- mean(sample_means)\nsample_str &lt;- sprintf(\"%.3f\", sample_est)\nsample_err &lt;- abs(sample_est - 3)\nsample_err_str &lt;- sprintf(\"%.3f\", sample_err)\nsample_output &lt;- paste0(\"1K samples estimate: \", sample_str, \" (abs. err: \", sample_err_str, \")\")\nbs_est &lt;- mean(bs_means)\nbs_str &lt;- sprintf(\"%.3f\", bs_est)\nbs_err &lt;- abs(bs_est - 3)\nbs_err_str &lt;- sprintf(\"%.3f\", bs_err)\nbs_output &lt;- paste0(\"Bootstrap estimate:  \", bs_str, \" (abs. err: \", bs_err_str, \")\")\nwriteLines(paste0(sample_output,\"\\n\",bs_output))\n\n1K samples estimate: 3.001 (abs. err: 0.001)\nBootstrap estimate:  3.083 (abs. err: 0.083)",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#bootstrapped-confidence-intervals",
    "href": "w11/index.html#bootstrapped-confidence-intervals",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Bootstrapped ‚ÄúConfidence‚Äù Intervals",
    "text": "Bootstrapped ‚ÄúConfidence‚Äù Intervals\n\nWe get a ‚Äúconfidence‚Äù interval for free!\n\\(\\alpha = 0.05\\)? Just take middle 95% of your bootstrapped estimates!\n\n\n\nCode\nquantile(bs_means, c(0.025, 0.975))\n\n\n    2.5%    97.5% \n2.890703 3.281231 \n\n\n\nEasily interpretable: ‚ÄúAfter repeating this process 1000 times, 95% of the results fell between 2.84 and 3.20‚Äù",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#hypothesis-testing-via-bootstrap",
    "href": "w11/index.html#hypothesis-testing-via-bootstrap",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Hypothesis Testing via Bootstrap",
    "text": "Hypothesis Testing via Bootstrap\n\nNote that our choice to estimate the mean was arbitrary!\nCould just as easily be any chosen test statistic: mean, median, variance, range, 35th percentile, etc.\nHypothesis testing requires choice for test statistic \\(t\\)\n\\(\\mathcal{H}_A\\): Group A taller than Group B\n\\(\\mathcal{H}_0\\): No difference between Group A and Group B heights\n\\(\\mathcal{H}_0 \\iff \\mu_A = \\mu_B \\iff \\underbrace{t = \\mu_A - \\mu_B}_{\\text{Test statistic for }\\mathcal{H}_0} = 0\\)\nBootstrapped test stat, therefore, is just \\(\\widehat{t} = \\widehat{\\mu}_A - \\widehat{\\mu}_B\\)!",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#veracity-of-hypothesis-is-relative-to-null-distributions",
    "href": "w11/index.html#veracity-of-hypothesis-is-relative-to-null-distributions",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Veracity of Hypothesis is Relative to Null Distributions",
    "text": "Veracity of Hypothesis is Relative to Null Distributions\n\nCounterfactual thinking: What would the world look like if the null hypothesis was true? That is, if the relationship of interest did not exist.\nSimulate the test statistic within this null world, say, \\(N = 10000\\) times.\nNow look at how likely/unlikely the observed test statistic is relative to these 10000 null-world-based test statistics.",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#real-world-example-charter-school-dropout-rates",
    "href": "w11/index.html#real-world-example-charter-school-dropout-rates",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Real World Example: Charter School Dropout Rates",
    "text": "Real World Example: Charter School Dropout Rates\n\n\n\n\n\n\n\n\n\n(New York City)\nPublic Schools\nCharter Schools\nTotal\n\n\n\n\nEnrolled Students\n\\(N_\\text{pub} \\approx 893000\\)\n\\(N_\\text{ch} \\approx 157000\\)\n\\(N = 1050649\\)\n\n\nYearly Dropouts\n\\(D_\\text{pub} \\approx 24500\\)\n\\(D_\\text{ch} \\approx 16000\\)\n\\(D \\approx 44000\\)\n\n\nYearly Dropout Rate\n\\(R_\\text{pub} \\approx 2.7\\%\\)\n\\(R_\\text{ch} \\approx 10\\%\\)\n\\(R \\approx 4.2\\%\\)\n\n\n\\(\\mathbb{E}[D \\mid R = 4.2\\%]\\)\n\\(\\mathbb{E}[D_\\text{pub}] = 37506\\)\n\\(\\mathbb{E}[D_\\text{ch}] = 6594\\)\n\\(\\mathbb{E}[\\Delta] = 30912\\)\n\n\n\n\nSo, are charter schools systematically pushing lower-performing students out?\nIt depends on how we model the decision to drop out, how we set up our null and alternative hypotheses, and what test statistic we use to evaluate these hypotheses!",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#intuition-check-why-do-we-need-to-do-all-this",
    "href": "w11/index.html#intuition-check-why-do-we-need-to-do-all-this",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Intuition Check: Why Do We Need To Do All This?",
    "text": "Intuition Check: Why Do We Need To Do All This?\n\nDoesn‚Äôt \\(R_\\text{ch} &gt; R_\\text{pub} \\implies\\) charter schools guilty?\nRemember our fair vs.¬†biased coins examples\nLet‚Äôs simulate a fair coin: \\(\\param{p} = \\Pr(\\textsf{H}) = 0.5\\)\n\n\n\nCode\nset.seed(5100)\nlibrary(Rlab)\nnum_flips &lt;- 10\np &lt;- 0.5\ncoin_obs &lt;- rbern(num_flips, p)\ncoin_str &lt;- paste0(coin_obs, collapse=' ')\nnum_heads &lt;- sum(coin_obs)\nwriteLines(paste0(coin_str,\" =&gt; \",num_heads,\" heads\"))\n\n\n1 0 0 0 1 0 0 0 0 1 =&gt; 3 heads\n\n\n\nSeeing 3 heads \\(~\\nimplies \\Pr(\\textsf{H}) = 0.3\\)!",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#so-how-can-we-determine-whether-the-coin-is-fair",
    "href": "w11/index.html#so-how-can-we-determine-whether-the-coin-is-fair",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "So How Can We Determine Whether The Coin Is Fair?",
    "text": "So How Can We Determine Whether The Coin Is Fair?\nlibrary(tidyverse)\nnum_replications &lt;- 1000\ncoin_seqs &lt;- replicate(num_replications, rbern(num_flips, p))\nheads_per_seq &lt;- colSums(coin_seqs)\nheads_df &lt;- tibble(num_heads = heads_per_seq)\nhighlight_3 &lt;- c(rep(\"grey\",2), rep(cbPalette[1],1), rep(\"grey\",7))\nggplot(heads_df, aes(x=factor(num_heads))) +\n  geom_histogram(stat='count', fill=highlight_3) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title=paste0(\"Results From N=\",num_replications,\" 10-Coin-Flip Trials\")\n  )\n\n\n\n\nWe have to generate many sequences of coin flips, then look at the distribution of the number of heads in each sequence ‚Üí\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nthree_df &lt;- heads_df |&gt; filter(num_heads == 3)\nnrow(three_df) / nrow(heads_df)\n\n\n\n\n\nNow we can quantify exactly how ‚Äúfishy‚Äù it was to get 3 heads: if the coin was fair, this would happen about 10.7% of the time:\n\n\n\n\n[1] 0.107",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#how-fishy-is-too-fishy",
    "href": "w11/index.html#how-fishy-is-too-fishy",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "How Fishy Is Too Fishy?",
    "text": "How Fishy Is Too Fishy?\n\nThis means, given a context within which we‚Äôre analyzing the data, we can construct a fishiness threshold \\(T\\): then, if \\(\\Pr(\\text{observed outcome}) &lt; T%\\), we can say coin is not fair\nSome journals arbitrarily choose 5% (95% confidence)\nI prefer \\(T = 11\\%\\) (89% confidence), for same reason as anthropologist/statistician Richard McElreath:\n\n\n89 is a prime number, so if someone asks you to justify it, you can stare at them meaningfully and incant, ‚Äúwhy, because it‚Äôs prime, of course!‚Äù That‚Äôs no worse than the conventional justification for 95%. (mcelreath_statistical_2020?)",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#our-model-data-generating-process",
    "href": "w11/index.html#our-model-data-generating-process",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Our Model (Data-Generating Process)",
    "text": "Our Model (Data-Generating Process)\n\nWhat process gives rise to these dropout rates?\nStraightforward model (which we can extend / complicate to include additional factors as needed):\n\nStudent \\(i\\) flips a coin with \\(\\Pr(\\textsf{H}) = \\param{p}\\): if \\(\\textsf{H}\\) student drops out, if \\(\\textsf{T}\\) they stay enrolled\nLet \\(X_i = 1\\) if student \\(i\\) drops out, \\(0\\) otherwise.\n\nThen for school \\(j\\) with \\(N_j\\) students, \\(D_j = \\sum_{i=1}^{N_j}X_i\\) = number of dropouts. Since sum of Bernoulli RVs has Binomial distribution, \\(D_j \\sim \\text{Binom}(N_j, p_j)\\)",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#formulatingsimulating-the-null-hypothesis",
    "href": "w11/index.html#formulatingsimulating-the-null-hypothesis",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Formulating+Simulating the Null Hypothesis",
    "text": "Formulating+Simulating the Null Hypothesis\n\n\\(H_0: p_\\text{ch} = p_\\text{pub} \\iff p_\\text{ch} - p_\\text{pub} = 0\\). There is no difference between the individual-student dropout rate at public schools and the individual-student dropout rate at charter schools\n\\(H_A: p_\\text{pub} &lt; p_\\text{ch} \\iff p_\\text{pub} - p_\\text{ch} &lt; 0\\). There is an underlying difference between the rates at which charter school students and public school students choose to drop out. In this case, the former is greater than the latter\nSo, to simulate null-world, we will simulate public school population and charter school population with the same individual-student dropout rate: \\(\\param{p_\\text{pub}} = \\param{p_\\text{ch}} = \\param{p}\\) then check how often the school-level dropouts \\(D_\\text{pub}\\) and \\(D_\\text{ch}\\) differ by \\(24500 - 16000 = 8500\\) or more",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#coding-the-simulation",
    "href": "w11/index.html#coding-the-simulation",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Coding the Simulation",
    "text": "Coding the Simulation\n\nSimulating a few public-charter pairs:\n\n\n# The true population sizes\nN_ch &lt;- 157000\nN_pub &lt;- 893000\n# We'll use a function to compute num_sims simulations of a school with N_j\n# students, each with dropout probability p\nsimulate_dropouts &lt;- function(num_sims, N_j, p) {\n  return(rbinom(num_sims, N_j, p))\n}\n# We're simulating \"null world\" by generating data\n# on the basis of the assumption p_pub_sim = p_ch_sim\n# So we call the function with the same p for both\n# simulated schools. In this case, we'll use the\n# *overall average* dropout rate across all schools:\n# 4.2% = 0.042\np_sim &lt;- 0.042\n# But we'll write a general function for simulating\n# pairs of schools, whether or not they have the same\n# Pr(dropout):\nsimulate_pair &lt;- function(num_sims, p_ch, p_pub) {\n  D_ch &lt;- simulate_dropouts(num_sims, N_ch, p_ch)\n  D_pub &lt;- simulate_dropouts(num_sims, N_pub, p_pub)\n  sim_df &lt;- tibble(D_ch=D_ch, D_pub=D_pub)\n  return(sim_df)\n}\n# Run the simulation, with the *same* p parameter\n# for both our simulated schools:\nrun_sims_same_p &lt;- function(num_sims, printResults=FALSE) {\n  sim_df &lt;- simulate_pair(num_sims, p_sim, p_sim)\n  # And from these two counts, we can compute the\n  # *test statistic*: in this case, the difference\n  sim_df &lt;- sim_df |&gt; mutate(\n    test_stat = D_pub - D_ch\n  )\n  return(sim_df)\n}\nsmall_sim_df &lt;- run_sims_same_p(3)\nsmall_sim_df\n\n\n\n\n\nD_ch\nD_pub\ntest_stat\n\n\n\n\n6528\n37395\n30867\n\n\n6606\n37287\n30681\n\n\n6607\n37469\n30862",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#generating-the-null-distribution",
    "href": "w11/index.html#generating-the-null-distribution",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Generating The Null Distribution",
    "text": "Generating The Null Distribution\n\nThis is the range of values we might expect to see (under our model!) if two schools had the same underlying dropout probabilities\n\\(\\Pr(D_\\text{pub} - D_\\text{ch} = v \\mid H_0) \\propto\\) height of bar at \\(x = v\\):\n\n\nnum_trials &lt;- 10000000\nbw &lt;- 100\nsim_df &lt;- run_sims_same_p(num_trials)\n# And plot the values of our test statistic\nnull_dist_plot &lt;- ggplot(sim_df, aes(x=test_stat)) +\n  geom_histogram(binwidth=bw) +\n  geom_density(\n    aes(y = bw * after_stat(count)),\n    linewidth = g_linewidth,\n    fill = cbPalette[1],\n    alpha = 0.333\n  ) +\n  dsan_theme() +\n  labs(\n    x = \"Test Statistic (D_pub - D_ch)\",\n    y = \"Count\",\n    title = paste0(\"(Public Dropouts - Charter Dropouts), \",format(num_trials,big.mark=' ', scientific=FALSE),\" Simulations\")\n  )\nnull_dist_plot",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#how-extreme-is-our-observed-value-relative-to-this-range",
    "href": "w11/index.html#how-extreme-is-our-observed-value-relative-to-this-range",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "How Extreme Is Our Observed Value Relative To This Range?",
    "text": "How Extreme Is Our Observed Value Relative To This Range?\n\nSame plot, with a vertical (red) line at our observed value:\n\n\nlibrary(scales)\nnull_obs_plot &lt;- ggplot(sim_df, aes(x=test_stat)) +\n  geom_histogram(binwidth=bw) +\n  geom_density(\n    aes(y = (bw/3) * after_stat(count)),\n    linewidth = g_linewidth,\n    fill = cbPalette[1],\n    alpha = 0.333\n  ) +\n  geom_vline(\n    xintercept = 8500,\n    color='red',\n    linewidth = g_linewidth,\n    linetype = 'dashed'\n  ) +\n  scale_x_continuous(breaks=seq(from=5000, to=35000, by=5000), limits=c(5000, 35000)) +\n  scale_y_continuous(labels = label_number(big.mark=' ')) +\n  dsan_theme() +\n  labs(\n    x = \"Test Statistic (D_pub - D_ch)\",\n    y = \"Count\",\n    title = paste0(\"(Public Dropouts - Charter Dropouts), \",format(num_trials,big.mark=' ',scientific=FALSE),\" Simulations\")\n  )\nnull_obs_plot",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#drawing-conclusions",
    "href": "w11/index.html#drawing-conclusions",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Drawing Conclusions",
    "text": "Drawing Conclusions\nmean(sim_df$test_stat)\ncdf_at_val &lt;- function(v) {\n  lt_val_df &lt;- sim_df |&gt; filter(test_stat &lt; v)\n  prop_lt &lt;- nrow(lt_val_df) / nrow(sim_df)\n  return(prop_lt)\n}\nwriteLines(format(cdf_at_val(31000), scientific=FALSE))\nwriteLines(format(cdf_at_val(30500), scientific=FALSE))\ncdf_val &lt;- cdf_at_val(30000)\ncdf_val_fmt &lt;- format(cdf_val, scientific=FALSE)\nlt30k_df &lt;- sim_df |&gt; filter(test_stat &lt; 30000)\nnum_lt30k &lt;- nrow(lt30k_df)\nnum_total &lt;- nrow(sim_df)\nnum_total_fmt &lt;- format(num_total, big.mark=',')\nwriteLines(paste0(cdf_val_fmt,\" = \",num_lt30k,\" / \",num_total_fmt))\nmin(sim_df$test_stat)\n\n\n\n\n\\(\\overline{T} = \\overline{D_\\text{pub} - D_\\text{ch}}\\):\n\n\n\n[1] 30911.98\n\n\n\n\\(\\Pr(D_\\text{pub} - D_\\text{ch}) &lt; 31000\\):\n\n\n\n0.6650288\n\n\n\n\\(\\Pr(D_\\text{pub} - D_\\text{ch}) &lt; 30500\\):\n\n\n\n0.0222126\n\n\n\n\n\n\\(\\Pr(D_\\text{pub} - D_\\text{ch}) &lt; 30000\\):\n\n\n\n0.0000037 = 37 / 10,000,000\n\n\n\nIn fact, the lowest value we ever saw, across 10 million simulations, was:\n\n\n\n[1] 29879",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#now-you-can-present-your-findings-in-congressional-testimony",
    "href": "w11/index.html#now-you-can-present-your-findings-in-congressional-testimony",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "(Now You Can Present Your Findings In Congressional Testimony üòâ)",
    "text": "(Now You Can Present Your Findings In Congressional Testimony üòâ)\n\n\n\n(From The Guardian, 2016 Feb 21)",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#references",
    "href": "w11/index.html#references",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "w11/index.html#footnotes",
    "href": "w11/index.html#footnotes",
    "title": "Week 11: Method of Moments and Bootstrap",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt‚Äôs even more complicated, since we don‚Äôt even know whether the features \\(X\\) we‚Äôve chosen are actually the features in the world that causally affect \\(Y\\), but that‚Äôs for later classes‚Ä¶ Or see (hastie_elements_2013?)!‚Ü©Ô∏é\nThe fact that this ‚Äújust works‚Äù is similar to the surprising efficacy of the Na√Øve Bayes model (see DSAN 5000!)‚Ü©Ô∏é",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "writeups/conditional-expectation/index.html",
    "href": "writeups/conditional-expectation/index.html",
    "title": "Deriving Conditional Expectation from Conditional Probability + Expectation",
    "section": "",
    "text": "Code\nsource(\"../../dsan-globals/_globals.r\")\nProblem 2d on your Lab 5 Assignment, which asks you to:\nis a step up in difficulty relative to parts 2a through 2c, since it requires ‚Äúfusing together‚Äù two pieces of knowledge you have, about two topics that were taught separately ‚Äì conditional probability on the one hand and expected value on the other ‚Äì in order to derive a solution. So, I hope this writeup can help steer you in the right direction, by drawing these two separate topics closer together, while also refreshing your memory about important aspects of both!"
  },
  {
    "objectID": "writeups/conditional-expectation/index.html#piece-1-conditional-probability",
    "href": "writeups/conditional-expectation/index.html#piece-1-conditional-probability",
    "title": "Deriving Conditional Expectation from Conditional Probability + Expectation",
    "section": "Piece 1: Conditional Probability",
    "text": "Piece 1: Conditional Probability\nLong story short, the main lesson I hope I was able to convey when we first encountered conditional probability is that all probabilities are conditional probabilities!\nIt was our first encounter with a new type of probability distribution, beyond just a ‚Äústandard‚Äù single-variable distribution, so I drew a diagram on the board that looked something like:\n\n\n\n\n\nThe real point of drawing this diagram (for now!) was just to ‚Äúcollapse‚Äù what may seem like two different formulas down into one: Expressions for probability distributions like \\(\\Pr(Y = v_Y)\\) are really already expressions for conditional distributions, since we can always rewrite a probabilistic statement about a single event \\(E\\) as a conditional statement:\n\\[\n\\Pr(E) = \\Pr(E \\mid \\Omega) = \\frac{\\Pr(E, \\Omega)}{\\Pr(\\Omega)},\n\\]\nwhere \\(\\Omega\\) is a special ‚Äúevent‚Äù that literally just means ‚Äúanything at all occurs‚Äù, so that the denominator of this fraction is exactly \\(1\\) and the numerator is exactly \\(\\Pr(E)\\) (‚Äúthe probability that something occurs and \\(E\\) occurs‚Äù).\nMoving from the case of generic events like \\(E\\) to events involving Random Variables, consider e.g.¬†\\(X = v_X\\), the event that the Random Variable \\(X\\) takes on the particular value \\(v_X\\). Since the ‚Äúuniverse‚Äù of possible values that \\(X\\) could take on is represented by its support \\(\\mathcal{R}_X\\), we can derive a similar kind of conditional statement from any non-conditional statement about \\(X\\):\n\\[\n\\Pr(X = v_X) = \\Pr(X = v_X \\mid X \\in \\mathcal{R}_X) = \\frac{\\Pr(X = v_X, X \\in \\mathcal{R}_X)}{\\Pr(X \\in \\mathcal{R}_X)},\n\\]\nwhere again the denominator of the fraction is exactly \\(1\\) (‚Äúthe probability that \\(X\\) takes on one of the possible values that \\(X\\) can take on‚Äù), and the numerator is exactly \\(\\Pr(X = v_X)\\). So, when we are working with probabilities involving Random Variables, we are again always working with conditional probabilities. We don‚Äôt need to carry around separate non-conditional and conditional formulas for RVs in our heads!\nIn the context of this problem, the takeaway is: if we already know about expectation (see: next section), we may be able to think through and derive a conditional form for it, therefore deriving precisely the ‚Äúconditional expectation‚Äù that this problem is asking for, even if we haven‚Äôt encountered the expected value in conditional form before.\nBefore turning to the expected value, though, let‚Äôs write out one more atomic-conditional ‚Äúlinkage‚Äù here, this time for continuous distributions, where we therefore have to work with probability densities rather than probabilities themselves. As long as we keep in mind the caveat that probability density values are not probabilities themselves (but that they can be integrated to produce probability values), we can define a conditional probability density function for e.g.¬†the random variable \\(Y \\mid X\\) as\n\\[\nf_{Y \\mid X}(y \\mid x) = \\frac{f_{Y,X}(y,x)}{f_X(x)}.\n\\]\nWith this in hand, we can then (repetitively keeping in mind that we need to use integration over regions to generate probability values from probability density functions) see the connection between this conditional density and non-conditional density via our final identity showing how all probability density functions are conditional probability density functions:\n\\[\nf_{Y}(y) = f_{Y \\mid X}(y \\mid \\mathcal{R}_x) = \\int_{-\\infty}^{\\infty}f_{Y \\mid X}(y \\mid x)\\mathrm{d}x\n\\]\nWhere we only had to abuse notation a little bit here at the very end by letting \\(\\mathcal{R}_X\\) stand in for the longer ‚Äúany value at all in \\(X\\)‚Äôs support‚Äù, i.e., ‚Äúany value from \\(-\\infty\\) to \\(\\infty\\)‚Äù."
  },
  {
    "objectID": "writeups/conditional-expectation/index.html#piece-2-expected-value",
    "href": "writeups/conditional-expectation/index.html#piece-2-expected-value",
    "title": "Deriving Conditional Expectation from Conditional Probability + Expectation",
    "section": "Piece 2: Expected Value",
    "text": "Piece 2: Expected Value\nWhile the guiding principle behind the previous section was that all probabilities are conditional probabilities, here our guiding principle is that expected values are just weighted averages. Specifically, \\(\\mathbb{E}[X]\\) is a weighted average where:\n\nThe things being averaged are the possible values \\(v_X\\) that \\(X\\) can take on, that is, \\(v_X \\in \\mathcal{R}_X\\), and\nThe weight for each value \\(v_X\\) is the probability \\(\\Pr(X = v_X)\\) that \\(X\\) in fact takes on that value.\n\nSo, in discrete world (the world where the set of possible values for \\(X\\), \\(\\mathcal{R}_X\\), is countable), this can be written out symbolically as\n\\[\n\\mathbb{E}[X] = \\sum_{v_X \\in \\mathcal{R}_X}{\\color{#e69f00}v_X}{\\color{#56b4e9}\\Pr(X = v_X)}\n\\]\nAnd in continuous world1, it can be written out symbolically as\n\\[\n\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty}{\\color{#e69f00}v_X}{\\color{#56b4e9}f_X(v_X)}.\n\\]"
  },
  {
    "objectID": "writeups/conditional-expectation/index.html#snapping-the-pieces-together",
    "href": "writeups/conditional-expectation/index.html#snapping-the-pieces-together",
    "title": "Deriving Conditional Expectation from Conditional Probability + Expectation",
    "section": "Snapping the Pieces Together",
    "text": "Snapping the Pieces Together\nNow that we‚Äôve looked at each piece individually, let‚Äôs think about how we might be able to ‚Äúfuse‚Äù them together into an expression for a conditional expectation \\(\\mathbb{E}[Y \\mid X]\\).\nFirst, since we‚Äôre firmly within continuous world in this Lab, I won‚Äôt bore you with the discrete analogue first (though I think it‚Äôs helpful to think through!). Instead, let‚Äôs look at the definition we have for the expected value \\(\\mathbb{E}[Y]\\):\n\\[\n\\mathbb{E}[Y] = \\int_{-\\infty}^{\\infty}yf_Y(y)\\mathrm{d}y\n\\]\nGiven that \\(\\mathrm{d}y\\) is sort of just‚Ä¶ notation that we carry over from calculus2, the two relevant pieces of this expression that we can focus on are \\(y\\) (our variable of integration) and \\(f_Y(y)\\) (the pdf of \\(Y\\) evaluated at the point \\(y\\)).\nSo, since we eventually want \\(\\mathbb{E}[Y \\mid X]\\)‚Ä¶ let‚Äôs see what the previous expression could look like if we literally just clunkily ‚Äúplugged in‚Äù \\(Y \\mid X\\) everywhere we see \\(Y\\), and \\(y \\mid x\\) everywhere we see \\(y\\). We‚Äôll call this our ‚Äúfirst draft‚Äù for a definition of conditional expectation:\n\\[\n\\mathbb{E}[Y \\mid X] = \\int_{\\infty}^{\\infty}(y \\mid x)f_{Y \\mid X}(y \\mid x)\\mathrm{d}(y \\mid x)\n\\]\nIf we stare at this for a bit and try to think through what each piece might mean, my hope is that you can start to get a vague sense of the following two observations:\n\nThe plugging-in was ‚Äúsuccessful‚Äù for \\(f_{Y \\mid X}(y \\mid x)\\), in the sense that this expression is something we do understand and have seen before: it‚Äôs the conditional probability that our random variable \\(Y\\) takes on the specific value \\(y\\) within a world where our random variable \\(X\\) has taken on the specific value \\(x\\).\nThe \\((y \\mid x)\\) term, on the other hand, doesn‚Äôt seem very well-defined: \\(y\\) and \\(x\\) are non-random values like \\(3\\) or \\(\\pi\\), and here they‚Äôre not being plugged into a probability measure like \\(\\Pr(X = x)\\) or a density like \\(f_{Y \\mid X}(y \\mid x)\\).\n\nSo, diving into the second observation: What would \\((y \\mid x)\\) even mean? Semantically, we know that the conditional bar \\(|\\) in the middle means ‚Äúgiven‚Äù, so that if we read \\((y \\mid x)\\) out it means something like ‚ÄúThe value of \\(y\\) given the value of \\(x\\)‚Äù. But, to drive the point home: knowing the value of \\(x\\) here is totally irrelevant to the value of \\(y\\), since there‚Äôs no randomness or probabilistic uncertainty involved in determining the value of \\(y\\) at all!\nIt‚Äôs crucial to distinguish between \\(Y\\) and \\(y\\) here to make sense of this, at least in my brain3. Here \\(y\\) is not a probabilistic Random Variable, it‚Äôs an algebraic variable which exists in the expression solely as a ‚Äústand-in‚Äù for particular values (ranging from \\(-\\infty\\) to \\(\\infty\\)) that we‚Äôd have to plug in to evaluate the integral.\nI know that way of thinking about it might not click with everyone, but I hope it does click for some! And if it does, then I hope it might have also ‚Äúclicked‚Äù ideas in your head with respect to how we could ‚Äúhandle‚Äù the \\((y \\mid x)\\) here:\n\n\\((y \\mid x)\\) represents ‚Äúthe value of \\(y\\) given the value of \\(x\\)‚Äù. But‚Ä¶\nThe value of \\(y\\) is not affected by the value of \\(x\\). So‚Ä¶\n\\((y \\mid x)\\) is equivalent to just \\(y\\)!\n\nIf you‚Äôve followed all of the above, then we can apply this conclusion to our ‚Äúfirst draft‚Äù from above, and simplify it to just\n\\[\n\\mathbb{E}[Y \\mid X] = \\int_{-\\infty}^{\\infty}yf_{Y \\mid X}(y \\mid x)\\mathrm{d}y\n\\]\nAnd indeed, we did it, we‚Äôve arrived at the definition of conditional expectation, for continuous random variables \\(X\\) and \\(Y\\)!\nIf it helps, we could also rewrite this using our definition of conditional probability density,\n\\[\nf_{Y \\mid X}(y \\mid x) = \\frac{f_{Y,X}(y,x)}{f_X(x)},\n\\]\nto derive the following alternative forms (which are also given in the above Wikipedia article):\n\\[\n\\mathbb{E}[Y \\mid X] = \\int_{-\\infty}^{\\infty}y\\frac{f_{Y,X}(y,x)}{f_X(x)}\\mathrm{d}y = \\frac{1}{f_X(x)}\\int_{-\\infty}^{\\infty}yf_{Y,X}(y,x)\\mathrm{d}y.\n\\]"
  },
  {
    "objectID": "writeups/conditional-expectation/index.html#footnotes",
    "href": "writeups/conditional-expectation/index.html#footnotes",
    "title": "Deriving Conditional Expectation from Conditional Probability + Expectation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhere, remember, we‚Äôre only able to utilize the probability density function \\(f_X(x)\\) in place of the probability mass function \\(p_X(x) = \\Pr(X)\\) because we‚Äôre integrating it over a range of values. \\(f_X(v_X)\\) is not itself a probability, it is a function we use to generate valid probability values between \\(0\\) and \\(1\\) via integration.‚Ü©Ô∏é\nSpecifically, notation that we carry over from Riemann sums, which ensures that our integrand represents a product: Looking at \\(\\int_{-\\infty}^{\\infty}xf(x)\\mathrm{d}x\\), for example, the integrand represents the product of (a) the ‚Äúheight‚Äù of \\(xf(x)\\) and (b) the (infinitesimally-small) ‚Äúwidths‚Äù \\(\\mathrm{d}x\\). And, as we know, multiplying a width by a height gives us an area! Therefore, when we sum each of these tiny areas from \\(-\\infty\\) to \\(\\infty\\), we end up with the total area under the curve formed by \\(xf(x)\\).‚Ü©Ô∏é\nHopefully, if you‚Äôve gotten this far, you can start to understand why I hate the \\(X = x\\) notation, and why I always try to use \\(X = v_X\\) and \\(Y = v_Y\\) instead‚Ä¶‚Ü©Ô∏é"
  },
  {
    "objectID": "writeups/index.html",
    "href": "writeups/index.html",
    "title": "Extra Writeups",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nWeek\n\n\nAssignment\n\n\n\n\n\n\nMathematical Optimization\n\n\n13\n\n\nQuiz 4\n\n\n\n\nLab 6 Clarifications\n\n\n7\n\n\nLab 6\n\n\n\n\nDeriving a pdf from Scratch\n\n\n6\n\n\nLab 5\n\n\n\n\nMarginal Distributions and ‚ÄúMarginalizing Out‚Äù A Variable\n\n\n6\n\n\nLab 5\n\n\n\n\nContinuous Probability and the Order of Integration\n\n\n6\n\n\nLab 5\n\n\n\n\nDeriving Conditional Expectation from Conditional Probability + Expectation\n\n\n6\n\n\nLab 5\n\n\n\n\nSimulating Sample Spaces With Tibbles\n\n\n5\n\n\nQuiz 1\n\n\n\n\nTwo Ways to Compute Probabilities in R/Python\n\n\n3\n\n\nLabs 1-3\n\n\n\n\nTwo Ways of Sampling from a Data Frame\n\n\n3\n\n\nLabs 1-3\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Extra Writeups"
    ]
  },
  {
    "objectID": "writeups/computing-probabilities/index.html",
    "href": "writeups/computing-probabilities/index.html",
    "title": "Two Ways to Compute Probabilities in R/Python",
    "section": "",
    "text": "# For slides\nlibrary(ggplot2)\ncbPalette &lt;- c(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\noptions(ggplot2.discrete.colour = cbPalette)\n# Theme generator, for given sizes\ndsan_theme &lt;- function(plot_type = \"full\") {\n    if (plot_type == \"full\") {\n        custom_base_size &lt;- 16\n    } else if (plot_type == \"half\") {\n        custom_base_size &lt;- 22\n    } else if (plot_type == \"quarter\") {\n        custom_base_size &lt;- 28\n    } else {\n        # plot_type == \"col\"\n        custom_base_size &lt;- 22\n    }\n    theme &lt;- theme_classic(base_size = custom_base_size) +\n        theme(\n            plot.title = element_text(hjust = 0.5),\n            plot.subtitle = element_text(hjust = 0.5),\n            legend.title = element_text(hjust = 0.5),\n            legend.box.background = element_rect(colour = \"black\")\n        )\n    return(theme)\n}\n\nknitr::opts_chunk$set(fig.align = \"center\")\ng_pointsize &lt;- 5\ng_linesize &lt;- 1\n# Technically it should always be linewidth\ng_linewidth &lt;- 1\ng_textsize &lt;- 14\n\nremove_legend_title &lt;- function() {\n    return(theme(\n        legend.title = element_blank(),\n        legend.spacing.y = unit(0, \"mm\")\n    ))\n}\nIn several of the assignments for DSAN5100, we ask you to ‚Äúcompute‚Äù a probability. This can be ambiguous, as we‚Äôve already learned several different ways to compute probabilities, so here I will try to distinguish between two different approaches to computing a probability using a computer. Hopefully it will help you in general when asking us questions, and will help us clarify which of these approaches we are looking for when we ask you to compute a probability in future assignments."
  },
  {
    "objectID": "writeups/computing-probabilities/index.html#approach-1-using-r-like-a-fancy-spreadsheet-program",
    "href": "writeups/computing-probabilities/index.html#approach-1-using-r-like-a-fancy-spreadsheet-program",
    "title": "Two Ways to Compute Probabilities in R/Python",
    "section": "Approach 1: Using R Like a Fancy Spreadsheet Program",
    "text": "Approach 1: Using R Like a Fancy Spreadsheet Program\nThis approach implicitly assumes the na√Øve definition of probability, from early on in the course:\n\n\n\n\n\n\n Na√Øve Definition of Probability\n\n\n\nGiven a sample space \\(S\\), and an event \\(E \\subset S\\),\n\\[\n\\Pr(\\underbrace{E}_{\\text{event}}) = \\frac{\\text{\\# Favorable Outcomes}}{\\text{\\# Possible Outcomes}} = \\frac{|E|}{|S|}\n\\]\n\n\nIt follows the following logic:\n\nIf we want to use our computer to compute a probability, and if the probability space we‚Äôre working in is finite, then\n\nWe can represent the entire sample space \\(\\Omega\\) as a big tibble, and\n\n\nWe can represent the event of interest \\(E\\) as a subset of this tibble1.\n\n\nAs a super simple example that hopefully illustrates this approach, consider the case of rolling a single die, so that the sample space is\n\\[\n\\Omega = \\{1, 2, 3, 4, 5, 6\\}\n\\]\nand then consider the event of interest \\(E\\) to be ‚Äúthe outcome of the roll is even‚Äù, so that\n\\[\nE = \\{2, 4, 6\\} \\subseteq \\Omega\n\\]\nIn this approach we could construct a tibble representing the entire sample space \\(\\Omega\\) like\n\nlibrary(tibble)\nsample_space_df &lt;- tibble(outcome=seq(1,6))\nsample_space_df\n\n\n\n\n\noutcome\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n\n\n\n\nThen we could extract a subset of this tibble corresponding to the event \\(E\\) by selecting only those rows whose outcome value is even2:\n\nlibrary(dplyr)\nevent_df &lt;- sample_space_df %&gt;% filter(outcome %% 2 == 0)\nevent_df\n\n\n\n\n\noutcome\n\n\n\n\n2\n\n\n4\n\n\n6\n\n\n\n\n\n\nThese two tibbles together allow us to compute a probability using the na√Øve definition:\n\nnrow(event_df) / nrow(sample_space_df)\n\n[1] 0.5\n\n\nIt‚Äôs a bit silly to use this approach to study dice, since we can figure out the probabilistic properties of dice pretty intuitively (see below), but this approach becomes more useful when we think about problems focusing on data analysis.\nFor example, we might give you a problem that says\nLoad this dataset of country/region GDP data, and keep just the observations for the year 2010. What is the probability that an entity in this dataset had a GDP lower than $10 billion, and a country code containing the letter Z, in this year?\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\ngdp_df &lt;- read_csv(\"https://gist.githubusercontent.com/jpowerj/fecd437b96d0954893de727383f2eaf2/raw/fec58507f7095cb8341b229d6eb74ce53232d663/gdp_2010.csv\")\nbelow_10b_df &lt;- gdp_df %&gt;% filter(value &lt; 10000000000)\nbelow_10b_z_df &lt;- below_10b_df %&gt;% filter(str_detect(code, 'Z'))\nbelow_10b_z_df\n\n\n\n\n\nname\ncode\nyear\nvalue\n\n\n\n\nBelize\nBLZ\n2010\n1397113450\n\n\nKyrgyz Republic\nKGZ\n2010\n4794357795\n\n\nSwaziland\nSWZ\n2010\n4438778424\n\n\n\n\n\n\nSo that now we could compute the probability of a country having these properties:\n\np_event &lt;- nrow(below_10b_z_df) / nrow(gdp_df)\np_event\n\n[1] 0.01470588\n\n\nSo, this approach works well when we‚Äôre dealing with nice, simple, finite sample-spacing and outcomes which are easily definable using and or or (for example), but we won‚Äôt be able to use it to handle fancier cases like continuous probability distributions."
  },
  {
    "objectID": "writeups/computing-probabilities/index.html#approach-2-using-r-like-a-fancy-calculator",
    "href": "writeups/computing-probabilities/index.html#approach-2-using-r-like-a-fancy-calculator",
    "title": "Two Ways to Compute Probabilities in R/Python",
    "section": "Approach 2: Using R Like a Fancy Calculator",
    "text": "Approach 2: Using R Like a Fancy Calculator\nIn this approach, we basically just use R (or Python, or whatever else) as a glorified calculator. We take the hard part‚Äîreasoning about what the sample space might look like, for example, or whether events are independent‚Äîand do it in our heads, then use R to figure out what happens when we multiply/add/divide the things we already figured out.\nContinuing the dice example, for instance, this approach would go something like: we ask you\n\nWhat is the probability that you observe a roll greater than 4, followed by a roll less than or equal to 4, followed by a roll greater than 4?\n\nand you reason through this like,\n\nI already know that there are 6 outcomes, and that they‚Äôre all equally likely, so that the probability of seeing a particular outcome in \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\) is always \\(\\frac{1}{6}\\). Therefore I can define an event \\(E_&gt;\\) representing the event of observing an outcome greater than 4, and another event \\(E_\\leq\\) of observing an outcome less than or equal to 4. I know that\n\n\n\nSince the possible outcomes greater than 4 are 5 and 6, my event \\(E_&gt; = \\{5, 6\\}\\), and since \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\), I can compute the probability of \\(E_&gt;\\) as \\[\n\\Pr(E_&gt;) = \\frac{|E_&gt;|}{|\\Omega|} = \\frac{|\\{5, 6\\}|}{6} = \\frac{1}{3}\n\\]\n\n\n\n\nSince the possible outcomes less than or equal to 4 are 1, 2, 3, and 4, my event \\(E_\\leq = \\{1, 2, 3, 4\\}\\), so I can compute the probability of \\(E_\\leq\\) as \\[\n\\Pr(E_\\leq) = \\frac{|E_\\leq|}{|\\Omega|} = \\frac{|\\{1, 2, 3, 4|}{6} = \\frac{2}{3}\n\\]\n\n\n\nAnd now I can use R with these probabilities I computed in my head to derive the probabilities of them occurring in a particular sequence:\n\n\n# Encode probabilities of my two events\np_greater &lt;- 1/3\np_less_or_equal &lt;- 2/3\n# Use them to compute the probabilities of sequences\np_sequence &lt;- p_greater * p_less_or_equal * p_greater\np_sequence\n\n[1] 0.07407407\n\n\nThis approach may seem boring at first, since again we could have done this just on a calculator, but it becomes interesting when we ask you to vary the numbers to see what happens to the resulting probabilities.\nFor example, if you wrote the above code for some problem, then in the next problem we could say ‚ÄúIt turns out the person providing you with the dice was cheating! They rigged it so that there‚Äôs actually a 99% chance of getting a number greater than 4! Go back and compute the probability of this sequence but using the rigged die‚Äù\nAnd then you could just change the first line of your code, and re-run the whole thing, to obtain the new probability:\n\np_greater &lt;- 0.99\np_less_or_equal &lt;- 0.01\np_sequence &lt;- p_greater * p_less_or_equal * p_greater\np_sequence\n\n[1] 0.009801\n\n\nFinally, we might then ask you something like:\n‚ÄúYour friend actually invented a machine that can generated any rigged die at all, so that the probability of rolling a number greater than 4 is whatever they want it to be.\nYou are worried because you always play a game with this friend where you win if you roll something greater than 4, then less than or equal to 4, then greater than 4. So you want to see how the friend‚Äôs rigging machine could affect your likelihood of winning.\nWrite a function that computes your likelihood of winning (i.e., your likelihood of getting this sequence of three rolls), for any die with any probability of producing an outcome greater than 4.\nIn this case, you could now take your code and transform it into a function, like\n\ncompute_win_prob &lt;- function(p_greater) {\n    p_less_or_equal &lt;- 1 - p_greater\n    p_sequence &lt;- p_greater * p_less_or_equal * p_greater\n    return(p_sequence)\n}\n\nAnd then test it on some values:\n\ncompute_win_prob(0.01)\n\n[1] 9.9e-05\n\ncompute_win_prob(0.5)\n\n[1] 0.125\n\ncompute_win_prob(0.99)\n\n[1] 0.009801\n\n\nThen we could ask you to think about\nWhat value for p_greater do you think would maximize your probability of winning?\nand then\nProduce a plot showing your likelihood of winning for 1000 different values of p_greater, evenly spread between 0 and 1\nand you could use the function you wrote like\n\nlibrary(ggplot2)\np_greater_vals &lt;- seq(from = 0, to = 1, length.out = 1000)\n#p_greater_vals\nwin_prob_vals &lt;- sapply(p_greater_vals, compute_win_prob)\nwin_df &lt;- tibble(p_greater=p_greater_vals, win_prob=win_prob_vals)\nggplot(win_df, aes(x=p_greater, y=win_prob)) +\n  geom_line() +\n  dsan_theme(\"full\") +\n  labs(\n    title = \"Probability of Winning With Rigged Die\",\n    x = \"Pr(Result &gt; 4)\",\n    y = \"Pr(Win)\"\n  )\n\n\n\n\n\n\n\n\nAnd finally, we could ask you to draw a conclusion about this situation:\nLooking at the plot, approximately what value for the rigged die looks like it produces the maximum likelihood of winning? Now write code to compute the actual value, out of the 1000 evenly-spaced values you computed the win probability for, that maximizes your probability of winning. Does it match your guess from earlier?\nFor which you could write code like\n\nmax_prob &lt;- max(win_df$win_prob)\nmax_row &lt;- win_df %&gt;% filter(win_prob == max_prob)\nmax_row\n\n\n\n\n\np_greater\nwin_prob\n\n\n\n\n0.6666667\n0.1481481\n\n\n\n\n\n\nMy point in writing all this out is just to say: that was a whole other way to compute probabilities using a computer, where the focus wasn‚Äôt on making a big tibble and then extracting smaller chunks out of it and dividing their sizes. We did have to construct a tibble, in order to compute the win probabilities for a spectrum of values, but that was just so we could generate a plot (since ggplot() needed to know specifically what points to put at what coordinates).\nSo, in this approach, we don‚Äôt have a single tibble throughout the entire problem that serves as our sample space. We just use tibbles when we need them, as tools for doing math or making plots, while the probabilities themselves are still getting computed using simple multiplication.\nAnd, I mentioned above how the tibble-subsetting method doesn‚Äôt allow us to deal with continuous probability distributions. We‚Äôve now seen, on the other hand, how this ‚Äúfancy calculator‚Äù approach is able to deal with such distributions: we were really looking at the distribution of all possible rigged dice, meaning, the space of all dice with \\(\\Pr(\\text{roll greater than 4}) = p\\) for \\(p \\in [0,1]\\). We had to approximate this continuous space using a grid of 1000 samples, which brought us closer to the fancy-spreadsheet approach, but hopefully this can help make it a bit clearer how the fancy-calculator approach can help us when the fancy-spreadsheet approach can‚Äôt, even if it (the fancy-calculator approach) requires us to do a lot more math in our heads."
  },
  {
    "objectID": "writeups/computing-probabilities/index.html#footnotes",
    "href": "writeups/computing-probabilities/index.html#footnotes",
    "title": "Two Ways to Compute Probabilities in R/Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you‚Äôre a Python absolutist, you can take tibble here and replace it with pd.DataFrame, for example. If you‚Äôre a base-R absolutist you can replace it with data.frame.‚Ü©Ô∏é\nThe %% operator in R performs modular division: a %% b produces the remainder after dividing a by b (for example, 7 %% 3 produces 1).‚Ü©Ô∏é"
  },
  {
    "objectID": "writeups/optimization/index.html",
    "href": "writeups/optimization/index.html",
    "title": "Mathematical Optimization",
    "section": "",
    "text": "Code\nsource(\"../../dsan-globals/_globals.r\")\n\n\n\n\\[\n\\DeclareMathOperator*{\\argmax}{argmax}\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\newcommand{\\bigexp}[1]{\\exp\\mkern-4mu\\left[ #1 \\right]}\n\\newcommand{\\bigexpect}[1]{\\mathbb{E}\\mkern-4mu \\left[ #1 \\right]}\n\\newcommand{\\definedas}{\\overset{\\text{defn}}{=}}\n\\newcommand{\\definedalign}{\\overset{\\phantom{\\text{defn}}}{=}}\n\\newcommand{\\eqeventual}{\\overset{\\text{eventually}}{=}}\n\\newcommand{\\Err}{\\text{Err}}\n\\newcommand{\\expect}[1]{\\mathbb{E}[#1]}\n\\newcommand{\\expectsq}[1]{\\mathbb{E}^2[#1]}\n\\newcommand{\\fw}[1]{\\texttt{#1}}\n\\newcommand{\\given}{\\mid}\n\\newcommand{\\green}[1]{\\color{green}{#1}}\n\\newcommand{\\heads}{\\outcome{heads}}\n\\newcommand{\\iid}{\\overset{\\text{\\small{iid}}}{\\sim}}\n\\newcommand{\\lik}{\\mathcal{L}}\n\\newcommand{\\loglik}{\\ell}\n\\DeclareMathOperator*{\\maximize}{maximize}\n\\DeclareMathOperator*{\\minimize}{minimize}\n\\newcommand{\\mle}{\\textsf{ML}}\n\\newcommand{\\nimplies}{\\;\\not\\!\\!\\!\\!\\implies}\n\\newcommand{\\orange}[1]{\\color{orange}{#1}}\n\\newcommand{\\outcome}[1]{\\textsf{#1}}\n\\newcommand{\\param}[1]{{\\color{purple} #1}}\n\\newcommand{\\pgsamplespace}{\\{\\green{1},\\green{2},\\green{3},\\purp{4},\\purp{5},\\purp{6}\\}}\n\\newcommand{\\prob}[1]{P\\left( #1 \\right)}\n\\newcommand{\\purp}[1]{\\color{purple}{#1}}\n\\newcommand{\\sign}{\\text{Sign}}\n\\newcommand{\\spacecap}{\\; \\cap \\;}\n\\newcommand{\\spacewedge}{\\; \\wedge \\;}\n\\newcommand{\\tails}{\\outcome{tails}}\n\\newcommand{\\Var}[1]{\\text{Var}[#1]}\n\\newcommand{\\bigVar}[1]{\\text{Var}\\mkern-4mu \\left[ #1 \\right]}\n\\]\n\n\nAs we entered the unit on Parameter Estimation, encompassing both Maximum Likelihood Estimation (MLE) and Generalized Method of Moments (GMM) Estimation, a bunch of students helpfully pointed out how the mathematical content of the course suddenly kind of ‚Äúshifted into high gear‚Äù.\nSo, although it won‚Äôt help in terms of the Quizzes and Labs you‚Äôve already completed on these topics, I think it is helpful to return to the mathematical aspects of those units, since they will become fairly central to the problems you‚Äôll encounter in DSAN 5300: Statistical Learning, in the Spring semester.\nMy goals here are:\n\nTo start specifically with the Maximum Likelihood Estimation approach, going more slowly through some example problems emphasizing how MLE is rooted in optimization of an objective function, and then\nTo introduce constrained optimization via the Lagrange Multiplier approach, as the ‚Äúnext step‚Äù once you feel comfortable with MLE, again going through example problems that can then also serve as preparation for DSAN 5300!\n\nThe second bullet point is why I also mentioned GMM Estimation above: it turns out that, whereas MLE is an optimization problem without constraints, GMM can essentially be written as an optimization problem with only constraints.\nAs a preview of what this means, first assume we have:\n\nA vector-valued Random Variable \\(\\mathfrak{X}\\),\nAn \\(N\\)-dimensional vector \\(\\mathbf{x} = (x_1, \\ldots, x_N)\\), our dataset (a realization of \\(\\mathfrak{X}\\)),\nA vector of \\(J\\) parameters \\(\\param{\\boldsymbol\\theta} = (\\theta_1, \\ldots, \\theta_J)\\),\n\nFor example, if \\(\\mathfrak{X}\\) is distributed normally, it has \\(J = 2\\) parameters \\(\\param{\\boldsymbol\\theta} = (\\theta_1, \\theta_2) = (\\mu, \\sigma)\\)\n\nA likelihood function \\(\\mathcal{L}(\\mathfrak{X} = \\mathbf{x} \\mid \\param{\\boldsymbol\\theta})\\).\n\nYou can compare MLE for this scenario, written in the form of an optimization problem:\n\\[\n\\begin{alignat}{2}\n\\boldsymbol\\theta^* = &&\\max_{\\param{\\boldsymbol\\theta}} \\quad &\\mathcal{L}(\\mathfrak{X} = \\mathbf{x} \\mid \\param{\\boldsymbol\\theta}) \\\\\n&& \\text{s.t.} \\quad &\\varnothing\n\\end{alignat}\n\\]\nwith GMM estimation for this scenario written in the same form:\n\\[\n\\begin{alignat}{2}\n\\boldsymbol\\theta^* = &&\\max_{\\param{\\boldsymbol\\theta}} \\quad &\\varnothing \\\\\n&& \\text{s.t.} \\quad & \\mu_1(\\param{\\boldsymbol\\theta}) = \\widehat{\\mu}_1(\\mathbf{x}, \\param{\\boldsymbol\\theta}) \\\\\n&& \\quad & \\mu_2(\\param{\\boldsymbol\\theta}) = \\widehat{\\mu}_2(\\mathbf{x}, \\param{\\boldsymbol\\theta}) \\\\\n&& \\quad & \\phantom{\\mu_1(\\param{\\boldsymbol\\theta})} ~ \\vdots \\\\\n&& \\quad & \\mu_J(\\param{\\boldsymbol\\theta}) = \\widehat{\\mu}_J(\\mathbf{x}, \\param{\\boldsymbol\\theta}),\n\\end{alignat}\n\\]\nwhere:\n\n\\(\\mu_i(\\param{\\boldsymbol\\theta})\\) is the \\(i\\)th theoretical moment of \\(\\mathfrak{X}\\)\n\nFor example, if \\(\\mathfrak{X}\\) is distributed normally, \\(\\mu_1(\\theta_1, \\theta_2) = \\mathbb{E}[\\mathfrak{X}]\\)\n\n\\(\\widehat{\\mu}_i(\\mathbf{x}, \\param{\\boldsymbol\\theta})\\) is the \\(i\\)th empirical moment of \\(\\mathfrak{X}\\)\n\nFor example, since \\(\\mu_1 = \\mathbb{E}[\\mathfrak{X}]\\), \\(\\widehat{\\mu_1}\\) is the sample ‚Äúversion‚Äù of \\(\\mathbb{E}[\\mathfrak{X}]\\), namely, \\(\\widehat{\\mu}_1 = \\frac{1}{N}\\sum_{i=1}^{N}x_i\\)\n\n\nIn both cases, the symbol \\(\\varnothing\\) literally just means ‚Äúnothing‚Äù: in the MLE case, we have no constraints, whereas in the GMM estimation case, we have no objective function.\nFor readability, \\(\\text{s.t.}\\) is just shorthand for ‚Äúsubject to‚Äù, or sometimes ‚Äúsuch that‚Äù. This means that the full expression in general can be read like ‚Äú\\(\\param{\\boldsymbol\\theta}^*\\) is the maximum of ____, subject to _____‚Äù"
  },
  {
    "objectID": "writeups/optimization/index.html#motivation-a-closer-look-at-parameter-estimation",
    "href": "writeups/optimization/index.html#motivation-a-closer-look-at-parameter-estimation",
    "title": "Mathematical Optimization",
    "section": "",
    "text": "Code\nsource(\"../../dsan-globals/_globals.r\")\n\n\n\n\\[\n\\DeclareMathOperator*{\\argmax}{argmax}\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\newcommand{\\bigexp}[1]{\\exp\\mkern-4mu\\left[ #1 \\right]}\n\\newcommand{\\bigexpect}[1]{\\mathbb{E}\\mkern-4mu \\left[ #1 \\right]}\n\\newcommand{\\definedas}{\\overset{\\text{defn}}{=}}\n\\newcommand{\\definedalign}{\\overset{\\phantom{\\text{defn}}}{=}}\n\\newcommand{\\eqeventual}{\\overset{\\text{eventually}}{=}}\n\\newcommand{\\Err}{\\text{Err}}\n\\newcommand{\\expect}[1]{\\mathbb{E}[#1]}\n\\newcommand{\\expectsq}[1]{\\mathbb{E}^2[#1]}\n\\newcommand{\\fw}[1]{\\texttt{#1}}\n\\newcommand{\\given}{\\mid}\n\\newcommand{\\green}[1]{\\color{green}{#1}}\n\\newcommand{\\heads}{\\outcome{heads}}\n\\newcommand{\\iid}{\\overset{\\text{\\small{iid}}}{\\sim}}\n\\newcommand{\\lik}{\\mathcal{L}}\n\\newcommand{\\loglik}{\\ell}\n\\DeclareMathOperator*{\\maximize}{maximize}\n\\DeclareMathOperator*{\\minimize}{minimize}\n\\newcommand{\\mle}{\\textsf{ML}}\n\\newcommand{\\nimplies}{\\;\\not\\!\\!\\!\\!\\implies}\n\\newcommand{\\orange}[1]{\\color{orange}{#1}}\n\\newcommand{\\outcome}[1]{\\textsf{#1}}\n\\newcommand{\\param}[1]{{\\color{purple} #1}}\n\\newcommand{\\pgsamplespace}{\\{\\green{1},\\green{2},\\green{3},\\purp{4},\\purp{5},\\purp{6}\\}}\n\\newcommand{\\prob}[1]{P\\left( #1 \\right)}\n\\newcommand{\\purp}[1]{\\color{purple}{#1}}\n\\newcommand{\\sign}{\\text{Sign}}\n\\newcommand{\\spacecap}{\\; \\cap \\;}\n\\newcommand{\\spacewedge}{\\; \\wedge \\;}\n\\newcommand{\\tails}{\\outcome{tails}}\n\\newcommand{\\Var}[1]{\\text{Var}[#1]}\n\\newcommand{\\bigVar}[1]{\\text{Var}\\mkern-4mu \\left[ #1 \\right]}\n\\]\n\n\nAs we entered the unit on Parameter Estimation, encompassing both Maximum Likelihood Estimation (MLE) and Generalized Method of Moments (GMM) Estimation, a bunch of students helpfully pointed out how the mathematical content of the course suddenly kind of ‚Äúshifted into high gear‚Äù.\nSo, although it won‚Äôt help in terms of the Quizzes and Labs you‚Äôve already completed on these topics, I think it is helpful to return to the mathematical aspects of those units, since they will become fairly central to the problems you‚Äôll encounter in DSAN 5300: Statistical Learning, in the Spring semester.\nMy goals here are:\n\nTo start specifically with the Maximum Likelihood Estimation approach, going more slowly through some example problems emphasizing how MLE is rooted in optimization of an objective function, and then\nTo introduce constrained optimization via the Lagrange Multiplier approach, as the ‚Äúnext step‚Äù once you feel comfortable with MLE, again going through example problems that can then also serve as preparation for DSAN 5300!\n\nThe second bullet point is why I also mentioned GMM Estimation above: it turns out that, whereas MLE is an optimization problem without constraints, GMM can essentially be written as an optimization problem with only constraints.\nAs a preview of what this means, first assume we have:\n\nA vector-valued Random Variable \\(\\mathfrak{X}\\),\nAn \\(N\\)-dimensional vector \\(\\mathbf{x} = (x_1, \\ldots, x_N)\\), our dataset (a realization of \\(\\mathfrak{X}\\)),\nA vector of \\(J\\) parameters \\(\\param{\\boldsymbol\\theta} = (\\theta_1, \\ldots, \\theta_J)\\),\n\nFor example, if \\(\\mathfrak{X}\\) is distributed normally, it has \\(J = 2\\) parameters \\(\\param{\\boldsymbol\\theta} = (\\theta_1, \\theta_2) = (\\mu, \\sigma)\\)\n\nA likelihood function \\(\\mathcal{L}(\\mathfrak{X} = \\mathbf{x} \\mid \\param{\\boldsymbol\\theta})\\).\n\nYou can compare MLE for this scenario, written in the form of an optimization problem:\n\\[\n\\begin{alignat}{2}\n\\boldsymbol\\theta^* = &&\\max_{\\param{\\boldsymbol\\theta}} \\quad &\\mathcal{L}(\\mathfrak{X} = \\mathbf{x} \\mid \\param{\\boldsymbol\\theta}) \\\\\n&& \\text{s.t.} \\quad &\\varnothing\n\\end{alignat}\n\\]\nwith GMM estimation for this scenario written in the same form:\n\\[\n\\begin{alignat}{2}\n\\boldsymbol\\theta^* = &&\\max_{\\param{\\boldsymbol\\theta}} \\quad &\\varnothing \\\\\n&& \\text{s.t.} \\quad & \\mu_1(\\param{\\boldsymbol\\theta}) = \\widehat{\\mu}_1(\\mathbf{x}, \\param{\\boldsymbol\\theta}) \\\\\n&& \\quad & \\mu_2(\\param{\\boldsymbol\\theta}) = \\widehat{\\mu}_2(\\mathbf{x}, \\param{\\boldsymbol\\theta}) \\\\\n&& \\quad & \\phantom{\\mu_1(\\param{\\boldsymbol\\theta})} ~ \\vdots \\\\\n&& \\quad & \\mu_J(\\param{\\boldsymbol\\theta}) = \\widehat{\\mu}_J(\\mathbf{x}, \\param{\\boldsymbol\\theta}),\n\\end{alignat}\n\\]\nwhere:\n\n\\(\\mu_i(\\param{\\boldsymbol\\theta})\\) is the \\(i\\)th theoretical moment of \\(\\mathfrak{X}\\)\n\nFor example, if \\(\\mathfrak{X}\\) is distributed normally, \\(\\mu_1(\\theta_1, \\theta_2) = \\mathbb{E}[\\mathfrak{X}]\\)\n\n\\(\\widehat{\\mu}_i(\\mathbf{x}, \\param{\\boldsymbol\\theta})\\) is the \\(i\\)th empirical moment of \\(\\mathfrak{X}\\)\n\nFor example, since \\(\\mu_1 = \\mathbb{E}[\\mathfrak{X}]\\), \\(\\widehat{\\mu_1}\\) is the sample ‚Äúversion‚Äù of \\(\\mathbb{E}[\\mathfrak{X}]\\), namely, \\(\\widehat{\\mu}_1 = \\frac{1}{N}\\sum_{i=1}^{N}x_i\\)\n\n\nIn both cases, the symbol \\(\\varnothing\\) literally just means ‚Äúnothing‚Äù: in the MLE case, we have no constraints, whereas in the GMM estimation case, we have no objective function.\nFor readability, \\(\\text{s.t.}\\) is just shorthand for ‚Äúsubject to‚Äù, or sometimes ‚Äúsuch that‚Äù. This means that the full expression in general can be read like ‚Äú\\(\\param{\\boldsymbol\\theta}^*\\) is the maximum of ____, subject to _____‚Äù"
  },
  {
    "objectID": "writeups/optimization/index.html#visualizing-unconstrained-and-constrained-optimization",
    "href": "writeups/optimization/index.html#visualizing-unconstrained-and-constrained-optimization",
    "title": "Mathematical Optimization",
    "section": "Visualizing Unconstrained and Constrained Optimization",
    "text": "Visualizing Unconstrained and Constrained Optimization\nThe unconstrained optimizations we will carry out here can be visualized as ‚Äúhill climbing‚Äù: the optimization approach you probably learned in calculus class‚Äîcomputing the derivative and setting it equal to zero‚Äîworks precisely because the top of the ‚Äúhill‚Äù is the point at which the derivative becomes zero. For example, if we started climbing from the left side of the following plot, the derivative would get lower and lower as we moved right, hitting zero when we reach the top of the ‚Äúhill‚Äù:\n\n\nCode\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nmy_hill &lt;- function(x) exp(-(1/2)*x^2)\nmy_slope &lt;- function(x) -x*exp(-(1/2)*x^2)\nx0_vals &lt;- c(-1.75, -0.333, 0)\ntangent_at_x0 &lt;- function(x,x0) my_slope(x0)*(x - x0) + my_hill(x0)\ntan_x1 &lt;- function(x) tangent_at_x0(x, x0_vals[1])\ntan_x2 &lt;- function(x) tangent_at_x0(x, x0_vals[2])\ntan_x3 &lt;- function(x) tangent_at_x0(x, x0_vals[3])\neval_df &lt;- tibble(x=x0_vals) |&gt; mutate(y=my_hill(x))\ntan_ext &lt;- 0.5\nslopes &lt;- round(c(\n  my_slope(x0_vals[1]),\n  my_slope(x0_vals[2]),\n  my_slope(x0_vals[3])\n), 3)\nopt_df &lt;- tibble(x=0, y=my_hill(0))\nx_df &lt;- tibble(x=c(-3, 3))\nx_df |&gt; ggplot(aes(x=x)) +\n  stat_function(fun=my_hill, linewidth=1) +\n  geom_function(\n    fun=tan_x1, aes(color=\"x1\"), linewidth=1,\n    xlim=c(\n      x0_vals[1]-tan_ext,\n      x0_vals[1]+tan_ext\n    )\n  ) +\n  geom_function(\n    fun=tan_x2, aes(color=\"x2\"), linewidth=1,\n    xlim=c(\n      x0_vals[2]-tan_ext,\n      x0_vals[2]+tan_ext\n    )\n  ) +\n  geom_function(\n    fun=tan_x3, aes(color=\"x3\"), linewidth=1,\n    xlim=c(\n      -1,1\n    )\n  ) +\n  geom_point(\n    data=eval_df,\n    aes(x=x, y=y, color=c(\"x1\",\"x2\",\"x3\")),\n    size=2\n  ) +\n  geom_point(\n    data=opt_df,\n    aes(x=x, y=y, shape=\"mle\"),\n    size=2\n  ) +\n  scale_shape_manual(\n    element_blank(),\n    values=19,\n    labels=\"MLE Estimate\"\n  ) +\n  scale_color_manual(\n    \"Slope at x\",\n    values=c(cb_palette[1], cb_palette[2], cb_palette[3]),\n    labels=slopes\n  ) +\n  theme_classic(base_size=18) +\n  ylim(c(0, 1.15))\n\n\n\n\n\nThe derivatives ‚Äúpoint‚Äù in the direction you should go to get to the maximum value, at which it has value zero\n\n\n\n\nUsing this same metaphor of the top of a hill being the ‚Äúbest‚Äù point, constrained optimization is a bit harder to visualize, but you can think of it like:\n\nGetting (almost) crunched between two walls coming closer together, then\nGetting (almost) crunched between a floor and a ceiling coming closer together,\n\nwhere that coming-closer-together is set up so as to crunch the space, making it smaller and smaller until the only point(s) left are the point(s) representing the optimal solution:\n\n\nCode\nxl &lt;- -0.06\nxu &lt;- 0.06\nyl &lt;- 0.985\nyu &lt;- 1.015\nanno_x &lt;- -1.8\nanno_y &lt;- 0.2\nx_df &lt;- tibble(x=c(-3, 3))\nrib_df &lt;- x_df |&gt; mutate(\n  ymin = -0.1,\n  ymax = 0.1\n)\nx_df |&gt; ggplot(aes(x=x)) +\n  stat_function(fun=my_hill, linewidth=1) +\n  geom_rect(\n    aes(fill=\"x\"), xmin=xl, xmax=xu, ymin=-Inf, ymax=Inf, alpha=0.5, color='black'\n  ) +\n  geom_segment(x=xl, xend=xl, y=-Inf, yend=Inf) +\n  geom_segment(x=xu, xend=xu, y=-Inf, yend=Inf) +\n  geom_rect(\n    aes(fill=\"y\"), xmin=-Inf, xmax=Inf, ymin=yl, ymax=yu, alpha=0.5, color='black'\n  ) +\n  geom_segment(x=-Inf, xend=Inf, y=yl, yend=yl) +\n  geom_segment(x=-Inf, xend=Inf, y=yu, yend=yu) +\n  # Anno xmin\n  annotate(\n    \"segment\", y=anno_y, yend=anno_y, x = xl-0.5, xend = xl-0.04,\n    linewidth=1, linejoin = \"mitre\",\n    arrow = arrow(type = \"closed\", length = unit(0.02, \"npc\"))\n  ) +\n  annotate(\n    \"text\", y=anno_y, x=xl-1.2, label = \"x &gt; a\", color = \"black\",\n    angle = 0, hjust = 0, vjust=0.5, size = 5\n  ) +\n  # Anno xmax\n  annotate(\n    \"segment\", y=anno_y, yend=anno_y, x = xu+0.5, xend = xu+0.04,\n    linewidth=1, linejoin = \"mitre\",\n    arrow = arrow(type = \"closed\", length = unit(0.02, \"npc\"))\n  ) +\n  annotate(\n    \"text\", y=anno_y, x=xu+0.6, label = \"x &lt; b\", color = \"black\",\n    angle = 0, hjust = 0, vjust=0.5, size = 5\n  ) +\n  # Anno ymin\n  annotate(\n    \"segment\", x=anno_x, xend=anno_x, y = yl-0.2, yend = yl-0.015,\n    linewidth=1, linejoin = \"mitre\",\n    arrow = arrow(type = \"closed\", length = unit(0.02, \"npc\"))\n  ) +\n  annotate(\n    \"text\", x=anno_x, y=yl-0.25, label = \"y &gt; c\", color = \"black\",\n    angle = 0, hjust = 0.5, vjust=0.5, size = 5\n  ) +\n  # Anno ymax\n  annotate(\n    \"segment\", x=anno_x, xend=anno_x, y = yu+0.2, yend = yu+0.015,\n    linewidth=1, linejoin = \"mitre\",\n    arrow = arrow(type = \"closed\", length = unit(0.02, \"npc\"))\n  ) +\n  annotate(\n    \"text\", x=anno_x, y=yu+0.2, label = \"y &lt; d\", color = \"black\",\n    angle = 0, hjust = 0.5, vjust=-0.5, size = 5\n  ) +\n  scale_fill_manual(\n    \"Constraints:\",\n    values=c(cb_palette[1], cb_palette[2]),\n    labels=c(\"a &lt; x &lt; b\", \"c &lt; y &lt; d\")\n  ) +\n  geom_point(\n    data=opt_df,\n    aes(x=x, y=y, shape=\"gmm\"),\n    size=2\n  ) +\n  scale_shape_manual(\n    element_blank(),\n    values=19,\n    labels=\"GMM Estimate\"\n  ) +\n  theme_classic(base_size=18) +\n  ylim(c(0, 1.5))\n\n\n\n\n\nThe constraints ‚Äúcrunch‚Äù the admissible values of \\(x\\) until only one point (the Method of Moments estimate) is left. The metaphor is a bit more contrived in this case, however, since we usually don‚Äôt manually compute these constraints in exactly this form (they are implicit in the GMM‚Äôs system of equations), though numerically (i.e., if we use R to compute the GMM estimate), this is exactly how the constraints would be applied!\n\n\n\n\nLet‚Äôs look at how we can work through both MLE and GMM estimation (which we previously learned separately!) as optimization problems, and how that will give us a unified optimization framework for estimating parameters in the fancier ML models you‚Äôll see in DSAN 5300!"
  },
  {
    "objectID": "writeups/optimization/index.html#general-unconstrained-optimization",
    "href": "writeups/optimization/index.html#general-unconstrained-optimization",
    "title": "Mathematical Optimization",
    "section": "General Unconstrained Optimization",
    "text": "General Unconstrained Optimization\nAs the name implies, Maximum likelihood estimation involves maximizing something:\n\nIn MLE, that thing is the Likelihood Function \\(\\mathcal{L}(X \\mid \\theta)\\).\nIn optimization, more generally, that thing is called the objective function \\(f(x, \\theta)\\).\n\nThis is the reasoning behind something I might have mentioned in class in earlier weeks, that ‚Äúthe objective function in MLE is the likelihood function‚Äù.\nIn other words, when you see the term ‚Äúobjective function‚Äù, just replace it in your brain with ‚Äúthing I‚Äôm trying to optimize (minimize or maximize) here‚Äù.1\nBefore we look at MLE specifically, therefore, let‚Äôs look at a general unconstrained optimization problem, something you almost surely have already solved tons of times (even if you didn‚Äôt have the vocabulary of optimization, objective functions, constraints, and so on):\n\n\n\n\n\n\nExample 1: General Unconstrained Optimization\n\n\n\nFind \\(x^*\\), the solution to\n\\[\n\\begin{align}\n    \\min_{x} ~ & f(x) = 3x^2 - x \\\\\n    \\text{s.t. } ~ & \\varnothing\n\\end{align}\n\\]\n\n\nFrom calculus, we know that finding the optimum value for a function like this (whether minimum or maximum) boils down to:\n\nComputing the derivative \\(f'(x) = \\frac{\\partial}{\\partial x}f(x)\\),\nSetting it equal to zero: \\(f'(x) = 0\\), and\nSolving this equal for \\(x\\), i.e., finding values \\(x^*\\) which satisfy \\(f'(x^*) = 0\\)\n\nHere, without any constraints, we can follow this exact procedure to find the minimum value. We start by computing the derivative:\n\\[\nf'(x) = \\frac{\\partial}{\\partial x}f(x) = \\frac{\\partial}{\\partial x}\\left[3x^2 - x\\right] = 6x - 1,\n\\]\nthen solve for \\(x^*\\) as the value(s) satisfying \\(\\frac{\\partial}{\\partial x}f'(x^*) = 0\\) for the just-derived \\(f'(x)\\):\n\\[\nf'(x^*) = 0 \\iff 6x^* - 1 = 0 \\iff x^* = \\frac{1}{6}.\n\\]\n\n\n\n\n\n\nDerivative Cheatsheet (Click to Collapse / Expand)\n\n\n\n\n\n(These green boxes are where I get to pop off a tiny bit, but in a way that I hope is helpful! üòú)\nPersonally, I absolutely hate, despise memorizing things. So much of school growing up felt like memorizing a ton of things for no reason, since they were things we could just Google 90% of the time‚Ä¶\nSo, even though people usually associate math with memorization of formulas, for whatever reason I have the opposite association: math was the one class where I didn‚Äôt have to memorize things, because (unlike‚Ä¶ ‚Äúthe mitochondria is the powerhouse of the cell‚Äù) I had really good teachers who always walked us through how to derive things from more basic principles.\nSo, I‚Äôm providing this here as a small set of ‚Äúshortcuts‚Äù, but long story short each of these can be derived from even simpler procedures (I don‚Äôt want to clutter this writeup even more by writing those out, but I‚Äôm happy to walk you through how you could derive these, in office hours for example!)\n\n\n\n\n\n\n\n\nType of Thing\nThing\nChange in Thing when \\(x\\) Changes by Tiny Amount\n\n\n\n\nPolynomial\n\\(f(x) = x^n\\)\n\\(f'(x) = \\frac{\\partial}{\\partial x}f(x) = nx^{n-1}\\)\n\n\nFraction\n\\(f(x) = \\frac{1}{x}\\)\nUse Polynomial rule (since \\(\\frac{1}{x} = x^{-1}\\)) to get \\(f'(x) = -\\frac{1}{x^2}\\)\n\n\nLogarithm\n\\(f(x) = \\ln(x)\\)\n\\(f'(x) = \\frac{\\partial}{\\partial x} = \\frac{1}{x}\\)\n\n\nExponential\n\\(f(x) = e^x\\)\n\\(f'(x) = \\frac{\\partial}{\\partial x}e^x = e^x\\) (üßê‚ùóÔ∏è)\n\n\nMultiplication\n\\(f(x) = g(x)h(x)\\)\n\\(f'(x) = g'(x)h(x) + g(x)h'(x)\\)\n\n\nDivision\n\\(f(x) = \\frac{g(x)}{h(x)}\\)\nToo hard to memorize‚Ä¶ turn it into Multiplication, as \\(f(x) = g(x)(h(x))^{-1}\\)\n\n\nComposition (Chain Rule)\n\\(f(x) = g(h(x))\\)\n\\(f'(x) = g'(h(x))h'(x)\\)\n\n\nFancy Logarithm\n\\(f(x) = \\ln(g(x))\\)\n\\(f'(x) = \\frac{g'(x)}{g(x)}\\) by Chain Rule\n\n\nFancy Exponential\n\\(f(x) = e^{g(x)}\\)\n\\(f'(x) = g'(x)e^{g(x)}\\) by Chain Rule\n\n\n\n\n\n\nThe reason why derivatives are so important for optimization is that we‚Äôre trying to climb a hill (for maximization; if we‚Äôre minimizing then we‚Äôre trying to reach the bottom of a lake)"
  },
  {
    "objectID": "writeups/optimization/index.html#maximum-likelihood-estimation-as-unconstrained-optimization",
    "href": "writeups/optimization/index.html#maximum-likelihood-estimation-as-unconstrained-optimization",
    "title": "Mathematical Optimization",
    "section": "Maximum Likelihood Estimation as Unconstrained Optimization",
    "text": "Maximum Likelihood Estimation as Unconstrained Optimization\nNow that we have this general procedure for non-constrained optimization in general, let‚Äôs use it to obtain a maximum likelihood estimate for some probabilistic model.\n\n‚ÄúStandard‚Äù Example: Poisson Distribution\nWe‚Äôll start with an example more similar to the ones you did in DSAN 5100: estimating the rate parameter \\(\\param{\\lambda}\\) for a random variable \\(X\\) with a Poisson distribution.\n\n\n\n\n\n\nExample 2: MLE for Poisson-Distributed RV\n\n\n\nGiven a dataset consisting of \\(N\\) i.i.d. realizations \\(\\mathbf{x} = (x_1, \\ldots, x_n)\\) of Poisson-distributed random variables\n\\[\nX_1, \\ldots, X_n \\sim \\text{Pois}(\\param{\\lambda}),\n\\]\nfind the Maximum Likelihood Estimate for the parameter \\(\\param{\\lambda}\\).\n\n\nLike with other distributions we looked at in class, the way to approach problems like this is to write out the details step-by-step until you have enough information to start deriving the MLE. So, the first piece of information we have is:\n\nA random variable \\(X \\sim \\text{Pois}(\\param{\\lambda})\\)\n\nGiven how the Poisson distribution works, this means that2\n\\[\n\\Pr(X = k; \\param{\\lambda}) = \\frac{\\param{\\lambda}^ke^{-\\param{\\lambda}}}{k!},\n\\tag{1}\\]\nwhere we can use probability mass \\(\\Pr(X = k)\\) rather than probability density \\(f_X(k)\\) since the Poisson distribution is a discrete distribution (modeling integer counts rather than continuous values like the normal distribution).\nThe next piece of information we have, in a Maximum Likelihood setup, is an observed dataset containing \\(N\\) i.i.d. datapoints,\n\n\\(\\mathbf{x} = (x_1, \\ldots, x_n)\\),\n\nwhere each point is assumed to be drawn from this Poisson distribution with parameter \\(\\param{\\lambda}\\). This assumption means that we treat each of these observed points \\(x_i\\) as the realization of a Poisson-distributed Random Variable \\(X_i\\), so that (by Equation¬†1 above):\n\\[\n\\Pr(X_i = x_i; \\param{\\lambda}) =  \\frac{\\param{\\lambda}^{x_i}e^{-\\param{\\lambda}}}{x_i!},\n\\]\nOur goal in Maximum Likelihood Estimation is to take this observed dataset and figure out what value of the parameter \\(\\param{\\lambda}\\) is most likely to have produced \\(\\mathbf{x}\\).\nIn other words, we are trying to find the value of \\(\\param{\\lambda}\\) which maximizes the joint probability that \\(X_1\\) is realized as \\(x_1\\), \\(X_2\\), is realized as \\(x_2\\), and so on up to \\(X_n\\) being realized as \\(x_n\\), which we call the likelihood \\(\\mathcal{L}(\\mathbf{x}; \\param{\\lambda})\\) of the dataset:\n\\[\n\\mathcal{L}(\\mathbf{x}; \\param{\\lambda}) = \\Pr(X_1 = x_1, X_2 = x_2, \\ldots, X_n = x_n; \\param{\\lambda}).\n\\]\nThe key for being able to compute this giant joint probability is the independence assumption: since the values in \\(\\mathbf{x}\\) are assumed to be independent and identically distributed (i.i.d.), by the definition of independence, we can factor this full joint probability into the product of individual-variable probabilities:\n\\[\n\\begin{align*}\n\\mathcal{L}(\\mathbf{x}; \\param{\\lambda}) &= \\Pr(X_1 = x_1, X_2 = x_2, \\ldots, X_n = x_n; \\param{\\lambda}) \\\\\n&= \\Pr(X_1 = x_1; \\param{\\lambda}) \\times \\cdots \\times \\Pr(X_n = x_n; \\param{\\lambda}) \\\\\n&= \\prod_{i=1}^{N}\\Pr(X_i = x_i; \\param{\\lambda})\n\\end{align*}\n\\]\nThis factoring into individual terms is the key to solving this problem! Now that we‚Äôve done this, the rest of the problem boils down to a calculus problem. Let‚Äôs write out this product (which will look messy at first, but we‚Äôll make it simpler using \\(\\log()\\) below!):\n\\[\n\\begin{align*}\n\\mathcal{L}(\\mathbf{x}; \\param{\\lambda}) &= \\prod_{i=1}^{N}\\Pr(X_i = x_i; \\param{\\lambda}) \\\\\n&= \\prod_{i=1}^{N}\\frac{\\param{\\lambda}^{x_i}e^{-\\param{\\lambda}}}{x_i!}\n\\end{align*}\n\\]\nBecause \\(\\log()\\) is a monotonic function, the value of \\(x\\) which maximizes \\(\\log(f(x))\\) will be the same as the value which maximizes \\(f(x)\\). So, to make our lives easier since \\(\\log()\\) turns multiplications into additions, we compute the log-likelihood (the log of the likelihood function above), which we denote \\(\\ell(\\mathbf{x}; \\param{\\lambda})\\):\n\\[\n\\ell(\\mathbf{x}; \\param{\\lambda}) = \\log\\left[ \\prod_{i=1}^{N}\\frac{\\param{\\lambda}^{x_i}e^{-\\param{\\lambda}}}{x_i!} \\right]\n\\]\nI recommend working through this application of \\(\\log()\\) yourself, if you can, then you can click the following button to show the worked-out solution:\n\n\nClick to Show Solution\n\n\\[\n\\begin{align*}\n\\ell(\\mathbf{x}; \\param{\\lambda}) &= \\log\\left[ \\prod_{i=1}^{N}\\frac{\\param{\\lambda}^{x_i}e^{-\\param{\\lambda}}}{x_i!} \\right] \\\\\n&= \\sum_{i=1}^{N}\\log\\left[ \\frac{\\param{\\lambda}^{x_i}e^{-\\lambda}}{x_i!} \\right] \\\\\n&= \\sum_{i=1}^{N}\\log (\\param{\\lambda}^{x_i}e^{-\\lambda}) - \\sum_{i=1}^N\\log(x_i!) \\\\\n&= \\sum_{i=1}^{N}x_i\\log(\\param{\\lambda}) + \\sum_{i=1}^{N}\\log(e^{-\\param{\\lambda}}) - \\sum_{i=1}^{N}\\log(x_i!) \\\\\n&= \\log(\\param{\\lambda})\\sum_{i=1}^{N}x_i - N\\param{\\lambda} - \\sum_{i=1}^{N}\\log(x_i!).\n\\end{align*}\n\\]\n\nThis might look scary at first, for example, because of the term with the \\(x_i!\\). However, keep in mind that we won‚Äôt need to worry about this term, since it does not involve \\(\\param{\\lambda}\\), the parameter we are maximizing over!\nSo, following the same procedure as our previous example, we maximize this log-likelihood function with respect to \\(\\param{\\lambda}\\). We start by computing the derivative of \\(\\ell(\\mathbf{x}; \\param{\\lambda})\\) with respect to \\(\\param{\\lambda}\\):\n\\[\n\\frac{\\partial}{\\partial \\param{\\lambda}}\\ell(\\mathbf{x}; \\param{\\lambda}) = \\frac{\\partial}{\\partial \\param{\\lambda}}\\left[ \\log(\\param{\\lambda})\\sum_{i=1}^{N}x_i - N\\param{\\lambda} - \\sum_{i=1}^{N}\\log(x_i!) \\right]\n\\]\nLike before, I recommend working through this yourself on paper, and then you can click the following to show the worked-out solution:\n\n\nClick to Show Solution\n\nSince both \\(\\sum_{i=1}^{N}x_i\\) and \\(\\sum_{i=1}^{N}\\log(x_i!)\\) are constants with respect to \\(\\param{\\lambda}\\), and since the derivative operator \\(\\frac{\\partial}{\\partial\\param{\\lambda}}\\) is linear, this reduces to:\n\\[\n\\begin{align*}\n\\frac{\\partial}{\\partial \\param{\\lambda}}\\ell(\\mathbf{x}; \\param{\\lambda}) &= \\left( \\sum_{i=1}^{N}x_i\\right) \\frac{\\partial}{\\partial \\param{\\lambda}}[\\log(\\param{\\lambda})] - N\\frac{\\partial}{\\partial\\param{\\lambda}}[\\param{\\lambda}] \\\\\n&= \\frac{\\sum_{i=1}^{N}x_i}{\\param{\\lambda}} - N.\n\\end{align*}\n\\]\nAnd now we can set this equal to zero and solve to obtain the maximum-likelihood estimator \\(\\lambda^*\\):\n\\[\n\\begin{align*}\n&\\frac{\\sum_{i=1}^{N}x_i}{\\lambda^*} - N = 0 \\\\\n\\iff &\\frac{\\sum_{i=1}^{N}x_i}{\\lambda^*} = N \\\\\n\\iff &\\sum_{i=1}^{N}x_i = N\\lambda^* \\\\\n\\iff &\\lambda^* = \\frac{1}{N}\\sum_{i=1}^{N}x_i,\n\\end{align*}\n\\]\n\nmeaning that, after all this work, the maximum likelihood estimator for a dataset containing realizations of i.i.d. Poisson RVs is the sample mean of those points, \\(\\frac{1}{N}\\sum_{i=1}^{N}x_i\\).\nIn other words, if you are given a dataset \\(\\mathbf{x} = (x_1, \\ldots, x_n)\\), and you think that the entries in this dataset were generated via the Poisson distribution, then the ‚Äúbest guess‚Äù (if we define ‚Äúbest guess‚Äù as ‚Äúguess with maximum likelihood‚Äù) for the parameter \\(\\param{\\lambda}\\) of this Poisson distribution is the sample mean of the observed points, \\(\\frac{1}{N}\\sum_{i=1}^{N}x_i\\).\n\n\nTrickier Example: Linear Regression\nSince I think linear regression is a really important model to have in the back of your mind as you move towards fancier Machine Learning models, but is a bit more complex than the Poisson case we just looked at, a good starting point is an over-simplified version of linear regression, where we don‚Äôt even have an intercept.\n\n\n\n\n\n\nExample 3: Zero-Intercept Linear Regression\n\n\n\nAssume we have a dataset \\(\\mathbf{d} = ((x_1,y_1),\\ldots,(x_N,y_N))\\) containing noisy observations from some underlying linear relationship \\(y = \\param{\\beta} x\\), so that we model what we observe in \\(\\mathbf{d}\\) as realizations of random variables \\(X\\), \\(Y\\), and \\(\\varepsilon_i\\):\n\\[\nY_i = \\param{\\beta} X_i + \\varepsilon_i,\n\\]\nwhere the variables \\(\\varepsilon_i\\) are i.i.d. normally-distributed variables with mean zero and a given variance \\(\\sigma^2\\): \\(\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\).\nFind the Maximum Likelihood Estimator for the single parameter in this case, \\(\\param{\\beta}\\).\n\n\nNote that in general, if a random variable \\(X\\) is distributed normally, then adding things to \\(X\\) just shifts the mean parameter \\(\\mu\\) (meaning, for example, if \\(X \\sim \\mathcal{N}(\\mu, \\sigma)\\), then \\(X + 3 \\sim \\mathcal{N}(\\mu + 3, \\sigma)\\)).\nHere, since \\(\\varepsilon_i\\) is a normally-distributed random variable with \\(\\mu = 0\\), the left-hand side of the above equation means that \\(Y_i \\sim \\mathcal{N}(\\param{\\beta} X_i, \\sigma)\\).\nJust as we used the Poisson PMF in the previous example, here you will use the Normal pdf, the probability density function for \\(Y_i\\) in this case, which is typically denoted using the Greek letter \\(\\varphi\\) (‚ÄúPhi‚Äù):\n\\[\n\\varphi(v; \\param{\\mu}, \\param{\\sigma}) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left[-\\frac{1}{2}\\left(\\frac{v - \\mu}{\\sigma}\\right)^2\\right].\n\\]\nAlthough in this ‚Äústandard form‚Äù for the pdf of the normal distribution the two parameters are \\(\\mu\\) and \\(\\sigma\\), in our case note that we are not estimating the parameters \\(\\mu\\) and \\(\\sigma\\) itself. Instead, we are estimating a single parameter \\(\\param{\\beta}\\), which is not the mean or standard deviation itself, though it ends up affecting the mean since \\(Y_i \\sim \\mathcal{N}(\\param{\\beta} X_i, \\sigma)\\).\nSo, the way we obtain the likelihood which we can then use to estimate \\(\\param{\\beta}\\) is by plugging \\(\\param{\\beta} X_i\\) into the pdf above, to obtain:\n\\[\n\\begin{align*}\n\\mathcal{L}(\\mathbf{d}; \\param{\\beta}) &= \\prod_{i=1}^{N}\\varphi(y_i; \\param{\\beta}x_i, \\sigma) \\\\\n&= \\prod_{i=1}^{N}\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left[ -\\frac{1}{2}\\left(\\frac{y_i - \\param{\\beta}x_i}{\\sigma}\\right)^2 \\right]\n\\end{align*}\n\\]\nLike in the Poisson case, this looks scary until you transform it into the log-likelihood function, at which point lots of things simplify and you can compute a closed-form solution!\n\n\nClick to Show Solution\n\n\\[\n\\begin{align*}\n\\ell(\\mathbf{d}; \\param{\\beta}) &= \\log\\left[ \\prod_{i=1}^{N}\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left[ -\\frac{1}{2}\\left(\\frac{y_i - \\param{\\beta}x_i}{\\sigma}\\right)^2 \\right] \\right] \\\\\n&= \\sum_{i=1}^{N}\\log\\left[ \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left[ -\\frac{1}{2}\\left(\\frac{y_i - \\param{\\beta}x_i}{\\sigma}\\right)^2 \\right] \\right] \\\\\n&= \\sum_{i=1}^{N}-\\log\\left(\\sqrt{2\\pi}\\sigma \\right) - \\frac{1}{2}\\sum_{i=1}^{N}\\left(\\frac{y_i - \\param{\\beta} x_i}{\\sigma}\\right)^2 \\\\\n&= -N\\log\\left(\\sqrt{2\\pi}\\sigma \\right) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{N}\\left(y_i - \\param{\\beta} x_i\\right)^2.\n\\end{align*}\n\\]\nAnd we now have the log-likelihood in a form where we can compute a derivative straightforwardly (using the derivative ‚Äúrules‚Äù in the table presented earlier):\n\\[\n\\begin{align*}\n\\frac{\\partial}{\\partial\\param{\\beta}}\\ell(\\mathbf{d}; \\param{\\beta}) &= \\frac{\\partial}{\\partial\\param{\\beta}}\\left[ -N\\log\\left(\\sqrt{2\\pi}\\sigma \\right) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{N}\\left(y_i - \\param{\\beta} x_i\\right)^2 \\right] \\\\\n&= -\\frac{1}{2\\sigma^2} \\sum_{i=1}^{N}\\frac{\\partial}{\\partial\\param{\\beta}}\\left[ (y_i - \\param{\\beta}x_i)^2 \\right] \\\\\n&= -\\frac{1}{\\sigma^2}\\sum_{i=1}^{N}(y_i-\\param{\\beta}x_i)x_i \\\\\n&= -\\frac{1}{\\sigma^2}\\left[\\sum_{i=1}^{N}x_iy_i - \\param{\\beta}\\sum_{i=1}^{N}x_i^2\\right].\n\\end{align*}\n\\]\nBy setting this equal to zero, we can now solve for the MLE estimator \\(\\beta^*\\):\n\\[\n\\begin{align*}\n&-\\frac{1}{\\sigma^2}\\left[\\sum_{i=1}^{N}x_iy_i - \\param{\\beta}\\sum_{i=1}^{N}x_i^2\\right] = 0 \\\\\n\\iff &\\sum_{i=1}^{N}x_iy_i - \\param{\\beta}\\sum_{i=1}^{N}x_i^2 = 0 \\\\\n\\iff &\\sum_{i=1}^{N}x_iy_i = \\param{\\beta}\\sum_{i=1}^{N}x_i^2,\n\\end{align*}\n\\]\nAnd thus the MLE for \\(\\param{\\beta}\\) in this case is\n\\[\n\\widehat{\\beta}_{MLE} = \\frac{\\sum_{i=1}^{N}x_iy_i}{\\sum_{i=1}^{N}x_i^2}.\n\\]\n\nThis means that, if we want the line of ‚Äúbest‚Äù fit for a dataset \\(\\mathbf{d} = ((x_1,y_1),\\ldots,(x_n,y_n))\\), where ‚Äúbest fit‚Äù is defined to be ‚Äúslope with maximum likelihood, with intercept 0‚Äù, this line is\n\\[\ny = \\widehat{\\beta}_{MLE}x = \\frac{\\sum_{i=1}^{N}x_iy_i}{\\sum_{i=1}^{N}x_i^2}x.\n\\]"
  },
  {
    "objectID": "writeups/optimization/index.html#general-constraints-only-optimization",
    "href": "writeups/optimization/index.html#general-constraints-only-optimization",
    "title": "Mathematical Optimization",
    "section": "General Constraints-Only Optimization",
    "text": "General Constraints-Only Optimization\nSeeing an optimization problem written out with only constraints looks a bit weird at first, but will be helpful to consider before we look at full-on constrained optimization.\nLike how we looked at a ‚Äúbasic‚Äù calculus problem before applying the same methodology to MLE before, here let‚Äôs look at a ‚Äúbasic‚Äù algebra problem with inequalities:\n\n\n\n\n\n\nExample 4: Inequality Constraints\n\n\n\nFind the value \\(x^*\\) which satisfies the system of inequalities\n\\[\n\\begin{alignat}{2}\nx^* = &&\\max_{x} \\quad &f(x,y) = 0 \\\\\n&&\\text{s.t.} \\quad & y \\geq x^2 + 1 \\\\\n&& \\quad & y \\leq \\sqrt{1 - x^2}\n\\end{alignat}\n\\]\n\n\nIt looks weird at first because, the \\(\\max_x\\) portion doesn‚Äôt give us anything to work with: we‚Äôre ‚Äúmaximizing‚Äù \\(f(x)\\) which is always just the number \\(0\\)! So, instead, we focus on just the constraints:\n\n\\(y \\geq x^2 + 1\\)\n\\(y \\leq \\sqrt{1 - x^2}\\)\n\nPlotting these two functions, we can see that they meet at exactly one point:\n\n\nCode\nlibrary(latex2exp)\nx_df &lt;- tibble(x=c(-2,2))\nf1 &lt;- function(x) x^2 + 1\nf1_lab &lt;- TeX(\"$y \\\\geq x^2 + 1$\")\nf2 &lt;- function(x) sqrt(1 - x^2)\nf2_lab &lt;- TeX(\"$y \\\\leq \\\\sqrt{1 - x^2}$\")\nsoln_df &lt;- tibble(x=0, y=1)\nx_df |&gt; ggplot(aes(x=x)) +\n  stat_function(fun=f1, color='black') +\n  stat_function(fun=f1, geom=\"ribbon\", mapping=aes(ymin=after_stat(y),ymax=4, fill=\"f1\"), alpha=0.5) +\n  stat_function(fun=f2, color='black') +\n  stat_function(fun=f2, geom=\"area\", aes(fill=\"f2\"), alpha=0.5) +\n  geom_point(data=soln_df, aes(x=x, y=y)) +\n  theme_classic() +\n  scale_fill_manual(\n    \"Constraints:\",\n    values=c(cb_palette[1], cb_palette[2]),\n    labels=c(f1_lab, f2_lab)\n  ) +\n  ylim(0,4)\n\n\n\n\n\n\n\n\n\nwhich means that we can solve for where they‚Äôre equal to derive the unique optimal solution \\(x^*\\)!\n\\[\n\\begin{align*}\n&x^2 + 1 = \\sqrt{1 - x^2} \\\\\n\\iff &(x^2 + 1)^2 = 1 - x^2 \\\\\n\\iff & x^4 + 2x^2 + 1 = 1 - x^2 \\\\\n\\iff & x^4 + 3x^2 = 0 \\\\\n\\iff & x^2(x^2 + 3) = 0,\n\\end{align*}\n\\]\nwhich means that the only possible solutions are the solutions to \\(x^2 = 0\\) and \\(x^2 + 3 = 0\\). The only \\(x\\) which satisfies \\(x^2 = 0\\) is \\(x^* = 0\\). The only \\(x\\) which satisfies \\(x^2 + 3 = 0\\) is \\(x^* = \\sqrt{-3}= \\pm 3i\\), meaning that our only real solution is \\(x^* = 0\\), forming the unique (real) solution to our optimization problem."
  },
  {
    "objectID": "writeups/optimization/index.html#gmm-estimation-as-constraints-only-optimization",
    "href": "writeups/optimization/index.html#gmm-estimation-as-constraints-only-optimization",
    "title": "Mathematical Optimization",
    "section": "GMM Estimation as Constraints-Only Optimization",
    "text": "GMM Estimation as Constraints-Only Optimization\nThe Generalized Method of Moments approach basically takes advantage of the type of ‚Äúcrunching‚Äù we saw in the previous example, setting up a system of equations which ‚Äúcrunches‚Äù the set of possible values for the desired parameter \\(\\param{\\theta}\\) down into just a single value.\nIt is able to accomplish this, basically, by saying:\nIf the entries in our dataset \\(\\mathbf{x} = (x_1, \\ldots, x_n)\\) are realizations of RVs \\(X_1, \\ldots, X_n\\) drawn i.i.d. from some distribution \\(\\mathcal{D}(\\param{\\boldsymbol\\theta})\\) with parameters \\(\\param{\\boldsymbol\\theta}\\), then the moments of the theoretical distribution \\(\\mathcal{D}(\\param{\\boldsymbol\\theta})\\) should match their observed counterparts.‚Äù\nSpecifically, \\(\\param{\\boldsymbol\\theta}\\) should be the value which makes the:\n\n\n\n\n\n\n\n\nExpected mean \\(\\mu = \\mathbb{E}[X_i]\\) of \\(X_i \\sim \\mathcal{D}(\\param{\\boldsymbol\\theta})\\)\nequal to the\nobserved mean of the dataset, \\(\\widehat{\\mu} = \\frac{1}{N}\\sum_{i=1}^{N}x_i\\)\n\n\nExpected variance \\(\\sigma^2 = \\mathbb{E}[(X_i - \\mu)^2]\\) of \\(X_i \\sim \\mathcal{D}(\\param{\\boldsymbol\\theta})\\)\nequal to the\nobserved variance of the dataset, \\(\\widehat{\\sigma^2} = \\frac{1}{N}\\sum_{i=1}^{N}(x_i - \\widehat{\\mu})^2\\)\n\n\nExpected skewness \\(\\gamma = \\mathbb{E}[(X_i - \\mu)^3]\\) of \\(X_i \\sim \\mathcal{D}(\\param{\\boldsymbol\\theta})\\)\nequal to the\nobserved skewness of the dataset, \\(\\widehat{\\gamma} = \\frac{1}{N}\\sum_{i=1}^{N}(x_i - \\widehat{\\mu})^3\\)\n\n\nExpected kurtosis \\(\\kappa = \\mathbb{E}[(X_i - \\mu)^4]\\) of \\(X_i \\sim \\mathcal{D}(\\param{\\boldsymbol\\theta})\\)\nequal to the\nobserved skewness of the dataset, \\(\\widehat{\\kappa} = \\frac{1}{N}\\sum_{i=1}^{N}(x_i - \\widehat{\\mu})^4\\)\n\n\n\nand so on‚Äîas many equations as we need to estimate the parameters \\(\\param{\\boldsymbol\\theta}\\) of the distribution \\(\\mathcal{D}\\)!\nSo, let‚Äôs repeat the earlier problem with the Poisson distribution, using GMM instead of MLE, to compute an estimator for the rate parameter \\(\\param{\\lambda}\\).\n\n\n\n\n\n\nExample 5: GMM Estimate for Poisson-Distributed RV\n\n\n\nGiven a dataset consisting of \\(N\\) i.i.d. realizations \\(\\mathbf{x} = (x_1, \\ldots, x_n)\\) of Poisson-distributed random variables\n\\[\nX_1, \\ldots, X_n \\sim \\text{Pois}(\\param{\\lambda}),\n\\]\nfind the Generalized Method of Moments estimate for the parameter \\(\\param{\\lambda}\\).\n\n\nHere, since our distribution only has one parameter \\(\\param{\\lambda}\\), we only need one equation in our system of equations, which will ‚Äúmatch‚Äù the expected value of a Poisson-distributed RV with the mean of our dataset \\(\\mathbf{x}\\):\n\\[\n\\begin{align*}\n&\\mu = \\widehat{\\mu} \\\\\n\\iff &\\mathbb{E}[X_i] = \\frac{1}{N}\\sum_{i=1}^{N}x_i \\\\\n\\iff &\\param{\\lambda} = \\frac{1}{N}\\sum_{i=1}^{N}x_i\n\\end{align*}\n\\]\nAnd‚Ä¶ yup, that‚Äôs it! Since the expected value of a poisson-distributed Random Variable \\(X_i\\) is just exactly the rate parameter \\(\\param{\\lambda}\\)3, we‚Äôve obtained the GMM estimate of \\(\\param{\\lambda}\\) as desired here, and we see that in fact the GMM estimator is the same as the MLE estimator in this case."
  },
  {
    "objectID": "writeups/optimization/index.html#general-constrained-optimization",
    "href": "writeups/optimization/index.html#general-constrained-optimization",
    "title": "Mathematical Optimization",
    "section": "General Constrained Optimization",
    "text": "General Constrained Optimization\nThough we introduced objective functions and constraints separately here, in reality most problems will require you to optimize with respect to both of these to find the solution to your problem.\nTo use the example I used throughout the semester one more time: if you are trying to estimate the population mean height from a sample of heights, you may want to have:\n\nAn objective function quantifying how ‚Äúgood‚Äù a normal distribution \\(\\mathcal{N}(\\mu, \\sigma^2)\\) is in terms of fitting the data (this would be precisely the likelihood function), but also\nA constraint on \\(\\mu\\) to ensure that you don‚Äôt get negative values (since heights in reality can‚Äôt be negative), and perhaps another constraint to ensure that you don‚Äôt get absurdly high numbers in the millions and billions as well.\n\nWhile you‚Äôve seen likelihood functions, constraints in optimization world are written out as:\n\nEqualities like \\(\\sum_{i=1}^{N}\\theta_i = 1\\) or\nInequalities like \\(\\theta_i &lt; 0.5 ~ \\forall i\\).\n\nSo, for the normal distribution example just mentioned, you could introduce inequality constraints to re-write the problem in the following form (where we just include the non-negative constraint, for simplicity):\n\\[\n\\begin{alignat}{2}\n\\boldsymbol\\theta^* = &&\\max_{\\param{\\mu}, \\sigma} \\quad &\\mathcal{L}(X = v_X \\mid \\param{\\mu}, \\sigma) \\\\\n&& \\text{s.t.} \\quad & \\param{\\mu} &gt; 0\n\\end{alignat}\n\\]\nThese two working together (the objective function and the constraints), it turns out, will ‚Äúsupercharge‚Äù your estimation! Now, instead of just guessing a random number from \\(-\\infty\\) to \\(\\infty\\) as your initial guess for \\(\\widehat{\\mu}\\), you have the power to ‚Äúguide‚Äù the optimization by (say) starting at the lower bound on \\(\\widehat{\\mu}\\), in this case, 0.\nFor solving by hand, though, we‚Äôll need to use a technique called the Lagrange Multiplier approach, to turn this constrained optimization problem back into an unconstrained optimization, since this is the case where we know how to use calculus to solve!\n\n\n\n\n\n\nExample 6: Constrained Optimization via Lagrange Multipliers\n\n\n\nFind the optimal value \\(x^*\\) for the following optimization problem:\n\\[\n\\begin{alignat}{2}\nx^* = &&\\min_{x} \\quad &f(x, y) = 2 - x^2 - 2y^2 \\\\\n&& \\text{s.t.} \\quad & x^2 + y^2 = 1\n\\end{alignat}\n\\]\n\n\nWe can visualize the two ‚Äúpieces‚Äù of this optimization, to see (finally!) how the objective function and the constraints come together:\n\n\nCode\nlibrary(ggforce)\nmy_f &lt;- function(x,y) 2 - x^2 - 2*y^2\nx_vals &lt;- seq(from=-2, to=2, by=0.1)\ny_vals &lt;- seq(from=-2, to=2, by=0.1)\ndata_df &lt;- expand_grid(x=x_vals, y=y_vals)\ndata_df &lt;- data_df |&gt; mutate(\n  z = my_f(x, y)\n)\ndata_df |&gt; ggplot(aes(x=x, y=y, z=z)) +\n  # geom_rect(xmin=0, xmax=1, ymin=-Inf, ymax=Inf, alpha=0.5, fill=cb_palette[1]) +\n  # geom_vline(xintercept=0, linewidth=0.75) +\n  geom_contour_filled(alpha=0.9, binwidth = 0.5, color='black', linewidth=0.2) +\n  geom_point(aes(x=0, y=0)) +\n  geom_circle(aes(x0=0, y0=0, r=1)) +\n  geom_segment(aes(x=0, y=0, xend=1, yend=0), linetype=\"dashed\") +\n  scale_fill_viridis_d(option=\"C\") +\n  theme_classic() +\n  # theme(legend.position=\"none\") +\n  coord_equal()\n\n\n\n\n\n\n\n\nFigure¬†1: The goal of our constrained optimization problem is to find the optimal value(s) \\((x^*,y^*)\\) which maximize \\(f(x,y)\\) (higher values are brighter yellow here), subject to the constraint that the point \\((x^*, y^*)\\) lies on the unit circle.\n\n\n\n\n\nSadly, our earlier approach of finding the derivative of the objective function, setting it equal to zero, and solving, won‚Äôt work here. Let‚Äôs see why. First compute the partial derivatives:\n\\[\n\\begin{align*}\n\\frac{\\partial}{\\partial x}f(x,y) = -2x \\\\\n\\frac{\\partial}{\\partial y}f(x,y) = -4y\n\\end{align*}\n\\]\nThen set them equal to zero and solve the system of equations:\n\\[\n\\begin{align*}\n\\frac{\\partial}{\\partial x}f(x,y) = 0 \\iff -2x^* = 0 \\iff &\\boxed{x^* = 0} \\\\\n\\frac{\\partial}{\\partial y}f(x,y) = 0 \\iff -4y^* = 0 \\iff &\\boxed{y^* = 0}.\n\\end{align*}\n\\]\nWe can see now that our computed optimal point, \\((0, 0)\\), violates the desired constraint, since it does not lie on the unit circle \\(x^2 + y^2 = 1\\):\n\\[\n(x^*)^2 + (y^*)^2 = 0^2 + 0^2 = 0 \\neq 1.\n\\]\nThe Lagrange Multiplier approach comes to the rescue here, because it allows us to use this same derivative-based method by incorporating the constraints into the function we take the derivative of and set equal to zero to solve.\nThe new approach you can use to solve for \\(x^*\\) in situations like this is based on constructing a new function \\(\\mathscr{L}(x, y, \\lambda)\\), called the Lagrangian, where the new parameter \\(\\lambda\\) is just the coefficient on a constraint function \\(g(x, y)\\).\nThis \\(g(x, y)\\) may seem complicated at first, but I think of it like a ‚Äúhelper function‚Äù which you derive from the constraint(s), finding a \\(g(x, y)\\) such that:\n\n\\(g(x) = 0\\) when the constraint is satisfied, and\n\\(g(x) \\neq 0\\) when the constraint is violated.\n\nIn our case, therefore, we can rewrite the constraint like:\n\\[\nx^2 + y^2 = 1 \\iff x^2 + y^2 - 1 = 0,\n\\]\nand choose our \\(g(x,y)\\) to be the left side of this equation: \\(g(x,y) = x^2 + y^2 - 1\\).\nWith our constraint function now chosen, we construct the Lagrangian:\n\\[\n\\begin{align*}\n\\mathscr{L}(x, \\lambda) &= f(x) + \\lambda g(x) = 2 - x^2 - 2y^2 + \\lambda(x^2 + y^2 - 1) \\\\\n&= 2 - x^2 - 2y^2 + \\lambda x^2 + \\lambda y^2 - \\lambda\n\\end{align*}\n\\]\nand optimize in the same way we‚Äôve always optimized via calculus, making sure to compute all three of the partial derivatives:\n\nWith respect to \\(x\\):\n\\[\n\\frac{\\partial \\mathscr{L}}{\\partial x} = -2x + 2\\lambda x\n\\]\nWith respect to \\(y\\):\n\\[\n\\frac{\\partial \\mathscr{L}}{\\partial y} = -4y + 2\\lambda y\n\\]\nAnd with respect to \\(\\lambda\\):\n\\[\n\\frac{\\partial \\mathscr{L}}{\\partial \\lambda} = x^2 + y^2 - 1\n\\]\n\nwe can now set all of these derivatives equal to zero, to obtain a system of equations:\n\\[\n\\begin{align*}\n-2x + 2\\lambda x &= 0 \\\\\n-4y + 2\\lambda y &= 0 \\\\\nx^2 + y^2 - 1 &= 0\n\\end{align*}\n\\]\nThere are a few ways to solve this system (including using matrices!), but here‚Äôs how I solved it, by solving for \\(\\lambda^*\\) first:\n\\[\n\\begin{align*}\n-2x + 2\\lambda^* x = 0 \\iff 2\\lambda^* x = 2x \\iff \\boxed{\\lambda^* = 1},\n\\end{align*}\n\\]\nthen deriving the value of \\(y\\):\n\\[\n\\begin{align*}\n&-4y^* + 2\\lambda^* y^* = 0 \\iff -4y^* + 2(1)y^* = 0 \\\\\n&\\iff -4y^* + 2y^* = 0 \\iff \\boxed{y^* = 0},\n\\end{align*}\n\\]\nand \\(x\\):\n\\[\n\\begin{align*}\n&(x^*)^2 + (y^*)^2 - 1 = 0 \\iff (x^*)^2 + (0)^2 - 1 = 0 \\\\\n&\\iff (x^*)^2 = 1 \\iff \\boxed{x^* = \\pm 1}\n\\end{align*}\n\\]\nAnd indeed, by looking at the plot in Figure¬†1 above, we see that \\((-1,0)\\) and \\((1,0)\\) are the two optimal values here!"
  },
  {
    "objectID": "writeups/optimization/index.html#references",
    "href": "writeups/optimization/index.html#references",
    "title": "Mathematical Optimization",
    "section": "References",
    "text": "References\n\n\nBoyd, Stephen P., and Lieven Vandenberghe. 2004. Convex Optimization. Cambridge University Press. https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf."
  },
  {
    "objectID": "writeups/optimization/index.html#footnotes",
    "href": "writeups/optimization/index.html#footnotes",
    "title": "Mathematical Optimization",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA somewhat important point, but I thought I‚Äôd make it a footnote in case it‚Äôs already clear to some folks: when you enter the ‚Äúworld‚Äù of optimization problems, you stop caring so much about whether the problem is a maximization or minimization problem. Instead, you literally just use whichever is easier to compute: the max of \\(f(x)\\) or the min of \\(-f(x)\\). To be a little more specific: in convex optimization, the most general type of optimization we have efficient algorithms for, you always minimize, and then just transform \\(f(x)\\) into \\(-f(x)\\) if your original intent was to maximize (this is‚Ä¶ by convention essentially. See Boyd and Vandenberghe (2004) for more!).‚Ü©Ô∏é\nNote how we use ‚Äú;‚Äù to separate random variables like \\(X\\) in this case from non-random variables like \\(\\lambda\\) in this case: sometimes people use the conditional operator ‚Äú|‚Äù for this, but that can sometimes lead to confusion since conditioning on the value of a Random Variable is different from having the value of a non-random variable as a parameter to the function.‚Ü©Ô∏é\nYou can find a proof of this fact here.‚Ü©Ô∏é"
  },
  {
    "objectID": "writeups/deriving-pdf/index.html",
    "href": "writeups/deriving-pdf/index.html",
    "title": "Deriving a pdf from Scratch",
    "section": "",
    "text": "Setting Random Seed\n\n\n\n(At the beginning of code where you‚Äôre dealing with distributions, make sure you set the random seed to 5100, or at least some constant value, to make sure results are reproducible across different computers at different times)\n\nset.seed(5100)\n# This just loads some global ggplot settings, you\n# can uncomment this if trying to run on your own/on Colab\nsource(\"../../dsan-globals/_globals.r\")\nOn the Lab 5 Assignment, I think a lot of students might be wrestling with what‚Äôs ‚Äúgoing on‚Äù on Problem 1, so I wanted to make a quick writeup with some intuition around where to start on this problem.\nWhereas in Problem 2 you are given a CDF (there are unknown variables, but you have something concrete to start ‚Äúdoing math‚Äù with), in Problem 1 it may seem at first like you don‚Äôt have enough information to complete the problem, since you only have information about a constraint on the possible values that \\(X\\) and \\(Y\\) can take on, rather than (e.g.) the actual probability density that the pdf \\(f_{X,Y}(x,y)\\) should take on.\nIn reality, though, that‚Äôs part of the difficulty of the problem: namely, how to derive a valid pdf from only these tiny scraps of information!"
  },
  {
    "objectID": "writeups/deriving-pdf/index.html#necessary-vs.-sufficient-conditions",
    "href": "writeups/deriving-pdf/index.html#necessary-vs.-sufficient-conditions",
    "title": "Deriving a pdf from Scratch",
    "section": "Necessary vs.¬†Sufficient Conditions",
    "text": "Necessary vs.¬†Sufficient Conditions\nBefore we start, in case the distinction between necessary and sufficient conditions isn‚Äôt something you‚Äôve learned before:\n\nIf [a predicate] \\(p\\) is necessary for [a predicate] \\(q\\), then if we know \\(p\\) is false then \\(q\\) must be false.\n\nFor example, let \\(p = [x &gt; 3]\\) and \\(q = [x &gt; 5]\\).\nThen \\(p\\) is a necessary condition for \\(q\\), because in this case if we know that \\(p\\) is false \\(q\\) must also be false.\nNote that the converse does not hold! That is, knowing that \\(p\\) is true does not tell us that \\(q\\) is true: if we know \\(p\\) (so we know that \\(x &gt; 3\\)), we still don‚Äôt know \\(q\\), since we could have e.g.¬†\\(x = 4\\).\n\nIf \\(p\\) is sufficient for \\(q\\), then if we know \\(p\\) is true we also know that \\(q\\) is true.\n\nFor example, let \\(p = [x\\text{ is divisible by }4]\\) and \\(q = [x\\text{ is even}]\\)\nThen \\(p\\) is a sufficient condition for \\(q\\), since all numbers divisible by 4 are also even.\nAgain you have to be careful, because the converse does not hold: knowing that \\(q\\) is false in this example does not tell us that \\(p\\) is false: if we know \\(\\neg q\\), we know \\(x\\) is not divisible by 4, but \\(p\\) can still be true, since e.g.¬†\\(x\\) could be 6 (an even number not divisible by 4).\n\n\nI think keeping this in mind is helpful for this specific problem, because we can think about the following two necessary conditions that must hold for a given function \\(f_Z(v)\\) to represent a valid pdf for the random variable \\(Z\\).\n\n\n\n\n\n\nGoing from Single-Valued to Multi-Valued pdfs\n\n\n\nI use \\(Z\\) to define the pdf \\(f_Z(v)\\) here to emphasize how pdfs are (at their core) defined for single random variables like \\(X\\), \\(Y\\), or \\(Z\\).\nNonetheless, as we enter into multivariable probability world we can consider \\(f_Z(v)\\) as the pdf for a vector-valued random variable \\(Z\\), so that \\(Z\\) can in fact represent a point that is decomposable into an \\(x\\)-coordinate (represented by a random variable \\(X\\)) and a \\(y\\)-coordinate (represented by a random variable \\(Y\\)). In this case, we can rewrite \\(Z\\) as \\((X,Y)\\) and call our pdf \\(f_{(X,Y)}(v_X, x_Y)\\), which for succinctness we usually shorten to just \\(f_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "writeups/deriving-pdf/index.html#two-necessary-conditions-for-a-valid-pdf-which-are-jointly-sufficient",
    "href": "writeups/deriving-pdf/index.html#two-necessary-conditions-for-a-valid-pdf-which-are-jointly-sufficient",
    "title": "Deriving a pdf from Scratch",
    "section": "Two Necessary Conditions for a Valid pdf Which Are Jointly Sufficient",
    "text": "Two Necessary Conditions for a Valid pdf Which Are Jointly Sufficient\nGiven the above definitions+examples of necessary vs.¬†sufficient conditions, here (if we call the first condition \\(NC_1\\) and the second \\(NC_2\\)) they are individually necessary but jointly sufficient: meaning that if we define a new condition \\(B\\) for ‚Äúboth‚Äù, such that \\(B = (NC_1 \\wedge NC_2)\\), then \\(B\\) is in fact a sufficient condition for \\(f\\) to be a valid pdf. If we can ensure that both of the necessary conditions given below are true, then we know that our function \\(f_Z\\) defines a valid pdf for a random variable \\(Z\\).\n\nNecessary Condition 1 (\\(NC_1\\), Single-Variable): The integral of the pdf \\(f_Z(v)\\) over \\(\\mathcal{R}_Z\\) (where \\(\\mathcal{R}_Z\\) is the support of \\(Z\\)) must equal 1.\nNecessary Condition 1 (\\(NC_1\\), Multi-Value): The double-integral of the pdf \\(f_{X,Y}(x,y)\\) over \\(\\mathcal{R}_X\\) and \\(\\mathcal{R}_Y\\) must equal 1.\nNecessary Condition 2 (\\(NC_2\\), Single-Value): If \\(Z\\) is defined over a range \\([a, b]\\), then the pdf \\(f_Z\\) must assign nonzero probability density to all non-empty one-dimensional intervals of radius \\(\\varepsilon\\) around \\(v \\in [a,b]\\), and zero probability density to all other intervals.\nNecessary Condition 2 (\\(NC_2\\), Multi-Value): If \\(X\\) is defined over a range \\([a_X, b_X]\\) and \\(Y\\) is defined over a range \\([a_Y, b_Y]\\), then the pdf \\(f_{X,Y}\\) must assign nonzero probability density to all non-empty two-dimensional circles of radius \\(\\varepsilon\\) around points \\(\\{ (x,y) \\mid x \\in [a_X,b_X]\\text{ and }y \\in [a_Y,b_Y]\\}\\).\n\nI know Necessary Condition 2 is extremely scary-looking and confusing, but it is mainly that way to handle extremely ‚Äúweird‚Äù cases where we‚Äôd like to define probability distributions over bizarre sets like the Sierpi≈Ñski triangle.\nSince in Problem 1 on the Lab Assignment we are working with a nicely-behaved set (the set that you plotted in part 1, which is just a triangle taking up the bottom 1/2 of the unit square), we can transform Necessary Condition 2 into a much more intuitive version\n\nNecessary Condition 2 (\\(NC_2\\), RVs Defined over ‚ÄúWell-Behaved‚Äù Spaces): If \\(X\\) is defined over a range \\([a_X, b_X]\\) and \\(Y\\) is defined over a range \\([a_Y, b_Y]\\), then the pdf \\(f_{X,Y}\\) must assign nonzero probability density to all points \\(\\{(x,y) \\mid x \\in [a_X,b_X]\\text{ and }y \\in [a_Y,b_Y]\\}\\).\n\nIf the difference between the ‚Äúwell-behaved‚Äù case and the general case above is not clear, compare the definitions closely (in the ‚Äúsimplified version‚Äù just given, we don‚Äôt have to worry about circles around points, just points themselves)."
  },
  {
    "objectID": "writeups/deriving-pdf/index.html#why-are-you-telling-us-all-this-how-does-it-help-solve-problem-1",
    "href": "writeups/deriving-pdf/index.html#why-are-you-telling-us-all-this-how-does-it-help-solve-problem-1",
    "title": "Deriving a pdf from Scratch",
    "section": "Why Are You Telling Us All This? How Does It Help Solve Problem 1?",
    "text": "Why Are You Telling Us All This? How Does It Help Solve Problem 1?\nIf you‚Äôve made it all the way to this point, you may be frustrated that I still haven‚Äôt pointed exactly to how these two conditions help us solve Problem 1.\nSince I can‚Äôt give away the solution for that particular problem, here I will show the applicability of these two conditions to a similar problem, and then your job is to think about how the way I work through this problem can help you work through problem 1.\nThe example problem: Given two random variables \\(X \\sim \\mathcal{U}[0,1]\\) and \\(Y \\sim \\mathcal{U}[0,1]\\), consider the joint distribution of the vector-valued random variable \\(Z = (X,Y)\\), where the possible realizations of \\(Z\\) are restricted to only those values of \\(X\\) and \\(Y\\) such that they lie within a circle of radius \\(1\\) around the origin: that is, \\(X^2 + Y^2 &lt; 1\\). This means that we could create a plot which ‚Äúfills in‚Äù the possible values of \\(Z\\) more and more as we sample more points, by generating values of \\(X\\) sampled from from \\(\\mathcal{U}[0,1]\\) and values of \\(Y\\) sampled from \\(\\mathcal{U}[0,1]\\), then placing the points on the plot if they are ‚Äúadmissible‚Äù (if they form a valid realization of \\(Z\\)) and throwing the points away otherwise:\n\nlibrary(tidyverse)\nN &lt;- 2500\nx_vals &lt;- runif(N, -1, 1)\ny_vals &lt;- runif(N, -1, 1)\nsample_df &lt;- tibble(x=x_vals, y=y_vals)\nsample_df &lt;- sample_df |&gt;\n  mutate(\n    admissible = x^2 + y^2 &lt; 1\n  )\nsample_df |&gt; head()\n\n\n\n\n\nx\ny\nadmissible\n\n\n\n\n0.0853844\n0.4159406\nTRUE\n\n\n-0.4991692\n-0.6671818\nTRUE\n\n\n-0.5449181\n0.9697597\nFALSE\n\n\n-0.2142207\n-0.8855359\nTRUE\n\n\n0.8015973\n0.2324585\nTRUE\n\n\n-0.6283825\n-0.0055527\nTRUE\n\n\n\n\n\n\nWe see that, given how admissible is defined, plotting only the points for which admissible == TRUE will mean that we are ‚Äúfilling out‚Äù the subset of all possible values in the square \\([-1,1] \\times [-1,1]\\) that satisfy our contstraint:\n\nadmissible_df &lt;- sample_df |&gt;\n  filter(admissible)\nggplot(admissible_df, aes(x=x, y=y)) +\n  geom_point() +\n  dsan_theme() +\n  # If you were wondering how to make it an actual perfect circle\n  coord_fixed()\n\n\n\n\n\n\n\n\nAnd now we can finally use our two necessary conditions, albeit in reverse order:\n\nApplying Necessary Condition 2 (Simplified Version) To This Case:\nTo satisfy this condition, let‚Äôs literally just define a pdf \\(f_{X,Y}\\) that has some non-zero value \\(c\\) for points within the circle in the above plot, and has value \\(0\\) otherwise:\n\\[\nf_{X,Y}(x,y) = \\begin{cases}\nc &\\text{if }x^2 + y^2 &lt; 1, \\\\\n0 &\\text{otherwise.}\n\\end{cases}\n\\]\nSo far, we‚Äôve satisfied Necessary Condition 1 (\\(NC_1\\)) for \\(f_{X,Y}\\) to be a valid pdf. Now if we can figure out how to also make this function satisfy Necessary Condition 2 (\\(NC_2\\)), we‚Äôll know that we have a valid pdf for \\(Z = (X,Y)\\).\n\n\nApplying Necessary Condition 1 To This Case\nGiven that \\(X\\) and \\(Y\\) are both defined (in a nicely-behaved way) over the range \\([-1,1]\\), the remaining condition \\(NC_1\\) is satisfied if the following equality holds:\n\\[\n\\int_{-1}^{1}\\int_{-1}^{1}f_{X,Y}(x,y)dxdy = 1\n\\tag{1}\\]\nIf you calculate these two definite integrals (you could do it using fancy math, like variable substitution, or just using geometry, e.g.¬†by thinking about what the integral would be given what you know about the areas of circles), you will find that this integral-filled equality reduces to the equality\n\\[\nc\\pi = 1\n\\]\nSo that, finally, we can solve for the value of \\(c\\) which now lets us ‚Äúfill in this detail‚Äù: that if we choose \\(c = \\frac{1}{\\pi}\\), so that\n\\[\nf_{X,Y}(x,y) = \\begin{cases}\n\\frac{1}{\\pi} &\\text{if }x^2 + y^2 &lt; 1, \\\\\n0 &\\text{otherwise.}\n\\end{cases}\n\\]\nthen we get a nice chain of realizations:\n\nThe equality Equation¬†1 holds, so\nWe have satisfied \\(NC_1\\), after already satisfying \\(NC_2\\) above, so\nWe have now satisfied both \\(NC_1\\) and \\(NC_2\\),\nThis means we have satisfied \\(B\\), so that finally\nWe have defined a valid pdf \\(f_{X,Y}(x,y)\\) (since \\(B\\) is a sufficient condition for valid pdfs).\n\nI hope that helps somewhat: I wrote things out in excruciating detail, using necessary and sufficient conditions and etc., to try and show how there is a general logic to these types of problems (or at least, a general logic for how we can use the information we‚Äôre given to construct a distribution which encodes this information)."
  },
  {
    "objectID": "w02/slides.html#prof.-jeff-introduction",
    "href": "w02/slides.html#prof.-jeff-introduction",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Prof.¬†Jeff Introduction!",
    "text": "Prof.¬†Jeff Introduction!\n\nBorn and raised in NW DC ‚Üí high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Economics (2008-2012)"
  },
  {
    "objectID": "w02/slides.html#grad-school",
    "href": "w02/slides.html#grad-school",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Grad School",
    "text": "Grad School\n\nStudied abroad in Beijing (Peking University/ÂåóÂ§ß) ‚Üí internship with Huawei in Hong Kong (HKUST)\n\n\n\n\nStanford for MS in Computer Science (2012-2014)\nResearch Economist at UC Berkeley (2014-2015)\n\n\n\n\n\nColumbia (NYC) for PhD[+Postdoc] in Political Science (2015-2023)"
  },
  {
    "objectID": "w02/slides.html#dissertation-political-science-history",
    "href": "w02/slides.html#dissertation-political-science-history",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Dissertation (Political Science + History)",
    "text": "Dissertation (Political Science + History)\n‚ÄúOur Word is Our Weapon‚Äù: Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada"
  },
  {
    "objectID": "w02/slides.html#research-labor-economics",
    "href": "w02/slides.html#research-labor-economics",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Research (Labor Economics)",
    "text": "Research (Labor Economics)\n\n\n\n‚ÄúMonopsony in Online Labor Markets‚Äù: Machine Learning to enhance causal estimates of the effect of job description language on uptake rate\n\n\n\n‚ÄúFreedom as Non-Domination in the Labor Market‚Äù: Game-theoretic models of workers‚Äô rights (monopsony vs.¬†labor discipline)\n\n\n\n\n‚ÄúUnsupervised Extraction of Workplace Rights and Duties from Collective Bargaining Agreements‚Äù: Linguistic (dependency) parses of contracts ‚Üí time series of worker vs.¬†employer rights and responsibilities over time"
  },
  {
    "objectID": "w02/slides.html#deterministic-processes",
    "href": "w02/slides.html#deterministic-processes",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Deterministic Processes",
    "text": "Deterministic Processes\n\nGiven a set of inputs, we can compute the outcome exactly\nExample: Given the radius of a circle, we can compute its area without any uncertainty. \\(r \\mapsto \\pi r^2\\)\n(The fact that we can compute the outcome doesn‚Äôt mean that it‚Äôs easy to do so! See, e.g., the double pendulum)\n\n\nImage credit: Tenor.com\nThe pendulum example points to the fact that the notion of a chaotic system, one which is ‚Äúsensitive to initial conditions‚Äù, is different from that of a stochastic system."
  },
  {
    "objectID": "w02/slides.html#holy-grail-deterministic-model-newtonian-physics",
    "href": "w02/slides.html#holy-grail-deterministic-model-newtonian-physics",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "‚ÄúHoly Grail‚Äù Deterministic Model: Newtonian Physics",
    "text": "‚ÄúHoly Grail‚Äù Deterministic Model: Newtonian Physics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\leadsto F_g = G\\frac{m_1m_2}{r^2}\n\\]\n\n\nFigure¬†1: Newton‚Äôs Law of Universal Gravitation‚Üê Dr.¬†Zirkel follows Newton‚Äôs famous steps. Coloured wood engraving. Wellcome Collection (Public Domain)"
  },
  {
    "objectID": "w02/slides.html#but-what-happens-when",
    "href": "w02/slides.html#but-what-happens-when",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "But What Happens When‚Ä¶",
    "text": "But What Happens When‚Ä¶\n\\[\n\\text{Outcome}\\left(\\text{Dice Roll}\\right) = \\; ?\\frac{?_1?_2}{?^2}\n\\]\n\n\n\nPre-Enlightenment\n\n\n\n\nHans Sebald Beham, Fortuna (1541), via Wikimedia Commons\n\n\n\n\nPost-Enlightenment\n\n\n\n\nBlaise Pascal, Trait√© du triangle arithm√©tique (1665), via Internet Archive"
  },
  {
    "objectID": "w02/slides.html#random-processes",
    "href": "w02/slides.html#random-processes",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Random Processes",
    "text": "Random Processes\n\n\n\nCan‚Äôt compute the outcome exactly, but can still say something about potential outcomes!\nExample: randomly chosen radius \\(r \\in [0,1]\\), what can we say about \\(A = \\pi r^2\\)?\nUnif: \\([0,\\pi]\\) equally likely\nExp: closer to \\(0\\) more likely\n\n\n\n\n\nCode\nplot_circ_with_distr &lt;- function(N, radii, ptitle, alpha=0.1) {\n  theta &lt;- seq(0, 360, 4)\n  #hist(radii)\n  circ_df &lt;- expand.grid(x = theta, y = radii)\n  #circ_df\n  ggplot(circ_df, aes(x = x, y = y, group = y)) +\n      geom_path(alpha = alpha, color = cbPalette[1], linewidth=g_linesize) +\n      # Plot the full unit circle\n      geom_path(data = data.frame(x = theta, y = 1), aes(x = x), linewidth=g_linesize) +\n      geom_point(data = data.frame(x = 0, y = 0), aes(x = x), size = g_pointsize) +\n      coord_polar(theta = \"x\", start = -pi / 2, direction = -1) +\n      ylim(0, 1) +\n      # scale_x_continuous(limits=c(0,360), breaks=seq(0,360,by=45)) +\n      scale_x_continuous(limits = c(0, 360), breaks = NULL) +\n      dsan_theme(\"quarter\") +\n      labs(\n          title = ptitle,\n          x = NULL,\n          y = NULL\n      ) +\n      # See https://stackoverflow.com/a/19821839\n      theme(\n          axis.line = element_blank(),\n          axis.text = element_blank(),\n          axis.ticks = element_blank(),\n          axis.title = element_blank(),\n          panel.border = element_blank(),\n          panel.grid.major=element_blank(),\n          panel.grid.minor=element_blank(),\n          plot.margin = unit(c(0,0,0,0), \"cm\"),\n          title = element_text(size=18)\n      )\n}\nN &lt;- 500\nradii &lt;- runif(N, 0, 1)\ntitle &lt;- paste0(N, \" Uniformly-Distributed Radii\")\nalpha &lt;- 0.2\nplot_circ_with_distr(N, radii, title, alpha)\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\nN &lt;- 1000\nradii &lt;- rexp(N, 4)\ntitle &lt;- paste0(N, \" Exponentially-Distributed Radii\")\nplot_circ_with_distr(N, radii, title, alpha=0.15)"
  },
  {
    "objectID": "w02/slides.html#data-ground-truth-noise",
    "href": "w02/slides.html#data-ground-truth-noise",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Data = Ground Truth + Noise",
    "text": "Data = Ground Truth + Noise\n\nDepressing but true origin of statistics (as opposed to probability): the Plague üò∑\n\n\n\n\n\n\nGround Truth: The Great Plague (Lord Have Mercy on London, Unknown Artist, circa 1665, via Wikimedia Commons)\n\n\n\n\n\n\nNoisy Data (Recorded amidst chaos): London Bill of Mortality, 1665 (Public Domain, Wellcome Collection)"
  },
  {
    "objectID": "w02/slides.html#random-variables",
    "href": "w02/slides.html#random-variables",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Random Variables",
    "text": "Random Variables\n\nIn algebra, to solve problems we work with variables\nIn probability theory, to solve problems we work with random variables\nRecall the difference between random and deterministic: \\(A = \\pi r^2\\) tells us that, given a value of \\(r\\), we can solve for the unique value of \\(A\\)\nIn probability theory, however, there is no one ‚Äútrue‚Äù value of a random variable \\(X\\).\nLet \\(X = f(N)\\) mean that \\(X\\) is the result of a rolled die, where the die has \\(N\\) sides.\nPlugging in \\(N = 6\\) (standard 6-sided die) still doesn‚Äôt mean we know ‚Äúthe‚Äù value of \\(X\\). However, (if the die is fair) we do know\n\n\\[\n\\Pr(X = 1) = \\Pr(X = 2) = \\cdots = \\Pr(X = 6) = \\frac{1}{6}\n\\]"
  },
  {
    "objectID": "w02/slides.html#discrete-vs.-continuous",
    "href": "w02/slides.html#discrete-vs.-continuous",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Discrete vs.¬†Continuous",
    "text": "Discrete vs.¬†Continuous\n\nMany complicated definitions, often misleading or unintuitive!\nHow I want you to remember: How many possible values between two known values?\nDiscrete: e.g., number of siblings\n\nI have 2 siblings, you have 3 siblings‚Ä¶ How many values (sibling counts) in between?\n\nContinuous: e.g., temperature\n\nIt is 27.0¬∞ C in my room, 28.0¬∞ C in your room‚Ä¶ How many values (temperatures) in between?\n\nSo, if \\(X\\) is the result of a rolled die, is \\(X\\) discrete or continuous? How many values can be rolled between 3 and 4?"
  },
  {
    "objectID": "w02/slides.html#thinking-about-independence",
    "href": "w02/slides.html#thinking-about-independence",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Thinking About Independence",
    "text": "Thinking About Independence\n\nWe‚Äôll define it formally later; for now, this is our working definition:\n\n\n\n\n\n Working Definition: Independence\n\n\nTwo random variables \\(X\\) and \\(Y\\) are independent if learning information about \\(X\\) does not give you information about the value of \\(Y\\), or vice-versa."
  },
  {
    "objectID": "w02/slides.html#na√Øve-definition-of-probability",
    "href": "w02/slides.html#na√Øve-definition-of-probability",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Na√Øve Definition of Probability",
    "text": "Na√Øve Definition of Probability\n\nSample Space: The set of all possible outcomes of an experiment\nEvent: A subset of the sample space\n\n\n\n\n\n Na√Øve Definition of Probability\n\n\nGiven a sample space \\(S\\), and an event \\(E \\subset S\\),\n\\[\n\\Pr(\\underbrace{E}_{\\text{event}}) = \\frac{\\text{\\# Favorable Outcomes}}{\\text{\\# Possible Outcomes}} = \\frac{|E|}{|S|}\n\\]"
  },
  {
    "objectID": "w02/slides.html#example-flipping-two-coins",
    "href": "w02/slides.html#example-flipping-two-coins",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Example: Flipping Two Coins",
    "text": "Example: Flipping Two Coins\n\n\n\n\n Na√Øve Definition of Probability\n\n\nGiven a sample space \\(S\\), and an event \\(E \\subset S\\),\n\\[\n\\Pr(\\underbrace{E}_{\\text{event}}) = \\frac{\\text{\\# Favorable Outcomes}}{\\text{\\# Possible Outcomes}} = \\frac{|E|}{|S|}\n\\]\n\n\n\n\n\nSample space \\(S = \\{TT, TH, HT, HH\\}\\)\nEvent \\(E_1\\): Result of first flip is \\(H\\), result of second flip is \\(T\\) \\(\\implies\\) \\(E_1 = \\{HT\\}\\)\nEvent \\(E_2\\): At least one \\(H\\) \\(\\implies\\) \\(E_2 = \\{TH, HT, HH\\}\\)\n\n\\[\n\\begin{align*}\n\\Pr(E_1) &= \\frac{|\\{HT\\}|}{|S|} = \\frac{|\\{HT\\}|}{|\\{TT, TH, HT, HH\\}|} = \\frac{1}{4} \\\\\n\\Pr(E_2) &= \\frac{|\\{TH, HT, HH\\}|}{|S|} = \\frac{|\\{TH, HT, HH\\}|}{|\\{TT, TH, HT, HH\\}|} = \\frac{3}{4}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w02/slides.html#events-neq-outcomes",
    "href": "w02/slides.html#events-neq-outcomes",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Events \\(\\neq\\) Outcomes!",
    "text": "Events \\(\\neq\\) Outcomes!\n\nOutcomes are things, events are sets of things\nSubtle but extremely important distinction!\nIn the coin flip example:\n\nThe event \\(E_1 = \\{HT\\}\\) can be confused with the outcome \\(HT\\).\nSo, try to remember instead the event \\(E_2 = \\{TH, HT, HH\\}\\): it is more clear, in this case, how this event does not correspond to any individual outcome"
  },
  {
    "objectID": "w02/slides.html#back-to-the-na√Øve-definition",
    "href": "w02/slides.html#back-to-the-na√Øve-definition",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Back to the Na√Øve Definition",
    "text": "Back to the Na√Øve Definition\n\n\n\n\n Na√Øve Definition of Probability\n\n\nGiven a sample space \\(S\\), and an event \\(E \\subset S\\),\n\\[\n\\Pr(\\underbrace{E}_{\\text{event}}) = \\frac{\\text{\\# Favorable Outcomes}}{\\text{\\# Possible Outcomes}} = \\frac{|E|}{|S|}\n\\]\n\n\n\n\n\nThe na√Øve definition tells us that probabilities are just ratios of counts:\n\nCount the number of ways the event \\(E\\) can happen, count the total number of things that can happen, and divide!\n\nThis is why we begin studying probability by studying combinatorics: the mathematics of counting"
  },
  {
    "objectID": "w02/slides.html#combinatorics-ice-cream-possibilities",
    "href": "w02/slides.html#combinatorics-ice-cream-possibilities",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Combinatorics: Ice Cream Possibilities",
    "text": "Combinatorics: Ice Cream Possibilities\n\n\n\n\n\nThe \\(6 = \\color{red}\\boxed{\\color{black}2 \\cdot 3}\\) possible cone+flavor combinations which can result from choosing a flavor first and a cone type second.\n\n\n\n\n\n\nThe \\(6 = \\color{red}\\boxed{\\color{black}3 \\cdot 2}\\) possible cone+flavor combinations which can result from choosing a flavor first and a cone type second."
  },
  {
    "objectID": "w02/slides.html#grouping-vs.-ordering",
    "href": "w02/slides.html#grouping-vs.-ordering",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Grouping vs.¬†Ordering",
    "text": "Grouping vs.¬†Ordering\n\nIn standard statistics/combinatorics introductions you‚Äôll learn different counting formulas for when order matters vs.¬†when order doesn‚Äôt matter\nThis is not a mathematical distinction so much as a pragmatic distinction: what are you trying to accomplish by counting?\nProblems with extremely similar descriptions can differ in small detail, so that the units you need to distinguish between in one version differ from the units you need to distinguish between in the other."
  },
  {
    "objectID": "w02/slides.html#does-order-matter",
    "href": "w02/slides.html#does-order-matter",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Does Order Matter?",
    "text": "Does Order Matter?\n\n\n\n\n Example: Student Government vs.¬†Student Sports\n\n\n\nConsider a school where students can either try out for swim team or run for a position in student government\nThe swim team has 4 slots, but slots aren‚Äôt differentiated: you‚Äôre either on the team (one of the chosen students) or not\nThe student government also has 4 slots, but there is a difference between the slots: first slot is President, second is Vice President, third is Secretary, and fourth is Treasurer.\n\n\n\n\n\n\nSimple case (for intuition): school only has 4 students. In this case, how many ways are there to form the swim team? What about the student government?\n\nSwim team: \\(1\\) way. You have only one choice, let all 4 students onto team\nStudent government: \\(4 \\cdot 3 \\cdot 2 \\cdot 1 = 24\\) ways. You have to let all 4 in, but you have a choice of who is President, Vice President, Secretary, and Treasurer\n\nHow did we get \\(4 \\cdot 3 \\cdot 2 \\cdot 1\\)? (Think about the ice cream example‚Ä¶)\n\nStart by choosing the President: 4 choices\nNow choose the Vice President: only 3 students left to choose from\nNow choose the Secretary: only 2 students left to choose from\nNow choose the Treasurer: only 1 student left to choose from"
  },
  {
    "objectID": "w02/slides.html#permutations-vs.-combinations",
    "href": "w02/slides.html#permutations-vs.-combinations",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Permutations vs.¬†Combinations",
    "text": "Permutations vs.¬†Combinations\n\nPermutations: How many ways can I choose groups of size \\(k\\) out of \\(n\\) total objects, where order within groups matters: \\(P_{n,k}\\) (sometimes written \\(_nP_k\\)).\n\nIn this case, we want to count \\((a,b)\\) and \\((b,a)\\) as two separate groups\n\nCombinations: How many ways can I choose groups of size \\(k\\) out of \\(n\\) total objects, where order in the groups doesn‚Äôt matter: \\(C_{n,k}\\) (sometimes written \\(_nC_k,\\binom{n}{k}\\)).\n\nIn this case, we don‚Äôt want to count \\((a, b)\\) and \\((b, a)\\) as two separate groups‚Ä¶\n\n\n\\[\n\\begin{align*}\nP_{n,k} = \\frac{n!}{(n-k)!}, \\; C_{n,k} = \\frac{n!}{k!(n-k)!}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w02/slides.html#no-need-to-memorize",
    "href": "w02/slides.html#no-need-to-memorize",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "No Need to Memorize!",
    "text": "No Need to Memorize!\n\nKey point: you don‚Äôt have to remember these as two separate formulas!\nThe number of combinations is based on the number of permutations, but corrected for double counting: e.g., corrected for the fact that \\((a,b) \\neq (b,a)\\) when counting permutations but \\((a,b) = (b,a)\\) when counting combinations.\n\n\\[\nC_{n,k} = \\frac{P_{n,k}}{k!} \\genfrac{}{}{0pt}{}{\\leftarrow \\text{Permutations}}{\\leftarrow \\text{Duplicate groups}}\n\\]\nWhere does \\(k!\\) come from? (How many different orderings can we make of the same group?)\n\n\\(k = 2\\): \\((\\underbrace{\\boxed{\\phantom{a}}}_{\\text{2 choices}},\\underbrace{\\boxed{\\phantom{a}}}_{\\text{1 remaining choice}}) \\implies 2\\)\n\\(k = 3\\): \\((\\underbrace{\\boxed{\\phantom{a}}}_{\\text{3 choices}},\\underbrace{\\boxed{\\phantom{a}}}_{\\text{2 remaining choices}}, \\underbrace{\\boxed{\\phantom{a}}}_{\\text{1 remaining choice}}) \\implies 6\\)\n\\(k = 4\\): \\((\\underbrace{\\boxed{\\phantom{a}}}_{\\text{4 choices}}, \\underbrace{\\boxed{\\phantom{a}}}_{\\text{3 remaining choices}}, \\underbrace{\\boxed{\\phantom{a}}}_{\\text{2 remaining choices}}, \\underbrace{\\boxed{\\phantom{a}}}_{\\text{1 remaining choice}}) \\implies 24\\)"
  },
  {
    "objectID": "w02/slides.html#with-or-without-replacement",
    "href": "w02/slides.html#with-or-without-replacement",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "With or Without Replacement?",
    "text": "With or Without Replacement?\n\nBoils down to: can the same object be included in my sample more than once?\n\n\n\n\nWithout Replacement\nWith Replacement\n\n\n\n\nMost statistical problems: ‚ÄúCheck off‚Äù objects as you collect data about them, so that each observation in your data is unique\nSpecial (but important!) set of statistical problems: let objects appear in your sample multiple times, to ‚Äúsqueeze‚Äù more information out of the sample (called Bootstrapping‚Äîmuch more later in the course!)"
  },
  {
    "objectID": "w02/slides.html#how-many-possible-samples",
    "href": "w02/slides.html#how-many-possible-samples",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "How Many Possible Samples?",
    "text": "How Many Possible Samples?\nExample: From \\(N = 3\\) population, how many ways can we take samples of size \\(k = 2\\)?\n\n\n\n\n\n\n\nWithout Replacement\nWith Replacement\n\n\n\n\n\\(3 \\cdot 2 = 6\\) ways (3 objects to choose from for first element of sample, 2 remaining objects to choose from for second element of sample)\n\\(3\\cdot 3 = 3^2 = 9\\) ways (3 objects to choose from for first element of sample, still 3 objects to choose from for second element of sample)\n\n\n\nGeneral Case: From population of size \\(N\\), how many ways can we take samples of size \\(k\\)? (Try to extrapolate from above example before looking at answer!)\n\n\n\n\n\n\n\n\nWithout Replacement\nWith Replacement\n\n\n\n\n\\(\\displaystyle \\underbrace{N \\cdot (N-1) \\cdot \\cdots \\cdot (N - k + 1)}_{k\\text{ times}} = \\frac{N!}{(N - k )!}\\)(This formula should look somewhat familiar‚Ä¶)\n\\(\\displaystyle \\underbrace{N \\cdot N \\cdot \\cdots \\cdot N}_{k\\text{ times}} = N^k\\)"
  },
  {
    "objectID": "w02/slides.html#link-to-colab-notebook",
    "href": "w02/slides.html#link-to-colab-notebook",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Link to Colab Notebook",
    "text": "Link to Colab Notebook\n\nDSAN 5100-03 Lab 02"
  },
  {
    "objectID": "w02/slides.html#references",
    "href": "w02/slides.html#references",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nDSAN 5100-03 W02: Probabilistic Modeling"
  },
  {
    "objectID": "w02/index.html",
    "href": "w02/index.html",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "",
    "text": "Open slides in new window ‚Üí",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#prof.-jeff-introduction",
    "href": "w02/index.html#prof.-jeff-introduction",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Prof.¬†Jeff Introduction!",
    "text": "Prof.¬†Jeff Introduction!\n\nBorn and raised in NW DC ‚Üí high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Economics (2008-2012)",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#grad-school",
    "href": "w02/index.html#grad-school",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Grad School",
    "text": "Grad School\n\nStudied abroad in Beijing (Peking University/ÂåóÂ§ß) ‚Üí internship with Huawei in Hong Kong (HKUST)\n\n\n\n\nStanford for MS in Computer Science (2012-2014)\nResearch Economist at UC Berkeley (2014-2015)\n\n\n\n\n\n\nColumbia (NYC) for PhD[+Postdoc] in Political Science (2015-2023)",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#dissertation-political-science-history",
    "href": "w02/index.html#dissertation-political-science-history",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Dissertation (Political Science + History)",
    "text": "Dissertation (Political Science + History)\n‚ÄúOur Word is Our Weapon‚Äù: Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#research-labor-economics",
    "href": "w02/index.html#research-labor-economics",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Research (Labor Economics)",
    "text": "Research (Labor Economics)\n\n\n\n‚ÄúMonopsony in Online Labor Markets‚Äù: Machine Learning to enhance causal estimates of the effect of job description language on uptake rate\n\n\n\n‚ÄúFreedom as Non-Domination in the Labor Market‚Äù: Game-theoretic models of workers‚Äô rights (monopsony vs.¬†labor discipline)\n\n\n\n\n\n‚ÄúUnsupervised Extraction of Workplace Rights and Duties from Collective Bargaining Agreements‚Äù: Linguistic (dependency) parses of contracts ‚Üí time series of worker vs.¬†employer rights and responsibilities over time",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#deterministic-processes",
    "href": "w02/index.html#deterministic-processes",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Deterministic Processes",
    "text": "Deterministic Processes\n\nGiven a set of inputs, we can compute the outcome exactly\nExample: Given the radius of a circle, we can compute its area without any uncertainty. \\(r \\mapsto \\pi r^2\\)\n(The fact that we can compute the outcome doesn‚Äôt mean that it‚Äôs easy to do so! See, e.g., the double pendulum)\n\n\n\n\nImage credit: Tenor.com\n\n\n\nThe pendulum example points to the fact that the notion of a chaotic system, one which is ‚Äúsensitive to initial conditions‚Äù, is different from that of a stochastic system.",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#holy-grail-deterministic-model-newtonian-physics",
    "href": "w02/index.html#holy-grail-deterministic-model-newtonian-physics",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "‚ÄúHoly Grail‚Äù Deterministic Model: Newtonian Physics",
    "text": "‚ÄúHoly Grail‚Äù Deterministic Model: Newtonian Physics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\leadsto F_g = G\\frac{m_1m_2}{r^2}\n\\]\n\n\nFigure¬†1: Newton‚Äôs Law of Universal Gravitation‚Üê Dr.¬†Zirkel follows Newton‚Äôs famous steps. Coloured wood engraving. Wellcome Collection (Public Domain)",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#but-what-happens-when",
    "href": "w02/index.html#but-what-happens-when",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "But What Happens When‚Ä¶",
    "text": "But What Happens When‚Ä¶\n\\[\n\\text{Outcome}\\left(\\text{Dice Roll}\\right) = \\; ?\\frac{?_1?_2}{?^2}\n\\]\n\n\n\nPre-Enlightenment\n\n\n\n\nHans Sebald Beham, Fortuna (1541), via Wikimedia Commons\n\n\n\n\nPost-Enlightenment\n\n\n\n\nBlaise Pascal, Trait√© du triangle arithm√©tique (1665), via Internet Archive",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#random-processes",
    "href": "w02/index.html#random-processes",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Random Processes",
    "text": "Random Processes\n\n\n\nCan‚Äôt compute the outcome exactly, but can still say something about potential outcomes!\nExample: randomly chosen radius \\(r \\in [0,1]\\), what can we say about \\(A = \\pi r^2\\)?\nUnif: \\([0,\\pi]\\) equally likely\nExp: closer to \\(0\\) more likely\n\n\n\n\n\nCode\nplot_circ_with_distr &lt;- function(N, radii, ptitle, alpha=0.1) {\n  theta &lt;- seq(0, 360, 4)\n  #hist(radii)\n  circ_df &lt;- expand.grid(x = theta, y = radii)\n  #circ_df\n  ggplot(circ_df, aes(x = x, y = y, group = y)) +\n      geom_path(alpha = alpha, color = cbPalette[1], linewidth=g_linesize) +\n      # Plot the full unit circle\n      geom_path(data = data.frame(x = theta, y = 1), aes(x = x), linewidth=g_linesize) +\n      geom_point(data = data.frame(x = 0, y = 0), aes(x = x), size = g_pointsize) +\n      coord_polar(theta = \"x\", start = -pi / 2, direction = -1) +\n      ylim(0, 1) +\n      # scale_x_continuous(limits=c(0,360), breaks=seq(0,360,by=45)) +\n      scale_x_continuous(limits = c(0, 360), breaks = NULL) +\n      dsan_theme(\"quarter\") +\n      labs(\n          title = ptitle,\n          x = NULL,\n          y = NULL\n      ) +\n      # See https://stackoverflow.com/a/19821839\n      theme(\n          axis.line = element_blank(),\n          axis.text = element_blank(),\n          axis.ticks = element_blank(),\n          axis.title = element_blank(),\n          panel.border = element_blank(),\n          panel.grid.major=element_blank(),\n          panel.grid.minor=element_blank(),\n          plot.margin = unit(c(0,0,0,0), \"cm\"),\n          title = element_text(size=18)\n      )\n}\nN &lt;- 500\nradii &lt;- runif(N, 0, 1)\ntitle &lt;- paste0(N, \" Uniformly-Distributed Radii\")\nalpha &lt;- 0.2\nplot_circ_with_distr(N, radii, title, alpha)\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\nN &lt;- 1000\nradii &lt;- rexp(N, 4)\ntitle &lt;- paste0(N, \" Exponentially-Distributed Radii\")\nplot_circ_with_distr(N, radii, title, alpha=0.15)",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#data-ground-truth-noise",
    "href": "w02/index.html#data-ground-truth-noise",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Data = Ground Truth + Noise",
    "text": "Data = Ground Truth + Noise\n\nDepressing but true origin of statistics (as opposed to probability): the Plague üò∑\n\n\n\n\n\n\nGround Truth: The Great Plague (Lord Have Mercy on London, Unknown Artist, circa 1665, via Wikimedia Commons)\n\n\n\n\n\n\nNoisy Data (Recorded amidst chaos): London Bill of Mortality, 1665 (Public Domain, Wellcome Collection)",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#random-variables",
    "href": "w02/index.html#random-variables",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Random Variables",
    "text": "Random Variables\n\nIn algebra, to solve problems we work with variables\nIn probability theory, to solve problems we work with random variables\nRecall the difference between random and deterministic: \\(A = \\pi r^2\\) tells us that, given a value of \\(r\\), we can solve for the unique value of \\(A\\)\nIn probability theory, however, there is no one ‚Äútrue‚Äù value of a random variable \\(X\\).\nLet \\(X = f(N)\\) mean that \\(X\\) is the result of a rolled die, where the die has \\(N\\) sides.\nPlugging in \\(N = 6\\) (standard 6-sided die) still doesn‚Äôt mean we know ‚Äúthe‚Äù value of \\(X\\). However, (if the die is fair) we do know\n\n\\[\n\\Pr(X = 1) = \\Pr(X = 2) = \\cdots = \\Pr(X = 6) = \\frac{1}{6}\n\\]",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#discrete-vs.-continuous",
    "href": "w02/index.html#discrete-vs.-continuous",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Discrete vs.¬†Continuous",
    "text": "Discrete vs.¬†Continuous\n\nMany complicated definitions, often misleading or unintuitive!\nHow I want you to remember: How many possible values between two known values?\nDiscrete: e.g., number of siblings\n\nI have 2 siblings, you have 3 siblings‚Ä¶ How many values (sibling counts) in between?\n\nContinuous: e.g., temperature\n\nIt is 27.0¬∞ C in my room, 28.0¬∞ C in your room‚Ä¶ How many values (temperatures) in between?\n\nSo, if \\(X\\) is the result of a rolled die, is \\(X\\) discrete or continuous? How many values can be rolled between 3 and 4?",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#thinking-about-independence",
    "href": "w02/index.html#thinking-about-independence",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Thinking About Independence",
    "text": "Thinking About Independence\n\nWe‚Äôll define it formally later; for now, this is our working definition:\n\n\n\n\n\n\n\n Working Definition: Independence\n\n\n\nTwo random variables \\(X\\) and \\(Y\\) are independent if learning information about \\(X\\) does not give you information about the value of \\(Y\\), or vice-versa.",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#na√Øve-definition-of-probability",
    "href": "w02/index.html#na√Øve-definition-of-probability",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Na√Øve Definition of Probability",
    "text": "Na√Øve Definition of Probability\n\nSample Space: The set of all possible outcomes of an experiment\nEvent: A subset of the sample space\n\n\n\n\n\n\n\n Na√Øve Definition of Probability\n\n\n\nGiven a sample space \\(S\\), and an event \\(E \\subset S\\),\n\\[\n\\Pr(\\underbrace{E}_{\\text{event}}) = \\frac{\\text{\\# Favorable Outcomes}}{\\text{\\# Possible Outcomes}} = \\frac{|E|}{|S|}\n\\]",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#example-flipping-two-coins",
    "href": "w02/index.html#example-flipping-two-coins",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Example: Flipping Two Coins",
    "text": "Example: Flipping Two Coins\n\n\n\n\n\n\n Na√Øve Definition of Probability\n\n\n\nGiven a sample space \\(S\\), and an event \\(E \\subset S\\),\n\\[\n\\Pr(\\underbrace{E}_{\\text{event}}) = \\frac{\\text{\\# Favorable Outcomes}}{\\text{\\# Possible Outcomes}} = \\frac{|E|}{|S|}\n\\]\n\n\n\nSample space \\(S = \\{TT, TH, HT, HH\\}\\)\nEvent \\(E_1\\): Result of first flip is \\(H\\), result of second flip is \\(T\\) \\(\\implies\\) \\(E_1 = \\{HT\\}\\)\nEvent \\(E_2\\): At least one \\(H\\) \\(\\implies\\) \\(E_2 = \\{TH, HT, HH\\}\\)\n\n\\[\n\\begin{align*}\n\\Pr(E_1) &= \\frac{|\\{HT\\}|}{|S|} = \\frac{|\\{HT\\}|}{|\\{TT, TH, HT, HH\\}|} = \\frac{1}{4} \\\\\n\\Pr(E_2) &= \\frac{|\\{TH, HT, HH\\}|}{|S|} = \\frac{|\\{TH, HT, HH\\}|}{|\\{TT, TH, HT, HH\\}|} = \\frac{3}{4}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#events-neq-outcomes",
    "href": "w02/index.html#events-neq-outcomes",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Events \\(\\neq\\) Outcomes!",
    "text": "Events \\(\\neq\\) Outcomes!\n\nOutcomes are things, events are sets of things\nSubtle but extremely important distinction!\nIn the coin flip example:\n\nThe event \\(E_1 = \\{HT\\}\\) can be confused with the outcome \\(HT\\).\nSo, try to remember instead the event \\(E_2 = \\{TH, HT, HH\\}\\): it is more clear, in this case, how this event does not correspond to any individual outcome",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#back-to-the-na√Øve-definition",
    "href": "w02/index.html#back-to-the-na√Øve-definition",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Back to the Na√Øve Definition",
    "text": "Back to the Na√Øve Definition\n\n\n\n\n\n\n Na√Øve Definition of Probability\n\n\n\nGiven a sample space \\(S\\), and an event \\(E \\subset S\\),\n\\[\n\\Pr(\\underbrace{E}_{\\text{event}}) = \\frac{\\text{\\# Favorable Outcomes}}{\\text{\\# Possible Outcomes}} = \\frac{|E|}{|S|}\n\\]\n\n\n\nThe na√Øve definition tells us that probabilities are just ratios of counts:\n\nCount the number of ways the event \\(E\\) can happen, count the total number of things that can happen, and divide!\n\nThis is why we begin studying probability by studying combinatorics: the mathematics of counting",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#combinatorics-ice-cream-possibilities",
    "href": "w02/index.html#combinatorics-ice-cream-possibilities",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Combinatorics: Ice Cream Possibilities",
    "text": "Combinatorics: Ice Cream Possibilities\n\n\n\n\n\nThe \\(6 = \\color{red}\\boxed{\\color{black}2 \\cdot 3}\\) possible cone+flavor combinations which can result from choosing a flavor first and a cone type second.\n\n\n\n\n\n\nThe \\(6 = \\color{red}\\boxed{\\color{black}3 \\cdot 2}\\) possible cone+flavor combinations which can result from choosing a flavor first and a cone type second.",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#grouping-vs.-ordering",
    "href": "w02/index.html#grouping-vs.-ordering",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Grouping vs.¬†Ordering",
    "text": "Grouping vs.¬†Ordering\n\nIn standard statistics/combinatorics introductions you‚Äôll learn different counting formulas for when order matters vs.¬†when order doesn‚Äôt matter\nThis is not a mathematical distinction so much as a pragmatic distinction: what are you trying to accomplish by counting?\nProblems with extremely similar descriptions can differ in small detail, so that the units you need to distinguish between in one version differ from the units you need to distinguish between in the other.",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#does-order-matter",
    "href": "w02/index.html#does-order-matter",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Does Order Matter?",
    "text": "Does Order Matter?\n\n\n\n\n\n\n Example: Student Government vs.¬†Student Sports\n\n\n\n\nConsider a school where students can either try out for swim team or run for a position in student government\nThe swim team has 4 slots, but slots aren‚Äôt differentiated: you‚Äôre either on the team (one of the chosen students) or not\nThe student government also has 4 slots, but there is a difference between the slots: first slot is President, second is Vice President, third is Secretary, and fourth is Treasurer.\n\n\n\n\nSimple case (for intuition): school only has 4 students. In this case, how many ways are there to form the swim team? What about the student government?\n\nSwim team: \\(1\\) way. You have only one choice, let all 4 students onto team\nStudent government: \\(4 \\cdot 3 \\cdot 2 \\cdot 1 = 24\\) ways. You have to let all 4 in, but you have a choice of who is President, Vice President, Secretary, and Treasurer\n\nHow did we get \\(4 \\cdot 3 \\cdot 2 \\cdot 1\\)? (Think about the ice cream example‚Ä¶)\n\nStart by choosing the President: 4 choices\nNow choose the Vice President: only 3 students left to choose from\nNow choose the Secretary: only 2 students left to choose from\nNow choose the Treasurer: only 1 student left to choose from",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#permutations-vs.-combinations",
    "href": "w02/index.html#permutations-vs.-combinations",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Permutations vs.¬†Combinations",
    "text": "Permutations vs.¬†Combinations\n\nPermutations: How many ways can I choose groups of size \\(k\\) out of \\(n\\) total objects, where order within groups matters: \\(P_{n,k}\\) (sometimes written \\(_nP_k\\)).\n\nIn this case, we want to count \\((a,b)\\) and \\((b,a)\\) as two separate groups\n\nCombinations: How many ways can I choose groups of size \\(k\\) out of \\(n\\) total objects, where order in the groups doesn‚Äôt matter: \\(C_{n,k}\\) (sometimes written \\(_nC_k,\\binom{n}{k}\\)).\n\nIn this case, we don‚Äôt want to count \\((a, b)\\) and \\((b, a)\\) as two separate groups‚Ä¶\n\n\n\\[\n\\begin{align*}\nP_{n,k} = \\frac{n!}{(n-k)!}, \\; C_{n,k} = \\frac{n!}{k!(n-k)!}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#no-need-to-memorize",
    "href": "w02/index.html#no-need-to-memorize",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "No Need to Memorize!",
    "text": "No Need to Memorize!\n\nKey point: you don‚Äôt have to remember these as two separate formulas!\nThe number of combinations is based on the number of permutations, but corrected for double counting: e.g., corrected for the fact that \\((a,b) \\neq (b,a)\\) when counting permutations but \\((a,b) = (b,a)\\) when counting combinations.\n\n\\[\nC_{n,k} = \\frac{P_{n,k}}{k!} \\genfrac{}{}{0pt}{}{\\leftarrow \\text{Permutations}}{\\leftarrow \\text{Duplicate groups}}\n\\]\nWhere does \\(k!\\) come from? (How many different orderings can we make of the same group?)\n\n\\(k = 2\\): \\((\\underbrace{\\boxed{\\phantom{a}}}_{\\text{2 choices}},\\underbrace{\\boxed{\\phantom{a}}}_{\\text{1 remaining choice}}) \\implies 2\\)\n\\(k = 3\\): \\((\\underbrace{\\boxed{\\phantom{a}}}_{\\text{3 choices}},\\underbrace{\\boxed{\\phantom{a}}}_{\\text{2 remaining choices}}, \\underbrace{\\boxed{\\phantom{a}}}_{\\text{1 remaining choice}}) \\implies 6\\)\n\\(k = 4\\): \\((\\underbrace{\\boxed{\\phantom{a}}}_{\\text{4 choices}}, \\underbrace{\\boxed{\\phantom{a}}}_{\\text{3 remaining choices}}, \\underbrace{\\boxed{\\phantom{a}}}_{\\text{2 remaining choices}}, \\underbrace{\\boxed{\\phantom{a}}}_{\\text{1 remaining choice}}) \\implies 24\\)",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#with-or-without-replacement",
    "href": "w02/index.html#with-or-without-replacement",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "With or Without Replacement?",
    "text": "With or Without Replacement?\n\nBoils down to: can the same object be included in my sample more than once?\n\n\n\n\nWithout Replacement\nWith Replacement\n\n\n\n\nMost statistical problems: ‚ÄúCheck off‚Äù objects as you collect data about them, so that each observation in your data is unique\nSpecial (but important!) set of statistical problems: let objects appear in your sample multiple times, to ‚Äúsqueeze‚Äù more information out of the sample (called Bootstrapping‚Äîmuch more later in the course!)",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#how-many-possible-samples",
    "href": "w02/index.html#how-many-possible-samples",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "How Many Possible Samples?",
    "text": "How Many Possible Samples?\nExample: From \\(N = 3\\) population, how many ways can we take samples of size \\(k = 2\\)?\n\n\n\n\n\n\n\nWithout Replacement\nWith Replacement\n\n\n\n\n\\(3 \\cdot 2 = 6\\) ways (3 objects to choose from for first element of sample, 2 remaining objects to choose from for second element of sample)\n\\(3\\cdot 3 = 3^2 = 9\\) ways (3 objects to choose from for first element of sample, still 3 objects to choose from for second element of sample)\n\n\n\nGeneral Case: From population of size \\(N\\), how many ways can we take samples of size \\(k\\)? (Try to extrapolate from above example before looking at answer!)\n\n\n\n\n\n\n\n\nWithout Replacement\nWith Replacement\n\n\n\n\n\\(\\displaystyle \\underbrace{N \\cdot (N-1) \\cdot \\cdots \\cdot (N - k + 1)}_{k\\text{ times}} = \\frac{N!}{(N - k )!}\\)(This formula should look somewhat familiar‚Ä¶)\n\\(\\displaystyle \\underbrace{N \\cdot N \\cdot \\cdots \\cdot N}_{k\\text{ times}} = N^k\\)",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#link-to-colab-notebook",
    "href": "w02/index.html#link-to-colab-notebook",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Link to Colab Notebook",
    "text": "Link to Colab Notebook\n\nDSAN 5100-03 Lab 02",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#references",
    "href": "w02/index.html#references",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w05/slides.html#discrete-vs.-continuous",
    "href": "w05/slides.html#discrete-vs.-continuous",
    "title": "Week 5: Continuous Distributions",
    "section": "Discrete vs.¬†Continuous",
    "text": "Discrete vs.¬†Continuous\n\n\n\nDiscrete = ‚ÄúEasy mode‚Äù: Based (intuitively) on sets\n\\(\\Pr(A)\\): Four equally-likely marbles \\(\\{A, B, C, D\\}\\) in box, what is probability I pull out \\(A\\)?\n\n\n\n\n\n\n\n\n\n\n\\[\n\\Pr(A) = \\underset{\\mathclap{\\small \\text{Probability }\\textbf{mass}}}{\\boxed{\\frac{|\\{A\\}|}{|\\Omega|}}} = \\frac{1}{|\\{A,B,C,D\\}|} = \\frac{1}{4}\n\\]\n\n\nContinuous = ‚ÄúHard mode‚Äù: Based (intuitively) on areas\n\\(\\Pr(A)\\): Throw dart at random point in square, what is probability I hit \\(\\require{enclose}\\enclose{circle}{\\textsf{A}}\\)?\n\n\n\n\n\n\n\n\n\n\n\\[\n\\Pr(A) = \\underset{\\mathclap{\\small \\text{Probability }\\textbf{density}}}{\\boxed{\\frac{\\text{Area}(\\{A\\})}{\\text{Area}(\\Omega)}}} = \\frac{\\pi r^2}{s^2} = \\frac{\\pi \\left(\\frac{1}{4}\\right)^2}{4} = \\frac{\\pi}{64}\n\\]"
  },
  {
    "objectID": "w05/slides.html#the-technical-difference-tldr",
    "href": "w05/slides.html#the-technical-difference-tldr",
    "title": "Week 5: Continuous Distributions",
    "section": "The Technical Difference tl;dr",
    "text": "The Technical Difference tl;dr\n\nCountable Sets: Can be put into 1-to-1 correspondence with natural numbers \\(\\mathbb{N}\\)\n\nWhat are you doing when you‚Äôre counting? Saying ‚Äúfirst‚Äù, ‚Äúsecond‚Äù, ‚Äúthird‚Äù, ‚Ä¶\nYou‚Äôre pairing each object with a natural number! \\(\\{(\\texttt{a},1),(\\texttt{b},2),\\ldots,(\\texttt{z},26)\\}\\) \n\nUncountable Sets: Can‚Äôt be put into 1-to-1 correspondence with natural numbers.\n\\(\\mathbb{R}\\) is uncountable. Intuition: Try counting the real numbers. Proof \\[\n\\text{Assume }\\exists \\, (f: \\mathbb{R} \\leftrightarrow \\mathbb{N}):\n\\begin{array}{|c|c|c|c|c|c|c|}\\hline\n\\mathbb{R} & & & & & & \\Leftrightarrow \\mathbb{N} \\\\ \\hline\n\\color{orange}{3} & . & 1 & 4 & 1 & \\cdots & \\Leftrightarrow 1 \\\\\\hline\n4 & . & \\color{orange}{9} & 9 & 9 & \\cdots & \\Leftrightarrow 2 \\\\\\hline\n0 & . & 1 & \\color{orange}{2} & 3 & \\cdots &\\Leftrightarrow 3 \\\\\\hline\n1 & . & 2 & 3 & \\color{orange}{4} & \\cdots & \\Leftrightarrow 4 \\\\\\hline\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\\hline\n\\end{array} \\overset{\\color{blue}{y_{[i]}} = \\color{orange}{x_{[i]}} \\overset{\\mathbb{Z}_{10}}{+} 1}{\\underset{üòà}{\\longrightarrow}} \\color{blue}{y = 4.035 \\ldots} \\Leftrightarrow \\; ?\n\\]\n\n\n\nFun math challenge: Is \\(\\mathbb{Q}\\) countable? See this appendix slide for why the answer is yes, despite the fact that \\(\\forall x, y \\in \\mathbb{Q} \\left[ \\frac{x+y}{2} \\in \\mathbb{Q} \\right]\\)‚ùóÔ∏è The method used in the above proof is called Cantor diagonalization"
  },
  {
    "objectID": "w05/slides.html#the-practical-difference",
    "href": "w05/slides.html#the-practical-difference",
    "title": "Week 5: Continuous Distributions",
    "section": "The Practical Difference",
    "text": "The Practical Difference\n\nThis part of the course (discrete probability): \\(\\Pr(X = v), v \\in \\mathcal{R}_X \\subseteq \\mathbb{N}\\)\n\nExample: \\(\\Pr(\\)\\() = \\Pr(X = 3), 3 \\in \\{1,2,3,4,5,6\\} \\subseteq \\mathbb{N}\\)\n\nNext part of the course (continuous probability): \\(\\Pr(X \\in V), V \\subseteq \\mathbb{R}\\)\n\nExample: \\(\\Pr(X \\geq 2\\pi) = \\Pr(X \\in [\\pi,\\infty)), [\\pi,\\infty) \\subseteq \\mathbb{R}\\)\n\nWhy do they have to be in separate parts?\n\n\\[\n\\Pr(X \\underset{\\substack{\\uparrow \\\\ üö©}}{=} 2\\pi) = \\frac{\\text{Area}(\\overbrace{2\\pi}^{\\mathclap{\\small \\text{Single point}}})}{\\text{Area}(\\underbrace{\\mathbb{R}}_{\\mathclap{\\small \\text{(Uncountably) Infinite set of points}}})} = 0\n\\]"
  },
  {
    "objectID": "w05/slides.html#the-cdf-unifies-the-two-worlds",
    "href": "w05/slides.html#the-cdf-unifies-the-two-worlds",
    "title": "Week 5: Continuous Distributions",
    "section": "The CDF Unifies the Two Worlds!",
    "text": "The CDF Unifies the Two Worlds!\n\nCumulative Distribution Function (CDF): \\(F_X(v) = \\Pr(X \\leq v)\\)1\nFor discrete RV \\(X\\) (\\(\\mathcal{R}_X \\cong \\mathbb{N}\\)), Probability Mass Function (pmf) \\(p_X(v)\\): \\[\n\\begin{align*}\np_X(v) &\\definedas \\Delta F_X(v) \\definedas F_X(v) - F_X(v - 1) = \\underset{\\text{Meaningful}}{\\boxed{\\Pr(X = v)}} \\\\\n\\implies F_X(v) &= \\sum_{\\{w \\in \\mathcal{R}_X: \\; w \\leq v\\}}p_X(w) = \\underset{\\text{Meaningful}}{\\boxed{\\Pr(X \\leq v)}}\n\\end{align*}\n\\]\nFor continuous RV \\(X\\) (\\(\\mathcal{R}_X \\subseteq \\mathbb{R}\\)), Probability Density Function (pdf) \\(f_X(v)\\): \\[\n\\begin{align*}\nf_X(v) &\\definedas \\frac{d}{dx}F_X(v) \\definedas \\lim_{h \\rightarrow 0}\\frac{F(x + h) - F(x)}{h} = \\underset{\\text{Not Meaningful}}{\\boxed{\\; ? \\;}} \\\\\n\\implies F_X(v) &= \\int_{-\\infty}^v f_X(w)dw = \\underset{\\text{Meaningful}}{\\boxed{\\Pr(X \\leq v)}}\n\\end{align*}\n\\]\n\nTextbooks sometimes write \\(F(x) = \\Pr(X \\leq x)\\), where capital \\(X\\) is a RV while lowercase \\(x\\) is a particular value, like \\(3\\). To reduce confusion, I use \\(X\\) for the RV and \\(v\\) for the value at which we‚Äôre checking the CDF. Also note capitalized CDF but lowercase pmf/pdf, matching mathematical notation: \\(f_X(v)\\) is the derivative of \\(F_X(v)\\)."
  },
  {
    "objectID": "w05/slides.html#probability-density-neq-probability",
    "href": "w05/slides.html#probability-density-neq-probability",
    "title": "Week 5: Continuous Distributions",
    "section": "Probability Density \\(\\neq\\) Probability",
    "text": "Probability Density \\(\\neq\\) Probability\n\n‚ò†Ô∏èBEWARE‚ò†Ô∏è: \\(f_X(v) \\neq \\Pr(X = v)\\)!\nLong story short, for continuous variables, \\(\\Pr(X = v)\\) is just always \\(0\\)[^measurezero]\nHence, we instead construct a pdf \\(f_X(v)\\) whose sole purpose is to allow us to calculate \\(\\Pr(X \\in [a,b])\\) by integrating!\n\n\\(f_X(v)\\) is whatever satisfies \\(\\Pr(X \\in [a,b]) = \\int_{a}^bf_X(v)dv\\), and nothing more\n\ni.e., instead of \\(p_X(v) = \\Pr(X = v)\\) from discrete world, the relevant function here is \\(f_X(v)\\), the probability density of \\(X\\) at \\(v\\).\n\n\n\nScary math zone\n\n\n\nFor intuition: think of \\(X \\sim \\mathcal{U}(0,10) \\implies \\Pr(X = \\pi) = \\frac{|\\{v \\in \\mathbb{R}:\\; v = \\pi\\}|}{|\\mathbb{R}|} = \\frac{1}{2^{\\aleph_0}} \\approx 0\\). That is, finding the \\(\\pi\\) needle in the \\(\\mathbb{R}\\) haystack is a one-in-\\(\\left(\\infty^\\infty\\right)\\) event.\nIssue even if \\(\\mathcal{R}_X\\) countably infinite, like \\(\\mathcal{R}_X = \\mathbb{N}\\): \\(\\Pr(X = 3) = \\frac{|\\{x \\in \\mathbb{N} : \\; x = 3\\}|}{|\\mathbb{N}|} = \\frac{1}{\\aleph_0}\\). Finding the \\(3\\) needle in the \\(\\mathbb{N}\\) haystack is a one-in-\\(\\infty\\) event"
  },
  {
    "objectID": "w05/slides.html#bernoulli-distribution",
    "href": "w05/slides.html#bernoulli-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "Bernoulli Distribution",
    "text": "Bernoulli Distribution\n\nSingle trial with two outcomes, ‚Äúsuccess‚Äù (1) or ‚Äúfailure‚Äù (0): basic model of a coin flip (heads = 1, tails = 0)\n\\(X \\sim \\text{Bern}({\\color{purple} p}) \\implies \\mathcal{R}_X = \\{0,1\\}, \\; \\Pr(X = 1) = {\\color{purple}p}\\)."
  },
  {
    "objectID": "w05/slides.html#binomial-distribution",
    "href": "w05/slides.html#binomial-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nNumber of successes in \\({\\color{purple}N}\\) Bernoulli trials. \\(X \\sim \\text{Binom}({\\color{purple}N},{\\color{purple}k},{\\color{purple}p}) \\implies \\mathcal{R}_X = \\{0, 1, \\ldots, N\\}\\)\n\n\\(\\Pr(X = k)  = \\binom{N}{k}p^k(1-p)^{N-k}\\): probability of \\(k\\) successes out of \\(N\\) trials.\n\\(\\binom{N}{k} = \\frac{N!}{k!(N-k)!}\\): ‚ÄúBinomial coefficient‚Äù. How many groups of size \\(k\\) can be formed?1\n\n\n\n\n\nFun way to avoid memorizing! Imagine a pyramid like \\(\\genfrac{}{}{0pt}{}{}{\\boxed{\\phantom{1}}}\\genfrac{}{}{0pt}{}{\\boxed{\\phantom{1}}}{}\\genfrac{}{}{0pt}{}{}{\\boxed{\\phantom{1}}}\\), where boxes are slots for numbers. Put a \\(1\\) in box at the top. In bottom row, fill each slot with the sum of the two numbers above-left and above-right of it. Since \\(1 + \\text{(nothing)} = 1\\), this looks like: \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\). Continue filling in rows this way, so next row looks like \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{2}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\), then \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{3}\\genfrac{}{}{0pt}{}{2}{}\\genfrac{}{}{0pt}{}{}{3}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\), etc. The \\(k\\)th number in the \\(N\\)th row (counting from \\(0\\)) is \\(\\binom{N}{k}\\). Appendix shows triangle written out to 7th row!"
  },
  {
    "objectID": "w05/slides.html#visualizing-the-binomial",
    "href": "w05/slides.html#visualizing-the-binomial",
    "title": "Week 5: Continuous Distributions",
    "section": "Visualizing the Binomial",
    "text": "Visualizing the Binomial\n\n\nCode\nk &lt;- seq(0, 10)\nprob &lt;- dbinom(k, 10, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x=k, y=prob)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title=\"Binomial Distribution, N = 10, p = 0.5\",\n    y=\"Probability Mass\"\n  ) +\n  scale_x_continuous(breaks=seq(0,10)) +\n  dsan_theme(\"half\")\n\n\n\n\nSo who can tell me, from this plot, the approximate probability of getting 4 heads when flipping a coin 10 times?"
  },
  {
    "objectID": "w05/slides.html#multiple-classes-multinomial-distribution",
    "href": "w05/slides.html#multiple-classes-multinomial-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "Multiple Classes: Multinomial Distribution",
    "text": "Multiple Classes: Multinomial Distribution\n\nBernoulli only allows two outcomes: success or failure.\nWhat if we‚Äôre predicting soccer match outcomes?\n\n\\(X_i \\in \\{\\text{Win}, \\text{Loss}, \\text{Draw}\\}\\)\n\nCategorical Distribution: Generalizes Bernoulli to \\(k\\) possible outcomes. \\(X \\sim \\text{Categorical}(\\mathbf{p} = \\{p_1, p_2, \\ldots, p_k\\}), \\sum_{i=1}^kp_i = 1\\).\n\n\\(\\Pr(X = k) = p_k\\)\n\nMultinomial Distribution: Generalizes Binomial to \\(k\\) possible outcomes.\n\\(\\mathbf{X} \\sim \\text{Multinom}(N,k,\\mathbf{p}=\\{p_1,p_2,\\ldots,p_k\\}), \\sum_{i=1}^kp_i=1\\)\n\n\\(\\Pr(\\mathbf{X} = \\{x_1,x_2\\ldots,x_k\\}) = \\frac{N!}{x_1!x_2!\\cdots x_k!}p_1^{x_1}p_2^{x_2}\\cdots p_k^{x_k}\\)\n\\(\\Pr(\\text{30 wins}, \\text{4 losses}, \\text{4 draws}) = \\frac{38!}{30!4!4!}p_{\\text{win}}^{30}p_{\\text{lose}}^4p_{\\text{draw}}^4\\).\n\\(\\leadsto\\) ‚ÄúMultinomial Coefficient‚Äù: \\(\\binom{38}{30,4,4} = \\frac{38!}{30!4!4!}\\)"
  },
  {
    "objectID": "w05/slides.html#geometric-distribution",
    "href": "w05/slides.html#geometric-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nLikelihood that we need \\({\\color{purple}k}\\) trials to get our first success. \\(X \\sim \\text{Geom}({\\color{purple}k},{\\color{purple}p}) \\implies \\mathcal{R}_X = \\{1, 2, \\ldots\\}\\)\n\n\\(\\Pr(X = k) = \\underbrace{(1-p)^{k-1}}_{\\small k - 1\\text{ failures}}\\cdot \\underbrace{p}_{\\mathclap{\\small \\text{success}}}\\)\nProbability of \\(k\\) trials before first success"
  },
  {
    "objectID": "w05/slides.html#less-common-but-important-distributions",
    "href": "w05/slides.html#less-common-but-important-distributions",
    "title": "Week 5: Continuous Distributions",
    "section": "Less Common (But Important) Distributions",
    "text": "Less Common (But Important) Distributions\n\nDiscrete Uniform: \\(N\\) equally-likely outcomes\n\n\\(X \\sim U\\{{\\color{purple}a},{\\color{purple}b}\\} \\implies \\mathcal{R}_X = \\{a, a+1, \\ldots, b\\}, \\Pr(X = k) = \\frac{1}{{\\color{purple}b} - {\\color{purple}a} + 1}\\)\n\nBeta: \\(X \\sim \\text{Beta}({\\color{purple}\\alpha}, {\\color{purple}\\beta})\\): conjugate prior for Bernoulli, Binomial, and Geometric dists.\n\nIntuition: If we use Beta to encode our prior hypothesis, then observe data drawn from Binomial, distribution of our updated hypothesis is still Beta.\n\\(\\underbrace{\\Pr(\\text{biased}) = \\Pr(\\text{unbiased})}_{\\text{Prior: }\\text{Beta}({\\color{purple}\\alpha}, {\\color{purple}\\beta})} \\rightarrow\\) Observe \\(\\underbrace{\\frac{8}{10}\\text{ heads}}_{\\text{Data}} \\rightarrow \\underbrace{\\Pr(\\text{biased}) = 0.65}_{\\text{Posterior: }\\text{Beta}({\\color{purple}\\alpha + 8}, {\\color{purple}\\beta + 2})}\\)\n\nDirichlet: \\(\\mathbf{X} = (X_1, X_2, \\ldots, X_K) \\sim \\text{Dir}({\\color{purple} \\boldsymbol\\alpha})\\)\n\n\\(K\\)-dimensional extension of Beta (thus, conjugate prior for Multinomial)\n\n\n\n\nWe can now use \\(\\text{Beta}(\\alpha + 8, \\beta + 2)\\) as a prior for our next set of trials (encoding our knowledge up to that point), and update further once we know the results (to yet another Beta distribution)."
  },
  {
    "objectID": "w05/slides.html#interactive-visualizations",
    "href": "w05/slides.html#interactive-visualizations",
    "title": "Week 5: Continuous Distributions",
    "section": "Interactive Visualizations!",
    "text": "Interactive Visualizations!\nSeeing Theory, Brown University"
  },
  {
    "objectID": "w05/slides.html#what-things-have-distributions",
    "href": "w05/slides.html#what-things-have-distributions",
    "title": "Week 5: Continuous Distributions",
    "section": "What Things Have Distributions?",
    "text": "What Things Have Distributions?\n\nAnswer: Random Variables\nMeaning: \\(\\mathcal{N}(0, 1)\\) on its own is a ‚Äútemplate‚Äù, an exhibit at a museum within a glass case\nTo start using it, e.g., to generate random values, we need to consider a particular RV \\(X \\sim \\mathcal{N}(0,1)\\), then generate values on basis of this template:\n\n\\(X = 0\\) more likely than \\(X = 1\\) or \\(X = -1\\),\n\\(X = 1\\) more likely than \\(X = 2\\) or \\(X = -2\\),\nand so on"
  },
  {
    "objectID": "w05/slides.html#cdfspdfspmfs-what-are-they",
    "href": "w05/slides.html#cdfspdfspmfs-what-are-they",
    "title": "Week 5: Continuous Distributions",
    "section": "CDFs/pdfs/pmfs: What Are They?",
    "text": "CDFs/pdfs/pmfs: What Are They?\n\nFunctions which answer questions about a Random Variable (\\(X\\) in this case) with respect to a non-random value (\\(v\\) in this case, for ‚Äúvalue‚Äù)\nCDF: What is probability that \\(X\\) takes on a value less than or equal to \\(v\\)?\n\n\\[\nF_X(v) \\definedas \\Pr(X \\leq v)\n\\]\n\npmf: What is the probability of this exact value? (Discrete only)\n\n\\[\np_X(v) \\definedas \\Pr(X = v)\n\\]\n\npdf: üôà ‚Ä¶It‚Äôs the thing you integrate to get the CDF\n\n\\[\nf_X(v) \\definedas \\frac{d}{dv}F_X(v) \\iff \\int_{-\\infty}^{v} f_X(v)dv = F_X(v)\n\\]"
  },
  {
    "objectID": "w05/slides.html#cdfspdfspmfs-why-do-we-use-them",
    "href": "w05/slides.html#cdfspdfspmfs-why-do-we-use-them",
    "title": "Week 5: Continuous Distributions",
    "section": "CDFs/pdfs/pmfs: Why Do We Use Them?",
    "text": "CDFs/pdfs/pmfs: Why Do We Use Them?\n\nCDF is like the ‚ÄúAPI‚Äù that allows you to access all of the information about the distribution (pdf/pmf is derived from the CDF)\nExample: we know there‚Äôs some ‚Äúthing‚Äù called the Exponential Distribution‚Ä¶\nHow do we use this distribution to understand a random variable \\(X \\sim \\text{Exp}(\\lambda)\\)?\n\nAnswer: the CDF of \\(X\\)!\nSince all exponentially-distributed RVs have the same pdf (with different \\(\\lambda\\) values plugged in), we can call this pdf ‚Äúthe‚Äù exponential distribution\n\nSay we want to find the median of \\(X\\): The median is the number(s) \\(m\\) satisfying\n\n\\[\n\\Pr(X \\leq m) = \\frac{1}{2}\n\\]\n\nHow can we find this? What ‚Äútool‚Äù do we use to figure this out about \\(X\\)?"
  },
  {
    "objectID": "w05/slides.html#finding-a-median-via-the-cdf",
    "href": "w05/slides.html#finding-a-median-via-the-cdf",
    "title": "Week 5: Continuous Distributions",
    "section": "Finding a Median via the CDF",
    "text": "Finding a Median via the CDF\n\n\n\n\n Median of a Random Variable \\(X\\)\n\n\nThe median of a random variable \\(X\\) with some CDF \\(F_X(v_X)\\) is the [set of] numbers \\(m\\) for which the probability that \\(X\\) is lower than \\(m\\) is \\(\\frac{1}{2}\\):\n\\[\n\\begin{align*}\n\\text{Median}(X) &= \\left\\{m \\left| F_X(m) = \\frac{1}{2} \\right. \\right\\} \\\\\n&= \\left\\{m \\left| \\int_{-\\infty}^{m}f_X(v_X)dv_X = \\frac{1}{2} \\right. \\right\\}\n\\end{align*}\n\\]\n\n\n\n\n\n\n(If you‚Äôre wondering why we start with the median rather than the more commonly-used mean: it‚Äôs specifically because I want you to get used to calculating general functions \\(f(X)\\) of a random variable \\(X\\). It‚Äôs easy to just e.g.¬†learn how to compute the mean \\(\\expect{X}\\) and forget that this is only one of many possible choices for \\(f(X)\\).)"
  },
  {
    "objectID": "w05/slides.html#median-via-cdf-example",
    "href": "w05/slides.html#median-via-cdf-example",
    "title": "Week 5: Continuous Distributions",
    "section": "Median via CDF Example",
    "text": "Median via CDF Example\nExample: If \\(X \\sim \\text{Exp}(\\param{\\lambda})\\),\n\\[\nF_X(v) = 1 - e^{-\\lambda v}\n\\]\nSo we want to solve for \\(m\\) in\n\\[\nF_X(m) = \\frac{1}{2} \\iff 1 - e^{-\\lambda m} = \\frac{1}{2}\n\\]"
  },
  {
    "objectID": "w05/slides.html#step-by-step",
    "href": "w05/slides.html#step-by-step",
    "title": "Week 5: Continuous Distributions",
    "section": "Step-by-Step",
    "text": "Step-by-Step\n\\[\n\\begin{align*}\n1 - e^{-\\lambda m} &= \\frac{1}{2} \\\\\n\\iff e^{-\\lambda m} &= \\frac{1}{2} \\\\\n\\iff \\ln\\left[e^{-\\lambda m}\\right] &= \\ln\\left[\\frac{1}{2}\\right] \\\\\n\\iff -\\lambda m &= -\\ln(2) \\\\\n\\iff m &= \\frac{\\ln(2)}{\\lambda}\n%3x = 19-2y\n\\; \\llap{\\mathrel{\\boxed{\\phantom{m = \\frac{\\ln(2)}{\\lambda}}}}}.\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w05/slides.html#top-secret-fun-fact",
    "href": "w05/slides.html#top-secret-fun-fact",
    "title": "Week 5: Continuous Distributions",
    "section": "Top Secret Fun Fact",
    "text": "Top Secret Fun Fact\n\nEvery Discrete Distribution is [technically, in a weird way] a Continuous Distribution!\n\n\nSame intuition as: every natural number is a real number, but converse not true\nMarbles: Let \\(X\\) be a RV defined s.t. \\(X(A) = 1\\), \\(X(B) = 2\\), \\(X(C) = 3\\), \\(X(D) = 4\\). Then pmf for \\(X\\) is \\(p_X(i) = \\frac{1}{4}\\) for \\(i \\in \\{1, 2, 3, 4\\}\\).\nWe can then use the Dirac delta function \\(\\delta(v)\\) to define a continuous pdf\n\\[\n  f_X(v) = \\sum_{i \\in \\mathcal{R}_X}p_X(i)\\delta(v - i) = \\sum_{i=1}^4p_X(i)\\delta(v-i) = \\frac{1}{4}\\sum_{i=1}^4 \\delta(v - i)\n  \\]\nand use either the (discrete) pmf \\(p_X(v)\\) or (continuous) pdf \\(f_X(v)\\) to describe \\(X\\):\n\n\\[\n\\begin{align*}\n\\overbrace{\\Pr(X \\leq 3)}^{\\text{CDF}} &= \\sum_{i=1}^3\\overbrace{p_X(i)}^{\\text{pmf}} = \\frac{1}{4} + \\frac{1}{4} + \\frac{1}{4} = \\frac{3}{4} \\\\\n\\underbrace{\\Pr(X \\leq 3)}_{\\text{CDF}} &= \\int_{-\\infty}^{3} \\underbrace{f_X(v)}_{\\text{pdf}} = \\frac{1}{4}\\int_{-\\infty}^{3} \\sum_{i = 1}^{4}\\overbrace{\\delta(v-i)}^{\\small 0\\text{ unless }v = i}dv = \\frac{3}{4}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w05/slides.html#recall-binomial-distribution",
    "href": "w05/slides.html#recall-binomial-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "[Recall] Binomial Distribution",
    "text": "[Recall] Binomial Distribution\n\n\nCode\nk &lt;- seq(0, 10)\nprob &lt;- dbinom(k, 10, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x=k, y=prob)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title=\"Binomial Distribution, N = 10, p = 0.5\",\n    y=\"Probability Mass\"\n  ) +\n  scale_x_continuous(breaks=seq(0,10)) +\n  dsan_theme(\"half\")"
  },
  {
    "objectID": "w05/slides.html#the-emergence-of-order",
    "href": "w05/slides.html#the-emergence-of-order",
    "title": "Week 5: Continuous Distributions",
    "section": "The Emergence of Order",
    "text": "The Emergence of Order\n\n\n\nWho can guess the state of this process after 10 steps, with 1 person?\n10 people? 50? 100? (If they find themselves on the same spot, they stand on each other‚Äôs heads)\n100 steps? 1000?"
  },
  {
    "objectID": "w05/slides.html#the-result-16-steps",
    "href": "w05/slides.html#the-result-16-steps",
    "title": "Week 5: Continuous Distributions",
    "section": "The Result: 16 Steps",
    "text": "The Result: 16 Steps"
  },
  {
    "objectID": "w05/slides.html#the-result-64-steps",
    "href": "w05/slides.html#the-result-64-steps",
    "title": "Week 5: Continuous Distributions",
    "section": "The Result: 64 Steps",
    "text": "The Result: 64 Steps"
  },
  {
    "objectID": "w05/slides.html#whats-going-on-here",
    "href": "w05/slides.html#whats-going-on-here",
    "title": "Week 5: Continuous Distributions",
    "section": "What‚Äôs Going On Here?",
    "text": "What‚Äôs Going On Here?\n\n(Stay tuned for Markov processes \\(\\overset{t \\rightarrow \\infty}{\\leadsto}\\) Stationary distributions!)"
  },
  {
    "objectID": "w05/slides.html#properties-of-the-normal-distribution",
    "href": "w05/slides.html#properties-of-the-normal-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "Properties of the Normal Distribution",
    "text": "Properties of the Normal Distribution\n\nIf \\(X \\sim \\mathcal{N}(\\param{\\mu}, \\param{\\theta})\\), then \\(X\\) has pdf \\(f_X(v)\\) defined by\n\n\\[\nf_X(v) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\bigexp{-\\frac{1}{2}\\left(\\frac{v - \\mu}{\\sigma}\\right)^2}\n\\]\n\nI hate memorizing as much as you do, I promise ü•¥\nThe important part (imo): this is the most conservative out of all possible (symmetric) prior distributions defined on \\(\\mathbb{R}\\) (defined from \\(-\\infty\\) to \\(\\infty\\))"
  },
  {
    "objectID": "w05/slides.html#most-conservative-how",
    "href": "w05/slides.html#most-conservative-how",
    "title": "Week 5: Continuous Distributions",
    "section": "‚ÄúMost Conservative‚Äù How?",
    "text": "‚ÄúMost Conservative‚Äù How?\n\nOf all possible distributions with mean \\(\\mu\\), variance \\(\\sigma^2\\), \\(\\mathcal{N}(\\mu, \\sigma^2)\\) is the entropy-maximizing distribution\nRoughly: using any other distribution (implicitly/secretly) imports additional information beyond the fact that mean is \\(\\mu\\) and variance is \\(\\sigma^2\\)\nExample: let \\(X\\) be an RV. If we know mean is \\(\\mu\\), variance is \\(\\sigma^2\\), but then we learn that \\(X \\neq 3\\), or \\(X\\) is even, or the 15th digit of \\(X\\) is 7, can update \\(\\mathcal{N}(\\mu,\\sigma^2)\\) to derive a ‚Äúbetter‚Äù distribution (incorporating this additional info)"
  },
  {
    "objectID": "w05/slides.html#the-takeaway",
    "href": "w05/slides.html#the-takeaway",
    "title": "Week 5: Continuous Distributions",
    "section": "The Takeaway",
    "text": "The Takeaway\n\nGiven info we know, we can find a distribution that ‚Äúencodes‚Äù only this info\nMore straightforward example: if we only know that the value is something in the range \\([a,b]\\), entropy-maximizing distribution is the Uniform Distribution\n\n\n\n\n\n\n\n\n\nIf We Know\nAnd We Know\n(Max-Entropy) Distribution Is‚Ä¶\n\n\n\n\n\\(\\text{Mean}[X] = \\mu\\)\n\\(\\text{Var}[X] = \\sigma^2\\)\n\\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\n\n\n\\(\\text{Mean}[X] = \\lambda\\)\n\\(X \\geq 0\\)\n\\(X \\sim \\text{Exp}\\left(\\frac{1}{\\lambda}\\right)\\)\n\n\n\\(X \\geq a\\)\n\\(X \\leq b\\)\n\\(X \\sim \\mathcal{U}[a,b]\\)"
  },
  {
    "objectID": "w05/slides.html#recall-discrete-uniform-distribution",
    "href": "w05/slides.html#recall-discrete-uniform-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "[Recall] Discrete Uniform Distribution",
    "text": "[Recall] Discrete Uniform Distribution\n\n\nCode\nlibrary(tibble)\nbar_data &lt;- tribble(\n  ~x, ~prob,\n  1, 1/6,\n  2, 1/6,\n  3, 1/6,\n  4, 1/6,\n  5, 1/6,\n  6, 1/6\n)\nggplot(bar_data, aes(x=x, y=prob)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title=\"Discrete Uniform pmf: a = 1, b = 6\",\n    y=\"Probability Mass\",\n    x=\"Value\"\n  ) +\n  scale_x_continuous(breaks=seq(1,6)) +\n  dsan_theme(\"half\")"
  },
  {
    "objectID": "w05/slides.html#continuous-uniform-distribution",
    "href": "w05/slides.html#continuous-uniform-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "Continuous Uniform Distribution",
    "text": "Continuous Uniform Distribution\n\nIf \\(X \\sim \\mathcal{U}[a,b]\\), then intuitively \\(X\\) is a value randomly selected from within \\([a,b]\\), with all values equally likely.\nDiscrete case: what we‚Äôve been using all along (e.g., dice): if \\(X \\sim \\mathcal{U}\\{1,6\\}\\), then\n\n\\[\n\\Pr(X = 1) = \\Pr(X = 2) = \\cdots = \\Pr(X = 6) = \\frac{1}{6}\n\\]\n\nFor continuous case‚Ä¶ what do we put in the denominator? \\(X \\sim \\mathcal{U}[1,6] \\implies \\Pr(X = \\pi) = \\frac{1}{?}\\)‚Ä¶\n\nAnswer: \\(\\Pr(X = \\pi) = \\frac{1}{|[1,6]|} = \\frac{1}{\\aleph_0} = 0\\)"
  },
  {
    "objectID": "w05/slides.html#constructing-the-uniform-cdf",
    "href": "w05/slides.html#constructing-the-uniform-cdf",
    "title": "Week 5: Continuous Distributions",
    "section": "Constructing the Uniform CDF",
    "text": "Constructing the Uniform CDF\n\nWe were ready for this! We already knew \\(\\Pr(X = v) = 0\\) for continuous \\(X\\)\nSo, we forget about \\(\\Pr(X = v)\\), and focus on \\(\\Pr(X \\in [v_0, v_1])\\).\nIn 2D (dartboard) we had \\(\\Pr(X \\in \\circ) = \\frac{\\text{Area}(\\circ)}{\\text{Area}(\\Omega)}\\), so here we should have\n\n\\[\nP(X \\in [v_0,v_1]) = \\frac{\\text{Length}([v_0,v_1])}{\\text{Length}([1,6])}\n\\]\n\nAnd indeed, the CDF of \\(X\\) is \\(\\boxed{F_X(v) = \\Pr(X \\leq v) = \\frac{v-a}{b-a}}\\), so that\n\n\\[\n\\Pr(X \\in [v_0,v_1]) = F_X(v_1) - F_X(v_0) = \\frac{v_1-a}{b-a} - \\frac{v_0-a}{b-a} = \\frac{v_1 - v_0}{b-a}\n\\]\n\nSince \\(a = 1\\), \\(b = 6\\) in our example, \\(\\Pr(X \\in [v_0,v_1]) = \\frac{v_1-v_0}{6-1} = \\frac{\\text{Length}([v_0,v_1])}{\\text{Length}([1,6])} \\; ‚úÖ\\)"
  },
  {
    "objectID": "w05/slides.html#exponential-distribution",
    "href": "w05/slides.html#exponential-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nRecall the (discrete) Geometric Distribution:\n\n\n\nCode\nlibrary(ggplot2)\nk &lt;- seq(0, 8)\nprob &lt;- dgeom(k, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x = k, y = prob)) +\n    geom_bar(stat = \"identity\", fill = cbPalette[1]) +\n    labs(\n        title = \"Geometric Distribution pmf: p = 0.5\",\n        y = \"Probability Mass\"\n    ) +\n    scale_x_continuous(breaks = seq(0, 8)) +\n    dsan_theme(\"half\")"
  },
  {
    "objectID": "w05/slides.html#now-in-continuous-form",
    "href": "w05/slides.html#now-in-continuous-form",
    "title": "Week 5: Continuous Distributions",
    "section": "Now In Continuous Form!",
    "text": "Now In Continuous Form!\n\n\nCode\nmy_dexp &lt;- function(x) dexp(x, rate = 1/2)\nggplot(data.frame(x=c(0,8)), aes(x=x)) +\n  stat_function(fun=my_dexp, size=g_linesize, fill=cbPalette[1], alpha=0.8) +\n  stat_function(fun=my_dexp, geom='area', fill=cbPalette[1], alpha=0.75) +\n  dsan_theme(\"half\") +\n  labs(\n    title=\"Exponential Distribution pdf: Œª (rate) = 0.5\",\n    x = \"v\",\n    y = \"f_X(v)\"\n  )"
  },
  {
    "objectID": "w05/slides.html#the-dreaded-cauchy-distribution",
    "href": "w05/slides.html#the-dreaded-cauchy-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "The Dreaded Cauchy Distribution",
    "text": "The Dreaded Cauchy Distribution\n\n\nCode\nggplot(data.frame(x=c(-4,4)), aes(x=x)) +\n  stat_function(fun=dcauchy, size=g_linesize, fill=cbPalette[1], alpha=0.75) +\n  stat_function(fun=dcauchy, geom='area', fill=cbPalette[1], alpha=0.75) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title=\"PDF of R\",\n    x = \"r\",\n    y = \"f(r)\"\n  )\n\n\n\n\nPaxton is a Houston Rockets fan, while Jeff is a Chicago Bulls fan. Paxton creates a RV \\(H\\) modeling how many games above .500 (wins minus losses) the Rockets will be in a season, while Jeff creates a similar RV \\(C\\) for the Bulls\nThey decide to combine their RVs to create a new RV, \\(R = \\frac{H}{C}\\), which now models how much better the Nuggets will be in a season (\\(R\\) for ‚ÄúRatio‚Äù)\nFor example, if the Rockets are \\(10\\) games above .500, while the Bulls are only \\(5\\) above .500, \\(R = \\frac{10}{5} = 2\\). If they‚Äôre both 3 games above .500, \\(R = \\frac{3}{3} = 1\\)."
  },
  {
    "objectID": "w05/slides.html#so-whats-the-issue",
    "href": "w05/slides.html#so-whats-the-issue",
    "title": "Week 5: Continuous Distributions",
    "section": "So What‚Äôs the Issue?",
    "text": "So What‚Äôs the Issue?\n\nSo far so good. It turns out (though Paxton and Jeff don‚Äôt know this) the teams are both mediocre: \\(H \\sim \\mathcal{N}(0,10)\\), \\(B \\sim \\mathcal{N}(0,10)\\)‚Ä¶ What is the distribution of \\(R\\)?\n\n\n\n\\[\n\\begin{gather*}\nR \\sim \\text{Cauchy}\\left( 0, 1 \\right)\n\\end{gather*}\n\\]\n\\[\n\\begin{align*}\n\\expect{R} &= ‚ò†Ô∏è \\\\\n\\Var{R} &= ‚ò†Ô∏è \\\\\nM_R(t) &= ‚ò†Ô∏è\n\\end{align*}\n\\]\n\n\n\n\nFrom (agnesi_analytical_1801?) [Internet Archive]\n\n\n\n\nEven worse, this is true regardless of variances: \\(D \\sim \\mathcal{N}(0,d)\\) and \\(W \\sim \\mathcal{N}(0,w)\\) \\(\\implies R \\sim \\text{Cauchy}\\left( 0,\\frac{d}{w} \\right)\\)‚Ä¶"
  },
  {
    "objectID": "w05/slides.html#lab-4-demo",
    "href": "w05/slides.html#lab-4-demo",
    "title": "Week 5: Continuous Distributions",
    "section": "Lab 4 Demo",
    "text": "Lab 4 Demo\n\nLab 4 Demo Link\nChoose your own adventure:\n\nOfficial lab demo\nMath puzzle lab demo\nMove on to Expectation, Variance, Moments"
  },
  {
    "objectID": "w05/slides.html#lab-4-assignment-prep",
    "href": "w05/slides.html#lab-4-assignment-prep",
    "title": "Week 5: Continuous Distributions",
    "section": "Lab 4 Assignment Prep",
    "text": "Lab 4 Assignment Prep\n\nOne of my favorite math puzzles ever:\n\n\n\n\n\nThe Problem of the Broken Stick (gardner_colossal_2001?)\n\n\nIf a stick is broken at random into three pieces, what is the probability that the pieces can be put back together into a triangle?\nThis cannot be answered without additional information about the exact method of breaking\n\nOne method is to select, independently and at random, two points from the points that range uniformly along the stick, then break the stick at these two points\nSuppose, however, that we interpret in a different way the statement ‚Äúbreak a stick at random into three pieces‚Äù. We break the stick at random, we select randomly one of the two pieces, and we break that piece at random.\n\n\n\n\n\n\nWill these two interpretations result in the same probabilities?\nIf yes, what is that probability?\nIf no, what are the probabilities in each case?"
  },
  {
    "objectID": "w05/slides.html#lab-4-assignment",
    "href": "w05/slides.html#lab-4-assignment",
    "title": "Week 5: Continuous Distributions",
    "section": "Lab 4 Assignment",
    "text": "Lab 4 Assignment\n\nLab 4 Assignment Link"
  },
  {
    "objectID": "w05/slides.html#references",
    "href": "w05/slides.html#references",
    "title": "Week 5: Continuous Distributions",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "w05/slides.html#appendix-i-dirac-delta-function",
    "href": "w05/slides.html#appendix-i-dirac-delta-function",
    "title": "Week 5: Continuous Distributions",
    "section": "Appendix I: Dirac Delta Function",
    "text": "Appendix I: Dirac Delta Function\n\n\\(\\delta(v)\\) as used in the ‚ÄúTop Secret Fun Fact‚Äù slide is called the Dirac Delta function.\nIt enables conversion of discrete distributions into continuous distributions as it represents an ‚Äúinfinite point mass‚Äù at \\(0\\) that can be integrated1:\n\n\\[\n\\delta(v) = \\begin{cases}\\infty & v = 0 \\\\ 0 & v \\neq 0\\end{cases}\n\\]\n\nIts integral also has a name: integrating over \\(v \\in (-\\infty, \\infty)\\) produces the Heaviside step function \\(\\theta(v)\\):\n\n\\[\n\\int_{-\\infty}^{\\infty}\\delta(v)dv = \\theta(v) = \\begin{cases} 1 & v = 0 \\\\ 0 & v \\neq 0\\end{cases}\n\\]\nThis is leaving out some of the complexities of defining this function so it ‚Äúworks‚Äù in this way: for example, we need to use the Lebesgue integral rather than the (standard) Riemann integral for it to be defined at all, and even then it technically fails the conditions necessary for a fully-well-defined Lebesgue integral. For full details see this section from the Wiki article on PDFs, and follow the links therein."
  },
  {
    "objectID": "w05/slides.html#appendix-ii-countability-of-mathbbq",
    "href": "w05/slides.html#appendix-ii-countability-of-mathbbq",
    "title": "Week 5: Continuous Distributions",
    "section": "Appendix II: Countability of \\(\\mathbb{Q}\\)",
    "text": "Appendix II: Countability of \\(\\mathbb{Q}\\)\n\nBad definition: ‚Äú\\(\\mathbb{N}\\) is countable because no \\(x \\in \\mathbb{N}\\) between \\(0\\) and \\(1\\). \\(\\mathbb{R}\\) is uncountable because infinitely-many \\(x \\in \\mathbb{R}\\) between \\(0\\) and \\(1\\).‚Äù (\\(\\implies \\mathbb{Q}\\) uncountable)\nAnd yet, \\(\\mathbb{Q}\\) is countable‚Ä¶\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\begin{array}{ll}\ns: \\mathbb{N} \\leftrightarrow \\mathbb{Z} & s(n) = (-1)^n \\left\\lfloor \\frac{n+1}{2} \\right\\rfloor \\\\\nh_+: \\mathbb{Z}^+ \\leftrightarrow \\mathbb{Q}^+ & p_1^{a_1}p_2^{a_2}\\cdots \\mapsto p_1^{s(a_1)}p_2^{s(a_2)}\\cdots \\\\\nh: \\mathbb{Z} \\leftrightarrow \\mathbb{Q} & h(n) = \\begin{cases}h_+(n) &n &gt; 0 \\\\ 0 & n = 0 \\\\\n-h_+(-n) & n &lt; 0\\end{cases} \\\\\n(h \\circ s): \\mathbb{N} \\leftrightarrow \\mathbb{Q} & ‚úÖü§Ø\n\\end{array}\n\\end{align*}\n\\]\n\n\n\nImage credit: Rebecca J. Stones, Math StackExchange. Math credit: Thomas Andrews, Math StackExchange"
  },
  {
    "objectID": "w05/slides.html#appendix-iii-binomial-triangle",
    "href": "w05/slides.html#appendix-iii-binomial-triangle",
    "title": "Week 5: Continuous Distributions",
    "section": "Appendix III: Binomial Triangle",
    "text": "Appendix III: Binomial Triangle\n\n\n\n\nDSAN 5100-03 W05: Continuous Distributions"
  },
  {
    "objectID": "w05/index.html",
    "href": "w05/index.html",
    "title": "Week 5: Continuous Distributions",
    "section": "",
    "text": "Open slides in new window ‚Üí",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#discrete-vs.-continuous",
    "href": "w05/index.html#discrete-vs.-continuous",
    "title": "Week 5: Continuous Distributions",
    "section": "Discrete vs.¬†Continuous",
    "text": "Discrete vs.¬†Continuous\n\n\n\nDiscrete = ‚ÄúEasy mode‚Äù: Based (intuitively) on sets\n\\(\\Pr(A)\\): Four equally-likely marbles \\(\\{A, B, C, D\\}\\) in box, what is probability I pull out \\(A\\)?\n\n\nlibrary(tibble)\nlibrary(ggplot2)\ndisc_df &lt;- tribble(\n  ~x, ~y, ~label,\n  0, 0, \"A\",\n  0, 1, \"B\",\n  1, 0, \"C\",\n  1, 1, \"D\"\n)\nggplot(disc_df, aes(x=x, y=y, label=label)) +\n    geom_point(size=g_pointsize) +\n    geom_text(\n      size=g_textsize,\n      hjust=1.5,\n      vjust=-0.5\n    ) +\n    xlim(-0.5,1.5) + ylim(-0.5,1.5) +\n    coord_fixed() +\n    dsan_theme(\"quarter\") +\n    labs(\n      title=\"Discrete Probability Space in N\"\n    )\n\n\n\n\n\n\n\n\n\\[\n\\Pr(A) = \\underset{\\mathclap{\\small \\text{Probability }\\textbf{mass}}}{\\boxed{\\frac{|\\{A\\}|}{|\\Omega|}}} = \\frac{1}{|\\{A,B,C,D\\}|} = \\frac{1}{4}\n\\]\n\n\nContinuous = ‚ÄúHard mode‚Äù: Based (intuitively) on areas\n\\(\\Pr(A)\\): Throw dart at random point in square, what is probability I hit \\(\\require{enclose}\\enclose{circle}{\\textsf{A}}\\)?\n\n\nlibrary(ggforce)\nggplot(disc_df, aes(x=x, y=y, label=label)) +\n    xlim(-0.5,1.5) + ylim(-0.5,1.5) +\n    geom_rect(aes(xmin = -0.5, xmax = 1.5, ymin = -0.5, ymax = 1.5), fill=cbPalette[1], color=\"black\", alpha=0.3) +\n    geom_circle(aes(x0=x, y0=y, r=0.25), fill=cbPalette[2]) +\n    coord_fixed() +\n    dsan_theme(\"quarter\") +\n    geom_text(\n      size=g_textsize,\n      #hjust=1.75,\n      #vjust=-0.75\n    ) +\n    geom_text(\n      data=data.frame(label=\"Œ©\"),\n      aes(x=-0.4,y=1.39),\n      parse=TRUE,\n      size=10\n    ) +\n    labs(\n      title=expression(\"Continuous Probability Space in \"*R^2)\n    )\n\n\n\n\n\n\n\n\n\\[\n\\Pr(A) = \\underset{\\mathclap{\\small \\text{Probability }\\textbf{density}}}{\\boxed{\\frac{\\text{Area}(\\{A\\})}{\\text{Area}(\\Omega)}}} = \\frac{\\pi r^2}{s^2} = \\frac{\\pi \\left(\\frac{1}{4}\\right)^2}{4} = \\frac{\\pi}{64}\n\\]",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#the-technical-difference-tldr",
    "href": "w05/index.html#the-technical-difference-tldr",
    "title": "Week 5: Continuous Distributions",
    "section": "The Technical Difference tl;dr",
    "text": "The Technical Difference tl;dr\n\nCountable Sets: Can be put into 1-to-1 correspondence with natural numbers \\(\\mathbb{N}\\)\n\nWhat are you doing when you‚Äôre counting? Saying ‚Äúfirst‚Äù, ‚Äúsecond‚Äù, ‚Äúthird‚Äù, ‚Ä¶\nYou‚Äôre pairing each object with a natural number! \\(\\{(\\texttt{a},1),(\\texttt{b},2),\\ldots,(\\texttt{z},26)\\}\\) \n\nUncountable Sets: Can‚Äôt be put into 1-to-1 correspondence with natural numbers.\n\\(\\mathbb{R}\\) is uncountable. Intuition: Try counting the real numbers. Proof \\[\n\\text{Assume }\\exists \\, (f: \\mathbb{R} \\leftrightarrow \\mathbb{N}):\n\\begin{array}{|c|c|c|c|c|c|c|}\\hline\n\\mathbb{R} & & & & & & \\Leftrightarrow \\mathbb{N} \\\\ \\hline\n\\color{orange}{3} & . & 1 & 4 & 1 & \\cdots & \\Leftrightarrow 1 \\\\\\hline\n4 & . & \\color{orange}{9} & 9 & 9 & \\cdots & \\Leftrightarrow 2 \\\\\\hline\n0 & . & 1 & \\color{orange}{2} & 3 & \\cdots &\\Leftrightarrow 3 \\\\\\hline\n1 & . & 2 & 3 & \\color{orange}{4} & \\cdots & \\Leftrightarrow 4 \\\\\\hline\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\\hline\n\\end{array} \\overset{\\color{blue}{y_{[i]}} = \\color{orange}{x_{[i]}} \\overset{\\mathbb{Z}_{10}}{+} 1}{\\underset{üòà}{\\longrightarrow}} \\color{blue}{y = 4.035 \\ldots} \\Leftrightarrow \\; ?\n\\]\n\n\n\nFun math challenge: Is \\(\\mathbb{Q}\\) countable? See this appendix slide for why the answer is yes, despite the fact that \\(\\forall x, y \\in \\mathbb{Q} \\left[ \\frac{x+y}{2} \\in \\mathbb{Q} \\right]\\)‚ùóÔ∏è The method used in the above proof is called Cantor diagonalization",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#the-practical-difference",
    "href": "w05/index.html#the-practical-difference",
    "title": "Week 5: Continuous Distributions",
    "section": "The Practical Difference",
    "text": "The Practical Difference\n\nThis part of the course (discrete probability): \\(\\Pr(X = v), v \\in \\mathcal{R}_X \\subseteq \\mathbb{N}\\)\n\nExample: \\(\\Pr(\\)\\() = \\Pr(X = 3), 3 \\in \\{1,2,3,4,5,6\\} \\subseteq \\mathbb{N}\\)\n\nNext part of the course (continuous probability): \\(\\Pr(X \\in V), V \\subseteq \\mathbb{R}\\)\n\nExample: \\(\\Pr(X \\geq 2\\pi) = \\Pr(X \\in [\\pi,\\infty)), [\\pi,\\infty) \\subseteq \\mathbb{R}\\)\n\nWhy do they have to be in separate parts?\n\n\\[\n\\Pr(X \\underset{\\substack{\\uparrow \\\\ üö©}}{=} 2\\pi) = \\frac{\\text{Area}(\\overbrace{2\\pi}^{\\mathclap{\\small \\text{Single point}}})}{\\text{Area}(\\underbrace{\\mathbb{R}}_{\\mathclap{\\small \\text{(Uncountably) Infinite set of points}}})} = 0\n\\]",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#the-cdf-unifies-the-two-worlds",
    "href": "w05/index.html#the-cdf-unifies-the-two-worlds",
    "title": "Week 5: Continuous Distributions",
    "section": "The CDF Unifies the Two Worlds!",
    "text": "The CDF Unifies the Two Worlds!\n\nCumulative Distribution Function (CDF): \\(F_X(v) = \\Pr(X \\leq v)\\)1\nFor discrete RV \\(X\\) (\\(\\mathcal{R}_X \\cong \\mathbb{N}\\)), Probability Mass Function (pmf) \\(p_X(v)\\): \\[\n\\begin{align*}\np_X(v) &\\definedas \\Delta F_X(v) \\definedas F_X(v) - F_X(v - 1) = \\underset{\\text{Meaningful}}{\\boxed{\\Pr(X = v)}} \\\\\n\\implies F_X(v) &= \\sum_{\\{w \\in \\mathcal{R}_X: \\; w \\leq v\\}}p_X(w) = \\underset{\\text{Meaningful}}{\\boxed{\\Pr(X \\leq v)}}\n\\end{align*}\n\\]\nFor continuous RV \\(X\\) (\\(\\mathcal{R}_X \\subseteq \\mathbb{R}\\)), Probability Density Function (pdf) \\(f_X(v)\\): \\[\n\\begin{align*}\nf_X(v) &\\definedas \\frac{d}{dx}F_X(v) \\definedas \\lim_{h \\rightarrow 0}\\frac{F(x + h) - F(x)}{h} = \\underset{\\text{Not Meaningful}}{\\boxed{\\; ? \\;}} \\\\\n\\implies F_X(v) &= \\int_{-\\infty}^v f_X(w)dw = \\underset{\\text{Meaningful}}{\\boxed{\\Pr(X \\leq v)}}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#probability-density-neq-probability",
    "href": "w05/index.html#probability-density-neq-probability",
    "title": "Week 5: Continuous Distributions",
    "section": "Probability Density \\(\\neq\\) Probability",
    "text": "Probability Density \\(\\neq\\) Probability\n\n‚ò†Ô∏èBEWARE‚ò†Ô∏è: \\(f_X(v) \\neq \\Pr(X = v)\\)!\nLong story short, for continuous variables, \\(\\Pr(X = v)\\) is just always \\(0\\)[^measurezero]\nHence, we instead construct a pdf \\(f_X(v)\\) whose sole purpose is to allow us to calculate \\(\\Pr(X \\in [a,b])\\) by integrating!\n\n\\(f_X(v)\\) is whatever satisfies \\(\\Pr(X \\in [a,b]) = \\int_{a}^bf_X(v)dv\\), and nothing more\n\ni.e., instead of \\(p_X(v) = \\Pr(X = v)\\) from discrete world, the relevant function here is \\(f_X(v)\\), the probability density of \\(X\\) at \\(v\\).\n\n\n\nScary math zone\n\n\n\nFor intuition: think of \\(X \\sim \\mathcal{U}(0,10) \\implies \\Pr(X = \\pi) = \\frac{|\\{v \\in \\mathbb{R}:\\; v = \\pi\\}|}{|\\mathbb{R}|} = \\frac{1}{2^{\\aleph_0}} \\approx 0\\). That is, finding the \\(\\pi\\) needle in the \\(\\mathbb{R}\\) haystack is a one-in-\\(\\left(\\infty^\\infty\\right)\\) event.\nIssue even if \\(\\mathcal{R}_X\\) countably infinite, like \\(\\mathcal{R}_X = \\mathbb{N}\\): \\(\\Pr(X = 3) = \\frac{|\\{x \\in \\mathbb{N} : \\; x = 3\\}|}{|\\mathbb{N}|} = \\frac{1}{\\aleph_0}\\). Finding the \\(3\\) needle in the \\(\\mathbb{N}\\) haystack is a one-in-\\(\\infty\\) event",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#bernoulli-distribution",
    "href": "w05/index.html#bernoulli-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "Bernoulli Distribution",
    "text": "Bernoulli Distribution\n\nSingle trial with two outcomes, ‚Äúsuccess‚Äù (1) or ‚Äúfailure‚Äù (0): basic model of a coin flip (heads = 1, tails = 0)\n\\(X \\sim \\text{Bern}({\\color{purple} p}) \\implies \\mathcal{R}_X = \\{0,1\\}, \\; \\Pr(X = 1) = {\\color{purple}p}\\).\n\n\nlibrary(ggplot2)\nlibrary(tibble)\nbern_tibble &lt;- tribble(\n  ~Outcome, ~Probability, ~Color,\n  \"Failure\", 0.2, cbPalette[1],\n  \"Success\", 0.8, cbPalette[2]\n)\nggplot(data = bern_tibble, aes(x=Outcome, y=Probability)) +\n  geom_bar(aes(fill=Outcome), stat = \"identity\") +\n  dsan_theme(\"half\") +\n  labs(\n    y = \"Probability Mass\"\n  ) +\n  scale_fill_manual(values=c(cbPalette[1], cbPalette[2])) +\n  remove_legend()",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#binomial-distribution",
    "href": "w05/index.html#binomial-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nNumber of successes in \\({\\color{purple}N}\\) Bernoulli trials. \\(X \\sim \\text{Binom}({\\color{purple}N},{\\color{purple}k},{\\color{purple}p}) \\implies \\mathcal{R}_X = \\{0, 1, \\ldots, N\\}\\)\n\n\\(\\Pr(X = k)  = \\binom{N}{k}p^k(1-p)^{N-k}\\): probability of \\(k\\) successes out of \\(N\\) trials.\n\\(\\binom{N}{k} = \\frac{N!}{k!(N-k)!}\\): ‚ÄúBinomial coefficient‚Äù. How many groups of size \\(k\\) can be formed?2",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#visualizing-the-binomial",
    "href": "w05/index.html#visualizing-the-binomial",
    "title": "Week 5: Continuous Distributions",
    "section": "Visualizing the Binomial",
    "text": "Visualizing the Binomial\n\n\nCode\nk &lt;- seq(0, 10)\nprob &lt;- dbinom(k, 10, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x=k, y=prob)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title=\"Binomial Distribution, N = 10, p = 0.5\",\n    y=\"Probability Mass\"\n  ) +\n  scale_x_continuous(breaks=seq(0,10)) +\n  dsan_theme(\"half\")\n\n\n\n\n\n\n\n\n\n\nSo who can tell me, from this plot, the approximate probability of getting 4 heads when flipping a coin 10 times?",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#multiple-classes-multinomial-distribution",
    "href": "w05/index.html#multiple-classes-multinomial-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "Multiple Classes: Multinomial Distribution",
    "text": "Multiple Classes: Multinomial Distribution\n\nBernoulli only allows two outcomes: success or failure.\nWhat if we‚Äôre predicting soccer match outcomes?\n\n\\(X_i \\in \\{\\text{Win}, \\text{Loss}, \\text{Draw}\\}\\)\n\nCategorical Distribution: Generalizes Bernoulli to \\(k\\) possible outcomes. \\(X \\sim \\text{Categorical}(\\mathbf{p} = \\{p_1, p_2, \\ldots, p_k\\}), \\sum_{i=1}^kp_i = 1\\).\n\n\\(\\Pr(X = k) = p_k\\)\n\nMultinomial Distribution: Generalizes Binomial to \\(k\\) possible outcomes.\n\\(\\mathbf{X} \\sim \\text{Multinom}(N,k,\\mathbf{p}=\\{p_1,p_2,\\ldots,p_k\\}), \\sum_{i=1}^kp_i=1\\)\n\n\\(\\Pr(\\mathbf{X} = \\{x_1,x_2\\ldots,x_k\\}) = \\frac{N!}{x_1!x_2!\\cdots x_k!}p_1^{x_1}p_2^{x_2}\\cdots p_k^{x_k}\\)\n\\(\\Pr(\\text{30 wins}, \\text{4 losses}, \\text{4 draws}) = \\frac{38!}{30!4!4!}p_{\\text{win}}^{30}p_{\\text{lose}}^4p_{\\text{draw}}^4\\).\n\\(\\leadsto\\) ‚ÄúMultinomial Coefficient‚Äù: \\(\\binom{38}{30,4,4} = \\frac{38!}{30!4!4!}\\)",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#geometric-distribution",
    "href": "w05/index.html#geometric-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nLikelihood that we need \\({\\color{purple}k}\\) trials to get our first success. \\(X \\sim \\text{Geom}({\\color{purple}k},{\\color{purple}p}) \\implies \\mathcal{R}_X = \\{1, 2, \\ldots\\}\\)\n\n\\(\\Pr(X = k) = \\underbrace{(1-p)^{k-1}}_{\\small k - 1\\text{ failures}}\\cdot \\underbrace{p}_{\\mathclap{\\small \\text{success}}}\\)\nProbability of \\(k\\) trials before first success\n\n\n\nlibrary(ggplot2)\nk &lt;- seq(0, 8)\nprob &lt;- dgeom(k, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x = k, y = prob)) +\n    geom_bar(stat = \"identity\", fill = cbPalette[1]) +\n    labs(\n        title = \"Geometric Distribution, p = 0.5\",\n        y = \"Probability Mass\"\n    ) +\n    scale_x_continuous(breaks = seq(0, 8)) +\n    dsan_theme(\"half\")",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#less-common-but-important-distributions",
    "href": "w05/index.html#less-common-but-important-distributions",
    "title": "Week 5: Continuous Distributions",
    "section": "Less Common (But Important) Distributions",
    "text": "Less Common (But Important) Distributions\n\nDiscrete Uniform: \\(N\\) equally-likely outcomes\n\n\\(X \\sim U\\{{\\color{purple}a},{\\color{purple}b}\\} \\implies \\mathcal{R}_X = \\{a, a+1, \\ldots, b\\}, \\Pr(X = k) = \\frac{1}{{\\color{purple}b} - {\\color{purple}a} + 1}\\)\n\nBeta: \\(X \\sim \\text{Beta}({\\color{purple}\\alpha}, {\\color{purple}\\beta})\\): conjugate prior for Bernoulli, Binomial, and Geometric dists.\n\nIntuition: If we use Beta to encode our prior hypothesis, then observe data drawn from Binomial, distribution of our updated hypothesis is still Beta.\n\\(\\underbrace{\\Pr(\\text{biased}) = \\Pr(\\text{unbiased})}_{\\text{Prior: }\\text{Beta}({\\color{purple}\\alpha}, {\\color{purple}\\beta})} \\rightarrow\\) Observe \\(\\underbrace{\\frac{8}{10}\\text{ heads}}_{\\text{Data}} \\rightarrow \\underbrace{\\Pr(\\text{biased}) = 0.65}_{\\text{Posterior: }\\text{Beta}({\\color{purple}\\alpha + 8}, {\\color{purple}\\beta + 2})}\\)\n\nDirichlet: \\(\\mathbf{X} = (X_1, X_2, \\ldots, X_K) \\sim \\text{Dir}({\\color{purple} \\boldsymbol\\alpha})\\)\n\n\\(K\\)-dimensional extension of Beta (thus, conjugate prior for Multinomial)\n\n\n\n\nWe can now use \\(\\text{Beta}(\\alpha + 8, \\beta + 2)\\) as a prior for our next set of trials (encoding our knowledge up to that point), and update further once we know the results (to yet another Beta distribution).",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#interactive-visualizations",
    "href": "w05/index.html#interactive-visualizations",
    "title": "Week 5: Continuous Distributions",
    "section": "Interactive Visualizations!",
    "text": "Interactive Visualizations!\nSeeing Theory, Brown University",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#what-things-have-distributions",
    "href": "w05/index.html#what-things-have-distributions",
    "title": "Week 5: Continuous Distributions",
    "section": "What Things Have Distributions?",
    "text": "What Things Have Distributions?\n\nAnswer: Random Variables\nMeaning: \\(\\mathcal{N}(0, 1)\\) on its own is a ‚Äútemplate‚Äù, an exhibit at a museum within a glass case\nTo start using it, e.g., to generate random values, we need to consider a particular RV \\(X \\sim \\mathcal{N}(0,1)\\), then generate values on basis of this template:\n\n\\(X = 0\\) more likely than \\(X = 1\\) or \\(X = -1\\),\n\\(X = 1\\) more likely than \\(X = 2\\) or \\(X = -2\\),\nand so on",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#cdfspdfspmfs-what-are-they",
    "href": "w05/index.html#cdfspdfspmfs-what-are-they",
    "title": "Week 5: Continuous Distributions",
    "section": "CDFs/pdfs/pmfs: What Are They?",
    "text": "CDFs/pdfs/pmfs: What Are They?\n\nFunctions which answer questions about a Random Variable (\\(X\\) in this case) with respect to a non-random value (\\(v\\) in this case, for ‚Äúvalue‚Äù)\nCDF: What is probability that \\(X\\) takes on a value less than or equal to \\(v\\)?\n\n\\[\nF_X(v) \\definedas \\Pr(X \\leq v)\n\\]\n\npmf: What is the probability of this exact value? (Discrete only)\n\n\\[\np_X(v) \\definedas \\Pr(X = v)\n\\]\n\npdf: üôà ‚Ä¶It‚Äôs the thing you integrate to get the CDF\n\n\\[\nf_X(v) \\definedas \\frac{d}{dv}F_X(v) \\iff \\int_{-\\infty}^{v} f_X(v)dv = F_X(v)\n\\]",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#cdfspdfspmfs-why-do-we-use-them",
    "href": "w05/index.html#cdfspdfspmfs-why-do-we-use-them",
    "title": "Week 5: Continuous Distributions",
    "section": "CDFs/pdfs/pmfs: Why Do We Use Them?",
    "text": "CDFs/pdfs/pmfs: Why Do We Use Them?\n\nCDF is like the ‚ÄúAPI‚Äù that allows you to access all of the information about the distribution (pdf/pmf is derived from the CDF)\nExample: we know there‚Äôs some ‚Äúthing‚Äù called the Exponential Distribution‚Ä¶\nHow do we use this distribution to understand a random variable \\(X \\sim \\text{Exp}(\\lambda)\\)?\n\nAnswer: the CDF of \\(X\\)!\nSince all exponentially-distributed RVs have the same pdf (with different \\(\\lambda\\) values plugged in), we can call this pdf ‚Äúthe‚Äù exponential distribution\n\nSay we want to find the median of \\(X\\): The median is the number(s) \\(m\\) satisfying\n\n\\[\n\\Pr(X \\leq m) = \\frac{1}{2}\n\\]\n\nHow can we find this? What ‚Äútool‚Äù do we use to figure this out about \\(X\\)?",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#finding-a-median-via-the-cdf",
    "href": "w05/index.html#finding-a-median-via-the-cdf",
    "title": "Week 5: Continuous Distributions",
    "section": "Finding a Median via the CDF",
    "text": "Finding a Median via the CDF\n\n\n\n\n\n\n Median of a Random Variable \\(X\\)\n\n\n\nThe median of a random variable \\(X\\) with some CDF \\(F_X(v_X)\\) is the [set of] numbers \\(m\\) for which the probability that \\(X\\) is lower than \\(m\\) is \\(\\frac{1}{2}\\):\n\\[\n\\begin{align*}\n\\text{Median}(X) &= \\left\\{m \\left| F_X(m) = \\frac{1}{2} \\right. \\right\\} \\\\\n&= \\left\\{m \\left| \\int_{-\\infty}^{m}f_X(v_X)dv_X = \\frac{1}{2} \\right. \\right\\}\n\\end{align*}\n\\]\n\n\n\n\n(If you‚Äôre wondering why we start with the median rather than the more commonly-used mean: it‚Äôs specifically because I want you to get used to calculating general functions \\(f(X)\\) of a random variable \\(X\\). It‚Äôs easy to just e.g.¬†learn how to compute the mean \\(\\expect{X}\\) and forget that this is only one of many possible choices for \\(f(X)\\).)",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#median-via-cdf-example",
    "href": "w05/index.html#median-via-cdf-example",
    "title": "Week 5: Continuous Distributions",
    "section": "Median via CDF Example",
    "text": "Median via CDF Example\nExample: If \\(X \\sim \\text{Exp}(\\param{\\lambda})\\),\n\\[\nF_X(v) = 1 - e^{-\\lambda v}\n\\]\nSo we want to solve for \\(m\\) in\n\\[\nF_X(m) = \\frac{1}{2} \\iff 1 - e^{-\\lambda m} = \\frac{1}{2}\n\\]",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#step-by-step",
    "href": "w05/index.html#step-by-step",
    "title": "Week 5: Continuous Distributions",
    "section": "Step-by-Step",
    "text": "Step-by-Step\n\\[\n\\begin{align*}\n1 - e^{-\\lambda m} &= \\frac{1}{2} \\\\\n\\iff e^{-\\lambda m} &= \\frac{1}{2} \\\\\n\\iff \\ln\\left[e^{-\\lambda m}\\right] &= \\ln\\left[\\frac{1}{2}\\right] \\\\\n\\iff -\\lambda m &= -\\ln(2) \\\\\n\\iff m &= \\frac{\\ln(2)}{\\lambda}\n%3x = 19-2y\n\\; \\llap{\\mathrel{\\boxed{\\phantom{m = \\frac{\\ln(2)}{\\lambda}}}}}.\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#top-secret-fun-fact",
    "href": "w05/index.html#top-secret-fun-fact",
    "title": "Week 5: Continuous Distributions",
    "section": "Top Secret Fun Fact",
    "text": "Top Secret Fun Fact\n\nEvery Discrete Distribution is [technically, in a weird way] a Continuous Distribution!\n\n\nSame intuition as: every natural number is a real number, but converse not true\nMarbles: Let \\(X\\) be a RV defined s.t. \\(X(A) = 1\\), \\(X(B) = 2\\), \\(X(C) = 3\\), \\(X(D) = 4\\). Then pmf for \\(X\\) is \\(p_X(i) = \\frac{1}{4}\\) for \\(i \\in \\{1, 2, 3, 4\\}\\).\nWe can then use the Dirac delta function \\(\\delta(v)\\) to define a continuous pdf\n\\[\n  f_X(v) = \\sum_{i \\in \\mathcal{R}_X}p_X(i)\\delta(v - i) = \\sum_{i=1}^4p_X(i)\\delta(v-i) = \\frac{1}{4}\\sum_{i=1}^4 \\delta(v - i)\n  \\]\nand use either the (discrete) pmf \\(p_X(v)\\) or (continuous) pdf \\(f_X(v)\\) to describe \\(X\\):\n\n\\[\n\\begin{align*}\n\\overbrace{\\Pr(X \\leq 3)}^{\\text{CDF}} &= \\sum_{i=1}^3\\overbrace{p_X(i)}^{\\text{pmf}} = \\frac{1}{4} + \\frac{1}{4} + \\frac{1}{4} = \\frac{3}{4} \\\\\n\\underbrace{\\Pr(X \\leq 3)}_{\\text{CDF}} &= \\int_{-\\infty}^{3} \\underbrace{f_X(v)}_{\\text{pdf}} = \\frac{1}{4}\\int_{-\\infty}^{3} \\sum_{i = 1}^{4}\\overbrace{\\delta(v-i)}^{\\small 0\\text{ unless }v = i}dv = \\frac{3}{4}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#recall-binomial-distribution",
    "href": "w05/index.html#recall-binomial-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "[Recall] Binomial Distribution",
    "text": "[Recall] Binomial Distribution\n\n\nCode\nk &lt;- seq(0, 10)\nprob &lt;- dbinom(k, 10, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x=k, y=prob)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title=\"Binomial Distribution, N = 10, p = 0.5\",\n    y=\"Probability Mass\"\n  ) +\n  scale_x_continuous(breaks=seq(0,10)) +\n  dsan_theme(\"half\")",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#the-emergence-of-order",
    "href": "w05/index.html#the-emergence-of-order",
    "title": "Week 5: Continuous Distributions",
    "section": "The Emergence of Order",
    "text": "The Emergence of Order\n\n\n\nWho can guess the state of this process after 10 steps, with 1 person?\n10 people? 50? 100? (If they find themselves on the same spot, they stand on each other‚Äôs heads)\n100 steps? 1000?",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#the-result-16-steps",
    "href": "w05/index.html#the-result-16-steps",
    "title": "Week 5: Continuous Distributions",
    "section": "The Result: 16 Steps",
    "text": "The Result: 16 Steps\n\n\nCode\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(ggExtra)\nlibrary(dplyr)\nlibrary(tidyr)\n# From McElreath!\ngen_histo &lt;- function(reps, num_steps) {\n  support &lt;- c(-1,1)\n  pos &lt;-replicate(reps, sum(sample(support,num_steps,replace=TRUE,prob=c(0.5,0.5))))\n  #print(mean(pos))\n  #print(var(pos))\n  pos_df &lt;- tibble(x=pos)\n  clt_distr &lt;- function(x) dnorm(x, 0, sqrt(num_steps))\n  plot &lt;- ggplot(pos_df, aes(x=x)) +\n    geom_histogram(aes(y = after_stat(density)), fill=cbPalette[1], binwidth = 2) +\n    stat_function(fun = clt_distr) +\n    dsan_theme(\"quarter\") +\n    theme(title=element_text(size=16)) +\n    labs(\n      title=paste0(reps,\" Random Walks, \",num_steps,\" Steps\")\n    )\n  return(plot)\n}\ngen_walkplot &lt;- function(num_people, num_steps, opacity=0.15) {\n  support &lt;- c(-1, 1)\n  # Unique id for each person\n  pid &lt;- seq(1, num_people)\n  pid_tib &lt;- tibble(pid)\n  pos_df &lt;- tibble()\n  end_df &lt;- tibble()\n  all_steps &lt;- t(replicate(num_people, sample(support, num_steps, replace = TRUE, prob = c(0.5, 0.5))))\n  csums &lt;- t(apply(all_steps, 1, cumsum))\n  csums &lt;- cbind(0, csums)\n  # Last col is the ending positions\n  ending_pos &lt;- csums[, dim(csums)[2]]\n  end_tib &lt;- tibble(pid = seq(1, num_people), endpos = ending_pos, x = num_steps)\n  # Now convert to tibble\n  ctib &lt;- as_tibble(csums, name_repair = \"none\")\n  merged_tib &lt;- bind_cols(pid_tib, ctib)\n  long_tib &lt;- merged_tib %&gt;% pivot_longer(!pid)\n  # Convert name -&gt; step_num\n  long_tib &lt;- long_tib %&gt;% mutate(step_num = strtoi(gsub(\"V\", \"\", name)) - 1)\n  # print(end_df)\n  grid_color &lt;- rgb(0, 0, 0, 0.1)\n\n  # And plot!\n  walkplot &lt;- ggplot(\n      long_tib,\n      aes(\n          x = step_num,\n          y = value,\n          group = pid,\n          # color=factor(label)\n      )\n  ) +\n      geom_line(linewidth = g_linesize, alpha = opacity, color = cbPalette[1]) +\n      geom_point(data = end_tib, aes(x = x, y = endpos), alpha = 0) +\n      scale_x_continuous(breaks = seq(0, num_steps, num_steps / 4)) +\n      scale_y_continuous(breaks = seq(-20, 20, 10)) +\n      dsan_theme(\"quarter\") +\n      theme(\n          legend.position = \"none\",\n          title = element_text(size = 16)\n      ) +\n      theme(\n          panel.grid.major.y = element_line(color = grid_color, linewidth = 1, linetype = 1)\n      ) +\n      labs(\n          title = paste0(num_people, \" Random Walks, \", num_steps, \" Steps\"),\n          x = \"Number of Steps\",\n          y = \"Position\"\n      )\n}\nwp1 &lt;- gen_walkplot(500, 16, 0.05)\nggMarginal(wp1, margins = \"y\", type = \"histogram\", yparams = list(binwidth = 1))",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#the-result-64-steps",
    "href": "w05/index.html#the-result-64-steps",
    "title": "Week 5: Continuous Distributions",
    "section": "The Result: 64 Steps",
    "text": "The Result: 64 Steps\n\n\nCode\nlibrary(ggExtra)\nwp2 &lt;- gen_walkplot(5000,64,0.008) +\n  ylim(-30,30)\nggMarginal(wp2, margins = \"y\", type = \"histogram\", yparams = list(binwidth = 1))\n\n\n\n\n\n\n\n\n\n\n\n\np2 &lt;- gen_histo(1000, 16)\np2\n\n\n\n\n\n\n\n\n\np3 &lt;- gen_histo(10000, 32)\np3",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#whats-going-on-here",
    "href": "w05/index.html#whats-going-on-here",
    "title": "Week 5: Continuous Distributions",
    "section": "What‚Äôs Going On Here?",
    "text": "What‚Äôs Going On Here?\n\n\n\n\n\n(Stay tuned for Markov processes \\(\\overset{t \\rightarrow \\infty}{\\leadsto}\\) Stationary distributions!)",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#properties-of-the-normal-distribution",
    "href": "w05/index.html#properties-of-the-normal-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "Properties of the Normal Distribution",
    "text": "Properties of the Normal Distribution\n\nIf \\(X \\sim \\mathcal{N}(\\param{\\mu}, \\param{\\theta})\\), then \\(X\\) has pdf \\(f_X(v)\\) defined by\n\n\\[\nf_X(v) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\bigexp{-\\frac{1}{2}\\left(\\frac{v - \\mu}{\\sigma}\\right)^2}\n\\]\n\nI hate memorizing as much as you do, I promise ü•¥\nThe important part (imo): this is the most conservative out of all possible (symmetric) prior distributions defined on \\(\\mathbb{R}\\) (defined from \\(-\\infty\\) to \\(\\infty\\))",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#most-conservative-how",
    "href": "w05/index.html#most-conservative-how",
    "title": "Week 5: Continuous Distributions",
    "section": "‚ÄúMost Conservative‚Äù How?",
    "text": "‚ÄúMost Conservative‚Äù How?\n\nOf all possible distributions with mean \\(\\mu\\), variance \\(\\sigma^2\\), \\(\\mathcal{N}(\\mu, \\sigma^2)\\) is the entropy-maximizing distribution\nRoughly: using any other distribution (implicitly/secretly) imports additional information beyond the fact that mean is \\(\\mu\\) and variance is \\(\\sigma^2\\)\nExample: let \\(X\\) be an RV. If we know mean is \\(\\mu\\), variance is \\(\\sigma^2\\), but then we learn that \\(X \\neq 3\\), or \\(X\\) is even, or the 15th digit of \\(X\\) is 7, can update \\(\\mathcal{N}(\\mu,\\sigma^2)\\) to derive a ‚Äúbetter‚Äù distribution (incorporating this additional info)",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#the-takeaway",
    "href": "w05/index.html#the-takeaway",
    "title": "Week 5: Continuous Distributions",
    "section": "The Takeaway",
    "text": "The Takeaway\n\nGiven info we know, we can find a distribution that ‚Äúencodes‚Äù only this info\nMore straightforward example: if we only know that the value is something in the range \\([a,b]\\), entropy-maximizing distribution is the Uniform Distribution\n\n\n\n\n\n\n\n\n\nIf We Know\nAnd We Know\n(Max-Entropy) Distribution Is‚Ä¶\n\n\n\n\n\\(\\text{Mean}[X] = \\mu\\)\n\\(\\text{Var}[X] = \\sigma^2\\)\n\\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\n\n\n\\(\\text{Mean}[X] = \\lambda\\)\n\\(X \\geq 0\\)\n\\(X \\sim \\text{Exp}\\left(\\frac{1}{\\lambda}\\right)\\)\n\n\n\\(X \\geq a\\)\n\\(X \\leq b\\)\n\\(X \\sim \\mathcal{U}[a,b]\\)",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#recall-discrete-uniform-distribution",
    "href": "w05/index.html#recall-discrete-uniform-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "[Recall] Discrete Uniform Distribution",
    "text": "[Recall] Discrete Uniform Distribution\n\n\nCode\nlibrary(tibble)\nbar_data &lt;- tribble(\n  ~x, ~prob,\n  1, 1/6,\n  2, 1/6,\n  3, 1/6,\n  4, 1/6,\n  5, 1/6,\n  6, 1/6\n)\nggplot(bar_data, aes(x=x, y=prob)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title=\"Discrete Uniform pmf: a = 1, b = 6\",\n    y=\"Probability Mass\",\n    x=\"Value\"\n  ) +\n  scale_x_continuous(breaks=seq(1,6)) +\n  dsan_theme(\"half\")",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#continuous-uniform-distribution",
    "href": "w05/index.html#continuous-uniform-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "Continuous Uniform Distribution",
    "text": "Continuous Uniform Distribution\n\nIf \\(X \\sim \\mathcal{U}[a,b]\\), then intuitively \\(X\\) is a value randomly selected from within \\([a,b]\\), with all values equally likely.\nDiscrete case: what we‚Äôve been using all along (e.g., dice): if \\(X \\sim \\mathcal{U}\\{1,6\\}\\), then\n\n\\[\n\\Pr(X = 1) = \\Pr(X = 2) = \\cdots = \\Pr(X = 6) = \\frac{1}{6}\n\\]\n\nFor continuous case‚Ä¶ what do we put in the denominator? \\(X \\sim \\mathcal{U}[1,6] \\implies \\Pr(X = \\pi) = \\frac{1}{?}\\)‚Ä¶\n\nAnswer: \\(\\Pr(X = \\pi) = \\frac{1}{|[1,6]|} = \\frac{1}{\\aleph_0} = 0\\)",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#constructing-the-uniform-cdf",
    "href": "w05/index.html#constructing-the-uniform-cdf",
    "title": "Week 5: Continuous Distributions",
    "section": "Constructing the Uniform CDF",
    "text": "Constructing the Uniform CDF\n\nWe were ready for this! We already knew \\(\\Pr(X = v) = 0\\) for continuous \\(X\\)\nSo, we forget about \\(\\Pr(X = v)\\), and focus on \\(\\Pr(X \\in [v_0, v_1])\\).\nIn 2D (dartboard) we had \\(\\Pr(X \\in \\circ) = \\frac{\\text{Area}(\\circ)}{\\text{Area}(\\Omega)}\\), so here we should have\n\n\\[\nP(X \\in [v_0,v_1]) = \\frac{\\text{Length}([v_0,v_1])}{\\text{Length}([1,6])}\n\\]\n\nAnd indeed, the CDF of \\(X\\) is \\(\\boxed{F_X(v) = \\Pr(X \\leq v) = \\frac{v-a}{b-a}}\\), so that\n\n\\[\n\\Pr(X \\in [v_0,v_1]) = F_X(v_1) - F_X(v_0) = \\frac{v_1-a}{b-a} - \\frac{v_0-a}{b-a} = \\frac{v_1 - v_0}{b-a}\n\\]\n\nSince \\(a = 1\\), \\(b = 6\\) in our example, \\(\\Pr(X \\in [v_0,v_1]) = \\frac{v_1-v_0}{6-1} = \\frac{\\text{Length}([v_0,v_1])}{\\text{Length}([1,6])} \\; ‚úÖ\\)",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#exponential-distribution",
    "href": "w05/index.html#exponential-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nRecall the (discrete) Geometric Distribution:\n\n\n\nCode\nlibrary(ggplot2)\nk &lt;- seq(0, 8)\nprob &lt;- dgeom(k, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x = k, y = prob)) +\n    geom_bar(stat = \"identity\", fill = cbPalette[1]) +\n    labs(\n        title = \"Geometric Distribution pmf: p = 0.5\",\n        y = \"Probability Mass\"\n    ) +\n    scale_x_continuous(breaks = seq(0, 8)) +\n    dsan_theme(\"half\")",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#now-in-continuous-form",
    "href": "w05/index.html#now-in-continuous-form",
    "title": "Week 5: Continuous Distributions",
    "section": "Now In Continuous Form!",
    "text": "Now In Continuous Form!\n\n\nCode\nmy_dexp &lt;- function(x) dexp(x, rate = 1/2)\nggplot(data.frame(x=c(0,8)), aes(x=x)) +\n  stat_function(fun=my_dexp, size=g_linesize, fill=cbPalette[1], alpha=0.8) +\n  stat_function(fun=my_dexp, geom='area', fill=cbPalette[1], alpha=0.75) +\n  dsan_theme(\"half\") +\n  labs(\n    title=\"Exponential Distribution pdf: Œª (rate) = 0.5\",\n    x = \"v\",\n    y = \"f_X(v)\"\n  )",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#the-dreaded-cauchy-distribution",
    "href": "w05/index.html#the-dreaded-cauchy-distribution",
    "title": "Week 5: Continuous Distributions",
    "section": "The Dreaded Cauchy Distribution",
    "text": "The Dreaded Cauchy Distribution\n\n\nCode\nggplot(data.frame(x=c(-4,4)), aes(x=x)) +\n  stat_function(fun=dcauchy, size=g_linesize, fill=cbPalette[1], alpha=0.75) +\n  stat_function(fun=dcauchy, geom='area', fill=cbPalette[1], alpha=0.75) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title=\"PDF of R\",\n    x = \"r\",\n    y = \"f(r)\"\n  )\n\n\n\n\n\n\n\n\n\n\nPaxton is a Houston Rockets fan, while Jeff is a Chicago Bulls fan. Paxton creates a RV \\(H\\) modeling how many games above .500 (wins minus losses) the Rockets will be in a season, while Jeff creates a similar RV \\(C\\) for the Bulls\nThey decide to combine their RVs to create a new RV, \\(R = \\frac{H}{C}\\), which now models how much better the Nuggets will be in a season (\\(R\\) for ‚ÄúRatio‚Äù)\nFor example, if the Rockets are \\(10\\) games above .500, while the Bulls are only \\(5\\) above .500, \\(R = \\frac{10}{5} = 2\\). If they‚Äôre both 3 games above .500, \\(R = \\frac{3}{3} = 1\\).",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#so-whats-the-issue",
    "href": "w05/index.html#so-whats-the-issue",
    "title": "Week 5: Continuous Distributions",
    "section": "So What‚Äôs the Issue?",
    "text": "So What‚Äôs the Issue?\n\nSo far so good. It turns out (though Paxton and Jeff don‚Äôt know this) the teams are both mediocre: \\(H \\sim \\mathcal{N}(0,10)\\), \\(B \\sim \\mathcal{N}(0,10)\\)‚Ä¶ What is the distribution of \\(R\\)?\n\n\n\n\\[\n\\begin{gather*}\nR \\sim \\text{Cauchy}\\left( 0, 1 \\right)\n\\end{gather*}\n\\]\n\\[\n\\begin{align*}\n\\expect{R} &= ‚ò†Ô∏è \\\\\n\\Var{R} &= ‚ò†Ô∏è \\\\\nM_R(t) &= ‚ò†Ô∏è\n\\end{align*}\n\\]\n\n\n\n\nFrom (agnesi_analytical_1801?) [Internet Archive]\n\n\n\n\n\nEven worse, this is true regardless of variances: \\(D \\sim \\mathcal{N}(0,d)\\) and \\(W \\sim \\mathcal{N}(0,w)\\) \\(\\implies R \\sim \\text{Cauchy}\\left( 0,\\frac{d}{w} \\right)\\)‚Ä¶",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#lab-4-demo",
    "href": "w05/index.html#lab-4-demo",
    "title": "Week 5: Continuous Distributions",
    "section": "Lab 4 Demo",
    "text": "Lab 4 Demo\n\nLab 4 Demo Link\nChoose your own adventure:\n\nOfficial lab demo\nMath puzzle lab demo\nMove on to Expectation, Variance, Moments",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#lab-4-assignment-prep",
    "href": "w05/index.html#lab-4-assignment-prep",
    "title": "Week 5: Continuous Distributions",
    "section": "Lab 4 Assignment Prep",
    "text": "Lab 4 Assignment Prep\n\nOne of my favorite math puzzles ever:\n\n\n\n\n\n\n\nThe Problem of the Broken Stick (gardner_colossal_2001?)\n\n\n\nIf a stick is broken at random into three pieces, what is the probability that the pieces can be put back together into a triangle?\nThis cannot be answered without additional information about the exact method of breaking\n\nOne method is to select, independently and at random, two points from the points that range uniformly along the stick, then break the stick at these two points\nSuppose, however, that we interpret in a different way the statement ‚Äúbreak a stick at random into three pieces‚Äù. We break the stick at random, we select randomly one of the two pieces, and we break that piece at random.\n\n\n\n\nWill these two interpretations result in the same probabilities?\nIf yes, what is that probability?\nIf no, what are the probabilities in each case?",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#lab-4-assignment",
    "href": "w05/index.html#lab-4-assignment",
    "title": "Week 5: Continuous Distributions",
    "section": "Lab 4 Assignment",
    "text": "Lab 4 Assignment\n\nLab 4 Assignment Link",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#references",
    "href": "w05/index.html#references",
    "title": "Week 5: Continuous Distributions",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#appendix-i-dirac-delta-function",
    "href": "w05/index.html#appendix-i-dirac-delta-function",
    "title": "Week 5: Continuous Distributions",
    "section": "Appendix I: Dirac Delta Function",
    "text": "Appendix I: Dirac Delta Function\n\n\\(\\delta(v)\\) as used in the ‚ÄúTop Secret Fun Fact‚Äù slide is called the Dirac Delta function.\nIt enables conversion of discrete distributions into continuous distributions as it represents an ‚Äúinfinite point mass‚Äù at \\(0\\) that can be integrated3:\n\n\\[\n\\delta(v) = \\begin{cases}\\infty & v = 0 \\\\ 0 & v \\neq 0\\end{cases}\n\\]\n\nIts integral also has a name: integrating over \\(v \\in (-\\infty, \\infty)\\) produces the Heaviside step function \\(\\theta(v)\\):\n\n\\[\n\\int_{-\\infty}^{\\infty}\\delta(v)dv = \\theta(v) = \\begin{cases} 1 & v = 0 \\\\ 0 & v \\neq 0\\end{cases}\n\\]",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#appendix-ii-countability-of-mathbbq",
    "href": "w05/index.html#appendix-ii-countability-of-mathbbq",
    "title": "Week 5: Continuous Distributions",
    "section": "Appendix II: Countability of \\(\\mathbb{Q}\\)",
    "text": "Appendix II: Countability of \\(\\mathbb{Q}\\)\n\nBad definition: ‚Äú\\(\\mathbb{N}\\) is countable because no \\(x \\in \\mathbb{N}\\) between \\(0\\) and \\(1\\). \\(\\mathbb{R}\\) is uncountable because infinitely-many \\(x \\in \\mathbb{R}\\) between \\(0\\) and \\(1\\).‚Äù (\\(\\implies \\mathbb{Q}\\) uncountable)\nAnd yet, \\(\\mathbb{Q}\\) is countable‚Ä¶\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\begin{array}{ll}\ns: \\mathbb{N} \\leftrightarrow \\mathbb{Z} & s(n) = (-1)^n \\left\\lfloor \\frac{n+1}{2} \\right\\rfloor \\\\\nh_+: \\mathbb{Z}^+ \\leftrightarrow \\mathbb{Q}^+ & p_1^{a_1}p_2^{a_2}\\cdots \\mapsto p_1^{s(a_1)}p_2^{s(a_2)}\\cdots \\\\\nh: \\mathbb{Z} \\leftrightarrow \\mathbb{Q} & h(n) = \\begin{cases}h_+(n) &n &gt; 0 \\\\ 0 & n = 0 \\\\\n-h_+(-n) & n &lt; 0\\end{cases} \\\\\n(h \\circ s): \\mathbb{N} \\leftrightarrow \\mathbb{Q} & ‚úÖü§Ø\n\\end{array}\n\\end{align*}\n\\]\n\n\n\n\nImage credit: Rebecca J. Stones, Math StackExchange. Math credit: Thomas Andrews, Math StackExchange",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#appendix-iii-binomial-triangle",
    "href": "w05/index.html#appendix-iii-binomial-triangle",
    "title": "Week 5: Continuous Distributions",
    "section": "Appendix III: Binomial Triangle",
    "text": "Appendix III: Binomial Triangle",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#footnotes",
    "href": "w05/index.html#footnotes",
    "title": "Week 5: Continuous Distributions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTextbooks sometimes write \\(F(x) = \\Pr(X \\leq x)\\), where capital \\(X\\) is a RV while lowercase \\(x\\) is a particular value, like \\(3\\). To reduce confusion, I use \\(X\\) for the RV and \\(v\\) for the value at which we‚Äôre checking the CDF. Also note capitalized CDF but lowercase pmf/pdf, matching mathematical notation: \\(f_X(v)\\) is the derivative of \\(F_X(v)\\).‚Ü©Ô∏é\nFun way to avoid memorizing! Imagine a pyramid like \\(\\genfrac{}{}{0pt}{}{}{\\boxed{\\phantom{1}}}\\genfrac{}{}{0pt}{}{\\boxed{\\phantom{1}}}{}\\genfrac{}{}{0pt}{}{}{\\boxed{\\phantom{1}}}\\), where boxes are slots for numbers. Put a \\(1\\) in box at the top. In bottom row, fill each slot with the sum of the two numbers above-left and above-right of it. Since \\(1 + \\text{(nothing)} = 1\\), this looks like: \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\). Continue filling in rows this way, so next row looks like \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{2}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\), then \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{3}\\genfrac{}{}{0pt}{}{2}{}\\genfrac{}{}{0pt}{}{}{3}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\), etc. The \\(k\\)th number in the \\(N\\)th row (counting from \\(0\\)) is \\(\\binom{N}{k}\\). Appendix shows triangle written out to 7th row!‚Ü©Ô∏é\nThis is leaving out some of the complexities of defining this function so it ‚Äúworks‚Äù in this way: for example, we need to use the Lebesgue integral rather than the (standard) Riemann integral for it to be defined at all, and even then it technically fails the conditions necessary for a fully-well-defined Lebesgue integral. For full details see this section from the Wiki article on PDFs, and follow the links therein.‚Ü©Ô∏é",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w03/slides.html#logic-sets-and-probability",
    "href": "w03/slides.html#logic-sets-and-probability",
    "title": "Week 3: Random Variables",
    "section": "Logic, Sets, and Probability",
    "text": "Logic, Sets, and Probability\nDeep connection between objects and operations of logic, set theory, and probability:\n\n\n\n\n\n\n\n\n\n\nLogic\nSet Theory\nProbability Theory\n\n\n\n\nObjects\nPredicates\\(p, q \\in \\{T, F\\}\\)\nSets\\(S = \\{a, b, \\ldots\\}\\)\nEvents\\(E = \\{TT, TH, HT, HH\\}\\)\n\n\nConjunction\nAnd (\\(\\wedge\\))\\(p \\wedge q\\)\nIntersection (\\(\\cap\\))\\(A \\cap B\\)\nMultiplication (\\(\\times\\)):\\(\\Pr(E_1 \\cap E_2) = \\Pr(E_1)\\times \\Pr(E_2)\\)\n\n\nDisjunction\nOr (\\(\\vee\\))\\(p \\vee q\\)\nUnion (\\(\\cup\\))\\(A \\cup B\\)\nAddition (\\(+\\)): \\(\\Pr(E_1 \\cup E_2) =\\)\\(\\Pr(E_1) + \\Pr(E_2) - \\Pr(E_1 \\wedge E_2)\\)\n\n\nNegation\nNot (\\(\\neg\\))\\(\\neg p\\)\nComplement (\\(^c\\))\\(S^c\\)\nSubtract from 1\\(\\Pr(A^c) = 1 - \\Pr(A)\\)"
  },
  {
    "objectID": "w03/slides.html#example-flipping-two-coins",
    "href": "w03/slides.html#example-flipping-two-coins",
    "title": "Week 3: Random Variables",
    "section": "Example: Flipping Two Coins",
    "text": "Example: Flipping Two Coins\n\nLogic: We can define 4 predicates:\n\n\\(p_1\\) = ‚ÄúFirst result is \\(H\\)‚Äù, \\(q_1\\) = ‚ÄúFirst result is \\(T\\)‚Äù\n\\(p_2\\) = ‚ÄúSecond result is \\(H\\)‚Äù, \\(q_2\\) = ‚ÄúSecond result is \\(T\\)‚Äù\n\nLogical formulas:\n\n\\(f_1 = p_1 \\wedge q_2\\): ‚ÄúFirst result is \\(H\\) and second result is \\(T\\)‚Äù\n\\(f_2 = p_1 \\vee q_2\\): ‚ÄúFirst result is \\(H\\) or second result is \\(T\\)‚Äù\n\\(f_3 = \\neg p_1\\): ‚ÄúFirst result is not \\(H\\)‚Äù\n\nThe issue?: We don‚Äôt know, until after the coins have been flipped, whether these are true or false!\nBut, we should still be able to say something about their likelihood, for example, whether \\(f_1\\) or \\(f_2\\) is more likely to happen‚Ä¶ Enter probability theory!"
  },
  {
    "objectID": "w03/slides.html#logic-rightarrow-probability",
    "href": "w03/slides.html#logic-rightarrow-probability",
    "title": "Week 3: Random Variables",
    "section": "Logic \\(\\rightarrow\\) Probability",
    "text": "Logic \\(\\rightarrow\\) Probability\n\nProbability theory lets us reason about the uncertainty surrounding logical predicates like \\(p\\) and \\(q\\), by:\n\nencoding them as sets of possibilities \\(P\\) and \\(Q\\), and\nrepresenting uncertainty around a given possibility using a probability measure \\(\\Pr: S \\mapsto [0,1]\\),\n\nthus allowing us to reason about\n\nthe likelihood of these set-encoded predicates on their own: \\(\\Pr(P)\\) and \\(\\Pr(Q)\\), but also\ntheir logical connections: \\(\\Pr(p \\wedge q) = \\Pr(P \\cap Q)\\), \\(\\Pr(\\neg p) = \\Pr(P^c)\\), and so on."
  },
  {
    "objectID": "w03/slides.html#flipping-two-coins-logic-rightarrow-probability",
    "href": "w03/slides.html#flipping-two-coins-logic-rightarrow-probability",
    "title": "Week 3: Random Variables",
    "section": "Flipping Two Coins: Logic \\(\\rightarrow\\) Probability",
    "text": "Flipping Two Coins: Logic \\(\\rightarrow\\) Probability\n\nReturning to the two coins example: we can look at the predicates and see that they exhaust all possibilities, so that we can define a sample space \\(\\Omega = \\{TT, TH, HT, HH\\}\\) of all possible outcomes of our coin-flipping experiment, noting that \\(|\\Omega| = 4\\), so there are 4 possible outcomes.\nThen we can associate each predicate with an event, a subset of the sample space, and use our na√Øve definition to compute the probability of these events:\n\n\n\n\n\n\n\n\n\nPredicate\nEvent\nProbability\n\n\n\n\n\\(p_1\\) = ‚ÄúFirst result is \\(H\\)‚Äù\n\\(P_1 = \\{HT, HH\\}\\)\n\\(\\Pr(P_1) = \\frac{|P_1|}{|\\Omega|} = \\frac{2}{4} = \\frac{1}{2}\\)\n\n\n\\(q_1\\) = ‚ÄúFirst result is \\(T\\)‚Äù\n\\(Q_1 = \\{TT, TH\\}\\)\n\\(\\Pr(Q_1) = \\frac{|Q_1|}{|\\Omega|} = \\frac{2}{4} = \\frac{1}{2}\\)\n\n\n\\(p_2\\) = ‚ÄúSecond result is \\(H\\)‚Äù\n\\(P_2 = \\{TH, HH\\}\\)\n\\(\\Pr(P_2) = \\frac{|P_2|}{|\\Omega|} = \\frac{2}{4} = \\frac{1}{2}\\)\n\n\n\\(q_2\\) = ‚ÄúSecond result is \\(T\\)‚Äù\n\\(Q_2 = \\{TT, HT\\}\\)\n\\(\\Pr(Q_2) = \\frac{|Q_2|}{|\\Omega|} = \\frac{2}{4} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "w03/slides.html#moving-from-predicates-to-formulas",
    "href": "w03/slides.html#moving-from-predicates-to-formulas",
    "title": "Week 3: Random Variables",
    "section": "Moving from Predicates to Formulas",
    "text": "Moving from Predicates to Formulas\n\nNotice that, in the four rows of the previous table, we were only computing the probabilities of ‚Äúsimple‚Äù events: events corresponding to a single predicate\nBut we promised that probability theory lets us compute probabilities for logical formulas as well! ‚Ä¶The magic of encoding events as sets becomes clear:\n\n\n\n\n\n\n\n\n\nFormula\nEvent\nProbability\n\n\n\n\n\\(f_1 = p_1 \\wedge q_2\\)\n\\[ \\begin{align*} F_1 &= P_1 \\cap Q_2 \\\\ &= \\{HT, HH\\} \\cap \\{TT, HT\\} \\\\ &= \\{HT\\} \\end{align*} \\]\n\\[\\begin{align*} \\Pr(F_1) &= \\Pr(\\{HT\\}) \\\\ &= \\frac{|\\{HT\\}|}{|S|} = \\frac{1}{4} \\phantom{= \\frac{1}{4} = \\frac{1}{4}} \\end{align*}\\]\n\n\n\\(f_2 = p_1 \\vee q_2\\)\n\\[\\begin{align*} F_2 &= P_1 \\cup Q_2 \\\\ &= \\{HT, HH\\} \\cup \\{TT, HT\\} \\\\ &= \\{TT, HT, HH\\} \\end{align*}\\]\n\\[\\begin{align*} \\Pr(F_2) &= \\Pr(\\{TT, HT, HH\\}) \\\\ &= \\frac{|\\{TT, HT, HH\\}|}{|S|} = \\frac{3}{4} \\end{align*}\\]\n\n\n\\(f_3 = \\neg p_1\\)\n\\[\\begin{align*} F_3 &= P_1^c \\\\ &= \\{HT, HH\\}^c \\phantom{\\cup \\{TT, HT\\}} \\\\ &= \\{TT, TH\\}\\end{align*}\\]\n\\[\\begin{align*} \\Pr(F_3) &= \\Pr(\\{TT, TH\\}) \\\\ &= \\frac{|\\{TT, TH\\}|}{|S|} = \\frac{2}{4} = \\frac{1}{2} \\end{align*}\\]"
  },
  {
    "objectID": "w03/slides.html#using-rules-of-probability",
    "href": "w03/slides.html#using-rules-of-probability",
    "title": "Week 3: Random Variables",
    "section": "Using ‚ÄúRules‚Äù of Probability",
    "text": "Using ‚ÄúRules‚Äù of Probability\n\nHopefully, you found all this churning through set theory to be tedious‚Ä¶ ‚ò†Ô∏è\nThis is where rules of probability come from! They simplify set-theoretic computations into simple multiplications, additions, and subtractions:\n\n\\(\\Pr(A \\cap B) = \\Pr(A) \\times \\Pr(B)\\)\n\\(\\Pr(A \\cup B) = \\Pr(A) + \\Pr(B) - \\Pr(A \\cap B)\\)\n\\(\\Pr(A^c) = 1 - \\Pr(A)\\)\n\nSince we know probabilities of the ‚Äúsimple‚Äù events \\(P_1\\), \\(Q_1\\), \\(P_2\\), \\(Q_2\\), we don‚Äôt need to ‚Äúlook inside them‚Äù! Just take the probabilities and multiply/add/subtract as needed:\n\n\n\n\n\n\n\n\n\nFormula\nEvent\nProbability\n\n\n\n\n\\(f_1 = p_1 \\wedge q_2\\)\n\\(F_1 = P_1 \\cap Q_2\\)\n\\(\\Pr(F_1) = \\Pr(P_1) \\times \\Pr(Q_2) = \\frac{1}{2}\\times \\frac{1}{2} = \\frac{1}{4}\\)\n\n\n\\(f_2 = p_1 \\vee q_2\\)\n\\(F_2 = P_1 \\cup Q_2\\)\n\\[\\textstyle{\\begin{align*} \\textstyle \\Pr(F_2) &= \\Pr(P_1) + \\Pr(Q_2) - \\Pr(P_1 \\cap Q_2) \\\\ \\textstyle &= \\frac{1}{2} + \\frac{1}{2} - \\frac{1}{4} = \\frac{3}{4} \\end{align*}}\\]\n\n\n\\(f_3 = \\neg p_1\\)\n\\(F_3 = P_1^c\\)\n\\(\\Pr(F_3) = 1 - \\Pr(P_1) = 1 - \\frac{1}{2} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "w03/slides.html#importing-results-from-logic",
    "href": "w03/slides.html#importing-results-from-logic",
    "title": "Week 3: Random Variables",
    "section": "‚ÄúImporting‚Äù Results from Logic",
    "text": "‚ÄúImporting‚Äù Results from Logic\n\nThis deep connection between the three fields means that, if we have some useful theorem or formula from one field, we can immediately put it to use in another!\nFor example: DeMorgan‚Äôs Laws were developed in logic (DeMorgan was a 19th-century logician), and basically just tell us how to distribute logic operators:\n\n\\[\n\\begin{align*}\n\\underbrace{\\neg(p \\wedge q)}_{\\text{``}p\\text{ and }q\\text{'' is not true}} &\\iff \\underbrace{\\neg p \\vee \\neg q}_{p\\text{ is not true or }q\\text{ is not true}} \\\\\n\\underbrace{\\neg(p \\vee q)}_{\\text{``}p\\text{ or }q\\text{'' is not true}} &\\iff \\underbrace{\\neg p \\wedge \\neg q}_{p\\text{ is not true and }q\\text{ is not true}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w03/slides.html#converting-to-probability-theory",
    "href": "w03/slides.html#converting-to-probability-theory",
    "title": "Week 3: Random Variables",
    "section": "Converting to Probability Theory",
    "text": "Converting to Probability Theory\n\nSo, using the same principles we used in our coin flipping examples, we can consider events \\(P\\) and \\(Q\\), and get the following ‚Äútranslation‚Äù of DeMorgan‚Äôs Laws:\n\n\n\n\n\n\n\n\n\nLogic\nSet Theory\nProbability Theory\n\n\n\n\n\\(\\neg(p \\wedge q) = \\neg p \\vee \\neg q\\)\n\\((P \\cap Q)^c = P^c \\cup Q^c\\)\n\\(\\Pr((P \\cap Q)^c) = \\Pr(P^c \\cup Q^c)\\)\n\n\n\\(\\neg(p \\vee q) = \\neg p \\wedge \\neg q\\)\n\\((P \\cup Q)^c = P^c \\cap Q^c\\)\n\\(\\Pr((P \\cup Q)^c) = \\Pr(P^c \\cap Q^c)\\)\n\n\n\n\nNote that, since these are isomorphic to one another, we could have derived DeMorgan‚Äôs Laws from within probability theory, rather than the other way around:\n\n\\[\n\\begin{align*}\n\\Pr((P \\cap Q)^c) &= 1 - \\Pr(P \\cap Q) = 1 - \\Pr(P)\\Pr(Q) \\\\\n&= 1 - (1-\\Pr(P^c))(1 - \\Pr(Q^c)) \\\\\n&= 1 - [1 - \\Pr(P^c) - \\Pr(Q^c) + \\Pr(P^c)\\Pr(Q^c)] \\\\\n&= \\Pr(P^c) + \\Pr(Q^c) - \\Pr(P^c)\\Pr(Q^c) \\\\\n&= \\Pr(P^c) + \\Pr(Q^c) - \\Pr(P^c \\cap Q^c) \\\\\n&= \\Pr(P^c \\cup Q^c) \\; ‚úÖ\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w03/slides.html#random-variables",
    "href": "w03/slides.html#random-variables",
    "title": "Week 3: Random Variables",
    "section": "Random Variables",
    "text": "Random Variables\n\nRecall our discussion of random variables: used by analogy to algebra, since we can do math with them:\nJust as \\(2 \\cdot 3\\) is shorthand for \\(2 + 2 + 2\\), can define \\(X\\) as shorthand for possible outcomes of random process:\n\n\\[\n\\begin{align*}\nS = \\{ &\\text{result of dice roll is 1}, \\\\\n&\\text{result of dice roll is 2}, \\\\\n&\\text{result of dice roll is 3}, \\\\\n&\\text{result of dice roll is 4}, \\\\\n&\\text{result of dice roll is 5}, \\\\\n&\\text{result of dice roll is 6}\\} \\rightsquigarrow X \\in \\{1,\\ldots,6\\}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w03/slides.html#random-variables-as-events",
    "href": "w03/slides.html#random-variables-as-events",
    "title": "Week 3: Random Variables",
    "section": "Random Variables as Events",
    "text": "Random Variables as Events\n\nEach value \\(v_X\\) that a random variable \\(X\\) can take on gives rise to an event \\(X = v_X\\): the event that the random variable \\(X\\) takes on value \\(v\\).\nSince \\(X = v_X\\) is an event, we can compute its probability \\(\\Pr(X = v_X)\\)!\n\n\n\n\nEvent in words\nEvent in terms of RV\n\n\n\n\nResult of dice roll is 1\n\\(X = 1\\)\n\n\nResult of dice roll is 2\n\\(X = 2\\)\n\n\nResult of dice roll is 3\n\\(X = 3\\)\n\n\nResult of dice roll is 4\n\\(X = 4\\)\n\n\nResult of dice roll is 5\n\\(X = 5\\)\n\n\nResult of dice roll is 6\n\\(X = 6\\)"
  },
  {
    "objectID": "w03/slides.html#doing-math-with-events",
    "href": "w03/slides.html#doing-math-with-events",
    "title": "Week 3: Random Variables",
    "section": "Doing Math with Events",
    "text": "Doing Math with Events\n\nWe‚Äôve seen how \\(\\Pr()\\) ‚Äúencodes‚Äù logical expressions involving uncertain outcomes.\nEven more powerful when paired with the notion of random variables: lets us also ‚Äúencode‚Äù mathematical expressions involving uncertain quantities!\nConsider an experiment where we roll two dice. Let \\(X\\) be the RV encoding the outcome of the first roll, and \\(Y\\) be the RV encoding the outcome of the second roll.\nWe can compute probabilities involving \\(X\\) and \\(Y\\) separately, e.g., \\(\\Pr(X = 1) = \\frac{1}{6}\\), but we can also reason probabilistically about mathematical expressions involving \\(X\\) and \\(Y\\)! For example, we can reason about their sum:\n\n\\[\n\\begin{align*}\n\\Pr(\\text{rolls sum to 10}) &= \\Pr(X + Y = 10) \\\\\n&= \\Pr(Y = 10 - X)\n\\end{align*}\n\\]\n\nOr about how the outcome of one roll will relate to the outcome of the other:\n\n\\[\n\\begin{align*}\n\\Pr(\\text{first roll above mean}) &= \\Pr\\left(X &gt; \\frac{X+Y}{2}\\right) \\\\\n&= \\Pr(2X &gt; X+Y) = \\Pr(X &gt; Y)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w03/slides.html#are-random-variables-all-powerful",
    "href": "w03/slides.html#are-random-variables-all-powerful",
    "title": "Week 3: Random Variables",
    "section": "Are Random Variables All-Powerful??",
    "text": "Are Random Variables All-Powerful??\n\nJust remember that probability \\(\\Pr(\\cdot)\\) is always probability of an event‚Äîrandom variables are just shorthand for quantifiable events.\nNot all events can be simplified via random variables!\n\n\\(\\text{catch a fish} \\mapsto \\Pr(\\text{trout}), \\Pr(\\text{bass}), \\ldots\\)\n\nWhat types of events can be quantified like this?\n\n(Hint: It has to do with a key topic in the early weeks of both DSAN 5000 and 5100‚Ä¶)\n\n\n\nThe answer is, broadly, any situation where you‚Äôre modeling things, like dice rolls, where mathematical operations like addition, multiplication, etc. make sense. So, if we‚Äôre modeling dice, it makes sense to say e.g.¬†‚Äúresult is 6‚Äù + ‚Äúresult is 3‚Äù = ‚Äútotal is 9‚Äù. More on the next page!"
  },
  {
    "objectID": "w03/slides.html#recall-types-of-variables",
    "href": "w03/slides.html#recall-types-of-variables",
    "title": "Week 3: Random Variables",
    "section": "Recall: Types of Variables",
    "text": "Recall: Types of Variables\n\nCategorical\n\nNo meaningful way to order values: \\(\\{\\text{trout}, \\text{bass}, \\ldots \\}\\)\n\nOrdinal\n\nCan place in order (bigger, smaller), though gaps aren‚Äôt meaningful: \\(\\{{\\color{orange}\\text{great}},{\\color{orange}\\text{greater}},{\\color{orange}\\text{greatest}}\\}\\)\n\\({\\color{orange}\\text{greater}} \\overset{?}{=} 2\\cdot {\\color{orange}\\text{great}} - 1\\)\n\nCardinal\n\nCan place in order, and gaps are meaningful \\(\\implies\\) can do ‚Äústandard‚Äù math with them! Example: \\(\\{{\\color{blue}1},{\\color{blue}2},\\ldots,{\\color{blue}10}\\}\\)\n\\({\\color{blue}7} \\overset{\\text{~‚úÖ~}}{=} 2 \\cdot {\\color{blue}4} - 1\\)\nIf events have this structure (meaningful way to define multiplication, addition, subtraction), then we can analyze them as random variables"
  },
  {
    "objectID": "w03/slides.html#visualizing-discrete-rvs",
    "href": "w03/slides.html#visualizing-discrete-rvs",
    "title": "Week 3: Random Variables",
    "section": "Visualizing Discrete RVs",
    "text": "Visualizing Discrete RVs\n\nUltimate Probability Pro-Tip: When you hear ‚Äúdiscrete distribution‚Äù, think of a bar graph: \\(x\\)-axis = events, bar height = probability of events\nTwo coins example: \\(X\\) = RV representing number of heads obtained in two coin flips"
  },
  {
    "objectID": "w03/slides.html#preview-visualizing-continuous-rvs",
    "href": "w03/slides.html#preview-visualizing-continuous-rvs",
    "title": "Week 3: Random Variables",
    "section": "(Preview:) Visualizing Continuous RVs",
    "text": "(Preview:) Visualizing Continuous RVs\n\nThis works even for continuous distributions, if you focus on the area under the curve instead of the height:"
  },
  {
    "objectID": "w03/slides.html#probability-theory-gives-us-distributions-for-rvs-not-numbers",
    "href": "w03/slides.html#probability-theory-gives-us-distributions-for-rvs-not-numbers",
    "title": "Week 3: Random Variables",
    "section": "Probability Theory Gives Us Distributions for RVs, not Numbers!",
    "text": "Probability Theory Gives Us Distributions for RVs, not Numbers!\n\nWe‚Äôre going beyond ‚Äúbase‚Äù probability theory if we want to summarize these distributions\nHowever, we can understand a lot about the full distribution by looking at some basic summary statistics. Most common way to summarize:\n\n\n\n\n\n\n\n\n\n\\(\\underbrace{\\text{point estimate}}_{\\text{mean/median}}\\)\n\\(\\pm\\)\n\\(\\underbrace{\\text{uncertainty}}_{\\text{variance/standard deviation}}\\)"
  },
  {
    "objectID": "w03/slides.html#example-game-reviews",
    "href": "w03/slides.html#example-game-reviews",
    "title": "Week 3: Random Variables",
    "section": "Example: Game Reviews",
    "text": "Example: Game Reviews\n\n(Data from Metacritic)"
  },
  {
    "objectID": "w03/slides.html#adding-a-single-line",
    "href": "w03/slides.html#adding-a-single-line",
    "title": "Week 3: Random Variables",
    "section": "Adding a Single Line",
    "text": "Adding a Single Line\n\n(Data from Metacritic)"
  },
  {
    "objectID": "w03/slides.html#or-a-single-ribbon",
    "href": "w03/slides.html#or-a-single-ribbon",
    "title": "Week 3: Random Variables",
    "section": "Or a Single Ribbon",
    "text": "Or a Single Ribbon"
  },
  {
    "objectID": "w03/slides.html#example-the-normal-distribution",
    "href": "w03/slides.html#example-the-normal-distribution",
    "title": "Week 3: Random Variables",
    "section": "Example: The Normal Distribution",
    "text": "Example: The Normal Distribution\n\n\n\n(The distribution you saw a few slides ago)\n\n\n\n\n\n\n\n\n\n\n\n\n‚ÄúRV \\(X\\) is normally distributed with mean \\({\\color{purple}\\mu}\\) and standard deviation \\({\\color{purple}\\sigma}\\)‚Äù\n\nTranslates to \\(X \\sim \\mathcal{N}(\\color{purple}{\\mu},\\color{purple}{\\sigma})\\)1\n\\(\\color{purple}{\\mu}\\) and \\(\\color{purple}{\\sigma}\\) are parameters2: the ‚Äúknobs‚Äù or ‚Äúsliders‚Äù which change the location/shape of the distribution\n\n\n\n\nThe parameters in this case give natural summaries of the data:\n\n\\({\\color{\\purple}\\mu}\\) = center (mean), \\({\\color{purple}\\sigma}\\) = [square root of] variance around center\n\nMean can usually be interpreted intuitively; for standard deviation, can use the 68-95-99.7 rule, which will make more sense relative to some real-world data‚Ä¶\n\nThroughout the course, this ‚Äúcalligraphic‚Äù font \\(\\mathcal{N}\\), \\(\\mathcal{D}\\), etc., will be used to denote distributionsThroughout the course, remember, purrple is for purrameters"
  },
  {
    "objectID": "w03/slides.html#real-data-and-the-68-95-99.7-rule",
    "href": "w03/slides.html#real-data-and-the-68-95-99.7-rule",
    "title": "Week 3: Random Variables",
    "section": "Real Data and the 68-95-99.7 Rule",
    "text": "Real Data and the 68-95-99.7 Rule\n\n\n\n\nCode\nlibrary(readr)\nheight_df &lt;- read_csv(\"https://gist.githubusercontent.com/jpowerj/9a23807fb71a5f6b6c2f37c09eb92ab3/raw/89fc6b8f0c57e41ebf4ce5cdf2b3cad6b2dd798c/sports_heights.csv\")\nmean_height &lt;- mean(height_df$height_cm)\nsd_height &lt;- sd(height_df$height_cm)\nheight_density &lt;- function(x) dnorm(x, mean_height, sd_height)\nm2_sd &lt;- mean_height - 2 * sd_height\nm1_sd &lt;- mean_height - 1 * sd_height\np1_sd &lt;- mean_height + 1 * sd_height\np2_sd &lt;- mean_height + 2 * sd_height\nvlines_data &lt;- tibble::tribble(\n  ~x, ~xend, ~y, ~yend, ~Params,\n  mean_height, mean_height, 0, height_density(mean_height), \"Mean\",\n  m2_sd, m2_sd, 0, height_density(m2_sd), \"SD\",\n  m1_sd, m1_sd, 0, height_density(m1_sd), \"SD\",\n  p1_sd, p1_sd, 0, height_density(p1_sd), \"SD\",\n  p2_sd, p2_sd, 0, height_density(p2_sd), \"SD\"\n)\nggplot(height_df, aes(x = height_cm)) +\n    geom_histogram(aes(y = after_stat(density)), binwidth = 5.0) +\n    #stat_function(fun = height_density, linewidth = g_linewidth) +\n    geom_area(stat = \"function\", fun = height_density, color=\"black\", linewidth = g_linewidth, fill = cbPalette[1], alpha=0.2) +\n    geom_segment(data=vlines_data, aes(x=x, xend=xend, y=y, yend=yend, linetype = Params), linewidth = g_linewidth, color=cbPalette[2]) +\n    labs(\n      title=paste0(\"Distribution of heights (cm), N=\",nrow(height_df),\" athletes\\nMean=\",round(mean_height,2),\", SD=\",round(sd_height,2)),\n      x=\"Height (cm)\",\n      y=\"Probability Density\"\n    ) +\n    dsan_theme(\"full\")\n\n\n\n\n\n\n\n\nFigure¬†1: Heights (cm) for 18K professional athletes\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†2: 68-95-99.7 Rule visualized (Wiki Commons)\n\n\n\n\nThe point estimate \\({\\color{purple}\\mu} = 186.48\\) is straightforward: the average height of the athletes is 186.48cm. Using the 68-95-99.7 Rule to interpret the SD, \\({\\color{purple}\\sigma} = 9.7\\), we get:\n\n\n\nAbout 68% of the heights fall between\n\n\n\n\n\n\n\n\n\n[\\({\\color{purple}\\mu} - 1\\cdot {\\color{purple}\\sigma}\\)\nand\n\\({\\color{purple}\\mu} + 1\\cdot {\\color{purple}\\sigma}\\)]\n\n\n[186.48 - 1 ¬∑ 9.7\nand\n186.48 + 1 ¬∑ 9.7]\n\n\n[176.78\nand\n196.18]\n\n\n\n\n\nAbout 95% of the heights fall between\n\n\n\n\n\n\n\n\n\n[\\({\\color{purple}\\mu} - 2 \\cdot {\\color{purple}\\sigma}\\)\nand\n\\({\\color{purple}\\mu} + 2 \\cdot {\\color{purple}\\sigma}\\)]\n\n\n[186.48 - 2 ¬∑ 9.7\nand\n186.48 + 2 ¬∑ 9.7]\n\n\n[167.08\nand\n205.88]"
  },
  {
    "objectID": "w03/slides.html#boxplots-comparing-multiple-distributions",
    "href": "w03/slides.html#boxplots-comparing-multiple-distributions",
    "title": "Week 3: Random Variables",
    "section": "Boxplots: Comparing Multiple Distributions",
    "text": "Boxplots: Comparing Multiple Distributions\n\n\n\n\n\nFrom Wikimedia Commons\n\n\n\n\n\n\nFrom Wikimedia Commons"
  },
  {
    "objectID": "w03/slides.html#another-option-joyplots",
    "href": "w03/slides.html#another-option-joyplots",
    "title": "Week 3: Random Variables",
    "section": "Another Option: Joyplots",
    "text": "Another Option: Joyplots\n\n\n\n\n\n\n\n\nFigure¬†3: (Iconic album cover)\n\n\n\n\n\n\n\n\n\n\nFigure¬†4: (Tooting my own horn)"
  },
  {
    "objectID": "w03/slides.html#multivariate-distributions-preview",
    "href": "w03/slides.html#multivariate-distributions-preview",
    "title": "Week 3: Random Variables",
    "section": "Multivariate Distributions: Preview",
    "text": "Multivariate Distributions: Preview\n\nThe bivariate normal distribution represents the distribution of two normally-distributed RVs \\(\\mathbf{X} = [\\begin{smallmatrix} X_1 & X_2\\end{smallmatrix}]\\), which may or may not be correlated:\n\n\\[\n\\mathbf{X} = \\begin{bmatrix}X_1 \\\\ X_2\\end{bmatrix}, \\; \\boldsymbol{\\mu} =\n%\\begin{bmatrix}\\mu_1 \\\\ \\mu_2\\end{bmatrix}\n\\begin{bmatrix}\\smash{\\overbrace{\\mu_1}^{\\mathbb{E}[X_1]}} \\\\ \\smash{\\underbrace{\\mu_2}_{\\mathbb{E}[X_2]}}\\end{bmatrix}\n, \\; \\mathbf{\\Sigma} = \\begin{bmatrix}\\smash{\\overbrace{\\sigma_1^2}^{\\text{Var}[X_1]}} & \\smash{\\overbrace{\\rho\\sigma_1\\sigma_2}^{\\text{Cov}[X_1,X_2]}} \\\\ \\smash{\\underbrace{\\rho\\sigma_2\\sigma_1}_{\\text{Cov}[X_2,X_1]}} & \\smash{\\underbrace{\\sigma_2^2}_{\\text{Var}[X_2]}}\\end{bmatrix}\n% \\begin{bmatrix}\\sigma_1^2 & \\rho\\sigma_1\\sigma_2 \\\\ \\rho\\sigma_2\\sigma_1 & \\sigma_2^2 \\end{bmatrix}\n% = \\begin{bmatrix}\\text{Var}[X_1] & \\text{Cov}[X_1,X_2] \\\\ \\text{Cov}[X_2,X_1] & \\text{Var}[X_2] \\end{bmatrix}\n\\]\n\nBy squishing all this information intro matrices, we can specify the parameters of multivariate-normally-distributed vectors of RVs similarly to how we specify single-dimensional normally-distributed RVs:\n\n\n\\[\n\\begin{align*}\n\\overbrace{X}^{\\mathclap{\\text{scalar}}} &\\sim \\mathcal{N}\\phantom{_k}(\\overbrace{\\mu}^{\\text{scalar}}, \\overbrace{\\sigma}^{\\text{scalar}}) \\tag{Univariate} \\\\\n\\underbrace{\\mathbf{X}}_{\\text{vector}} &\\sim \\boldsymbol{\\mathcal{N}}_k(\\smash{\\underbrace{\\boldsymbol{\\mu}}_{\\text{vector}}}, \\underbrace{\\mathbf{\\Sigma}}_{\\text{matrix}}) \\tag{Multivariate}\n\\end{align*}\n\\]\n\n\nNote: In the future I‚Äôll use the notation \\(\\mathbf{X}_{[a \\times b]}\\) to denote the dimensions of the vectors/matrices, like \\(\\mathbf{X}_{[k \\times 1]} \\sim \\boldsymbol{\\mathcal{N}}_k(\\boldsymbol{\\mu}_{[k \\times 1]}, \\mathbf{\\Sigma}_{[k \\times k]})\\)"
  },
  {
    "objectID": "w03/slides.html#visualizing-3d-distributions-projection",
    "href": "w03/slides.html#visualizing-3d-distributions-projection",
    "title": "Week 3: Random Variables",
    "section": "Visualizing 3D Distributions: Projection",
    "text": "Visualizing 3D Distributions: Projection\n\nMost of our intuitions about plots come from 2D \\(\\Rightarrow\\) super helpful exercise to take a 3D plot like this and imagine ‚Äúprojecting‚Äù it onto different 2D surfaces:\n\n\n(Adapted via LaTeX from StackExchange discussion)"
  },
  {
    "objectID": "w03/slides.html#visualizing-3d-distributions-contours",
    "href": "w03/slides.html#visualizing-3d-distributions-contours",
    "title": "Week 3: Random Variables",
    "section": "Visualizing 3D Distributions: Contours",
    "text": "Visualizing 3D Distributions: Contours\n\nFrom Prof.¬†Hickman‚Äôs slides!"
  },
  {
    "objectID": "w03/slides.html#visualizing-3d-distributions-contours-1",
    "href": "w03/slides.html#visualizing-3d-distributions-contours-1",
    "title": "Week 3: Random Variables",
    "section": "Visualizing 3D Distributions: Contours",
    "text": "Visualizing 3D Distributions: Contours\n\n\nAlso from Prof.¬†Hickman‚Äôs slides!"
  },
  {
    "objectID": "w03/slides.html#summarizing-what-we-know-so-far",
    "href": "w03/slides.html#summarizing-what-we-know-so-far",
    "title": "Week 3: Random Variables",
    "section": "Summarizing What We Know So Far",
    "text": "Summarizing What We Know So Far\n\nLogic \\(\\rightarrow\\) Set Theory \\(\\rightarrow\\) Probability Theory\nEntirety of probability theory can be derived from two axioms:\n\n\n\n\n\nThe Entirety of Probability Theory Follows From‚Ä¶\n\n\nAxiom 1 (Unitarity): \\(\\Pr(\\Omega) = 1\\) (The probability that something happens is 1)\nAxiom 2 (\\(\\sigma\\)-additivity): For mutually-exclusive events \\(E_1, E_2, \\ldots\\),\n\\[\n\\underbrace{\\Pr\\left(\\bigcup_{i=1}^{\\infty}E_i\\right)}_{\\Pr(E_1\\text{ occurs }\\vee E_2\\text{ occurs } \\vee \\cdots)} = \\underbrace{\\sum_{i=1}^{\\infty}\\Pr(E_i)}_{\\Pr(E_1\\text{ occurs}) + \\Pr(E_2\\text{ occurs}) + \\cdots}\n\\]\n\n\n\n\n\nBut what does ‚Äúmutually exclusive‚Äù mean‚Ä¶?"
  },
  {
    "objectID": "w03/slides.html#venn-diagrams-sets",
    "href": "w03/slides.html#venn-diagrams-sets",
    "title": "Week 3: Random Variables",
    "section": "Venn Diagrams: Sets",
    "text": "Venn Diagrams: Sets\n\n\n\\[\n\\begin{align*}\n&A = \\{1, 2, 3\\}, \\; B = \\{4, 5, 6\\} \\\\\n&\\implies A \\cap B = \\varnothing\n\\end{align*}\n\\]\n\n\n\nMutually-exclusive (disjoint) sets\n\n\n\n\\[\n\\begin{align*}\n&A = \\{1, 2, 3, 4\\}, \\; B = \\{3, 4, 5, 6\\} \\\\\n&\\implies A \\cap B = \\{3, 4\\}\n\\end{align*}\n\\]\n\n\n\nNon-mutually-exclusive sets"
  },
  {
    "objectID": "w03/slides.html#venn-diagrams-events-dice",
    "href": "w03/slides.html#venn-diagrams-events-dice",
    "title": "Week 3: Random Variables",
    "section": "Venn Diagrams: Events (Dice)",
    "text": "Venn Diagrams: Events (Dice)\n\\[\n\\begin{align*}\nA &= \\{\\text{Roll is even}\\} = \\{2, 4, 6\\} \\\\\nB &= \\{\\text{Roll is odd}\\} = \\{1, 3, 5\\} \\\\\nC &= \\{\\text{Roll is in Fibonnaci sequence}\\} = \\{1, 2, 3, 5\\}\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\n\n\nSet 1\nSet 2\nIntersection\nMutually Exclusive?\nCan Happen Simultaneously?\n\n\n\n\n\\(A\\)\n\\(B\\)\n\\(A \\cap B = \\varnothing\\)\nYes\nNo\n\n\n\\(A\\)\n\\(C\\)\n\\(A \\cap C = \\{2\\}\\)\nNo\nYes\n\n\n\\(B\\)\n\\(C\\)\n\\(B \\cap C = \\{1, 3, 5\\}\\)\nNo\nYes"
  },
  {
    "objectID": "w03/slides.html#rules-of-probability-1",
    "href": "w03/slides.html#rules-of-probability-1",
    "title": "Week 3: Random Variables",
    "section": "‚ÄúRules‚Äù of Probability",
    "text": "‚ÄúRules‚Äù of Probability\n(Remember: not ‚Äúrules‚Äù but ‚Äúfacts resulting from the logic \\(\\leftrightarrow\\) probability connection‚Äù)\n\n\n\n\n‚ÄúRules‚Äù of Probability\n\n\nFor logical predicates \\(p, q \\in \\{T, F\\}\\), events \\(P, Q\\) defined so \\(P\\) = event that \\(p\\) becomes true, \\(Q\\) = event that \\(q\\) becomes true,\n\nLogical AND = Probabilistic Multiplication\n\n\\[\n\\Pr(p \\wedge q) = \\Pr(P \\cap Q) = \\Pr(P) \\cdot \\Pr(Q)\n\\]\n\nLogical OR = Probabilistic Addition\n\n\\[\n\\Pr(p \\vee q) = \\Pr(P \\cup Q) = \\Pr(P) + \\Pr(Q) - \\underbrace{\\Pr(P \\cap Q)}_{\\text{(see rule 1)}}\n\\]\n\nLogical NOT = Probabilistic Complement\n\n\\[\n\\Pr(\\neg p) = \\Pr(P^c) = 1 - \\Pr(P)\n\\]"
  },
  {
    "objectID": "w03/slides.html#conditional-probability",
    "href": "w03/slides.html#conditional-probability",
    "title": "Week 3: Random Variables",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\nUsually if someone asks you probabilistic questions, like\n\n‚ÄúWhat is the likelihood that [our team] wins?‚Äù\n‚ÄúDo you think it will rain tomorrow?‚Äù\n\nYou don‚Äôt guess a random number, you consider and incorporate evidence.\nExample: \\(\\Pr(\\text{rain})\\) on its own, no other info? Tough question‚Ä¶ maybe \\(0.5\\)?\nIn reality, we would think about\n\n\\(\\Pr(\\text{rain} \\mid \\text{month of the year})\\)\n\\(\\Pr(\\text{rain} \\mid \\text{where we live})\\)\n\\(\\Pr(\\text{rain} \\mid \\text{did it rain yesterday?})\\)\n\nPsychologically, breaks down into two steps: (1) Think of baseline probability, (2) Update baseline to incorporate relevant evidence (more on this in a bit‚Ä¶)\nAlso recall: all probability is conditional probability, even if just conditioned on ‚Äúsomething happened‚Äù (\\(\\Omega\\), the thing defined so \\(\\Pr(\\Omega) = 1\\))"
  },
  {
    "objectID": "w03/slides.html#na√Øve-definition-2.0",
    "href": "w03/slides.html#na√Øve-definition-2.0",
    "title": "Week 3: Random Variables",
    "section": "Na√Øve Definition 2.0",
    "text": "Na√Øve Definition 2.0\n\n\n\n\n[Slightly Less] Na√Øve Definition of Probability\n\n\n\\[\n\\Pr(A \\mid B) = \\frac{\\text{\\# of Desired Outcomes in world where }B\\text{ happened}}{\\text{\\# Total outcomes in world where }B\\text{ happened}} = \\frac{|B \\cap A|}{|B|}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\nWorld Name\nWeather in World\nLikelihood of Rain Today\n\n\n\n\n\\(R\\)\nRained for the past 5 days\n\\(\\Pr(\\text{rain} \\mid R) &gt; 0.5\\)\n\n\n\\(M\\)\nMix of rain and non-rain over past 5 days\n\\(\\Pr(\\text{rain} \\mid M) \\approx 0.5\\)\n\n\n\\(S\\)\nSunny for the past 5 days\n\\(\\Pr(\\text{rain} \\mid S) &lt; 0.5\\)"
  },
  {
    "objectID": "w03/slides.html#law-of-total-probability",
    "href": "w03/slides.html#law-of-total-probability",
    "title": "Week 3: Random Variables",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\nSuppose the events \\(B_1, \\ldots, B_k\\) form a partition of the space \\(\\Omega\\) and \\(\\Pr(B_j) &gt; 0 \\forall j\\).\nThen, for every event \\(A\\) in \\(\\Omega\\),\n\\[\n  \\Pr(A) = \\sum_{i=1}^k \\Pr(B_j)\\Pr(A \\mid B_j)\n  \\]\nProbability of an event is the sum of its conditional probabilities across all conditions.\nIn other words: \\(A\\) is some event, \\(B_1, \\ldots, B_n\\) are mutually exclusive events filling entire sample-space, then\n\\[\n  \\Pr(A) = \\Pr(A \\mid B_1)\\Pr(B_1) + \\Pr(A \\mid B_2)\\Pr(B_2) + \\cdots + \\Pr(A \\mid B_n)\\Pr(B_n)\n  \\]\ni.e.¬†Compute the probability by summing over all possible cases.\n\n\nDraw pic on board!"
  },
  {
    "objectID": "w03/slides.html#example",
    "href": "w03/slides.html#example",
    "title": "Week 3: Random Variables",
    "section": "Example",
    "text": "Example\n\nProbability of completing job on time with and without rain: 0.42 and 0.9.\nProbability of rain is 0.45. What is probability job will be completed on time?\n\\(A\\) = job will be completed on time, \\(B\\) = rain\n\n\\[\n\\Pr(B) = 0.45 \\implies \\Pr(B^c) = 1 - \\Pr(B) = 0.55.\n\\]\n\nNote: Events \\(B\\) and \\(B^c\\) are exclusive and form partitions of the sample space \\(S\\)\nWe know \\(\\Pr(A \\mid B) = 0.24\\), \\(\\Pr(A \\mid B^c) = 0.9\\).\nBy the Law of Total Probability, we have\n\n\\[\n\\begin{align*}\n\\Pr(A) &= \\Pr(B)\\Pr(A \\mid B) + \\Pr(B^c)\\Pr(A \\mid B^c) \\\\\n&= 0.45(0.42) + 0.55(0.9) = 0.189 + 0.495 = 0684.\n\\end{align*}\n\\]\nSo, the probability that the job will be completed on time is 0.684. (source)"
  },
  {
    "objectID": "w03/slides.html#deriving-bayes-theorem",
    "href": "w03/slides.html#deriving-bayes-theorem",
    "title": "Week 3: Random Variables",
    "section": "Deriving Bayes‚Äô Theorem",
    "text": "Deriving Bayes‚Äô Theorem\n\nLiterally just a re-writing of the conditional probability definition (don‚Äôt be scared)!\n\n\n\n\nFor two events \\(A\\) and \\(B\\), definition of conditional probability says that\n\n\\[\n\\begin{align*}\n\\Pr(A \\mid B) &= \\frac{\\Pr(A \\cap B)}{\\Pr(B)} \\tag{1} \\\\\n\\Pr(B \\mid A) &= \\frac{\\Pr(B \\cap A)}{\\Pr(A)} \\tag{2}\n\\end{align*}\n\\]\n\nMultiply to get rid of fractions\n\n\\[\n\\begin{align*}\n\\Pr(A \\mid B)\\Pr(B) &= \\Pr(A \\cap B) \\tag{1*} \\\\\n\\Pr(B \\mid A)\\Pr(A) &= \\Pr(B \\cap A) \\tag{2*}\n\\end{align*}\n\\]\n\n\nBut set intersection is associative (just like multiplication‚Ä¶), \\(A \\cap B = B \\cap A\\)! So, we know LHS of \\((\\text{1*})\\) = LHS of \\((\\text{2*})\\):\n\n\\[\n\\Pr(A \\mid B)\\Pr(B) = \\Pr(B \\mid A)\\Pr(A)\n\\]\n\nDivide both sides by \\(\\Pr(B)\\) to get a new definition of \\(\\Pr(A \\mid B)\\), Bayes‚Äô Theorem!\n\n\n\n\n\\[\n\\boxed{\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)}}\n\\]\n\n\nFigure¬†5: Bayes‚Äô Theorem"
  },
  {
    "objectID": "w03/slides.html#why-is-this-helpful",
    "href": "w03/slides.html#why-is-this-helpful",
    "title": "Week 3: Random Variables",
    "section": "Why Is This Helpful?",
    "text": "Why Is This Helpful?\n\n\n\n\nBayes‚Äô Theorem\n\n\nFor any two events \\(A\\) and \\(B\\), \\[\n\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)}\n\\]\n\n\n\n\n\nIn words (as exciting as I can make it, for now): Bayes‚Äô Theorem allows us to take information about \\(B \\mid A\\) and use it to infer information about \\(A \\mid B\\)\nIt isn‚Äôt until you work through some examples that this becomes mind-blowing, the most powerful equation we have for inferring unknowns from knowns‚Ä¶\nConsider \\(A = \\{\\text{person has disease}\\}\\), \\(B = \\{\\text{person tests positive for disease}\\}\\)\n\nIs \\(A\\) observable on its own? No, but‚Ä¶\n\nIs \\(B\\) observable on its own? Yes, and\nCan we infer info about \\(A\\) from knowing \\(B\\)? Also Yes, thx Bayes!\n\nTherefore, we can use \\(B\\) to infer information about \\(A\\), i.e., calculate \\(\\Pr(A \\mid B)\\)‚Ä¶"
  },
  {
    "objectID": "w03/slides.html#why-is-this-helpful-for-data-science",
    "href": "w03/slides.html#why-is-this-helpful-for-data-science",
    "title": "Week 3: Random Variables",
    "section": "Why Is This Helpful for Data Science?",
    "text": "Why Is This Helpful for Data Science?\n\nIt merges probability theory and hypothesis testing into a single framework:\n\n\\[\n\\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{\\Pr(\\text{data} \\mid \\text{hypothesis})\\Pr(\\text{hypothesis})}{\\Pr(\\text{data})}\n\\]"
  },
  {
    "objectID": "w03/slides.html#probability-forwards-and-backwards",
    "href": "w03/slides.html#probability-forwards-and-backwards",
    "title": "Week 3: Random Variables",
    "section": "Probability Forwards and Backwards",
    "text": "Probability Forwards and Backwards\n\nTwo discrete RVs:\n\nWeather on a given day, \\(W \\in \\{\\textsf{Rain},\\textsf{Sun}\\}\\)\nAction that day, \\(A \\in \\{\\textsf{Go}, \\textsf{Stay}\\}\\): go to party or stay in and watch movie\n\nData-generating process: if \\(\\textsf{Sun}\\), rolls a die \\(R\\) and goes out unless \\(R = 6\\). If \\(\\textsf{Rain}\\), flips a coin and goes out if \\(\\textsf{H}\\).\nProbabilistic Graphical Model (PGM):"
  },
  {
    "objectID": "w03/slides.html#section",
    "href": "w03/slides.html#section",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "So, if we know \\(W = \\textsf{Sun}\\), what is \\(P(A = \\textsf{Go})\\)? \\[\n\\begin{align*}\nP(A = \\textsf{Go} \\mid W) &= 1 - P(R = 6) \\\\\n&= 1 - \\frac{1}{6} = \\frac{5}{6}\n\\end{align*}\n\\]\nConditional probability lets us go forwards (left to right):\n\n\n\n\n\n\n\nBut what if we want to perform inference going backwards?"
  },
  {
    "objectID": "w03/slides.html#section-1",
    "href": "w03/slides.html#section-1",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "If we see Ana at the party, we know \\(A = \\textsf{Go}\\)\nWhat does this tell us about the weather?\nIntuitively, we should increase our degree of belief that \\(W = \\textsf{Sun}\\). But, by how much?\nWe don‚Äôt know \\(P(W \\mid A)\\), only \\(P(A \\mid W)\\)‚Ä¶"
  },
  {
    "objectID": "w03/slides.html#section-2",
    "href": "w03/slides.html#section-2",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "\\[\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) = \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sun})}^{5/6~ ‚úÖ}\\overbrace{P(W = \\textsf{Sun})}^{‚ùì}}{\\underbrace{P(A = \\textsf{Go})}_{‚ùì}}\n\\]\n\nWe‚Äôve seen \\(P(W = \\textsf{Sun})\\) before, it‚Äôs our prior: the probability without having any additional relevant knowledge. So, let‚Äôs say 50/50. \\(P(W = \\textsf{Sun}) = \\frac{1}{2}\\)\nIf we lived in Seattle, we could pick \\(P(W = \\textsf{Sun}) = \\frac{1}{4}\\)"
  },
  {
    "objectID": "w03/slides.html#section-3",
    "href": "w03/slides.html#section-3",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "\\[\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) = \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sunny})}^{5/6~ ‚úÖ}\\overbrace{P(W = \\textsf{Sun})}^{1/2~ ‚úÖ}}{\\underbrace{P(A = \\textsf{Go})}_{‚ùì}}\n\\]\n\n\\(P(A = \\textsf{Go})\\) is trickier: the probability that Ana goes out regardless of what the weather is. But there are only two possible weather outcomes! So we just compute\n\n\\[\n\\begin{align*}\n&P(A = \\textsf{Go}) = \\sum_{\\omega \\in S(W)}P(A = \\textsf{Go}, \\omega) = \\sum_{\\omega \\in S(W)}P(A = \\textsf{Go} \\mid \\omega)P(\\omega) \\\\\n&= P(A = \\textsf{Go} \\mid W = \\textsf{Rain})P(W = \\textsf{Rain}) + P(A = \\textsf{Go} \\mid W = \\textsf{Sun})P(W = \\textsf{Sun}) \\\\\n&= \\left( \\frac{1}{2} \\right)\\left( \\frac{1}{2} \\right) + \\left( \\frac{5}{6} \\right)\\left( \\frac{1}{2} \\right) = \\frac{1}{4} + \\frac{5}{12} = \\frac{2}{3}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w03/slides.html#putting-it-all-together",
    "href": "w03/slides.html#putting-it-all-together",
    "title": "Week 3: Random Variables",
    "section": "Putting it All Together",
    "text": "Putting it All Together\n\\[\n\\begin{align*}\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) &= \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sunny})}^{3/4~ ‚úÖ}\\overbrace{P(W = \\textsf{Sun})}^{1/2~ ‚úÖ}}{\\underbrace{P(A = \\textsf{Go})}_{1/2~ ‚úÖ}} \\\\\n&= \\frac{\\left(\\frac{3}{4}\\right)\\left(\\frac{1}{2}\\right)}{\\frac{1}{2}} = \\frac{\\frac{3}{8}}{\\frac{1}{2}} = \\frac{3}{4}.\n\\end{align*}\n\\]\n\nGiven that we see Ana at the party, we should update our beliefs, so that \\(P(W = \\textsf{Sun}) = \\frac{3}{4}, P(W = \\textsf{Rain}) = \\frac{1}{4}\\)."
  },
  {
    "objectID": "w03/slides.html#a-scarier-example",
    "href": "w03/slides.html#a-scarier-example",
    "title": "Week 3: Random Variables",
    "section": "A Scarier Example",
    "text": "A Scarier Example\n\nBo worries he has a rare disease. He takes a test with 99% accuracy and tests positive. What‚Äôs the probability Bo has the disease? (Intuition: 99%? ‚Ä¶Let‚Äôs do the math!)\n\n\n\n\n\\(H \\in \\{\\textsf{sick}, \\textsf{healthy}\\}, T \\in \\{\\textsf{T}^+, \\textsf{T}^-\\}\\)\nThe test: 99% accurate. \\(\\Pr(T = \\textsf{T}^+ \\mid H = \\textsf{sick}) = 0.99\\), \\(\\Pr(T = \\textsf{T}^- \\mid H = \\textsf{healthy}) = 0.99\\).\nThe disease: 1 in 10K. \\(\\Pr(H = \\textsf{sick}) = \\frac{1}{10000}\\)\nWhat do we want to know? \\(\\Pr(H = \\textsf{sick} \\mid T = \\textsf{T}^+)\\)\nHow do we get there?\n\n\n\n\n\nThis photo, originally thought to be of Thomas Bayes, turns out to be probably someone else‚Ä¶ \\(\\Pr(\\textsf{Bayes})\\)?\n\n\n\n\n\\(H\\) for health, \\(T\\) for test result\nPhoto credit: https://thedatascientist.com/wp-content/uploads/2019/04/reverend-thomas-bayes.jpg"
  },
  {
    "objectID": "w03/slides.html#section-4",
    "href": "w03/slides.html#section-4",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "\\[\n\\begin{align*}\n\\Pr(H = \\textsf{sick} \\mid T = \\textsf{T}^+) &= \\frac{\\Pr(T = \\textsf{T}^+ \\mid H = \\textsf{sick})\\Pr(H = \\textsf{sick})}{\\Pr(T = \\textsf{T}^+)} \\\\\n&= \\frac{(0.99)\\left(\\frac{1}{10000}\\right)}{(0.99)\\left( \\frac{1}{10000} \\right) + (0.01)\\left( \\frac{9999}{10000} \\right)}\n\\end{align*}\n\\]\n\n\nCode\np_sick &lt;- 1 / 10000\np_healthy &lt;- 1 - p_sick\np_pos_given_sick &lt;- 0.99\np_neg_given_sick &lt;- 1 - p_pos_given_sick\np_neg_given_healthy &lt;- 0.99\np_pos_given_healthy &lt;- 1 - p_neg_given_healthy\nnumer &lt;- p_pos_given_sick * p_sick\ndenom1 &lt;- numer\ndenom2 &lt;- p_pos_given_healthy * p_healthy\nfinal_prob &lt;- numer / (denom1 + denom2)\nfinal_prob\n\n\n[1] 0.009803922\n\n\n\n‚Ä¶ Less than 1% üò±"
  },
  {
    "objectID": "w03/slides.html#proof-in-the-pudding",
    "href": "w03/slides.html#proof-in-the-pudding",
    "title": "Week 3: Random Variables",
    "section": "Proof in the Pudding",
    "text": "Proof in the Pudding\n\nLet‚Äôs generate a dataset of 5,000 people, using \\(\\Pr(\\textsf{Disease}) = \\frac{1}{10000}\\)\n\n\n\nCode\nlibrary(tibble)\nlibrary(dplyr)\n# Disease rarity\np_disease &lt;- 1 / 10000\n# 1K people\nnum_people &lt;- 10000\n# Give them ids\nppl_df &lt;- tibble(id=seq(1,num_people))\n# Whether they have the disease or not\nhas_disease &lt;- rbinom(num_people, 1, p_disease)\nppl_df &lt;- ppl_df %&gt;% mutate(has_disease=has_disease)\nppl_df |&gt; head()\n\n\n\n\n\n\nid\nhas_disease\n\n\n\n\n1\n0\n\n\n2\n0\n\n\n3\n0\n\n\n4\n0\n\n\n5\n0\n\n\n6\n0"
  },
  {
    "objectID": "w03/slides.html#binary-variable-trick",
    "href": "w03/slides.html#binary-variable-trick",
    "title": "Week 3: Random Variables",
    "section": "Binary Variable Trick",
    "text": "Binary Variable Trick\n\nSince has_disease \\(\\in \\{0, 1\\}\\), we can use\n\nsum(has_disease) to obtain the count of people with the disease, or\nmean(has_disease) to obtain the proportion of people who have the disease\n\nTo see this (or, if you forget in the future), just make a fake dataset with a binary variable and 3 rows, and think about sums vs.¬†means of that variable:\n\n\n\n\n\nCode\nbinary_df &lt;- tibble(\n  id=c(1,2,3),\n  x=c(0,1,0)\n)\nbinary_df\n\n\n\n\n\n\nid\nx\n\n\n\n\n1\n0\n\n\n2\n1\n\n\n3\n0\n\n\n\n\n\n\n\nTaking the sum tells us: one row where x == 1:\n\n\nCode\nsum(binary_df$x)\n\n\n[1] 1\n\n\nTaking the mean tells us: 1/3 of rows have x == 1:\n\n\nCode\nmean(binary_df$x)\n\n\n[1] 0.3333333"
  },
  {
    "objectID": "w03/slides.html#applying-this-to-the-disease-data",
    "href": "w03/slides.html#applying-this-to-the-disease-data",
    "title": "Week 3: Random Variables",
    "section": "Applying This to the Disease Data",
    "text": "Applying This to the Disease Data\n\nIf we want the number of people who have the disease:\n\n\n\nCode\n# Compute the *number* of people who have the disease\nsum(ppl_df$has_disease)\n\n\n[1] 0\n\n\n\nIf we want the proportion of people who have the disease:\n\n\n\nCode\n# Compute the *proportion* of people who have the disease\nmean(ppl_df$has_disease)\n\n\n[1] 0\n\n\n\n(And if you dislike scientific notation like I do‚Ä¶)\n\n\n\nCode\nformat(mean(ppl_df$has_disease), scientific = FALSE)\n\n\n[1] \"0\"\n\n\n\n(Foreshadowing Monte Carlo methods)"
  },
  {
    "objectID": "w03/slides.html#data-generating-process-test-results",
    "href": "w03/slides.html#data-generating-process-test-results",
    "title": "Week 3: Random Variables",
    "section": "Data-Generating Process: Test Results",
    "text": "Data-Generating Process: Test Results\n\n\nCode\nlibrary(dplyr)\n# Data Generating Process\ntake_test &lt;- function(is_sick) {\n  if (is_sick) {\n    return(rbinom(1,1,p_pos_given_sick))\n  } else {\n    return(rbinom(1,1,p_pos_given_healthy))\n  }\n}\nppl_df['test_result'] &lt;- unlist(lapply(ppl_df$has_disease, take_test))\nnum_positive &lt;- sum(ppl_df$test_result)\np_positive &lt;- mean(ppl_df$test_result)\nwriteLines(paste0(num_positive,\" positive tests / \",num_people,\" total = \",p_positive))\n\n\n92 positive tests / 10000 total = 0.0092\n\n\n\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n1\n0\n0\n\n\n2\n0\n0\n\n\n3\n0\n0\n\n\n4\n0\n0\n\n\n5\n0\n0\n\n\n6\n0\n0"
  },
  {
    "objectID": "w03/slides.html#zooming-in-on-positive-tests",
    "href": "w03/slides.html#zooming-in-on-positive-tests",
    "title": "Week 3: Random Variables",
    "section": "Zooming In On Positive Tests",
    "text": "Zooming In On Positive Tests\n\n\n\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n63\n0\n1\n\n\n150\n0\n1\n\n\n165\n0\n1\n\n\n288\n0\n1\n\n\n337\n0\n1\n\n\n345\n0\n1\n\n\n\n\n\n\n\n\nBo doesn‚Äôt have it, and neither do 110 of the 111 total people who tested positive!\nBut, in the real world, we only observe \\(T\\)"
  },
  {
    "objectID": "w03/slides.html#zooming-in-on-disease-havers",
    "href": "w03/slides.html#zooming-in-on-disease-havers",
    "title": "Week 3: Random Variables",
    "section": "Zooming In On Disease-Havers",
    "text": "Zooming In On Disease-Havers\n\nWhat if we look at only those who actually have the disease? Maybe the cost of 111 people panicking is worth it if we correctly catch those who do have it?\n\n\n\nCode\n#disp(ppl_df[ppl_df$has_disease == 1,])\nppl_df[ppl_df$has_disease == 1,]\n\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n\n\n\n\nIs this always going to be the case?\n\n\n\n\nNum with disease: 0\nProportion with disease: 0\nNumber of positive tests: 38\n\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n\n\n\n\n\n\n\nNum with disease: 0\nProportion with disease: 0\nNumber of positive tests: 53\n\n\n\n\n\n\nid\nhas_disease\ntest_result"
  },
  {
    "objectID": "w03/slides.html#worst-case-worlds",
    "href": "w03/slides.html#worst-case-worlds",
    "title": "Week 3: Random Variables",
    "section": "Worst-Case Worlds",
    "text": "Worst-Case Worlds\n\n\n\n\nWorld #72 / 1000 (5000 people):\n# A tibble: 2 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  1956           1           1\n2  2488           1           0\n\n\nWorld #267 / 1000 (5000 people):\n# A tibble: 1 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  1628           1           0\n\n\nWorld #603 / 1000 (5000 people):\n# A tibble: 2 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  1413           1           1\n2  4094           1           0\n\n\nWorld #965 / 1000 (5000 people):\n# A tibble: 2 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  2356           1           0\n2  3143           1           1\n\n\n[1] \"0.0000008\"\n\n\n\nHow unlikely is this? Math:\n\\[\n\\begin{align*}\n\\Pr(\\textsf{T}^- \\cap \\textsf{Sick}) &= \\Pr(\\textsf{T}^- \\mid \\textsf{Sick})\\Pr(\\textsf{Sick}) \\\\\n&= (0.01)\\frac{1}{10000} \\\\\n&= \\frac{1}{1000000}\n\\end{align*}\n\\]\nComputers:\n\n\nFalse Negatives: 0, Total Cases: 1000000\n\n\nFalse Negative Rate: 0\n\n\n(Perfect match!)"
  },
  {
    "objectID": "w03/slides.html#bayes-takeaway",
    "href": "w03/slides.html#bayes-takeaway",
    "title": "Week 3: Random Variables",
    "section": "Bayes: Takeaway",
    "text": "Bayes: Takeaway\n\nBayesian approach allows new evidence to be weighed against existing evidence, with statistically principled way to derive these weights:\n\n\\[\n\\begin{array}{ccccc}\n\\Pr_{\\text{post}}(\\mathcal{H}) &\\hspace{-6mm}\\propto &\\hspace{-6mm} \\Pr(X \\mid \\mathcal{H}) &\\hspace{-6mm} \\times &\\hspace{-6mm} \\Pr_{\\text{pre}}(\\mathcal{H}) \\\\\n\\text{Posterior} &\\hspace{-6mm}\\propto &\\hspace{-6mm}\\text{Evidence} &\\hspace{-6mm} \\times &\\hspace{-6mm} \\text{Prior}\n\\end{array}\n\\]"
  },
  {
    "objectID": "w03/slides.html#monte-carlo-methods-overview",
    "href": "w03/slides.html#monte-carlo-methods-overview",
    "title": "Week 3: Random Variables",
    "section": "Monte Carlo Methods: Overview",
    "text": "Monte Carlo Methods: Overview\n\nYou already saw an example, in our rare disease simulation!\nGenerally, using computers (rather than math, ‚Äúby hand‚Äù) to estimate probabilistic quantities\n\n\n\nPros:\n\nMost real-world processes have no analytic solution\nStep-by-step breakdown of complex processes\n\n\nCons:\n\nCan require immense computing power\n‚ö†Ô∏è Can generate incorrect answers ‚ö†Ô∏è\n\n\n\nBy step-by-step I mean, a lot of the time you are just walking through, generating the next column using previously-generated columns. Like we did in the example above, generating test_result based on has_disease."
  },
  {
    "objectID": "w03/slides.html#birthday-problem",
    "href": "w03/slides.html#birthday-problem",
    "title": "Week 3: Random Variables",
    "section": "Birthday Problem",
    "text": "Birthday Problem\n\n\n\n30 people gather in a room together. What is the probability that two of them share the same birthday?\nAnalytic solution is fun, but requires some thought‚Ä¶ Monte Carlo it!\n\n\n\n\nCode\ngen_bday_room &lt;- function(room_num=NULL) {\n  num_people &lt;- 30\n  num_days &lt;- 366\n  ppl_df &lt;- tibble(id=seq(1,num_people))\nbirthdays &lt;- sample(1:num_days, num_people,replace = T)\n  ppl_df['birthday'] &lt;- birthdays\n  if (!is.null(room_num)) {\n    ppl_df &lt;- ppl_df %&gt;% mutate(room_num=room_num) %&gt;% relocate(room_num)\n  }\n  return(ppl_df)\n}\nppl_df &lt;- gen_bday_room(1)\n#disp(ppl_df %&gt;% head())\nppl_df |&gt; head()\n\n\n\n\n\n\nroom_num\nid\nbirthday\n\n\n\n\n1\n1\n186\n\n\n1\n2\n281\n\n\n1\n3\n295\n\n\n1\n4\n34\n\n\n1\n5\n295\n\n\n1\n6\n43"
  },
  {
    "objectID": "w03/slides.html#section-5",
    "href": "w03/slides.html#section-5",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "i\nj\nbday\n\n\n\n\n2\n10\n281\n\n\n3\n5\n295"
  },
  {
    "objectID": "w03/slides.html#section-6",
    "href": "w03/slides.html#section-6",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "Let‚Äôs try more rooms‚Ä¶\n\n\n\n\nCode\n# Get tibbles for each room\nlibrary(purrr)\ngen_bday_rooms &lt;- function(num_rooms) {\n  rooms_df &lt;- tibble()\n  for (r in seq(1, num_rooms)) {\n      cur_room &lt;- gen_bday_room(r)\n      rooms_df &lt;- bind_rows(rooms_df, cur_room)\n  }\n  return(rooms_df)\n}\nnum_rooms &lt;- 10\nrooms_df &lt;- gen_bday_rooms(num_rooms)\nrooms_df %&gt;% group_by(room_num) %&gt;% group_map(~ get_shared_bdays(.x, is_grouped=TRUE))\n\n\n[[1]]\n# A tibble: 4 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1    28   303\n2     4    20   100\n3     8    10   190\n4     9    17    68\n\n[[2]]\n# A tibble: 0 √ó 0\n\n[[3]]\n# A tibble: 1 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1    11    26   214\n\n[[4]]\n# A tibble: 2 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     7    28   113\n2    11    24   366\n\n[[5]]\n# A tibble: 2 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1    14    28   154\n2    15    18   203\n\n[[6]]\n# A tibble: 1 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     9    16   213\n\n[[7]]\n# A tibble: 2 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     5     7   118\n2    21    27   131\n\n[[8]]\n# A tibble: 0 √ó 0\n\n[[9]]\n# A tibble: 2 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1    18   207\n2     7    13    11\n\n[[10]]\n# A tibble: 0 √ó 0\n\n\n\nNumber of shared birthdays per room:\n\n\nCode\n# Now just get the # shared bdays\nshared_per_room &lt;- rooms_df %&gt;%\n    group_by(room_num) %&gt;%\n    group_map(~ get_shared_bdays(.x, is_grouped = TRUE, return_num=TRUE))\nshared_per_room &lt;- unlist(shared_per_room)\nshared_per_room\n\n\n [1] 4 0 1 2 2 1 2 0 2 0\n\n\n\n\\(\\widehat{\\Pr}(\\text{shared})\\)\n\n\n\n[1] 0.7"
  },
  {
    "objectID": "w03/slides.html#section-7",
    "href": "w03/slides.html#section-7",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "How about A THOUSAND ROOMS?\n\n\n\n  [1] 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0\n [38] 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 0 0 1 0\n [75] 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0\n\n\n\n\\(\\widehat{\\Pr}(\\text{shared bday})\\)?\n\n\n\n[1] 0.65\n\n\n\nThe analytic solution: \\(\\Pr(\\text{shared} \\mid k\\text{ people in room}) = 1 - \\frac{366!}{366^{k}(366-k)!}\\)\nIn our case: \\(1 - \\frac{366!}{366^{30}(366-30)!} = 1 - \\frac{366!}{366^{30}336!} = 1 - \\frac{\\prod_{i=337}^{366}i}{366^{30}}\\)\nR can juust barely handle these numbers:\n\n\n\n[1] 0.7053034"
  },
  {
    "objectID": "w03/slides.html#wrapping-up",
    "href": "w03/slides.html#wrapping-up",
    "title": "Week 3: Random Variables",
    "section": "Wrapping Up",
    "text": "Wrapping Up"
  },
  {
    "objectID": "w03/slides.html#final-note-functions-of-random-variables",
    "href": "w03/slides.html#final-note-functions-of-random-variables",
    "title": "Week 3: Random Variables",
    "section": "Final Note: Functions of Random Variables",
    "text": "Final Note: Functions of Random Variables\n\n\\(X \\sim U[0,1], Y \\sim U[0,1]\\).\n\\(P(Y &lt; X^2)\\)?\nThe hard way: solve analytically\nThe easy way: simulate!"
  },
  {
    "objectID": "w03/slides.html#lab-2-demonstrations",
    "href": "w03/slides.html#lab-2-demonstrations",
    "title": "Week 3: Random Variables",
    "section": "Lab 2 Demonstrations",
    "text": "Lab 2 Demonstrations\nLab 2 Demonstrations"
  },
  {
    "objectID": "w03/slides.html#lab-2-assignment-overview",
    "href": "w03/slides.html#lab-2-assignment-overview",
    "title": "Week 3: Random Variables",
    "section": "Lab 2 Assignment Overview",
    "text": "Lab 2 Assignment Overview\nLab 2 Assignment\n\n\n\nDSAN 5100-03 W03: Random Variables"
  },
  {
    "objectID": "w03/index.html",
    "href": "w03/index.html",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "Open slides in new window ‚Üí",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#logic-sets-and-probability",
    "href": "w03/index.html#logic-sets-and-probability",
    "title": "Week 3: Random Variables",
    "section": "Logic, Sets, and Probability",
    "text": "Logic, Sets, and Probability\nDeep connection between objects and operations of logic, set theory, and probability:\n\n\n\n\n\n\n\n\n\n\nLogic\nSet Theory\nProbability Theory\n\n\n\n\nObjects\nPredicates\\(p, q \\in \\{T, F\\}\\)\nSets\\(S = \\{a, b, \\ldots\\}\\)\nEvents\\(E = \\{TT, TH, HT, HH\\}\\)\n\n\nConjunction\nAnd (\\(\\wedge\\))\\(p \\wedge q\\)\nIntersection (\\(\\cap\\))\\(A \\cap B\\)\nMultiplication (\\(\\times\\)):\\(\\Pr(E_1 \\cap E_2) = \\Pr(E_1)\\times \\Pr(E_2)\\)\n\n\nDisjunction\nOr (\\(\\vee\\))\\(p \\vee q\\)\nUnion (\\(\\cup\\))\\(A \\cup B\\)\nAddition (\\(+\\)): \\(\\Pr(E_1 \\cup E_2) =\\)\\(\\Pr(E_1) + \\Pr(E_2) - \\Pr(E_1 \\wedge E_2)\\)\n\n\nNegation\nNot (\\(\\neg\\))\\(\\neg p\\)\nComplement (\\(^c\\))\\(S^c\\)\nSubtract from 1\\(\\Pr(A^c) = 1 - \\Pr(A)\\)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#example-flipping-two-coins",
    "href": "w03/index.html#example-flipping-two-coins",
    "title": "Week 3: Random Variables",
    "section": "Example: Flipping Two Coins",
    "text": "Example: Flipping Two Coins\n\nLogic: We can define 4 predicates:\n\n\\(p_1\\) = ‚ÄúFirst result is \\(H\\)‚Äù, \\(q_1\\) = ‚ÄúFirst result is \\(T\\)‚Äù\n\\(p_2\\) = ‚ÄúSecond result is \\(H\\)‚Äù, \\(q_2\\) = ‚ÄúSecond result is \\(T\\)‚Äù\n\nLogical formulas:\n\n\\(f_1 = p_1 \\wedge q_2\\): ‚ÄúFirst result is \\(H\\) and second result is \\(T\\)‚Äù\n\\(f_2 = p_1 \\vee q_2\\): ‚ÄúFirst result is \\(H\\) or second result is \\(T\\)‚Äù\n\\(f_3 = \\neg p_1\\): ‚ÄúFirst result is not \\(H\\)‚Äù\n\nThe issue?: We don‚Äôt know, until after the coins have been flipped, whether these are true or false!\nBut, we should still be able to say something about their likelihood, for example, whether \\(f_1\\) or \\(f_2\\) is more likely to happen‚Ä¶ Enter probability theory!",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#logic-rightarrow-probability",
    "href": "w03/index.html#logic-rightarrow-probability",
    "title": "Week 3: Random Variables",
    "section": "Logic \\(\\rightarrow\\) Probability",
    "text": "Logic \\(\\rightarrow\\) Probability\n\nProbability theory lets us reason about the uncertainty surrounding logical predicates like \\(p\\) and \\(q\\), by:\n\nencoding them as sets of possibilities \\(P\\) and \\(Q\\), and\nrepresenting uncertainty around a given possibility using a probability measure \\(\\Pr: S \\mapsto [0,1]\\),\n\nthus allowing us to reason about\n\nthe likelihood of these set-encoded predicates on their own: \\(\\Pr(P)\\) and \\(\\Pr(Q)\\), but also\ntheir logical connections: \\(\\Pr(p \\wedge q) = \\Pr(P \\cap Q)\\), \\(\\Pr(\\neg p) = \\Pr(P^c)\\), and so on.",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#flipping-two-coins-logic-rightarrow-probability",
    "href": "w03/index.html#flipping-two-coins-logic-rightarrow-probability",
    "title": "Week 3: Random Variables",
    "section": "Flipping Two Coins: Logic \\(\\rightarrow\\) Probability",
    "text": "Flipping Two Coins: Logic \\(\\rightarrow\\) Probability\n\nReturning to the two coins example: we can look at the predicates and see that they exhaust all possibilities, so that we can define a sample space \\(\\Omega = \\{TT, TH, HT, HH\\}\\) of all possible outcomes of our coin-flipping experiment, noting that \\(|\\Omega| = 4\\), so there are 4 possible outcomes.\nThen we can associate each predicate with an event, a subset of the sample space, and use our na√Øve definition to compute the probability of these events:\n\n\n\n\n\n\n\n\n\nPredicate\nEvent\nProbability\n\n\n\n\n\\(p_1\\) = ‚ÄúFirst result is \\(H\\)‚Äù\n\\(P_1 = \\{HT, HH\\}\\)\n\\(\\Pr(P_1) = \\frac{|P_1|}{|\\Omega|} = \\frac{2}{4} = \\frac{1}{2}\\)\n\n\n\\(q_1\\) = ‚ÄúFirst result is \\(T\\)‚Äù\n\\(Q_1 = \\{TT, TH\\}\\)\n\\(\\Pr(Q_1) = \\frac{|Q_1|}{|\\Omega|} = \\frac{2}{4} = \\frac{1}{2}\\)\n\n\n\\(p_2\\) = ‚ÄúSecond result is \\(H\\)‚Äù\n\\(P_2 = \\{TH, HH\\}\\)\n\\(\\Pr(P_2) = \\frac{|P_2|}{|\\Omega|} = \\frac{2}{4} = \\frac{1}{2}\\)\n\n\n\\(q_2\\) = ‚ÄúSecond result is \\(T\\)‚Äù\n\\(Q_2 = \\{TT, HT\\}\\)\n\\(\\Pr(Q_2) = \\frac{|Q_2|}{|\\Omega|} = \\frac{2}{4} = \\frac{1}{2}\\)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#moving-from-predicates-to-formulas",
    "href": "w03/index.html#moving-from-predicates-to-formulas",
    "title": "Week 3: Random Variables",
    "section": "Moving from Predicates to Formulas",
    "text": "Moving from Predicates to Formulas\n\nNotice that, in the four rows of the previous table, we were only computing the probabilities of ‚Äúsimple‚Äù events: events corresponding to a single predicate\nBut we promised that probability theory lets us compute probabilities for logical formulas as well! ‚Ä¶The magic of encoding events as sets becomes clear:\n\n\n\n\n\n\n\n\n\nFormula\nEvent\nProbability\n\n\n\n\n\\(f_1 = p_1 \\wedge q_2\\)\n\\[ \\begin{align*} F_1 &= P_1 \\cap Q_2 \\\\ &= \\{HT, HH\\} \\cap \\{TT, HT\\} \\\\ &= \\{HT\\} \\end{align*} \\]\n\\[\\begin{align*} \\Pr(F_1) &= \\Pr(\\{HT\\}) \\\\ &= \\frac{|\\{HT\\}|}{|S|} = \\frac{1}{4} \\phantom{= \\frac{1}{4} = \\frac{1}{4}} \\end{align*}\\]\n\n\n\\(f_2 = p_1 \\vee q_2\\)\n\\[\\begin{align*} F_2 &= P_1 \\cup Q_2 \\\\ &= \\{HT, HH\\} \\cup \\{TT, HT\\} \\\\ &= \\{TT, HT, HH\\} \\end{align*}\\]\n\\[\\begin{align*} \\Pr(F_2) &= \\Pr(\\{TT, HT, HH\\}) \\\\ &= \\frac{|\\{TT, HT, HH\\}|}{|S|} = \\frac{3}{4} \\end{align*}\\]\n\n\n\\(f_3 = \\neg p_1\\)\n\\[\\begin{align*} F_3 &= P_1^c \\\\ &= \\{HT, HH\\}^c \\phantom{\\cup \\{TT, HT\\}} \\\\ &= \\{TT, TH\\}\\end{align*}\\]\n\\[\\begin{align*} \\Pr(F_3) &= \\Pr(\\{TT, TH\\}) \\\\ &= \\frac{|\\{TT, TH\\}|}{|S|} = \\frac{2}{4} = \\frac{1}{2} \\end{align*}\\]",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#using-rules-of-probability",
    "href": "w03/index.html#using-rules-of-probability",
    "title": "Week 3: Random Variables",
    "section": "Using ‚ÄúRules‚Äù of Probability",
    "text": "Using ‚ÄúRules‚Äù of Probability\n\nHopefully, you found all this churning through set theory to be tedious‚Ä¶ ‚ò†Ô∏è\nThis is where rules of probability come from! They simplify set-theoretic computations into simple multiplications, additions, and subtractions:\n\n\\(\\Pr(A \\cap B) = \\Pr(A) \\times \\Pr(B)\\)\n\\(\\Pr(A \\cup B) = \\Pr(A) + \\Pr(B) - \\Pr(A \\cap B)\\)\n\\(\\Pr(A^c) = 1 - \\Pr(A)\\)\n\nSince we know probabilities of the ‚Äúsimple‚Äù events \\(P_1\\), \\(Q_1\\), \\(P_2\\), \\(Q_2\\), we don‚Äôt need to ‚Äúlook inside them‚Äù! Just take the probabilities and multiply/add/subtract as needed:\n\n\n\n\n\n\n\n\n\nFormula\nEvent\nProbability\n\n\n\n\n\\(f_1 = p_1 \\wedge q_2\\)\n\\(F_1 = P_1 \\cap Q_2\\)\n\\(\\Pr(F_1) = \\Pr(P_1) \\times \\Pr(Q_2) = \\frac{1}{2}\\times \\frac{1}{2} = \\frac{1}{4}\\)\n\n\n\\(f_2 = p_1 \\vee q_2\\)\n\\(F_2 = P_1 \\cup Q_2\\)\n\\[\\textstyle{\\begin{align*} \\textstyle \\Pr(F_2) &= \\Pr(P_1) + \\Pr(Q_2) - \\Pr(P_1 \\cap Q_2) \\\\ \\textstyle &= \\frac{1}{2} + \\frac{1}{2} - \\frac{1}{4} = \\frac{3}{4} \\end{align*}}\\]\n\n\n\\(f_3 = \\neg p_1\\)\n\\(F_3 = P_1^c\\)\n\\(\\Pr(F_3) = 1 - \\Pr(P_1) = 1 - \\frac{1}{2} = \\frac{1}{2}\\)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#importing-results-from-logic",
    "href": "w03/index.html#importing-results-from-logic",
    "title": "Week 3: Random Variables",
    "section": "‚ÄúImporting‚Äù Results from Logic",
    "text": "‚ÄúImporting‚Äù Results from Logic\n\nThis deep connection between the three fields means that, if we have some useful theorem or formula from one field, we can immediately put it to use in another!\nFor example: DeMorgan‚Äôs Laws were developed in logic (DeMorgan was a 19th-century logician), and basically just tell us how to distribute logic operators:\n\n\\[\n\\begin{align*}\n\\underbrace{\\neg(p \\wedge q)}_{\\text{``}p\\text{ and }q\\text{'' is not true}} &\\iff \\underbrace{\\neg p \\vee \\neg q}_{p\\text{ is not true or }q\\text{ is not true}} \\\\\n\\underbrace{\\neg(p \\vee q)}_{\\text{``}p\\text{ or }q\\text{'' is not true}} &\\iff \\underbrace{\\neg p \\wedge \\neg q}_{p\\text{ is not true and }q\\text{ is not true}}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#converting-to-probability-theory",
    "href": "w03/index.html#converting-to-probability-theory",
    "title": "Week 3: Random Variables",
    "section": "Converting to Probability Theory",
    "text": "Converting to Probability Theory\n\nSo, using the same principles we used in our coin flipping examples, we can consider events \\(P\\) and \\(Q\\), and get the following ‚Äútranslation‚Äù of DeMorgan‚Äôs Laws:\n\n\n\n\n\n\n\n\n\nLogic\nSet Theory\nProbability Theory\n\n\n\n\n\\(\\neg(p \\wedge q) = \\neg p \\vee \\neg q\\)\n\\((P \\cap Q)^c = P^c \\cup Q^c\\)\n\\(\\Pr((P \\cap Q)^c) = \\Pr(P^c \\cup Q^c)\\)\n\n\n\\(\\neg(p \\vee q) = \\neg p \\wedge \\neg q\\)\n\\((P \\cup Q)^c = P^c \\cap Q^c\\)\n\\(\\Pr((P \\cup Q)^c) = \\Pr(P^c \\cap Q^c)\\)\n\n\n\n\nNote that, since these are isomorphic to one another, we could have derived DeMorgan‚Äôs Laws from within probability theory, rather than the other way around:\n\n\\[\n\\begin{align*}\n\\Pr((P \\cap Q)^c) &= 1 - \\Pr(P \\cap Q) = 1 - \\Pr(P)\\Pr(Q) \\\\\n&= 1 - (1-\\Pr(P^c))(1 - \\Pr(Q^c)) \\\\\n&= 1 - [1 - \\Pr(P^c) - \\Pr(Q^c) + \\Pr(P^c)\\Pr(Q^c)] \\\\\n&= \\Pr(P^c) + \\Pr(Q^c) - \\Pr(P^c)\\Pr(Q^c) \\\\\n&= \\Pr(P^c) + \\Pr(Q^c) - \\Pr(P^c \\cap Q^c) \\\\\n&= \\Pr(P^c \\cup Q^c) \\; ‚úÖ\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#random-variables",
    "href": "w03/index.html#random-variables",
    "title": "Week 3: Random Variables",
    "section": "Random Variables",
    "text": "Random Variables\n\nRecall our discussion of random variables: used by analogy to algebra, since we can do math with them:\nJust as \\(2 \\cdot 3\\) is shorthand for \\(2 + 2 + 2\\), can define \\(X\\) as shorthand for possible outcomes of random process:\n\n\\[\n\\begin{align*}\nS = \\{ &\\text{result of dice roll is 1}, \\\\\n&\\text{result of dice roll is 2}, \\\\\n&\\text{result of dice roll is 3}, \\\\\n&\\text{result of dice roll is 4}, \\\\\n&\\text{result of dice roll is 5}, \\\\\n&\\text{result of dice roll is 6}\\} \\rightsquigarrow X \\in \\{1,\\ldots,6\\}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#random-variables-as-events",
    "href": "w03/index.html#random-variables-as-events",
    "title": "Week 3: Random Variables",
    "section": "Random Variables as Events",
    "text": "Random Variables as Events\n\nEach value \\(v_X\\) that a random variable \\(X\\) can take on gives rise to an event \\(X = v_X\\): the event that the random variable \\(X\\) takes on value \\(v\\).\nSince \\(X = v_X\\) is an event, we can compute its probability \\(\\Pr(X = v_X)\\)!\n\n\n\n\nEvent in words\nEvent in terms of RV\n\n\n\n\nResult of dice roll is 1\n\\(X = 1\\)\n\n\nResult of dice roll is 2\n\\(X = 2\\)\n\n\nResult of dice roll is 3\n\\(X = 3\\)\n\n\nResult of dice roll is 4\n\\(X = 4\\)\n\n\nResult of dice roll is 5\n\\(X = 5\\)\n\n\nResult of dice roll is 6\n\\(X = 6\\)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#doing-math-with-events",
    "href": "w03/index.html#doing-math-with-events",
    "title": "Week 3: Random Variables",
    "section": "Doing Math with Events",
    "text": "Doing Math with Events\n\nWe‚Äôve seen how \\(\\Pr()\\) ‚Äúencodes‚Äù logical expressions involving uncertain outcomes.\nEven more powerful when paired with the notion of random variables: lets us also ‚Äúencode‚Äù mathematical expressions involving uncertain quantities!\nConsider an experiment where we roll two dice. Let \\(X\\) be the RV encoding the outcome of the first roll, and \\(Y\\) be the RV encoding the outcome of the second roll.\nWe can compute probabilities involving \\(X\\) and \\(Y\\) separately, e.g., \\(\\Pr(X = 1) = \\frac{1}{6}\\), but we can also reason probabilistically about mathematical expressions involving \\(X\\) and \\(Y\\)! For example, we can reason about their sum:\n\n\\[\n\\begin{align*}\n\\Pr(\\text{rolls sum to 10}) &= \\Pr(X + Y = 10) \\\\\n&= \\Pr(Y = 10 - X)\n\\end{align*}\n\\]\n\nOr about how the outcome of one roll will relate to the outcome of the other:\n\n\\[\n\\begin{align*}\n\\Pr(\\text{first roll above mean}) &= \\Pr\\left(X &gt; \\frac{X+Y}{2}\\right) \\\\\n&= \\Pr(2X &gt; X+Y) = \\Pr(X &gt; Y)\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#are-random-variables-all-powerful",
    "href": "w03/index.html#are-random-variables-all-powerful",
    "title": "Week 3: Random Variables",
    "section": "Are Random Variables All-Powerful??",
    "text": "Are Random Variables All-Powerful??\n\nJust remember that probability \\(\\Pr(\\cdot)\\) is always probability of an event‚Äîrandom variables are just shorthand for quantifiable events.\nNot all events can be simplified via random variables!\n\n\\(\\text{catch a fish} \\mapsto \\Pr(\\text{trout}), \\Pr(\\text{bass}), \\ldots\\)\n\nWhat types of events can be quantified like this?\n\n(Hint: It has to do with a key topic in the early weeks of both DSAN 5000 and 5100‚Ä¶)\n\n\n\nThe answer is, broadly, any situation where you‚Äôre modeling things, like dice rolls, where mathematical operations like addition, multiplication, etc. make sense. So, if we‚Äôre modeling dice, it makes sense to say e.g.¬†‚Äúresult is 6‚Äù + ‚Äúresult is 3‚Äù = ‚Äútotal is 9‚Äù. More on the next page!",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#recall-types-of-variables",
    "href": "w03/index.html#recall-types-of-variables",
    "title": "Week 3: Random Variables",
    "section": "Recall: Types of Variables",
    "text": "Recall: Types of Variables\n\nCategorical\n\nNo meaningful way to order values: \\(\\{\\text{trout}, \\text{bass}, \\ldots \\}\\)\n\nOrdinal\n\nCan place in order (bigger, smaller), though gaps aren‚Äôt meaningful: \\(\\{{\\color{orange}\\text{great}},{\\color{orange}\\text{greater}},{\\color{orange}\\text{greatest}}\\}\\)\n\\({\\color{orange}\\text{greater}} \\overset{?}{=} 2\\cdot {\\color{orange}\\text{great}} - 1\\)\n\nCardinal\n\nCan place in order, and gaps are meaningful \\(\\implies\\) can do ‚Äústandard‚Äù math with them! Example: \\(\\{{\\color{blue}1},{\\color{blue}2},\\ldots,{\\color{blue}10}\\}\\)\n\\({\\color{blue}7} \\overset{\\text{~‚úÖ~}}{=} 2 \\cdot {\\color{blue}4} - 1\\)\nIf events have this structure (meaningful way to define multiplication, addition, subtraction), then we can analyze them as random variables",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#visualizing-discrete-rvs",
    "href": "w03/index.html#visualizing-discrete-rvs",
    "title": "Week 3: Random Variables",
    "section": "Visualizing Discrete RVs",
    "text": "Visualizing Discrete RVs\n\nUltimate Probability Pro-Tip: When you hear ‚Äúdiscrete distribution‚Äù, think of a bar graph: \\(x\\)-axis = events, bar height = probability of events\nTwo coins example: \\(X\\) = RV representing number of heads obtained in two coin flips",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#preview-visualizing-continuous-rvs",
    "href": "w03/index.html#preview-visualizing-continuous-rvs",
    "title": "Week 3: Random Variables",
    "section": "(Preview:) Visualizing Continuous RVs",
    "text": "(Preview:) Visualizing Continuous RVs\n\nThis works even for continuous distributions, if you focus on the area under the curve instead of the height:\n\n\nfuncShaded &lt;- function(x, lower_bound, upper_bound) {\n    y &lt;- dnorm(x)\n    y[x &lt; lower_bound | x &gt; upper_bound] &lt;- NA\n    return(y)\n}\nfuncShadedBound1 &lt;- function(x) funcShaded(x, -Inf, 0)\nfuncShadedBound2 &lt;- function(x) funcShaded(x, 0.2, 1.8)\nfuncShadedBound3 &lt;- function(x) funcShaded(x, 2, Inf)\n\nnorm_plot &lt;- ggplot(data.frame(x=c(-3,3)), aes(x = x)) +\n    stat_function(fun = dnorm) +\n    labs(\n      title=\"Probability Density, X Normally Distributed\",\n      x=\"Possible Values of X\",\n      y=\"Probability Density\"\n    ) +\n    dsan_theme(\"half\") +\n    theme(legend.position = \"none\") +\n    coord_cartesian(clip = \"off\")\nlabel_df &lt;- tribble(\n  ~x, ~y, ~label,\n  -0.8, 0.1, \"Pr(X &lt; 0) = 0.5\",\n  1.0, 0.05, \"Pr(0.2 &lt; X &lt; 1.8)\\n= 0.385\",\n  2.5,0.1,\"Pr(X &gt; 1.96)\\n= 0.025\"\n)\nshaded_plot &lt;- norm_plot +\n  stat_function(fun = funcShadedBound1, geom = \"area\", fill=cbPalette[1], alpha = 0.5) +\n  stat_function(fun = funcShadedBound2, geom = \"area\", fill=cbPalette[2], alpha = 0.5) +\n  stat_function(fun = funcShadedBound3, geom = \"area\", fill=cbPalette[3], alpha = 0.5) +\n  geom_text(label_df, mapping=aes(x = x, y = y, label = label), size=6)\nshaded_plot",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#probability-theory-gives-us-distributions-for-rvs-not-numbers",
    "href": "w03/index.html#probability-theory-gives-us-distributions-for-rvs-not-numbers",
    "title": "Week 3: Random Variables",
    "section": "Probability Theory Gives Us Distributions for RVs, not Numbers!",
    "text": "Probability Theory Gives Us Distributions for RVs, not Numbers!\n\nWe‚Äôre going beyond ‚Äúbase‚Äù probability theory if we want to summarize these distributions\nHowever, we can understand a lot about the full distribution by looking at some basic summary statistics. Most common way to summarize:\n\n\n\n\n\n\n\n\n\n\\(\\underbrace{\\text{point estimate}}_{\\text{mean/median}}\\)\n\\(\\pm\\)\n\\(\\underbrace{\\text{uncertainty}}_{\\text{variance/standard deviation}}\\)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#example-game-reviews",
    "href": "w03/index.html#example-game-reviews",
    "title": "Week 3: Random Variables",
    "section": "Example: Game Reviews",
    "text": "Example: Game Reviews\n\nlibrary(readr)\nfig_title &lt;- \"Reviews for a Popular Nintendo Switch Game\"\n#score_df &lt;- read_csv(\"https://gist.githubusercontent.com/jpowerj/8b2b6a50cef5a682db640e874a14646b/raw/bbe07891a90874d1fe624224c1b82212b1ac8378/totk_scores.csv\")\nscore_df &lt;- read_csv(\"https://gist.githubusercontent.com/jpowerj/8b2b6a50cef5a682db640e874a14646b/raw/e3c2b9d258380e817289fbb64f91ba9ed4357d62/totk_scores.csv\")\nmean_score &lt;- mean(score_df$score)\nlibrary(ggplot2)\nggplot(score_df, aes(x=score)) +\n  geom_histogram() +\n  #geom_vline(xintercept=mean_score) +\n  labs(\n    title=fig_title,\n    x=\"Review Score\",\n    y=\"Number of Reviews\"\n  ) +\n  dsan_theme(\"full\")\n\n\n\n\n(Data from Metacritic)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#adding-a-single-line",
    "href": "w03/index.html#adding-a-single-line",
    "title": "Week 3: Random Variables",
    "section": "Adding a Single Line",
    "text": "Adding a Single Line\n\nlibrary(readr)\nmean_score &lt;- mean(score_df$score)\nmean_score_label &lt;- sprintf(\"%0.2f\", mean_score)\nlibrary(ggplot2)\nggplot(score_df, aes(x=score)) +\n  geom_histogram() +\n  geom_vline(aes(xintercept=mean_score, linetype=\"dashed\"), color=\"purple\", size=1) +\n  scale_linetype_manual(\"\", values=c(\"dashed\"=\"dashed\"), labels=c(\"dashed\"=\"Mean Score\")) +\n  # Add single additional tick\n  scale_x_continuous(breaks=c(60, 70, 80, 90, mean_score, 100), labels=c(\"60\",\"70\",\"80\",\"90\",mean_score_label,\"100\")) +\n  labs(\n    title=fig_title,\n    x=\"Review Score\",\n    y=\"Number of Reviews\"\n  ) +\n  dsan_theme(\"full\") +\n  theme(\n    legend.title = element_blank(),\n    legend.spacing.y = unit(0, \"mm\")\n  ) +\n  theme(axis.text.x = element_text(colour = c('black', 'black','black', 'black', 'purple', 'black')))\n\n\n\n\n(Data from Metacritic)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#or-a-single-ribbon",
    "href": "w03/index.html#or-a-single-ribbon",
    "title": "Week 3: Random Variables",
    "section": "Or a Single Ribbon",
    "text": "Or a Single Ribbon\nlibrary(tibble)\nN &lt;- 10\n# Each x value gets 10 y values\nx &lt;- sort(rep(seq(1,10),10))\ny &lt;- x + rnorm(length(x), 0, 5)\ndf &lt;- tibble(x=x,y=y)\ntotal_N &lt;- nrow(df)\nggplot(df, aes(x=x,y=y)) +\n  geom_point(size=g_pointsize) +\n  dsan_theme(\"column\") +\n  labs(\n    title=paste0(\"N=\",total_N,\" Randomly-Generated Points\")\n  )\n# This time, just the means\nlibrary(dplyr)\nmean_df &lt;- df %&gt;% group_by(x) %&gt;% summarize(mean=mean(y), min=min(y), max=max(y))\nggplot(mean_df, aes(x=x, y=mean)) +\n  geom_ribbon(aes(ymin=min, ymax=max, fill=\"ribbon\"), alpha=0.5) +\n  geom_point(aes(color=\"mean\"), size=g_pointsize) +\n  geom_line(size=g_linesize) +\n  dsan_theme(\"half\") +\n  scale_color_manual(\"\", values=c(\"mean\"=\"black\"), labels=c(\"mean\"=\"Mean\")) +\n  scale_fill_manual(\"\", values=c(\"ribbon\"=cbPalette[1]), labels=c(\"ribbon\"=\"Range\")) +\n  remove_legend_title() +\n  labs(\n    title=paste0(\"Means of N=\",total_N,\" Randomly-Generated Points\")\n  )\nlibrary(tibble)\nN &lt;- 100\n# Each x value gets 10 y values\nx &lt;- sort(rep(seq(1,10),10))\ny &lt;- x + rnorm(length(x), 0, 1)\ndf &lt;- tibble(x=x,y=y)\ntotal_N &lt;- nrow(df)\nggplot(df, aes(x=x,y=y)) +\n  geom_point(size=g_pointsize) +\n  dsan_theme(\"column\") +\n  labs(\n    title=paste0(\"N=\",total_N,\" Randomly-Generated Points\")\n  )\n# This time, just the means\nlibrary(dplyr)\nmean_df &lt;- df %&gt;% group_by(x) %&gt;% summarize(mean=mean(y), min=min(y), max=max(y))\nggplot(mean_df, aes(x=x, y=mean)) +\n  geom_ribbon(aes(ymin=min, ymax=max, fill=\"ribbon\"), alpha=0.5) +\n  geom_point(aes(color=\"mean\"), size=g_pointsize) +\n  geom_line(size=g_linesize) +\n  dsan_theme(\"half\") +\n  scale_color_manual(\"\", values=c(\"mean\"=\"black\"), labels=c(\"mean\"=\"Mean\")) +\n  scale_fill_manual(\"\", values=c(\"ribbon\"=cbPalette[1]), labels=c(\"ribbon\"=\"Range\")) +\n  remove_legend_title() +\n  labs(\n    title=paste0(\"Means of N=\",total_N,\" Randomly-Generated Points\")\n  )",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#example-the-normal-distribution",
    "href": "w03/index.html#example-the-normal-distribution",
    "title": "Week 3: Random Variables",
    "section": "Example: The Normal Distribution",
    "text": "Example: The Normal Distribution\n\n\n\n(The distribution you saw a few slides ago)\n\n\nvlines_std_normal &lt;- tibble::tribble(\n  ~x, ~xend, ~y, ~yend, ~Params,\n  0, 0, 0, dnorm(0), \"Mean\",\n  -2, -2, 0, dnorm(-2), \"SD\",\n  -1, -1, 0, dnorm(-1), \"SD\",\n  1, 1, 0, dnorm(1), \"SD\",\n  2, 2, 0, dnorm(2), \"SD\"\n)\nggplot(data.frame(x = c(-3, 3)), aes(x = x)) +\n    stat_function(fun = dnorm, linewidth = g_linewidth) +\n    geom_segment(data=vlines_std_normal, aes(x=x, xend=xend, y=y, yend=yend, linetype = Params), linewidth = g_linewidth, color=\"purple\") +\n    geom_area(stat = \"function\", fun = dnorm, fill = cbPalette[1], xlim = c(-3, 3), alpha=0.2) +\n    #geom_area(stat = \"function\", fun = dnorm, fill = \"blue\", xlim = c(0, 2))\n    dsan_theme(\"quarter\") +\n    labs(\n      x = \"v\",\n      y = \"Density f(v)\"\n    )\n\n\n\n\n\n\n\n\n\n\n‚ÄúRV \\(X\\) is normally distributed with mean \\({\\color{purple}\\mu}\\) and standard deviation \\({\\color{purple}\\sigma}\\)‚Äù\n\nTranslates to \\(X \\sim \\mathcal{N}(\\color{purple}{\\mu},\\color{purple}{\\sigma})\\)1\n\\(\\color{purple}{\\mu}\\) and \\(\\color{purple}{\\sigma}\\) are parameters2: the ‚Äúknobs‚Äù or ‚Äúsliders‚Äù which change the location/shape of the distribution\n\n\n\n\n\nThe parameters in this case give natural summaries of the data:\n\n\\({\\color{\\purple}\\mu}\\) = center (mean), \\({\\color{purple}\\sigma}\\) = [square root of] variance around center\n\nMean can usually be interpreted intuitively; for standard deviation, can use the 68-95-99.7 rule, which will make more sense relative to some real-world data‚Ä¶",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#real-data-and-the-68-95-99.7-rule",
    "href": "w03/index.html#real-data-and-the-68-95-99.7-rule",
    "title": "Week 3: Random Variables",
    "section": "Real Data and the 68-95-99.7 Rule",
    "text": "Real Data and the 68-95-99.7 Rule\n\n\n\n\nCode\nlibrary(readr)\nheight_df &lt;- read_csv(\"https://gist.githubusercontent.com/jpowerj/9a23807fb71a5f6b6c2f37c09eb92ab3/raw/89fc6b8f0c57e41ebf4ce5cdf2b3cad6b2dd798c/sports_heights.csv\")\nmean_height &lt;- mean(height_df$height_cm)\nsd_height &lt;- sd(height_df$height_cm)\nheight_density &lt;- function(x) dnorm(x, mean_height, sd_height)\nm2_sd &lt;- mean_height - 2 * sd_height\nm1_sd &lt;- mean_height - 1 * sd_height\np1_sd &lt;- mean_height + 1 * sd_height\np2_sd &lt;- mean_height + 2 * sd_height\nvlines_data &lt;- tibble::tribble(\n  ~x, ~xend, ~y, ~yend, ~Params,\n  mean_height, mean_height, 0, height_density(mean_height), \"Mean\",\n  m2_sd, m2_sd, 0, height_density(m2_sd), \"SD\",\n  m1_sd, m1_sd, 0, height_density(m1_sd), \"SD\",\n  p1_sd, p1_sd, 0, height_density(p1_sd), \"SD\",\n  p2_sd, p2_sd, 0, height_density(p2_sd), \"SD\"\n)\nggplot(height_df, aes(x = height_cm)) +\n    geom_histogram(aes(y = after_stat(density)), binwidth = 5.0) +\n    #stat_function(fun = height_density, linewidth = g_linewidth) +\n    geom_area(stat = \"function\", fun = height_density, color=\"black\", linewidth = g_linewidth, fill = cbPalette[1], alpha=0.2) +\n    geom_segment(data=vlines_data, aes(x=x, xend=xend, y=y, yend=yend, linetype = Params), linewidth = g_linewidth, color=cbPalette[2]) +\n    labs(\n      title=paste0(\"Distribution of heights (cm), N=\",nrow(height_df),\" athletes\\nMean=\",round(mean_height,2),\", SD=\",round(sd_height,2)),\n      x=\"Height (cm)\",\n      y=\"Probability Density\"\n    ) +\n    dsan_theme(\"full\")\n\n\n\n\n\n\n\n\nFigure¬†1: Heights (cm) for 18K professional athletes\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†2: 68-95-99.7 Rule visualized (Wiki Commons)\n\n\n\n\n\nThe point estimate \\({\\color{purple}\\mu} = 186.48\\) is straightforward: the average height of the athletes is 186.48cm. Using the 68-95-99.7 Rule to interpret the SD, \\({\\color{purple}\\sigma} = 9.7\\), we get:\n\n\n\nAbout 68% of the heights fall between\n\n\n\n\n\n\n\n\n\n[\\({\\color{purple}\\mu} - 1\\cdot {\\color{purple}\\sigma}\\)\nand\n\\({\\color{purple}\\mu} + 1\\cdot {\\color{purple}\\sigma}\\)]\n\n\n[186.48 - 1 ¬∑ 9.7\nand\n186.48 + 1 ¬∑ 9.7]\n\n\n[176.78\nand\n196.18]\n\n\n\n\n\nAbout 95% of the heights fall between\n\n\n\n\n\n\n\n\n\n[\\({\\color{purple}\\mu} - 2 \\cdot {\\color{purple}\\sigma}\\)\nand\n\\({\\color{purple}\\mu} + 2 \\cdot {\\color{purple}\\sigma}\\)]\n\n\n[186.48 - 2 ¬∑ 9.7\nand\n186.48 + 2 ¬∑ 9.7]\n\n\n[167.08\nand\n205.88]",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#boxplots-comparing-multiple-distributions",
    "href": "w03/index.html#boxplots-comparing-multiple-distributions",
    "title": "Week 3: Random Variables",
    "section": "Boxplots: Comparing Multiple Distributions",
    "text": "Boxplots: Comparing Multiple Distributions\n\n\n\n\n\nFrom Wikimedia Commons\n\n\n\n\n\n\nFrom Wikimedia Commons",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#another-option-joyplots",
    "href": "w03/index.html#another-option-joyplots",
    "title": "Week 3: Random Variables",
    "section": "Another Option: Joyplots",
    "text": "Another Option: Joyplots\n\n\n\n\n\n\n\n\nFigure¬†3: (Iconic album cover)\n\n\n\n\n\n\n\n\n\n\nFigure¬†4: (Tooting my own horn)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#multivariate-distributions-preview",
    "href": "w03/index.html#multivariate-distributions-preview",
    "title": "Week 3: Random Variables",
    "section": "Multivariate Distributions: Preview",
    "text": "Multivariate Distributions: Preview\n\nThe bivariate normal distribution represents the distribution of two normally-distributed RVs \\(\\mathbf{X} = [\\begin{smallmatrix} X_1 & X_2\\end{smallmatrix}]\\), which may or may not be correlated:\n\n\\[\n\\mathbf{X} = \\begin{bmatrix}X_1 \\\\ X_2\\end{bmatrix}, \\; \\boldsymbol{\\mu} =\n%\\begin{bmatrix}\\mu_1 \\\\ \\mu_2\\end{bmatrix}\n\\begin{bmatrix}\\smash{\\overbrace{\\mu_1}^{\\mathbb{E}[X_1]}} \\\\ \\smash{\\underbrace{\\mu_2}_{\\mathbb{E}[X_2]}}\\end{bmatrix}\n, \\; \\mathbf{\\Sigma} = \\begin{bmatrix}\\smash{\\overbrace{\\sigma_1^2}^{\\text{Var}[X_1]}} & \\smash{\\overbrace{\\rho\\sigma_1\\sigma_2}^{\\text{Cov}[X_1,X_2]}} \\\\ \\smash{\\underbrace{\\rho\\sigma_2\\sigma_1}_{\\text{Cov}[X_2,X_1]}} & \\smash{\\underbrace{\\sigma_2^2}_{\\text{Var}[X_2]}}\\end{bmatrix}\n% \\begin{bmatrix}\\sigma_1^2 & \\rho\\sigma_1\\sigma_2 \\\\ \\rho\\sigma_2\\sigma_1 & \\sigma_2^2 \\end{bmatrix}\n% = \\begin{bmatrix}\\text{Var}[X_1] & \\text{Cov}[X_1,X_2] \\\\ \\text{Cov}[X_2,X_1] & \\text{Var}[X_2] \\end{bmatrix}\n\\]\n\nBy squishing all this information intro matrices, we can specify the parameters of multivariate-normally-distributed vectors of RVs similarly to how we specify single-dimensional normally-distributed RVs:\n\n\n\\[\n\\begin{align*}\n\\overbrace{X}^{\\mathclap{\\text{scalar}}} &\\sim \\mathcal{N}\\phantom{_k}(\\overbrace{\\mu}^{\\text{scalar}}, \\overbrace{\\sigma}^{\\text{scalar}}) \\tag{Univariate} \\\\\n\\underbrace{\\mathbf{X}}_{\\text{vector}} &\\sim \\boldsymbol{\\mathcal{N}}_k(\\smash{\\underbrace{\\boldsymbol{\\mu}}_{\\text{vector}}}, \\underbrace{\\mathbf{\\Sigma}}_{\\text{matrix}}) \\tag{Multivariate}\n\\end{align*}\n\\]\n\n\nNote: In the future I‚Äôll use the notation \\(\\mathbf{X}_{[a \\times b]}\\) to denote the dimensions of the vectors/matrices, like \\(\\mathbf{X}_{[k \\times 1]} \\sim \\boldsymbol{\\mathcal{N}}_k(\\boldsymbol{\\mu}_{[k \\times 1]}, \\mathbf{\\Sigma}_{[k \\times k]})\\)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#visualizing-3d-distributions-projection",
    "href": "w03/index.html#visualizing-3d-distributions-projection",
    "title": "Week 3: Random Variables",
    "section": "Visualizing 3D Distributions: Projection",
    "text": "Visualizing 3D Distributions: Projection\n\nMost of our intuitions about plots come from 2D \\(\\Rightarrow\\) super helpful exercise to take a 3D plot like this and imagine ‚Äúprojecting‚Äù it onto different 2D surfaces:\n\n\n\n\n(Adapted via LaTeX from StackExchange discussion)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#visualizing-3d-distributions-contours",
    "href": "w03/index.html#visualizing-3d-distributions-contours",
    "title": "Week 3: Random Variables",
    "section": "Visualizing 3D Distributions: Contours",
    "text": "Visualizing 3D Distributions: Contours\n\n\n\nFrom Prof.¬†Hickman‚Äôs slides!",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#visualizing-3d-distributions-contours-1",
    "href": "w03/index.html#visualizing-3d-distributions-contours-1",
    "title": "Week 3: Random Variables",
    "section": "Visualizing 3D Distributions: Contours",
    "text": "Visualizing 3D Distributions: Contours\n\n\n\nAlso from Prof.¬†Hickman‚Äôs slides!",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#summarizing-what-we-know-so-far",
    "href": "w03/index.html#summarizing-what-we-know-so-far",
    "title": "Week 3: Random Variables",
    "section": "Summarizing What We Know So Far",
    "text": "Summarizing What We Know So Far\n\nLogic \\(\\rightarrow\\) Set Theory \\(\\rightarrow\\) Probability Theory\nEntirety of probability theory can be derived from two axioms:\n\n\n\n\n\n\n\nThe Entirety of Probability Theory Follows From‚Ä¶\n\n\n\nAxiom 1 (Unitarity): \\(\\Pr(\\Omega) = 1\\) (The probability that something happens is 1)\nAxiom 2 (\\(\\sigma\\)-additivity): For mutually-exclusive events \\(E_1, E_2, \\ldots\\),\n\\[\n\\underbrace{\\Pr\\left(\\bigcup_{i=1}^{\\infty}E_i\\right)}_{\\Pr(E_1\\text{ occurs }\\vee E_2\\text{ occurs } \\vee \\cdots)} = \\underbrace{\\sum_{i=1}^{\\infty}\\Pr(E_i)}_{\\Pr(E_1\\text{ occurs}) + \\Pr(E_2\\text{ occurs}) + \\cdots}\n\\]\n\n\n\nBut what does ‚Äúmutually exclusive‚Äù mean‚Ä¶?",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#venn-diagrams-sets",
    "href": "w03/index.html#venn-diagrams-sets",
    "title": "Week 3: Random Variables",
    "section": "Venn Diagrams: Sets",
    "text": "Venn Diagrams: Sets\n\n\n\\[\n\\begin{align*}\n&A = \\{1, 2, 3\\}, \\; B = \\{4, 5, 6\\} \\\\\n&\\implies A \\cap B = \\varnothing\n\\end{align*}\n\\]\n\n\n\nMutually-exclusive (disjoint) sets\n\n\n\n\\[\n\\begin{align*}\n&A = \\{1, 2, 3, 4\\}, \\; B = \\{3, 4, 5, 6\\} \\\\\n&\\implies A \\cap B = \\{3, 4\\}\n\\end{align*}\n\\]\n\n\n\nNon-mutually-exclusive sets",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#venn-diagrams-events-dice",
    "href": "w03/index.html#venn-diagrams-events-dice",
    "title": "Week 3: Random Variables",
    "section": "Venn Diagrams: Events (Dice)",
    "text": "Venn Diagrams: Events (Dice)\n\\[\n\\begin{align*}\nA &= \\{\\text{Roll is even}\\} = \\{2, 4, 6\\} \\\\\nB &= \\{\\text{Roll is odd}\\} = \\{1, 3, 5\\} \\\\\nC &= \\{\\text{Roll is in Fibonnaci sequence}\\} = \\{1, 2, 3, 5\\}\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\n\n\nSet 1\nSet 2\nIntersection\nMutually Exclusive?\nCan Happen Simultaneously?\n\n\n\n\n\\(A\\)\n\\(B\\)\n\\(A \\cap B = \\varnothing\\)\nYes\nNo\n\n\n\\(A\\)\n\\(C\\)\n\\(A \\cap C = \\{2\\}\\)\nNo\nYes\n\n\n\\(B\\)\n\\(C\\)\n\\(B \\cap C = \\{1, 3, 5\\}\\)\nNo\nYes",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#rules-of-probability-1",
    "href": "w03/index.html#rules-of-probability-1",
    "title": "Week 3: Random Variables",
    "section": "‚ÄúRules‚Äù of Probability",
    "text": "‚ÄúRules‚Äù of Probability\n(Remember: not ‚Äúrules‚Äù but ‚Äúfacts resulting from the logic \\(\\leftrightarrow\\) probability connection‚Äù)\n\n\n\n\n\n\n‚ÄúRules‚Äù of Probability\n\n\n\nFor logical predicates \\(p, q \\in \\{T, F\\}\\), events \\(P, Q\\) defined so \\(P\\) = event that \\(p\\) becomes true, \\(Q\\) = event that \\(q\\) becomes true,\n\nLogical AND = Probabilistic Multiplication\n\n\\[\n\\Pr(p \\wedge q) = \\Pr(P \\cap Q) = \\Pr(P) \\cdot \\Pr(Q)\n\\]\n\nLogical OR = Probabilistic Addition\n\n\\[\n\\Pr(p \\vee q) = \\Pr(P \\cup Q) = \\Pr(P) + \\Pr(Q) - \\underbrace{\\Pr(P \\cap Q)}_{\\text{(see rule 1)}}\n\\]\n\nLogical NOT = Probabilistic Complement\n\n\\[\n\\Pr(\\neg p) = \\Pr(P^c) = 1 - \\Pr(P)\n\\]",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#conditional-probability",
    "href": "w03/index.html#conditional-probability",
    "title": "Week 3: Random Variables",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\nUsually if someone asks you probabilistic questions, like\n\n‚ÄúWhat is the likelihood that [our team] wins?‚Äù\n‚ÄúDo you think it will rain tomorrow?‚Äù\n\nYou don‚Äôt guess a random number, you consider and incorporate evidence.\nExample: \\(\\Pr(\\text{rain})\\) on its own, no other info? Tough question‚Ä¶ maybe \\(0.5\\)?\nIn reality, we would think about\n\n\\(\\Pr(\\text{rain} \\mid \\text{month of the year})\\)\n\\(\\Pr(\\text{rain} \\mid \\text{where we live})\\)\n\\(\\Pr(\\text{rain} \\mid \\text{did it rain yesterday?})\\)\n\nPsychologically, breaks down into two steps: (1) Think of baseline probability, (2) Update baseline to incorporate relevant evidence (more on this in a bit‚Ä¶)\nAlso recall: all probability is conditional probability, even if just conditioned on ‚Äúsomething happened‚Äù (\\(\\Omega\\), the thing defined so \\(\\Pr(\\Omega) = 1\\))",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#na√Øve-definition-2.0",
    "href": "w03/index.html#na√Øve-definition-2.0",
    "title": "Week 3: Random Variables",
    "section": "Na√Øve Definition 2.0",
    "text": "Na√Øve Definition 2.0\n\n\n\n\n\n\n[Slightly Less] Na√Øve Definition of Probability\n\n\n\n\\[\n\\Pr(A \\mid B) = \\frac{\\text{\\# of Desired Outcomes in world where }B\\text{ happened}}{\\text{\\# Total outcomes in world where }B\\text{ happened}} = \\frac{|B \\cap A|}{|B|}\n\\]\n\n\n\n\n\n\n\n\n\n\nWorld Name\nWeather in World\nLikelihood of Rain Today\n\n\n\n\n\\(R\\)\nRained for the past 5 days\n\\(\\Pr(\\text{rain} \\mid R) &gt; 0.5\\)\n\n\n\\(M\\)\nMix of rain and non-rain over past 5 days\n\\(\\Pr(\\text{rain} \\mid M) \\approx 0.5\\)\n\n\n\\(S\\)\nSunny for the past 5 days\n\\(\\Pr(\\text{rain} \\mid S) &lt; 0.5\\)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#law-of-total-probability",
    "href": "w03/index.html#law-of-total-probability",
    "title": "Week 3: Random Variables",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\nSuppose the events \\(B_1, \\ldots, B_k\\) form a partition of the space \\(\\Omega\\) and \\(\\Pr(B_j) &gt; 0 \\forall j\\).\nThen, for every event \\(A\\) in \\(\\Omega\\),\n\\[\n  \\Pr(A) = \\sum_{i=1}^k \\Pr(B_j)\\Pr(A \\mid B_j)\n  \\]\nProbability of an event is the sum of its conditional probabilities across all conditions.\nIn other words: \\(A\\) is some event, \\(B_1, \\ldots, B_n\\) are mutually exclusive events filling entire sample-space, then\n\\[\n  \\Pr(A) = \\Pr(A \\mid B_1)\\Pr(B_1) + \\Pr(A \\mid B_2)\\Pr(B_2) + \\cdots + \\Pr(A \\mid B_n)\\Pr(B_n)\n  \\]\ni.e.¬†Compute the probability by summing over all possible cases.\n\n\nDraw pic on board!",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#example",
    "href": "w03/index.html#example",
    "title": "Week 3: Random Variables",
    "section": "Example",
    "text": "Example\n\nProbability of completing job on time with and without rain: 0.42 and 0.9.\nProbability of rain is 0.45. What is probability job will be completed on time?\n\\(A\\) = job will be completed on time, \\(B\\) = rain\n\n\\[\n\\Pr(B) = 0.45 \\implies \\Pr(B^c) = 1 - \\Pr(B) = 0.55.\n\\]\n\nNote: Events \\(B\\) and \\(B^c\\) are exclusive and form partitions of the sample space \\(S\\)\nWe know \\(\\Pr(A \\mid B) = 0.24\\), \\(\\Pr(A \\mid B^c) = 0.9\\).\nBy the Law of Total Probability, we have\n\n\\[\n\\begin{align*}\n\\Pr(A) &= \\Pr(B)\\Pr(A \\mid B) + \\Pr(B^c)\\Pr(A \\mid B^c) \\\\\n&= 0.45(0.42) + 0.55(0.9) = 0.189 + 0.495 = 0684.\n\\end{align*}\n\\]\nSo, the probability that the job will be completed on time is 0.684. (source)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#deriving-bayes-theorem",
    "href": "w03/index.html#deriving-bayes-theorem",
    "title": "Week 3: Random Variables",
    "section": "Deriving Bayes‚Äô Theorem",
    "text": "Deriving Bayes‚Äô Theorem\n\nLiterally just a re-writing of the conditional probability definition (don‚Äôt be scared)!\n\n\n\n\nFor two events \\(A\\) and \\(B\\), definition of conditional probability says that\n\n\\[\n\\begin{align*}\n\\Pr(A \\mid B) &= \\frac{\\Pr(A \\cap B)}{\\Pr(B)} \\tag{1} \\\\\n\\Pr(B \\mid A) &= \\frac{\\Pr(B \\cap A)}{\\Pr(A)} \\tag{2}\n\\end{align*}\n\\]\n\nMultiply to get rid of fractions\n\n\\[\n\\begin{align*}\n\\Pr(A \\mid B)\\Pr(B) &= \\Pr(A \\cap B) \\tag{1*} \\\\\n\\Pr(B \\mid A)\\Pr(A) &= \\Pr(B \\cap A) \\tag{2*}\n\\end{align*}\n\\]\n\n\nBut set intersection is associative (just like multiplication‚Ä¶), \\(A \\cap B = B \\cap A\\)! So, we know LHS of \\((\\text{1*})\\) = LHS of \\((\\text{2*})\\):\n\n\\[\n\\Pr(A \\mid B)\\Pr(B) = \\Pr(B \\mid A)\\Pr(A)\n\\]\n\nDivide both sides by \\(\\Pr(B)\\) to get a new definition of \\(\\Pr(A \\mid B)\\), Bayes‚Äô Theorem!\n\n\n\n\n\\[\n\\boxed{\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)}}\n\\]\n\n\nFigure¬†5: Bayes‚Äô Theorem",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#why-is-this-helpful",
    "href": "w03/index.html#why-is-this-helpful",
    "title": "Week 3: Random Variables",
    "section": "Why Is This Helpful?",
    "text": "Why Is This Helpful?\n\n\n\n\n\n\nBayes‚Äô Theorem\n\n\n\nFor any two events \\(A\\) and \\(B\\), \\[\n\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)}\n\\]\n\n\n\nIn words (as exciting as I can make it, for now): Bayes‚Äô Theorem allows us to take information about \\(B \\mid A\\) and use it to infer information about \\(A \\mid B\\)\nIt isn‚Äôt until you work through some examples that this becomes mind-blowing, the most powerful equation we have for inferring unknowns from knowns‚Ä¶\nConsider \\(A = \\{\\text{person has disease}\\}\\), \\(B = \\{\\text{person tests positive for disease}\\}\\)\n\nIs \\(A\\) observable on its own? No, but‚Ä¶\n\nIs \\(B\\) observable on its own? Yes, and\nCan we infer info about \\(A\\) from knowing \\(B\\)? Also Yes, thx Bayes!\n\nTherefore, we can use \\(B\\) to infer information about \\(A\\), i.e., calculate \\(\\Pr(A \\mid B)\\)‚Ä¶",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#why-is-this-helpful-for-data-science",
    "href": "w03/index.html#why-is-this-helpful-for-data-science",
    "title": "Week 3: Random Variables",
    "section": "Why Is This Helpful for Data Science?",
    "text": "Why Is This Helpful for Data Science?\n\nIt merges probability theory and hypothesis testing into a single framework:\n\n\\[\n\\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{\\Pr(\\text{data} \\mid \\text{hypothesis})\\Pr(\\text{hypothesis})}{\\Pr(\\text{data})}\n\\]",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#probability-forwards-and-backwards",
    "href": "w03/index.html#probability-forwards-and-backwards",
    "title": "Week 3: Random Variables",
    "section": "Probability Forwards and Backwards",
    "text": "Probability Forwards and Backwards\n\nTwo discrete RVs:\n\nWeather on a given day, \\(W \\in \\{\\textsf{Rain},\\textsf{Sun}\\}\\)\nAction that day, \\(A \\in \\{\\textsf{Go}, \\textsf{Stay}\\}\\): go to party or stay in and watch movie\n\nData-generating process: if \\(\\textsf{Sun}\\), rolls a die \\(R\\) and goes out unless \\(R = 6\\). If \\(\\textsf{Rain}\\), flips a coin and goes out if \\(\\textsf{H}\\).\nProbabilistic Graphical Model (PGM):",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#section",
    "href": "w03/index.html#section",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "So, if we know \\(W = \\textsf{Sun}\\), what is \\(P(A = \\textsf{Go})\\)? \\[\n\\begin{align*}\nP(A = \\textsf{Go} \\mid W) &= 1 - P(R = 6) \\\\\n&= 1 - \\frac{1}{6} = \\frac{5}{6}\n\\end{align*}\n\\]\nConditional probability lets us go forwards (left to right):\n\n\n\n\n\n\n\nBut what if we want to perform inference going backwards?",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#section-1",
    "href": "w03/index.html#section-1",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "If we see Ana at the party, we know \\(A = \\textsf{Go}\\)\nWhat does this tell us about the weather?\nIntuitively, we should increase our degree of belief that \\(W = \\textsf{Sun}\\). But, by how much?\nWe don‚Äôt know \\(P(W \\mid A)\\), only \\(P(A \\mid W)\\)‚Ä¶",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#section-2",
    "href": "w03/index.html#section-2",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "\\[\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) = \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sun})}^{5/6~ ‚úÖ}\\overbrace{P(W = \\textsf{Sun})}^{‚ùì}}{\\underbrace{P(A = \\textsf{Go})}_{‚ùì}}\n\\]\n\nWe‚Äôve seen \\(P(W = \\textsf{Sun})\\) before, it‚Äôs our prior: the probability without having any additional relevant knowledge. So, let‚Äôs say 50/50. \\(P(W = \\textsf{Sun}) = \\frac{1}{2}\\)\nIf we lived in Seattle, we could pick \\(P(W = \\textsf{Sun}) = \\frac{1}{4}\\)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#section-3",
    "href": "w03/index.html#section-3",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "\\[\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) = \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sunny})}^{5/6~ ‚úÖ}\\overbrace{P(W = \\textsf{Sun})}^{1/2~ ‚úÖ}}{\\underbrace{P(A = \\textsf{Go})}_{‚ùì}}\n\\]\n\n\\(P(A = \\textsf{Go})\\) is trickier: the probability that Ana goes out regardless of what the weather is. But there are only two possible weather outcomes! So we just compute\n\n\\[\n\\begin{align*}\n&P(A = \\textsf{Go}) = \\sum_{\\omega \\in S(W)}P(A = \\textsf{Go}, \\omega) = \\sum_{\\omega \\in S(W)}P(A = \\textsf{Go} \\mid \\omega)P(\\omega) \\\\\n&= P(A = \\textsf{Go} \\mid W = \\textsf{Rain})P(W = \\textsf{Rain}) + P(A = \\textsf{Go} \\mid W = \\textsf{Sun})P(W = \\textsf{Sun}) \\\\\n&= \\left( \\frac{1}{2} \\right)\\left( \\frac{1}{2} \\right) + \\left( \\frac{5}{6} \\right)\\left( \\frac{1}{2} \\right) = \\frac{1}{4} + \\frac{5}{12} = \\frac{2}{3}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#putting-it-all-together",
    "href": "w03/index.html#putting-it-all-together",
    "title": "Week 3: Random Variables",
    "section": "Putting it All Together",
    "text": "Putting it All Together\n\\[\n\\begin{align*}\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) &= \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sunny})}^{3/4~ ‚úÖ}\\overbrace{P(W = \\textsf{Sun})}^{1/2~ ‚úÖ}}{\\underbrace{P(A = \\textsf{Go})}_{1/2~ ‚úÖ}} \\\\\n&= \\frac{\\left(\\frac{3}{4}\\right)\\left(\\frac{1}{2}\\right)}{\\frac{1}{2}} = \\frac{\\frac{3}{8}}{\\frac{1}{2}} = \\frac{3}{4}.\n\\end{align*}\n\\]\n\nGiven that we see Ana at the party, we should update our beliefs, so that \\(P(W = \\textsf{Sun}) = \\frac{3}{4}, P(W = \\textsf{Rain}) = \\frac{1}{4}\\).",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#a-scarier-example",
    "href": "w03/index.html#a-scarier-example",
    "title": "Week 3: Random Variables",
    "section": "A Scarier Example",
    "text": "A Scarier Example\n\nBo worries he has a rare disease. He takes a test with 99% accuracy and tests positive. What‚Äôs the probability Bo has the disease? (Intuition: 99%? ‚Ä¶Let‚Äôs do the math!)\n\n\n\n\n\\(H \\in \\{\\textsf{sick}, \\textsf{healthy}\\}, T \\in \\{\\textsf{T}^+, \\textsf{T}^-\\}\\)\nThe test: 99% accurate. \\(\\Pr(T = \\textsf{T}^+ \\mid H = \\textsf{sick}) = 0.99\\), \\(\\Pr(T = \\textsf{T}^- \\mid H = \\textsf{healthy}) = 0.99\\).\nThe disease: 1 in 10K. \\(\\Pr(H = \\textsf{sick}) = \\frac{1}{10000}\\)\nWhat do we want to know? \\(\\Pr(H = \\textsf{sick} \\mid T = \\textsf{T}^+)\\)\nHow do we get there?\n\n\n\n\n\nThis photo, originally thought to be of Thomas Bayes, turns out to be probably someone else‚Ä¶ \\(\\Pr(\\textsf{Bayes})\\)?\n\n\n\n\n\n\\(H\\) for health, \\(T\\) for test result\nPhoto credit: https://thedatascientist.com/wp-content/uploads/2019/04/reverend-thomas-bayes.jpg",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#section-4",
    "href": "w03/index.html#section-4",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "\\[\n\\begin{align*}\n\\Pr(H = \\textsf{sick} \\mid T = \\textsf{T}^+) &= \\frac{\\Pr(T = \\textsf{T}^+ \\mid H = \\textsf{sick})\\Pr(H = \\textsf{sick})}{\\Pr(T = \\textsf{T}^+)} \\\\\n&= \\frac{(0.99)\\left(\\frac{1}{10000}\\right)}{(0.99)\\left( \\frac{1}{10000} \\right) + (0.01)\\left( \\frac{9999}{10000} \\right)}\n\\end{align*}\n\\]\n\np_sick &lt;- 1 / 10000\np_healthy &lt;- 1 - p_sick\np_pos_given_sick &lt;- 0.99\np_neg_given_sick &lt;- 1 - p_pos_given_sick\np_neg_given_healthy &lt;- 0.99\np_pos_given_healthy &lt;- 1 - p_neg_given_healthy\nnumer &lt;- p_pos_given_sick * p_sick\ndenom1 &lt;- numer\ndenom2 &lt;- p_pos_given_healthy * p_healthy\nfinal_prob &lt;- numer / (denom1 + denom2)\nfinal_prob\n\n[1] 0.009803922\n\n\n\n‚Ä¶ Less than 1% üò±",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#proof-in-the-pudding",
    "href": "w03/index.html#proof-in-the-pudding",
    "title": "Week 3: Random Variables",
    "section": "Proof in the Pudding",
    "text": "Proof in the Pudding\n\nLet‚Äôs generate a dataset of 5,000 people, using \\(\\Pr(\\textsf{Disease}) = \\frac{1}{10000}\\)\n\n\n\nCode\nlibrary(tibble)\nlibrary(dplyr)\n# Disease rarity\np_disease &lt;- 1 / 10000\n# 1K people\nnum_people &lt;- 10000\n# Give them ids\nppl_df &lt;- tibble(id=seq(1,num_people))\n# Whether they have the disease or not\nhas_disease &lt;- rbinom(num_people, 1, p_disease)\nppl_df &lt;- ppl_df %&gt;% mutate(has_disease=has_disease)\nppl_df |&gt; head()\n\n\n\n\n\n\nid\nhas_disease\n\n\n\n\n1\n0\n\n\n2\n0\n\n\n3\n0\n\n\n4\n0\n\n\n5\n0\n\n\n6\n0",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#binary-variable-trick",
    "href": "w03/index.html#binary-variable-trick",
    "title": "Week 3: Random Variables",
    "section": "Binary Variable Trick",
    "text": "Binary Variable Trick\n\nSince has_disease \\(\\in \\{0, 1\\}\\), we can use\n\nsum(has_disease) to obtain the count of people with the disease, or\nmean(has_disease) to obtain the proportion of people who have the disease\n\nTo see this (or, if you forget in the future), just make a fake dataset with a binary variable and 3 rows, and think about sums vs.¬†means of that variable:\n\n\n\n\n\nCode\nbinary_df &lt;- tibble(\n  id=c(1,2,3),\n  x=c(0,1,0)\n)\nbinary_df\n\n\n\n\n\n\nid\nx\n\n\n\n\n1\n0\n\n\n2\n1\n\n\n3\n0\n\n\n\n\n\n\n\nTaking the sum tells us: one row where x == 1:\n\n\nCode\nsum(binary_df$x)\n\n\n[1] 1\n\n\nTaking the mean tells us: 1/3 of rows have x == 1:\n\n\nCode\nmean(binary_df$x)\n\n\n[1] 0.3333333",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#applying-this-to-the-disease-data",
    "href": "w03/index.html#applying-this-to-the-disease-data",
    "title": "Week 3: Random Variables",
    "section": "Applying This to the Disease Data",
    "text": "Applying This to the Disease Data\n\nIf we want the number of people who have the disease:\n\n\n\nCode\n# Compute the *number* of people who have the disease\nsum(ppl_df$has_disease)\n\n\n[1] 1\n\n\n\nIf we want the proportion of people who have the disease:\n\n\n\nCode\n# Compute the *proportion* of people who have the disease\nmean(ppl_df$has_disease)\n\n\n[1] 1e-04\n\n\n\n(And if you dislike scientific notation like I do‚Ä¶)\n\n\n\nCode\nformat(mean(ppl_df$has_disease), scientific = FALSE)\n\n\n[1] \"0.0001\"\n\n\n\n(Foreshadowing Monte Carlo methods)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#data-generating-process-test-results",
    "href": "w03/index.html#data-generating-process-test-results",
    "title": "Week 3: Random Variables",
    "section": "Data-Generating Process: Test Results",
    "text": "Data-Generating Process: Test Results\n\n\nCode\nlibrary(dplyr)\n# Data Generating Process\ntake_test &lt;- function(is_sick) {\n  if (is_sick) {\n    return(rbinom(1,1,p_pos_given_sick))\n  } else {\n    return(rbinom(1,1,p_pos_given_healthy))\n  }\n}\nppl_df['test_result'] &lt;- unlist(lapply(ppl_df$has_disease, take_test))\nnum_positive &lt;- sum(ppl_df$test_result)\np_positive &lt;- mean(ppl_df$test_result)\nwriteLines(paste0(num_positive,\" positive tests / \",num_people,\" total = \",p_positive))\n\n\n82 positive tests / 10000 total = 0.0082\n\n\n\n#disp(ppl_df %&gt;% head(50), obs_per_page = 3)\nppl_df |&gt; head()\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n1\n0\n0\n\n\n2\n0\n0\n\n\n3\n0\n0\n\n\n4\n0\n0\n\n\n5\n0\n0\n\n\n6\n0\n0",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#zooming-in-on-positive-tests",
    "href": "w03/index.html#zooming-in-on-positive-tests",
    "title": "Week 3: Random Variables",
    "section": "Zooming In On Positive Tests",
    "text": "Zooming In On Positive Tests\n\n\n\npos_ppl &lt;- ppl_df %&gt;% filter(test_result == 1)\n#disp(pos_ppl, obs_per_page = 10)\npos_ppl |&gt; head()\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n64\n0\n1\n\n\n453\n0\n1\n\n\n747\n0\n1\n\n\n750\n0\n1\n\n\n904\n0\n1\n\n\n1171\n0\n1\n\n\n\n\n\n\n\n\nBo doesn‚Äôt have it, and neither do 110 of the 111 total people who tested positive!\nBut, in the real world, we only observe \\(T\\)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#zooming-in-on-disease-havers",
    "href": "w03/index.html#zooming-in-on-disease-havers",
    "title": "Week 3: Random Variables",
    "section": "Zooming In On Disease-Havers",
    "text": "Zooming In On Disease-Havers\n\nWhat if we look at only those who actually have the disease? Maybe the cost of 111 people panicking is worth it if we correctly catch those who do have it?\n\n\n\nCode\n#disp(ppl_df[ppl_df$has_disease == 1,])\nppl_df[ppl_df$has_disease == 1,]\n\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n1356\n1\n1\n\n\n\n\n\n\nIs this always going to be the case?\n\n\n\n\nNum with disease: 0\nProportion with disease: 0\nNumber of positive tests: 44\n\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n\n\n\n\n\n\n#disp(simulate_disease(5000, 1/10000))\nsimulate_disease(5000, 1/10000)\n\nNum with disease: 0\nProportion with disease: 0\nNumber of positive tests: 50\n\n\n\n\n\n\nid\nhas_disease\ntest_result",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#worst-case-worlds",
    "href": "w03/index.html#worst-case-worlds",
    "title": "Week 3: Random Variables",
    "section": "Worst-Case Worlds",
    "text": "Worst-Case Worlds\n\n\n\nfor (i in seq(1,1000)) {\n  sim_result &lt;- simulate_disease(5000, 1/10000, verbose = FALSE, return_all_detected = FALSE, return_df = FALSE, return_info = TRUE)\n  if (!sim_result$all_detected) {\n    writeLines(paste0(\"World #\",i,\" / 1000 (\",sim_result$num_people,\" people):\"))\n    print(sim_result$df)\n    writeLines('\\n')\n  }\n}\n\nWorld #577 / 1000 (5000 people):\n# A tibble: 2 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  1760           1           0\n2  4997           1           1\n\n\nWorld #621 / 1000 (5000 people):\n# A tibble: 2 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  2916           1           0\n2  3085           1           1\n\n\nWorld #698 / 1000 (5000 people):\n# A tibble: 2 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  3375           1           0\n2  4005           1           1\n\n\nWorld #950 / 1000 (5000 people):\n# A tibble: 1 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  1357           1           0\n\n\nWorld #1000 / 1000 (5000 people):\n# A tibble: 2 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  1674           1           0\n2  2352           1           1\n\nformat(4 / 5000000, scientific = FALSE)\n\n[1] \"0.0000008\"\n\n\n\nHow unlikely is this? Math:\n\\[\n\\begin{align*}\n\\Pr(\\textsf{T}^- \\cap \\textsf{Sick}) &= \\Pr(\\textsf{T}^- \\mid \\textsf{Sick})\\Pr(\\textsf{Sick}) \\\\\n&= (0.01)\\frac{1}{10000} \\\\\n&= \\frac{1}{1000000}\n\\end{align*}\n\\]\nComputers:\n\nresult_df &lt;- simulate_disease(1000000, 1/10000, verbose = FALSE, return_full_df = TRUE)\nfalse_negatives &lt;- result_df[result_df$has_disease == 1 & result_df$test_result == 0,]\nnum_false_negatives &lt;- nrow(false_negatives)\nwriteLines(paste0(\"False Negatives: \",num_false_negatives,\", Total Cases: \", nrow(result_df)))\n\nFalse Negatives: 1, Total Cases: 1000000\n\nfalse_negative_rate &lt;- num_false_negatives / nrow(result_df)\nfalse_negative_rate_decimal &lt;- format(false_negative_rate, scientific = FALSE)\nwriteLines(paste0(\"False Negative Rate: \", false_negative_rate_decimal))\n\nFalse Negative Rate: 0.000001\n\n\n(Perfect match!)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#bayes-takeaway",
    "href": "w03/index.html#bayes-takeaway",
    "title": "Week 3: Random Variables",
    "section": "Bayes: Takeaway",
    "text": "Bayes: Takeaway\n\nBayesian approach allows new evidence to be weighed against existing evidence, with statistically principled way to derive these weights:\n\n\\[\n\\begin{array}{ccccc}\n\\Pr_{\\text{post}}(\\mathcal{H}) &\\hspace{-6mm}\\propto &\\hspace{-6mm} \\Pr(X \\mid \\mathcal{H}) &\\hspace{-6mm} \\times &\\hspace{-6mm} \\Pr_{\\text{pre}}(\\mathcal{H}) \\\\\n\\text{Posterior} &\\hspace{-6mm}\\propto &\\hspace{-6mm}\\text{Evidence} &\\hspace{-6mm} \\times &\\hspace{-6mm} \\text{Prior}\n\\end{array}\n\\]",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#monte-carlo-methods-overview",
    "href": "w03/index.html#monte-carlo-methods-overview",
    "title": "Week 3: Random Variables",
    "section": "Monte Carlo Methods: Overview",
    "text": "Monte Carlo Methods: Overview\n\nYou already saw an example, in our rare disease simulation!\nGenerally, using computers (rather than math, ‚Äúby hand‚Äù) to estimate probabilistic quantities\n\n\n\nPros:\n\nMost real-world processes have no analytic solution\nStep-by-step breakdown of complex processes\n\n\nCons:\n\nCan require immense computing power\n‚ö†Ô∏è Can generate incorrect answers ‚ö†Ô∏è\n\n\n\n\nBy step-by-step I mean, a lot of the time you are just walking through, generating the next column using previously-generated columns. Like we did in the example above, generating test_result based on has_disease.",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#birthday-problem",
    "href": "w03/index.html#birthday-problem",
    "title": "Week 3: Random Variables",
    "section": "Birthday Problem",
    "text": "Birthday Problem\n\n\n\n30 people gather in a room together. What is the probability that two of them share the same birthday?\nAnalytic solution is fun, but requires some thought‚Ä¶ Monte Carlo it!\n\n\n\n\nCode\ngen_bday_room &lt;- function(room_num=NULL) {\n  num_people &lt;- 30\n  num_days &lt;- 366\n  ppl_df &lt;- tibble(id=seq(1,num_people))\nbirthdays &lt;- sample(1:num_days, num_people,replace = T)\n  ppl_df['birthday'] &lt;- birthdays\n  if (!is.null(room_num)) {\n    ppl_df &lt;- ppl_df %&gt;% mutate(room_num=room_num) %&gt;% relocate(room_num)\n  }\n  return(ppl_df)\n}\nppl_df &lt;- gen_bday_room(1)\n#disp(ppl_df %&gt;% head())\nppl_df |&gt; head()\n\n\n\n\n\n\nroom_num\nid\nbirthday\n\n\n\n\n1\n1\n5\n\n\n1\n2\n130\n\n\n1\n3\n61\n\n\n1\n4\n123\n\n\n1\n5\n24\n\n\n1\n6\n263",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#section-5",
    "href": "w03/index.html#section-5",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "# Inefficient version (return_num=FALSE) is for: if you want tibbles of *all* shared bdays for each room\nget_shared_bdays &lt;- function(df, is_grouped=NULL, return_num=FALSE, return_bool=FALSE) {\n  bday_pairs &lt;- tibble()\n  for (i in 1:(nrow(df)-1)) {\n    i_data &lt;- df[i,]\n    i_bday &lt;- i_data$birthday\n    for (j in (i+1):nrow(df)) {\n      j_data &lt;- df[j,]\n      j_bday &lt;- j_data$birthday\n      # Check if they're the same\n      same_bday &lt;- i_bday == j_bday\n      if (same_bday) {\n        if (return_bool) {\n          return(1)\n        }\n        pair_data &lt;- tibble(i=i,j=j,bday=i_bday)\n        if (!is.null(is_grouped)) {\n          i_room &lt;- i_data$room_num\n          pair_data['room'] &lt;- i_room\n        }\n        bday_pairs &lt;- bind_rows(bday_pairs, pair_data)\n      }\n    }\n  }\n  if (return_bool) {\n    return(0)\n  }\n  if (return_num) {\n    return(nrow(bday_pairs))\n  }\n  return(bday_pairs)\n}\n#get_shared_bdays(ppl_df)\nget_shared_bdays(ppl_df)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#section-6",
    "href": "w03/index.html#section-6",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "Let‚Äôs try more rooms‚Ä¶\n\n\n\n# Get tibbles for each room\nlibrary(purrr)\ngen_bday_rooms &lt;- function(num_rooms) {\n  rooms_df &lt;- tibble()\n  for (r in seq(1, num_rooms)) {\n      cur_room &lt;- gen_bday_room(r)\n      rooms_df &lt;- bind_rows(rooms_df, cur_room)\n  }\n  return(rooms_df)\n}\nnum_rooms &lt;- 10\nrooms_df &lt;- gen_bday_rooms(num_rooms)\nrooms_df %&gt;% group_by(room_num) %&gt;% group_map(~ get_shared_bdays(.x, is_grouped=TRUE))\n\n[[1]]\n# A tibble: 3 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     3    26   312\n2    11    23   163\n3    16    29   157\n\n[[2]]\n# A tibble: 2 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     4   269\n2     3    21   361\n\n[[3]]\n# A tibble: 3 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     2     8    77\n2    11    17    33\n3    15    16     6\n\n[[4]]\n# A tibble: 0 √ó 0\n\n[[5]]\n# A tibble: 2 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     4    28   296\n2     5     8   142\n\n[[6]]\n# A tibble: 2 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1    23   193\n2     8    25   319\n\n[[7]]\n# A tibble: 1 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1    20    26    83\n\n[[8]]\n# A tibble: 1 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     8    14   249\n\n[[9]]\n# A tibble: 3 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     4    21   216\n2    10    12   357\n3    13    30    90\n\n[[10]]\n# A tibble: 0 √ó 0\n\n\n\nNumber of shared birthdays per room:\n\n# Now just get the # shared bdays\nshared_per_room &lt;- rooms_df %&gt;%\n    group_by(room_num) %&gt;%\n    group_map(~ get_shared_bdays(.x, is_grouped = TRUE, return_num=TRUE))\nshared_per_room &lt;- unlist(shared_per_room)\nshared_per_room\n\n [1] 3 2 3 0 2 2 1 1 3 0\n\n\n\n\\(\\widehat{\\Pr}(\\text{shared})\\)\n\n\nsum(shared_per_room &gt; 0) / num_rooms\n\n[1] 0.8",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#section-7",
    "href": "w03/index.html#section-7",
    "title": "Week 3: Random Variables",
    "section": "",
    "text": "How about A THOUSAND ROOMS?\n\n\nnum_rooms_many &lt;- 100\nmany_rooms_df &lt;- gen_bday_rooms(num_rooms_many)\nanyshared_per_room &lt;- many_rooms_df %&gt;%\n    group_by(room_num) %&gt;%\n    group_map(~ get_shared_bdays(.x, is_grouped = TRUE, return_bool = TRUE))\nanyshared_per_room &lt;- unlist(anyshared_per_room)\nanyshared_per_room\n\n  [1] 1 0 0 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1\n [38] 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0\n [75] 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0\n\n\n\n\\(\\widehat{\\Pr}(\\text{shared bday})\\)?\n\n\n# And now the probability estimate\nsum(anyshared_per_room &gt; 0) / num_rooms_many\n\n[1] 0.63\n\n\n\nThe analytic solution: \\(\\Pr(\\text{shared} \\mid k\\text{ people in room}) = 1 - \\frac{366!}{366^{k}(366-k)!}\\)\nIn our case: \\(1 - \\frac{366!}{366^{30}(366-30)!} = 1 - \\frac{366!}{366^{30}336!} = 1 - \\frac{\\prod_{i=337}^{366}i}{366^{30}}\\)\nR can juust barely handle these numbers:\n\n\n(exact_solution &lt;- 1 - (prod(seq(337,366))) / (366^30))\n\n[1] 0.7053034",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#wrapping-up",
    "href": "w03/index.html#wrapping-up",
    "title": "Week 3: Random Variables",
    "section": "Wrapping Up",
    "text": "Wrapping Up\n\n\n\n\n\n\n\n\n\n\n\n\nSource: _bday-solutions-plot.ipynb",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#final-note-functions-of-random-variables",
    "href": "w03/index.html#final-note-functions-of-random-variables",
    "title": "Week 3: Random Variables",
    "section": "Final Note: Functions of Random Variables",
    "text": "Final Note: Functions of Random Variables\n\n\\(X \\sim U[0,1], Y \\sim U[0,1]\\).\n\\(P(Y &lt; X^2)\\)?\nThe hard way: solve analytically\nThe easy way: simulate!",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#lab-2-demonstrations",
    "href": "w03/index.html#lab-2-demonstrations",
    "title": "Week 3: Random Variables",
    "section": "Lab 2 Demonstrations",
    "text": "Lab 2 Demonstrations\nLab 2 Demonstrations",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#lab-2-assignment-overview",
    "href": "w03/index.html#lab-2-assignment-overview",
    "title": "Week 3: Random Variables",
    "section": "Lab 2 Assignment Overview",
    "text": "Lab 2 Assignment Overview\nLab 2 Assignment",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#footnotes",
    "href": "w03/index.html#footnotes",
    "title": "Week 3: Random Variables",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThroughout the course, this ‚Äúcalligraphic‚Äù font \\(\\mathcal{N}\\), \\(\\mathcal{D}\\), etc., will be used to denote distributions‚Ü©Ô∏é\nThroughout the course, remember, purrple is for purrameters‚Ü©Ô∏é",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w04/index.html",
    "href": "w04/index.html",
    "title": "Week 4: Discrete Distributions",
    "section": "",
    "text": "Open slides in new window ‚Üí",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#summarizing-what-we-know-so-far",
    "href": "w04/index.html#summarizing-what-we-know-so-far",
    "title": "Week 4: Discrete Distributions",
    "section": "Summarizing What We Know So Far",
    "text": "Summarizing What We Know So Far\n\nLogic \\(\\rightarrow\\) Set Theory \\(\\rightarrow\\) Probability Theory\nEntirety of probability theory can be derived from two axioms:\n\n\n\n\n\n\n\nThe Entirety of Probability Theory Follows From‚Ä¶\n\n\n\nAxiom 1 (Unitarity): \\(\\Pr(\\Omega) = 1\\) (The probability that something happens is 1)\nAxiom 2 (\\(\\sigma\\)-additivity): For mutually-exclusive events \\(E_1, E_2, \\ldots\\),\n\\[\n\\underbrace{\\Pr\\left(\\bigcup_{i=1}^{\\infty}E_i\\right)}_{\\Pr(E_1\\text{ occurs }\\vee E_2\\text{ occurs } \\vee \\cdots)} = \\underbrace{\\sum_{i=1}^{\\infty}\\Pr(E_i)}_{\\Pr(E_1\\text{ occurs}) + \\Pr(E_2\\text{ occurs}) + \\cdots}\n\\]\n\n\n\nBut what does ‚Äúmutually exclusive‚Äù mean‚Ä¶?",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#venn-diagrams-sets",
    "href": "w04/index.html#venn-diagrams-sets",
    "title": "Week 4: Discrete Distributions",
    "section": "Venn Diagrams: Sets",
    "text": "Venn Diagrams: Sets\n\n\n\\[\n\\begin{align*}\n&A = \\{1, 2, 3\\}, \\; B = \\{4, 5, 6\\} \\\\\n&\\implies A \\cap B = \\varnothing\n\\end{align*}\n\\]\n\n\n\nMutually-exclusive (disjoint) sets\n\n\n\n\\[\n\\begin{align*}\n&A = \\{1, 2, 3, 4\\}, \\; B = \\{3, 4, 5, 6\\} \\\\\n&\\implies A \\cap B = \\{3, 4\\}\n\\end{align*}\n\\]\n\n\n\nNon-mutually-exclusive sets",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#venn-diagrams-events-dice",
    "href": "w04/index.html#venn-diagrams-events-dice",
    "title": "Week 4: Discrete Distributions",
    "section": "Venn Diagrams: Events (Dice)",
    "text": "Venn Diagrams: Events (Dice)\n\\[\n\\begin{align*}\nA &= \\{\\text{Roll is even}\\} = \\{2, 4, 6\\} \\\\\nB &= \\{\\text{Roll is odd}\\} = \\{1, 3, 5\\} \\\\\nC &= \\{\\text{Roll is in Fibonnaci sequence}\\} = \\{1, 2, 3, 5\\}\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\n\n\nSet 1\nSet 2\nIntersection\nMutually Exclusive?\nCan Happen Simultaneously?\n\n\n\n\n\\(A\\)\n\\(B\\)\n\\(A \\cap B = \\varnothing\\)\nYes\nNo\n\n\n\\(A\\)\n\\(C\\)\n\\(A \\cap C = \\{2\\}\\)\nNo\nYes\n\n\n\\(B\\)\n\\(C\\)\n\\(B \\cap C = \\{1, 3, 5\\}\\)\nNo\nYes",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#rules-of-probability-1",
    "href": "w04/index.html#rules-of-probability-1",
    "title": "Week 4: Discrete Distributions",
    "section": "‚ÄúRules‚Äù of Probability",
    "text": "‚ÄúRules‚Äù of Probability\n(Remember: not ‚Äúrules‚Äù but ‚Äúfacts resulting from the logic \\(\\leftrightarrow\\) probability connection‚Äù)\n\n\n\n\n\n\n‚ÄúRules‚Äù of Probability\n\n\n\nFor logical predicates \\(p, q \\in \\{T, F\\}\\), events \\(P, Q\\) defined so \\(P\\) = event that \\(p\\) becomes true, \\(Q\\) = event that \\(q\\) becomes true,\n\nLogical AND = Probabilistic Multiplication\n\n\\[\n\\Pr(p \\wedge q) = \\Pr(P \\cap Q) = \\Pr(P) \\cdot \\Pr(Q)\n\\]\n\nLogical OR = Probabilistic Addition\n\n\\[\n\\Pr(p \\vee q) = \\Pr(P \\cup Q) = \\Pr(P) + \\Pr(Q) - \\underbrace{\\Pr(P \\cap Q)}_{\\text{(see rule 1)}}\n\\]\n\nLogical NOT = Probabilistic Complement\n\n\\[\n\\Pr(\\neg p) = \\Pr(P^c) = 1 - \\Pr(P)\n\\]",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#conditional-probability",
    "href": "w04/index.html#conditional-probability",
    "title": "Week 4: Discrete Distributions",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\nUsually if someone asks you probabilistic questions, like\n\n‚ÄúWhat is the likelihood that [our team] wins?‚Äù\n‚ÄúDo you think it will rain tomorrow?‚Äù\n\nYou don‚Äôt guess a random number, you consider and incorporate evidence.\nExample: \\(\\Pr(\\text{rain})\\) on its own, no other info? Tough question‚Ä¶ maybe \\(0.5\\)?\nIn reality, we would think about\n\n\\(\\Pr(\\text{rain} \\mid \\text{month of the year})\\)\n\\(\\Pr(\\text{rain} \\mid \\text{where we live})\\)\n\\(\\Pr(\\text{rain} \\mid \\text{did it rain yesterday?})\\)\n\nPsychologically, breaks down into two steps: (1) Think of baseline probability, (2) Update baseline to incorporate relevant evidence (more on this in a bit‚Ä¶)\nAlso recall: all probability is conditional probability, even if just conditioned on ‚Äúsomething happened‚Äù (\\(\\Omega\\), the thing defined so \\(\\Pr(\\Omega) = 1\\))",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#na√Øve-definition-2.0",
    "href": "w04/index.html#na√Øve-definition-2.0",
    "title": "Week 4: Discrete Distributions",
    "section": "Na√Øve Definition 2.0",
    "text": "Na√Øve Definition 2.0\n\n\n\n\n\n\n[Slightly Less] Na√Øve Definition of Probability\n\n\n\n\\[\n\\Pr(A \\mid B) = \\frac{\\text{\\# of Desired Outcomes in world where }B\\text{ happened}}{\\text{\\# Total outcomes in world where }B\\text{ happened}} = \\frac{|B \\cap A|}{|B|}\n\\]\n\n\n\n\n\n\n\n\n\n\nWorld Name\nWeather in World\nLikelihood of Rain Today\n\n\n\n\n\\(R\\)\nRained for the past 5 days\n\\(\\Pr(\\text{rain} \\mid R) &gt; 0.5\\)\n\n\n\\(M\\)\nMix of rain and non-rain over past 5 days\n\\(\\Pr(\\text{rain} \\mid M) \\approx 0.5\\)\n\n\n\\(S\\)\nSunny for the past 5 days\n\\(\\Pr(\\text{rain} \\mid S) &lt; 0.5\\)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#law-of-total-probability",
    "href": "w04/index.html#law-of-total-probability",
    "title": "Week 4: Discrete Distributions",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\nSuppose the events \\(B_1, \\ldots, B_k\\) form a partition of the space \\(\\Omega\\) and \\(\\Pr(B_j) &gt; 0 \\forall j\\).\nThen, for every event \\(A\\) in \\(\\Omega\\),\n\\[\n  \\Pr(A) = \\sum_{i=1}^k \\Pr(B_j)\\Pr(A \\mid B_j)\n  \\]\nProbability of an event is the sum of its conditional probabilities across all conditions.\nIn other words: \\(A\\) is some event, \\(B_1, \\ldots, B_n\\) are mutually exclusive events filling entire sample-space, then\n\\[\n  \\Pr(A) = \\Pr(A \\mid B_1)\\Pr(B_1) + \\Pr(A \\mid B_2)\\Pr(B_2) + \\cdots + \\Pr(A \\mid B_n)\\Pr(B_n)\n  \\]\ni.e.¬†Compute the probability by summing over all possible cases.\n\n\nDraw pic on board!",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#example",
    "href": "w04/index.html#example",
    "title": "Week 4: Discrete Distributions",
    "section": "Example",
    "text": "Example\n\nProbability of completing job on time with and without rain: 0.42 and 0.9.\nProbability of rain is 0.45. What is probability job will be completed on time?\n\\(A\\) = job will be completed on time, \\(B\\) = rain\n\n\\[\n\\Pr(B) = 0.45 \\implies \\Pr(B^c) = 1 - \\Pr(B) = 0.55.\n\\]\n\nNote: Events \\(B\\) and \\(B^c\\) are exclusive and form partitions of the sample space \\(S\\)\nWe know \\(\\Pr(A \\mid B) = 0.24\\), \\(\\Pr(A \\mid B^c) = 0.9\\).\nBy the Law of Total Probability, we have\n\n\\[\n\\begin{align*}\n\\Pr(A) &= \\Pr(B)\\Pr(A \\mid B) + \\Pr(B^c)\\Pr(A \\mid B^c) \\\\\n&= 0.45(0.42) + 0.55(0.9) = 0.189 + 0.495 = 0684.\n\\end{align*}\n\\]\nSo, the probability that the job will be completed on time is 0.684. (source)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#deriving-bayes-theorem",
    "href": "w04/index.html#deriving-bayes-theorem",
    "title": "Week 4: Discrete Distributions",
    "section": "Deriving Bayes‚Äô Theorem",
    "text": "Deriving Bayes‚Äô Theorem\n\nLiterally just a re-writing of the conditional probability definition (don‚Äôt be scared)!\n\n\n\n\nFor two events \\(A\\) and \\(B\\), definition of conditional probability says that\n\n\\[\n\\begin{align*}\n\\Pr(A \\mid B) &= \\frac{\\Pr(A \\cap B)}{\\Pr(B)} \\tag{1} \\\\\n\\Pr(B \\mid A) &= \\frac{\\Pr(B \\cap A)}{\\Pr(A)} \\tag{2}\n\\end{align*}\n\\]\n\nMultiply to get rid of fractions\n\n\\[\n\\begin{align*}\n\\Pr(A \\mid B)\\Pr(B) &= \\Pr(A \\cap B) \\tag{1*} \\\\\n\\Pr(B \\mid A)\\Pr(A) &= \\Pr(B \\cap A) \\tag{2*}\n\\end{align*}\n\\]\n\n\nBut set intersection is associative (just like multiplication‚Ä¶), \\(A \\cap B = B \\cap A\\)! So, we know LHS of \\((\\text{1*})\\) = LHS of \\((\\text{2*})\\):\n\n\\[\n\\Pr(A \\mid B)\\Pr(B) = \\Pr(B \\mid A)\\Pr(A)\n\\]\n\nDivide both sides by \\(\\Pr(B)\\) to get a new definition of \\(\\Pr(A \\mid B)\\), Bayes‚Äô Theorem!\n\n\n\n\n\\[\n\\boxed{\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)}}\n\\]\n\n\nFigure¬†1: Bayes‚Äô Theorem",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#why-is-this-helpful",
    "href": "w04/index.html#why-is-this-helpful",
    "title": "Week 4: Discrete Distributions",
    "section": "Why Is This Helpful?",
    "text": "Why Is This Helpful?\n\n\n\n\n\n\nBayes‚Äô Theorem\n\n\n\nFor any two events \\(A\\) and \\(B\\), \\[\n\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)}\n\\]\n\n\n\nIn words (as exciting as I can make it, for now): Bayes‚Äô Theorem allows us to take information about \\(B \\mid A\\) and use it to infer information about \\(A \\mid B\\)\nIt isn‚Äôt until you work through some examples that this becomes mind-blowing, the most powerful equation we have for inferring unknowns from knowns‚Ä¶\nConsider \\(A = \\{\\text{person has disease}\\}\\), \\(B = \\{\\text{person tests positive for disease}\\}\\)\n\nIs \\(A\\) observable on its own? No, but‚Ä¶\n\nIs \\(B\\) observable on its own? Yes, and\nCan we infer info about \\(A\\) from knowing \\(B\\)? Also Yes, thx Bayes!\n\nTherefore, we can use \\(B\\) to infer information about \\(A\\), i.e., calculate \\(\\Pr(A \\mid B)\\)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#why-is-this-helpful-for-data-science",
    "href": "w04/index.html#why-is-this-helpful-for-data-science",
    "title": "Week 4: Discrete Distributions",
    "section": "Why Is This Helpful for Data Science?",
    "text": "Why Is This Helpful for Data Science?\n\nIt merges probability theory and hypothesis testing into a single framework:\n\n\\[\n\\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{\\Pr(\\text{data} \\mid \\text{hypothesis})\\Pr(\\text{hypothesis})}{\\Pr(\\text{data})}\n\\]",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#probability-forwards-and-backwards",
    "href": "w04/index.html#probability-forwards-and-backwards",
    "title": "Week 4: Discrete Distributions",
    "section": "Probability Forwards and Backwards",
    "text": "Probability Forwards and Backwards\n\nTwo discrete RVs:\n\nWeather on a given day, \\(W \\in \\{\\textsf{Rain},\\textsf{Sun}\\}\\)\nAction that day, \\(A \\in \\{\\textsf{Go}, \\textsf{Stay}\\}\\): go to party or stay in and watch movie\n\nData-generating process: if \\(\\textsf{Sun}\\), rolls a die \\(R\\) and goes out unless \\(R = 6\\). If \\(\\textsf{Rain}\\), flips a coin and goes out if \\(\\textsf{H}\\).\nProbabilistic Graphical Model (PGM):",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#probability-forwards-and-backwards-1",
    "href": "w04/index.html#probability-forwards-and-backwards-1",
    "title": "Week 4: Discrete Distributions",
    "section": "Probability Forwards and Backwards",
    "text": "Probability Forwards and Backwards\n\nSo, if we know \\(W = \\textsf{Sun}\\), what is \\(P(A = \\textsf{Go})\\)? \\[\n\\begin{align*}\nP(A = \\textsf{Go} \\mid W) &= 1 - P(R = 6) \\\\\n&= 1 - \\frac{1}{6} = \\frac{5}{6}\n\\end{align*}\n\\]\nConditional probability lets us go forwards (left to right):\n\n\n\n\n\n\n\nBut what if we want to perform inference going backwards?",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#probability-forwards-and-backwards-2",
    "href": "w04/index.html#probability-forwards-and-backwards-2",
    "title": "Week 4: Discrete Distributions",
    "section": "Probability Forwards and Backwards",
    "text": "Probability Forwards and Backwards\n\n\n\nIf we see Ana at the party, we know \\(A = \\textsf{Go}\\)\nWhat does this tell us about the weather?\nIntuitively, we should increase our degree of belief that \\(W = \\textsf{Sun}\\). But, by how much?\nWe don‚Äôt know \\(P(W \\mid A)\\), only \\(P(A \\mid W)\\)‚Ä¶",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#probability-forwards-and-backwards-3",
    "href": "w04/index.html#probability-forwards-and-backwards-3",
    "title": "Week 4: Discrete Distributions",
    "section": "Probability Forwards and Backwards",
    "text": "Probability Forwards and Backwards\n\\[\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) = \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sun})}^{5/6~ ‚úÖ}\\overbrace{P(W = \\textsf{Sun})}^{‚ùì}}{\\underbrace{P(A = \\textsf{Go})}_{‚ùì}}\n\\]\n\nWe‚Äôve seen \\(P(W = \\textsf{Sun})\\) before, it‚Äôs our prior: the probability without having any additional relevant knowledge. So, let‚Äôs say 50/50. \\(P(W = \\textsf{Sun}) = \\frac{1}{2}\\)\nIf we lived in Seattle, we could pick \\(P(W = \\textsf{Sun}) = \\frac{1}{4}\\)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#probability-forwards-and-backwards-4",
    "href": "w04/index.html#probability-forwards-and-backwards-4",
    "title": "Week 4: Discrete Distributions",
    "section": "Probability Forwards and Backwards",
    "text": "Probability Forwards and Backwards\n\\[\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) = \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sunny})}^{5/6~ ‚úÖ}\\overbrace{P(W = \\textsf{Sun})}^{1/2~ ‚úÖ}}{\\underbrace{P(A = \\textsf{Go})}_{‚ùì}}\n\\]\n\n\\(P(A = \\textsf{Go})\\) is trickier: the probability that Ana goes out regardless of what the weather is. But there are only two possible weather outcomes! So we just compute\n\n\\[\n\\begin{align*}\n&P(A = \\textsf{Go}) = \\sum_{\\omega \\in S(W)}P(A = \\textsf{Go}, \\omega) = \\sum_{\\omega \\in S(W)}P(A = \\textsf{Go} \\mid \\omega)P(\\omega) \\\\\n&= P(A = \\textsf{Go} \\mid W = \\textsf{Rain})P(W = \\textsf{Rain}) + P(A = \\textsf{Go} \\mid W = \\textsf{Sun})P(W = \\textsf{Sun}) \\\\\n&= \\left( \\frac{1}{2} \\right)\\left( \\frac{1}{2} \\right) + \\left( \\frac{5}{6} \\right)\\left( \\frac{1}{2} \\right) = \\frac{1}{4} + \\frac{5}{12} = \\frac{2}{3}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#putting-it-all-together",
    "href": "w04/index.html#putting-it-all-together",
    "title": "Week 4: Discrete Distributions",
    "section": "Putting it All Together",
    "text": "Putting it All Together\n\\[\n\\begin{align*}\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) &= \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sunny})}^{3/4~ ‚úÖ}\\overbrace{P(W = \\textsf{Sun})}^{1/2~ ‚úÖ}}{\\underbrace{P(A = \\textsf{Go})}_{1/2~ ‚úÖ}} \\\\\n&= \\frac{\\left(\\frac{3}{4}\\right)\\left(\\frac{1}{2}\\right)}{\\frac{1}{2}} = \\frac{\\frac{3}{8}}{\\frac{1}{2}} = \\frac{3}{4}.\n\\end{align*}\n\\]\n\nGiven that we see Ana at the party, we should update our beliefs, so that \\(P(W = \\textsf{Sun}) = \\frac{3}{4}, P(W = \\textsf{Rain}) = \\frac{1}{4}\\).",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#a-scarier-example",
    "href": "w04/index.html#a-scarier-example",
    "title": "Week 4: Discrete Distributions",
    "section": "A Scarier Example",
    "text": "A Scarier Example\n\nBo worries he has a rare disease. He takes a test with 99% accuracy and tests positive. What‚Äôs the probability Bo has the disease? (Intuition: 99%? ‚Ä¶Let‚Äôs do the math!)\n\n\n\n\n\\(H \\in \\{\\textsf{sick}, \\textsf{healthy}\\}, T \\in \\{\\textsf{T}^+, \\textsf{T}^-\\}\\)\nThe test: 99% accurate. \\(\\Pr(T = \\textsf{T}^+ \\mid H = \\textsf{sick}) = 0.99\\), \\(\\Pr(T = \\textsf{T}^- \\mid H = \\textsf{healthy}) = 0.99\\).\nThe disease: 1 in 10K. \\(\\Pr(H = \\textsf{sick}) = \\frac{1}{10000}\\)\nWhat do we want to know? \\(\\Pr(H = \\textsf{sick} \\mid T = \\textsf{T}^+)\\)\nHow do we get there?\n\n\n\n\n\nThis photo, originally thought to be of Thomas Bayes, turns out to be probably someone else‚Ä¶ \\(\\Pr(\\textsf{Bayes})\\)?\n\n\n\n\n\n\\(H\\) for health, \\(T\\) for test result\nPhoto credit: https://thedatascientist.com/wp-content/uploads/2019/04/reverend-thomas-bayes.jpg",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#a-scarier-example-1",
    "href": "w04/index.html#a-scarier-example-1",
    "title": "Week 4: Discrete Distributions",
    "section": "A Scarier Example",
    "text": "A Scarier Example\n\\[\n\\begin{align*}\n\\Pr(H = \\textsf{sick} \\mid T = \\textsf{T}^+) &= \\frac{\\Pr(T = \\textsf{T}^+ \\mid H = \\textsf{sick})\\Pr(H = \\textsf{sick})}{\\Pr(T = \\textsf{T}^+)} \\\\\n&= \\frac{(0.99)\\left(\\frac{1}{10000}\\right)}{(0.99)\\left( \\frac{1}{10000} \\right) + (0.01)\\left( \\frac{9999}{10000} \\right)}\n\\end{align*}\n\\]\n\np_sick &lt;- 1 / 10000\np_healthy &lt;- 1 - p_sick\np_pos_given_sick &lt;- 0.99\np_neg_given_sick &lt;- 1 - p_pos_given_sick\np_neg_given_healthy &lt;- 0.99\np_pos_given_healthy &lt;- 1 - p_neg_given_healthy\nnumer &lt;- p_pos_given_sick * p_sick\ndenom1 &lt;- numer\ndenom2 &lt;- p_pos_given_healthy * p_healthy\nfinal_prob &lt;- numer / (denom1 + denom2)\nfinal_prob\n\n[1] 0.009803922\n\n\n\n‚Ä¶ Less than 1% üò±",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#proof-in-the-pudding",
    "href": "w04/index.html#proof-in-the-pudding",
    "title": "Week 4: Discrete Distributions",
    "section": "Proof in the Pudding",
    "text": "Proof in the Pudding\n\nLet‚Äôs generate a dataset of 5,000 people, using \\(\\Pr(\\textsf{Disease}) = \\frac{1}{10000}\\)\n\n\n\nCode\nlibrary(tibble)\nlibrary(dplyr)\n# Disease rarity\np_disease &lt;- 1 / 10000\n# 1K people\nnum_people &lt;- 10000\n# Give them ids\nppl_df &lt;- tibble(id=seq(1,num_people))\n# Whether they have the disease or not\nhas_disease &lt;- rbinom(num_people, 1, p_disease)\nppl_df &lt;- ppl_df %&gt;% mutate(has_disease=has_disease)\nppl_df |&gt; head()\n\n\n\n\n\n\nid\nhas_disease\n\n\n\n\n1\n0\n\n\n2\n0\n\n\n3\n0\n\n\n4\n0\n\n\n5\n0\n\n\n6\n0",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#binary-variable-trick",
    "href": "w04/index.html#binary-variable-trick",
    "title": "Week 4: Discrete Distributions",
    "section": "Binary Variable Trick",
    "text": "Binary Variable Trick\n\nSince has_disease \\(\\in \\{0, 1\\}\\), we can use\n\nsum(has_disease) to obtain the count of people with the disease, or\nmean(has_disease) to obtain the proportion of people who have the disease\n\nTo see this (or, if you forget in the future), just make a fake dataset with a binary variable and 3 rows, and think about sums vs.¬†means of that variable:\n\n\n\n\n\nCode\nbinary_df &lt;- tibble(\n  id=c(1,2,3),\n  x=c(0,1,0)\n)\nbinary_df\n\n\n\n\n\n\nid\nx\n\n\n\n\n1\n0\n\n\n2\n1\n\n\n3\n0\n\n\n\n\n\n\n\nTaking the sum tells us: one row where x == 1:\n\n\nCode\nsum(binary_df$x)\n\n\n[1] 1\n\n\nTaking the mean tells us: 1/3 of rows have x == 1:\n\n\nCode\nmean(binary_df$x)\n\n\n[1] 0.3333333",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#applying-this-to-the-disease-data",
    "href": "w04/index.html#applying-this-to-the-disease-data",
    "title": "Week 4: Discrete Distributions",
    "section": "Applying This to the Disease Data",
    "text": "Applying This to the Disease Data\n\nIf we want the number of people who have the disease:\n\n\n\nCode\n# Compute the *number* of people who have the disease\nsum(ppl_df$has_disease)\n\n\n[1] 1\n\n\n\nIf we want the proportion of people who have the disease:\n\n\n\nCode\n# Compute the *proportion* of people who have the disease\nmean(ppl_df$has_disease)\n\n\n[1] 1e-04\n\n\n\n(And if you dislike scientific notation like I do‚Ä¶)\n\n\n\nCode\nformat(mean(ppl_df$has_disease), scientific = FALSE)\n\n\n[1] \"0.0001\"\n\n\n\n(Foreshadowing Monte Carlo methods)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#data-generating-process-test-results",
    "href": "w04/index.html#data-generating-process-test-results",
    "title": "Week 4: Discrete Distributions",
    "section": "Data-Generating Process: Test Results",
    "text": "Data-Generating Process: Test Results\n\n\nCode\nlibrary(dplyr)\n# Data Generating Process\ntake_test &lt;- function(is_sick) {\n  if (is_sick) {\n    return(rbinom(1,1,p_pos_given_sick))\n  } else {\n    return(rbinom(1,1,p_pos_given_healthy))\n  }\n}\nppl_df['test_result'] &lt;- unlist(lapply(ppl_df$has_disease, take_test))\nnum_positive &lt;- sum(ppl_df$test_result)\np_positive &lt;- mean(ppl_df$test_result)\nwriteLines(paste0(num_positive,\" positive tests / \",num_people,\" total = \",p_positive))\n\n\n88 positive tests / 10000 total = 0.0088\n\n\n\n#disp(ppl_df %&gt;% head(50), obs_per_page = 3)\nppl_df |&gt; head()\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n1\n0\n0\n\n\n2\n0\n0\n\n\n3\n0\n0\n\n\n4\n0\n0\n\n\n5\n0\n0\n\n\n6\n0\n0",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#zooming-in-on-positive-tests",
    "href": "w04/index.html#zooming-in-on-positive-tests",
    "title": "Week 4: Discrete Distributions",
    "section": "Zooming In On Positive Tests",
    "text": "Zooming In On Positive Tests\n\n\n\npos_ppl &lt;- ppl_df %&gt;% filter(test_result == 1)\n#disp(pos_ppl, obs_per_page = 10)\npos_ppl |&gt; head()\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n121\n0\n1\n\n\n165\n0\n1\n\n\n522\n0\n1\n\n\n596\n0\n1\n\n\n655\n0\n1\n\n\n693\n0\n1\n\n\n\n\n\n\n\n\nBo doesn‚Äôt have it, and neither do 110 of the 111 total people who tested positive!\nBut, in the real world, we only observe \\(T\\)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#zooming-in-on-disease-havers",
    "href": "w04/index.html#zooming-in-on-disease-havers",
    "title": "Week 4: Discrete Distributions",
    "section": "Zooming In On Disease-Havers",
    "text": "Zooming In On Disease-Havers\n\nWhat if we look at only those who actually have the disease? Maybe the cost of 111 people panicking is worth it if we correctly catch those who do have it?\n\n\n\nCode\n#disp(ppl_df[ppl_df$has_disease == 1,])\nppl_df[ppl_df$has_disease == 1,]\n\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n6231\n1\n1\n\n\n\n\n\n\nIs this always going to be the case?\n\n\n\n\nNum with disease: 1\nProportion with disease: 0.0002\nNumber of positive tests: 43\n\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n2836\n1\n1\n\n\n\n\n\n\n\n\n#disp(simulate_disease(5000, 1/10000))\nsimulate_disease(5000, 1/10000)\n\nNum with disease: 0\nProportion with disease: 0\nNumber of positive tests: 55\n\n\n\n\n\n\nid\nhas_disease\ntest_result",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#worst-case-worlds",
    "href": "w04/index.html#worst-case-worlds",
    "title": "Week 4: Discrete Distributions",
    "section": "Worst-Case Worlds",
    "text": "Worst-Case Worlds\n\n\n\nfor (i in seq(1,1000)) {\n  sim_result &lt;- simulate_disease(5000, 1/10000, verbose = FALSE, return_all_detected = FALSE, return_df = FALSE, return_info = TRUE)\n  if (!sim_result$all_detected) {\n    writeLines(paste0(\"World #\",i,\" / 1000 (\",sim_result$num_people,\" people):\"))\n    print(sim_result$df)\n    writeLines('\\n')\n  }\n}\n\nWorld #68 / 1000 (5000 people):\n# A tibble: 1 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  1027           1           0\n\n\nWorld #159 / 1000 (5000 people):\n# A tibble: 1 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  2412           1           0\n\n\nWorld #238 / 1000 (5000 people):\n# A tibble: 1 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  1612           1           0\n\n\nWorld #240 / 1000 (5000 people):\n# A tibble: 1 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  2537           1           0\n\n\nWorld #270 / 1000 (5000 people):\n# A tibble: 1 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  1115           1           0\n\n\nWorld #413 / 1000 (5000 people):\n# A tibble: 1 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  4358           1           0\n\n\nWorld #420 / 1000 (5000 people):\n# A tibble: 2 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1   692           1           1\n2  1545           1           0\n\n\nWorld #496 / 1000 (5000 people):\n# A tibble: 1 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  2049           1           0\n\n\nWorld #608 / 1000 (5000 people):\n# A tibble: 1 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  1322           1           0\n\n\nWorld #842 / 1000 (5000 people):\n# A tibble: 1 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  3077           1           0\n\nformat(4 / 5000000, scientific = FALSE)\n\n[1] \"0.0000008\"\n\n\n\nHow unlikely is this? Math:\n\\[\n\\begin{align*}\n\\Pr(\\textsf{T}^- \\cap \\textsf{Sick}) &= \\Pr(\\textsf{T}^- \\mid \\textsf{Sick})\\Pr(\\textsf{Sick}) \\\\\n&= (0.01)\\frac{1}{10000} \\\\\n&= \\frac{1}{1000000}\n\\end{align*}\n\\]\nComputers:\n\nresult_df &lt;- simulate_disease(1000000, 1/10000, verbose = FALSE, return_full_df = TRUE)\nfalse_negatives &lt;- result_df[result_df$has_disease == 1 & result_df$test_result == 0,]\nnum_false_negatives &lt;- nrow(false_negatives)\nwriteLines(paste0(\"False Negatives: \",num_false_negatives,\", Total Cases: \", nrow(result_df)))\n\nFalse Negatives: 1, Total Cases: 1000000\n\nfalse_negative_rate &lt;- num_false_negatives / nrow(result_df)\nfalse_negative_rate_decimal &lt;- format(false_negative_rate, scientific = FALSE)\nwriteLines(paste0(\"False Negative Rate: \", false_negative_rate_decimal))\n\nFalse Negative Rate: 0.000001\n\n\n(Perfect match!)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#bayes-takeaway",
    "href": "w04/index.html#bayes-takeaway",
    "title": "Week 4: Discrete Distributions",
    "section": "Bayes: Takeaway",
    "text": "Bayes: Takeaway\n\nBayesian approach allows new evidence to be weighed against existing evidence, with statistically principled way to derive these weights:\n\n\\[\n\\begin{array}{ccccc}\n\\Pr_{\\text{post}}(\\mathcal{H}) &\\hspace{-6mm}\\propto &\\hspace{-6mm} \\Pr(X \\mid \\mathcal{H}) &\\hspace{-6mm} \\times &\\hspace{-6mm} \\Pr_{\\text{pre}}(\\mathcal{H}) \\\\\n\\text{Posterior} &\\hspace{-6mm}\\propto &\\hspace{-6mm}\\text{Evidence} &\\hspace{-6mm} \\times &\\hspace{-6mm} \\text{Prior}\n\\end{array}\n\\]",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#monte-carlo-methods-overview",
    "href": "w04/index.html#monte-carlo-methods-overview",
    "title": "Week 4: Discrete Distributions",
    "section": "Monte Carlo Methods: Overview",
    "text": "Monte Carlo Methods: Overview\n\nYou already saw an example, in our rare disease simulation!\nGenerally, using computers (rather than math, ‚Äúby hand‚Äù) to estimate probabilistic quantities\n\n\n\nPros:\n\nMost real-world processes have no analytic solution\nStep-by-step breakdown of complex processes\n\n\nCons:\n\nCan require immense computing power\n‚ö†Ô∏è Can generate incorrect answers ‚ö†Ô∏è\n\n\n\n\nBy step-by-step I mean, a lot of the time you are just walking through, generating the next column using previously-generated columns. Like we did in the example above, generating test_result based on has_disease.",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#birthday-problem",
    "href": "w04/index.html#birthday-problem",
    "title": "Week 4: Discrete Distributions",
    "section": "Birthday Problem",
    "text": "Birthday Problem\n\n\n\n30 people gather in a room together. What is the probability that two of them share the same birthday?\nAnalytic solution is fun, but requires some thought‚Ä¶ Monte Carlo it!\n\n\n\n\nCode\ngen_bday_room &lt;- function(room_num=NULL) {\n  num_people &lt;- 30\n  num_days &lt;- 366\n  ppl_df &lt;- tibble(id=seq(1,num_people))\nbirthdays &lt;- sample(1:num_days, num_people,replace = T)\n  ppl_df['birthday'] &lt;- birthdays\n  if (!is.null(room_num)) {\n    ppl_df &lt;- ppl_df %&gt;% mutate(room_num=room_num) %&gt;% relocate(room_num)\n  }\n  return(ppl_df)\n}\nppl_df &lt;- gen_bday_room(1)\n#disp(ppl_df %&gt;% head())\nppl_df |&gt; head()\n\n\n\n\n\n\nroom_num\nid\nbirthday\n\n\n\n\n1\n1\n268\n\n\n1\n2\n179\n\n\n1\n3\n229\n\n\n1\n4\n365\n\n\n1\n5\n297\n\n\n1\n6\n147",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#birthday-problem-1",
    "href": "w04/index.html#birthday-problem-1",
    "title": "Week 4: Discrete Distributions",
    "section": "Birthday Problem",
    "text": "Birthday Problem\n\n# Inefficient version (return_num=FALSE) is for: if you want tibbles of *all* shared bdays for each room\nget_shared_bdays &lt;- function(df, is_grouped=NULL, return_num=FALSE, return_bool=FALSE) {\n  bday_pairs &lt;- tibble()\n  for (i in 1:(nrow(df)-1)) {\n    i_data &lt;- df[i,]\n    i_bday &lt;- i_data$birthday\n    for (j in (i+1):nrow(df)) {\n      j_data &lt;- df[j,]\n      j_bday &lt;- j_data$birthday\n      # Check if they're the same\n      same_bday &lt;- i_bday == j_bday\n      if (same_bday) {\n        if (return_bool) {\n          return(1)\n        }\n        pair_data &lt;- tibble(i=i,j=j,bday=i_bday)\n        if (!is.null(is_grouped)) {\n          i_room &lt;- i_data$room_num\n          pair_data['room'] &lt;- i_room\n        }\n        bday_pairs &lt;- bind_rows(bday_pairs, pair_data)\n      }\n    }\n  }\n  if (return_bool) {\n    return(0)\n  }\n  if (return_num) {\n    return(nrow(bday_pairs))\n  }\n  return(bday_pairs)\n}\n#get_shared_bdays(ppl_df)\nget_shared_bdays(ppl_df)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#section",
    "href": "w04/index.html#section",
    "title": "Week 4: Discrete Distributions",
    "section": "",
    "text": "Let‚Äôs try more rooms‚Ä¶\n\n\n\n# Get tibbles for each room\nlibrary(purrr)\ngen_bday_rooms &lt;- function(num_rooms) {\n  rooms_df &lt;- tibble()\n  for (r in seq(1, num_rooms)) {\n      cur_room &lt;- gen_bday_room(r)\n      rooms_df &lt;- bind_rows(rooms_df, cur_room)\n  }\n  return(rooms_df)\n}\nnum_rooms &lt;- 10\nrooms_df &lt;- gen_bday_rooms(num_rooms)\nrooms_df %&gt;% group_by(room_num) %&gt;% group_map(~ get_shared_bdays(.x, is_grouped=TRUE))\n\n[[1]]\n# A tibble: 4 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     6    14   324\n2     6    27   324\n3    11    16   300\n4    14    27   324\n\n[[2]]\n# A tibble: 1 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     2     9   167\n\n[[3]]\n# A tibble: 0 √ó 0\n\n[[4]]\n# A tibble: 1 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     5     6   145\n\n[[5]]\n# A tibble: 2 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     5    24    50\n2    10    19   366\n\n[[6]]\n# A tibble: 0 √ó 0\n\n[[7]]\n# A tibble: 0 √ó 0\n\n[[8]]\n# A tibble: 1 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1    22    28   363\n\n[[9]]\n# A tibble: 1 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1    13    19   356\n\n[[10]]\n# A tibble: 0 √ó 0\n\n\n\nNumber of shared birthdays per room:\n\n# Now just get the # shared bdays\nshared_per_room &lt;- rooms_df %&gt;%\n    group_by(room_num) %&gt;%\n    group_map(~ get_shared_bdays(.x, is_grouped = TRUE, return_num=TRUE))\nshared_per_room &lt;- unlist(shared_per_room)\nshared_per_room\n\n [1] 4 1 0 1 2 0 0 1 1 0\n\n\n\n\\(\\widehat{\\Pr}(\\text{shared})\\)\n\n\nsum(shared_per_room &gt; 0) / num_rooms\n\n[1] 0.6",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#section-1",
    "href": "w04/index.html#section-1",
    "title": "Week 4: Discrete Distributions",
    "section": "",
    "text": "How about A THOUSAND ROOMS?\n\n\nnum_rooms_many &lt;- 100\nmany_rooms_df &lt;- gen_bday_rooms(num_rooms_many)\nanyshared_per_room &lt;- many_rooms_df %&gt;%\n    group_by(room_num) %&gt;%\n    group_map(~ get_shared_bdays(.x, is_grouped = TRUE, return_bool = TRUE))\nanyshared_per_room &lt;- unlist(anyshared_per_room)\nanyshared_per_room\n\n  [1] 0 0 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1\n [38] 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 0 1 0 0 1\n [75] 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1\n\n\n\n\\(\\widehat{\\Pr}(\\text{shared bday})\\)?\n\n\n# And now the probability estimate\nsum(anyshared_per_room &gt; 0) / num_rooms_many\n\n[1] 0.68\n\n\n\nThe analytic solution: \\(\\Pr(\\text{shared} \\mid k\\text{ people in room}) = 1 - \\frac{366!}{366^{k}(366-k)!}\\)\nIn our case: \\(1 - \\frac{366!}{366^{30}(366-30)!} = 1 - \\frac{366!}{366^{30}336!} = 1 - \\frac{\\prod_{i=337}^{366}i}{366^{30}}\\)\nR can juust barely handle these numbers:\n\n\n(exact_solution &lt;- 1 - (prod(seq(337,366))) / (366^30))\n\n[1] 0.7053034",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#wrapping-up",
    "href": "w04/index.html#wrapping-up",
    "title": "Week 4: Discrete Distributions",
    "section": "Wrapping Up",
    "text": "Wrapping Up\n\n\n\n\n\n\n\n\n\n\n\n\nSource: _bday-solutions-plot.ipynb",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#final-note-functions-of-random-variables",
    "href": "w04/index.html#final-note-functions-of-random-variables",
    "title": "Week 4: Discrete Distributions",
    "section": "Final Note: Functions of Random Variables",
    "text": "Final Note: Functions of Random Variables\n\n\\(X \\sim U[0,1], Y \\sim U[0,1]\\).\n\\(P(Y &lt; X^2)\\)?\nThe hard way: solve analytically\nThe easy way: simulate!",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#discrete-vs.-continuous",
    "href": "w04/index.html#discrete-vs.-continuous",
    "title": "Week 4: Discrete Distributions",
    "section": "Discrete vs.¬†Continuous",
    "text": "Discrete vs.¬†Continuous\n\n\n\nDiscrete = ‚ÄúEasy mode‚Äù: Based (intuitively) on sets\n\\(\\Pr(A)\\): Four marbles \\(\\{A, B, C, D\\}\\) in box, all equally likely, what is the probability I pull out \\(A\\)?\n\n\nlibrary(tibble)\nlibrary(ggplot2)\ndisc_df &lt;- tribble(\n  ~x, ~y, ~label,\n  0, 0, \"A\",\n  0, 1, \"B\",\n  1, 0, \"C\",\n  1, 1, \"D\"\n)\nggplot(disc_df, aes(x=x, y=y, label=label)) +\n    geom_point(size=g_pointsize) +\n    geom_text(\n      size=g_textsize,\n      hjust=1.5,\n      vjust=-0.5\n    ) +\n    xlim(-0.5,1.5) + ylim(-0.5,1.5) +\n    coord_fixed() +\n    dsan_theme(\"quarter\") +\n    labs(\n      title=\"Discrete Probability Space in N\"\n    )\n\n\n\n\n\n\n\n\n\\[\n\\Pr(A) = \\underbrace{\\frac{|\\{A\\}|}{|\\Omega|}}_{\\mathclap{\\small \\text{Probability }\\textbf{mass}}} = \\frac{1}{|\\{A,B,C,D\\}|} = \\frac{1}{4}\n\\]\n\n\nContinuous = ‚ÄúHard mode‚Äù: Based (intuitively) on areas\n\\(\\Pr(A)\\): If I throw a dart at this square, what is the probability that I hit region \\(A\\)?\n\n\nlibrary(ggforce)\nggplot(disc_df, aes(x=x, y=y, label=label)) +\n    xlim(-0.5,1.5) + ylim(-0.5,1.5) +\n    geom_rect(aes(xmin = -0.5, xmax = 1.5, ymin = -0.5, ymax = 1.5), fill=cbPalette[1], color=\"black\", alpha=0.3) +\n    geom_circle(aes(x0=x, y0=y, r=0.25), fill=cbPalette[2]) +\n    coord_fixed() +\n    dsan_theme(\"quarter\") +\n    geom_text(\n      size=g_textsize,\n      #hjust=1.75,\n      #vjust=-0.75\n    ) +\n    geom_text(\n      data=data.frame(label=\"Œ©\"),\n      aes(x=-0.4,y=1.39),\n      parse=TRUE,\n      size=g_textsize\n    ) +\n    labs(\n      title=expression(\"Continuous Probability Space in \"*R^2)\n    )\n\n\n\n\n\n\n\n\n\\[\n\\Pr(A) = \\underbrace{\\frac{\\text{Area}(\\{A\\})}{\\text{Area}(\\Omega)}}_{\\mathclap{\\small \\text{Probability }\\textbf{density}}} = \\frac{\\pi r^2}{s^2} = \\frac{\\pi \\left(\\frac{1}{4}\\right)^2}{4} = \\frac{\\pi}{64}\n\\]",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#the-technical-difference-tldr",
    "href": "w04/index.html#the-technical-difference-tldr",
    "title": "Week 4: Discrete Distributions",
    "section": "The Technical Difference tl;dr",
    "text": "The Technical Difference tl;dr\n\nCountable Sets: Can be put into 1-to-1 correspondence with the natural numbers \\(\\mathbb{N}\\)\n\nWhat are you doing when you‚Äôre counting? Saying ‚Äúfirst‚Äù, ‚Äúsecond‚Äù, ‚Äúthird‚Äù, ‚Ä¶\nYou‚Äôre pairing each object with a natural number! \\(\\{(\\texttt{a},1),(\\texttt{b},2),\\ldots,(\\texttt{z},26)\\}\\) \n\nUncountable Sets: Cannot be put into 1-to-1 correspondence with the natural numbers.\n\n\\(\\mathbb{R}\\) is uncountable. Intuition: Try counting the real numbers. Proof1 \\[\n\\text{Assume }\\exists (f: \\mathbb{R} \\leftrightarrow \\mathbb{N}) =\n\\begin{array}{|c|c|c|c|c|c|c|}\\hline\n\\mathbb{R} & & & & & & \\Leftrightarrow \\mathbb{N} \\\\ \\hline\n\\color{orange}{3} & . & 1 & 4 & 1 & \\cdots & \\Leftrightarrow 1 \\\\\\hline\n4 & . & \\color{orange}{9} & 9 & 9 & \\cdots & \\Leftrightarrow 2 \\\\\\hline\n0 & . & 1 & \\color{orange}{2} & 3 & \\cdots &\\Leftrightarrow 3 \\\\\\hline\n1 & . & 2 & 3 & \\color{orange}{4} & \\cdots & \\Leftrightarrow 4 \\\\\\hline\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\\hline\n\\end{array} \\overset{\\color{blue}{y_{[i]}} = \\color{orange}{x_{[i]}} \\overset{\\mathbb{Z}_{10}}{+} 1}{\\longrightarrow} \\color{blue}{y = 4.035 \\ldots} \\Leftrightarrow \\; ?\n\\]\n\n\n\n\nFun math challenge: Is \\(\\mathbb{Q}\\) countable? See this appendix slide for why the answer is yes, despite the fact that \\(\\forall x, y \\in \\mathbb{Q} \\left[ \\frac{x+y}{2} \\in \\mathbb{Q} \\right]\\)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#the-practical-difference",
    "href": "w04/index.html#the-practical-difference",
    "title": "Week 4: Discrete Distributions",
    "section": "The Practical Difference",
    "text": "The Practical Difference\n\nThis part of the course (discrete probability): \\(\\Pr(X = v), v \\in \\mathcal{R}_X \\subseteq \\mathbb{N}\\)\n\nExample: \\(\\Pr(\\)\\() = \\Pr(X = 3), 3 \\in \\{1,2,3,4,5,6\\} \\subseteq \\mathbb{N}\\)\n\nNext part of the course (continuous probability): \\(\\Pr(X \\in V), v \\subseteq \\mathbb{R}\\)\n\nExample: \\(\\Pr(X \\geq 2\\pi) = \\Pr(X \\in [\\pi,\\infty)), [\\pi,\\infty) \\subseteq \\mathbb{R}\\)\n\nWhy do they have to be in separate parts?\n\n\\[\n\\Pr(X = 2\\pi) = \\frac{\\text{Area}(\\overbrace{2\\pi}^{\\mathclap{\\small \\text{Single point}}})}{\\text{Area}(\\underbrace{\\mathbb{R}}_{\\mathclap{\\small \\text{(Uncountably) Infinite set of points}}})} = 0\n\\]",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#probability-mass-vs.-probability-density",
    "href": "w04/index.html#probability-mass-vs.-probability-density",
    "title": "Week 4: Discrete Distributions",
    "section": "Probability Mass vs.¬†Probability Density",
    "text": "Probability Mass vs.¬†Probability Density\n\nCumulative Distribution Function (CDF): \\(F_X(v) = \\Pr(X \\leq v)\\)\nFor discrete RV \\(X\\), Probability Mass Function (pmf) \\(p_X(v)\\): \\[\n\\begin{align*}\np_X(v) &= \\Pr(X = v) = F_X(v) - F_X(v-1) \\\\\n\\implies F_X(v) &= \\sum_{\\{w \\in \\mathcal{R}_X: \\; w \\leq v\\}}p_X(w)\n\\end{align*}\n\\]\nFor continuous RV \\(X\\) (\\(\\mathcal{R}_X \\subseteq \\mathbb{R}\\)), Probability Density Function (pdf) \\(f_X(v)\\): \\[\n\\begin{align*}\nf_X(v) &= \\frac{d}{dx}F_X(v) \\\\\n\\implies F_X(v) &= \\int_{-\\infty}^v f_X(w)dw\n\\end{align*}\n\\]\n\n\n\nFrustratingly, the CDF/pmf/pdf is usually written using \\(X\\) and \\(x\\), like \\(F_X(x) = \\Pr(X \\leq x)\\). To me this is extremely confusing, since the capitalized \\(X\\) is a random variable (not a number) while the lowercase \\(x\\) is some particular value, like \\(3\\). So, to emphasize this difference, I use \\(X\\) for the RV and \\(v\\) for the value at which we‚Äôre checking the CDF/pmf/pdf.\nAlso note the capitalized CDF but lowercase pmf/pdf, matching the mathematical notation where \\(f_X(v)\\) is the derivative of \\(F_X(v)\\).",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#probability-density-neq-probability",
    "href": "w04/index.html#probability-density-neq-probability",
    "title": "Week 4: Discrete Distributions",
    "section": "Probability Density \\(\\neq\\) Probability",
    "text": "Probability Density \\(\\neq\\) Probability\n\nBEWARE: \\(f_X(v) \\neq \\Pr(X = v)\\)!\nLong story short, for continuous variables, \\(\\Pr(X = v) = 0\\)2\nHence, we instead construct a PDF \\(f_X(v)\\) that enables us to calculate \\(\\Pr(X \\in [a,b])\\) by integrating: \\(f_X(v)\\) is whatever function satisfies \\(\\Pr(X \\in [a,b]) = \\int_{a}^bf_X(v)dv\\).\ni.e., instead of \\(p_X(v) = \\Pr(X = v)\\) from discrete world, the relevant function here is \\(f_X(v)\\), the probability density of \\(X\\) at \\(v\\).\nIf we really want to get something like the ‚Äúprobability of a value‚Äù in a continuous space üò™, we can get something kind of like this by using fancy limits \\[\nf_X(v) = \\lim_{\\varepsilon \\to 0}\\frac{P(X \\in [v-\\varepsilon, v + \\varepsilon])}{2\\varepsilon} = \\lim_{\\varepsilon \\to 0}\\frac{F(v + \\varepsilon) - F(v - \\varepsilon)}{2\\varepsilon} = \\frac{d}{dx}F_X(v)\n\\]",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#bernoulli-distribution",
    "href": "w04/index.html#bernoulli-distribution",
    "title": "Week 4: Discrete Distributions",
    "section": "Bernoulli Distribution",
    "text": "Bernoulli Distribution\n\nSingle trial with two outcomes, ‚Äúsuccess‚Äù (1) or ‚Äúfailure‚Äù (0): basic model of a coin flip (heads = 1, tails = 0)\n\\(X \\sim \\text{Bern}({\\color{purple} p}) \\implies \\mathcal{R}_X = \\{0,1\\}, \\; \\Pr(X = 1) = {\\color{purple}p}\\).\n\n\nlibrary(ggplot2)\nlibrary(tibble)\nbern_tibble &lt;- tribble(\n  ~Outcome, ~Probability, ~Color,\n  \"Failure\", 0.2, cbPalette[1],\n  \"Success\", 0.8, cbPalette[2]\n)\nggplot(data = bern_tibble, aes(x=Outcome, y=Probability)) +\n  geom_bar(aes(fill=Outcome), stat = \"identity\") +\n  dsan_theme(\"half\") +\n  labs(\n    y = \"Probability Mass\"\n  ) +\n  scale_fill_manual(values=c(cbPalette[1], cbPalette[2])) +\n  remove_legend()",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#binomial-distribution",
    "href": "w04/index.html#binomial-distribution",
    "title": "Week 4: Discrete Distributions",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nNumber of successes in \\({\\color{purple}N}\\) Bernoulli trials. \\(X \\sim \\text{Binom}({\\color{purple}N},{\\color{purple}k},{\\color{purple}p}) \\implies \\mathcal{R}_X = \\{0, 1, \\ldots, N\\}\\)\n\n\\(P(X = k)  = \\binom{N}{k}p^k(1-p)^{N-k}\\): probability of \\(k\\) successes out of \\(N\\) trials.\n\\(\\binom{N}{k} = \\frac{N!}{k!(N-k)!}\\): ‚ÄúBinomial coefficient‚Äù. How many groups of size \\(k\\) can be formed?3",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#visualizing-the-binomial",
    "href": "w04/index.html#visualizing-the-binomial",
    "title": "Week 4: Discrete Distributions",
    "section": "Visualizing the Binomial",
    "text": "Visualizing the Binomial\n\n\nCode\nk &lt;- seq(0, 10)\nprob &lt;- dbinom(k, 10, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x=k, y=prob)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title=\"Binomial Distribution, N = 10, p = 0.5\",\n    y=\"Probability Mass\"\n  ) +\n  scale_x_continuous(breaks=seq(0,10)) +\n  dsan_theme(\"half\")\n\n\n\n\n\n\n\n\n\n\nSo who can tell me, from this plot, the approximate probability of getting 4 heads when flipping a coin 10 times?",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#multiple-classes-multinomial-distribution",
    "href": "w04/index.html#multiple-classes-multinomial-distribution",
    "title": "Week 4: Discrete Distributions",
    "section": "Multiple Classes: Multinomial Distribution",
    "text": "Multiple Classes: Multinomial Distribution\n\nBernoulli only allows two outcomes: success or failure.\nWhat if we‚Äôre predicting soccer match outcomes?\n\n\\(X_i \\in \\{\\text{Win}, \\text{Loss}, \\text{Draw}\\}\\)\n\nCategorical Distribution: Generalization of Bernoulli to \\(k\\) outcomes. \\(X \\sim \\text{Categorical}(\\mathbf{p} = \\{p_1, p_2, \\ldots, p_k\\}), \\sum_{i=1}^kp_i = 1\\).\n\n\\(P(X = k) = p_k\\)\n\nMultinomial Distribution: Generalization of Binomial to \\(k\\) outcomes.\n\\(\\mathbf{X} \\sim \\text{Multinom}(N,k,\\mathbf{p}=\\{p_1,p_2,\\ldots,p_k\\}), \\sum_{i=1}^kp_i=1\\)\n\n\\(P(\\mathbf{X} = \\{x_1,x_2\\ldots,x_k\\}) = \\frac{N!}{x_1!x_2!\\cdots x_k!}p_1^{x_1}p_2^{x_2}\\cdots p_k^{x_k}\\)\n\\(P(\\text{30 wins}, \\text{4 losses}, \\text{4 draws}) = \\frac{38!}{30!4!4!}p_{\\text{win}}^{30}p_{\\text{lose}}^4p_{\\text{draw}}^4\\).",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#geometric-distribution",
    "href": "w04/index.html#geometric-distribution",
    "title": "Week 4: Discrete Distributions",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nGeometric: Likelihood that we need \\({\\color{purple}k}\\) trials to get our first success. \\(X \\sim \\text{Geom}({\\color{purple}k},{\\color{purple}p}) \\implies \\mathcal{R}_X = \\{0, 1, \\ldots\\}\\)\n\n\\(P(X = k) = \\underbrace{(1-p)^{k-1}}_{\\small k - 1\\text{ failures}}\\cdot \\underbrace{p}_{\\mathclap{\\small \\text{success}}}\\)\nProbability of \\(k-1\\) failures followed by a success\n\n\n\nlibrary(ggplot2)\nk &lt;- seq(0, 8)\nprob &lt;- dgeom(k, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x = k, y = prob)) +\n    geom_bar(stat = \"identity\", fill = cbPalette[1]) +\n    labs(\n        title = \"Geometric Distribution, p = 0.5\",\n        y = \"Probability Mass\"\n    ) +\n    scale_x_continuous(breaks = seq(0, 8)) +\n    dsan_theme(\"half\")",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#less-common-but-important-distributions",
    "href": "w04/index.html#less-common-but-important-distributions",
    "title": "Week 4: Discrete Distributions",
    "section": "Less Common (But Important) Distributions",
    "text": "Less Common (But Important) Distributions\n\nDiscrete Uniform: \\(N\\) equally-likely outcomes\n\n\\(X \\sim U\\{{\\color{purple}a},{\\color{purple}b}\\} \\implies \\mathcal{R}_X = \\{a, a+1, \\ldots, b\\}, P(X = k) = \\frac{1}{{\\color{purple}b} - {\\color{purple}a} + 1}\\)\n\nBeta: \\(X \\sim \\text{Beta}({\\color{purple}\\alpha}, {\\color{purple}\\beta})\\): conjugate prior for Bernoulli, Binomial, and Geometric dists.\n\nIntuition: If we use Beta to encode our prior hypothesis, then observe data drawn from Binomial, distribution of our updated hypothesis is still Beta.\n\\(\\underbrace{\\Pr(\\text{biased}) = \\Pr(\\text{unbiased})}_{\\text{Prior: }\\text{Beta}({\\color{purple}\\alpha}, {\\color{purple}\\beta})} \\rightarrow\\) Observe \\(\\underbrace{\\frac{8}{10}\\text{ heads}}_{\\text{Data}} \\rightarrow \\underbrace{\\Pr(\\text{biased}) = 0.65}_{\\text{Posterior: }\\text{Beta}({\\color{purple}\\alpha + 8}, {\\color{purple}\\beta + 2})}\\)\n\nDirichlet: \\(\\mathbf{X} = (X_1, X_2, \\ldots, X_K) \\sim \\text{Dir}({\\color{purple} \\boldsymbol\\alpha})\\)\n\n\\(K\\)-dimensional extension of Beta (thus, conjugate prior for Multinomial)\n\n\n\n\nWe can now use \\(\\text{Beta}(\\alpha + 8, \\beta + 2)\\) as a prior for our next set of trials (encoding our knowledge up to that point), and update further once we know the results (to yet another Beta distribution).",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#interactive-visualizations",
    "href": "w04/index.html#interactive-visualizations",
    "title": "Week 4: Discrete Distributions",
    "section": "Interactive Visualizations!",
    "text": "Interactive Visualizations!\nSeeing Theory, Brown University",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#appendix-countability-of-mathbbq",
    "href": "w04/index.html#appendix-countability-of-mathbbq",
    "title": "Week 4: Discrete Distributions",
    "section": "Appendix: Countability of \\(\\mathbb{Q}\\)",
    "text": "Appendix: Countability of \\(\\mathbb{Q}\\)\n\nBad definition: ‚Äú\\(\\mathbb{N}\\) is countable because no \\(x \\in \\mathbb{N}\\) between \\(0\\) and \\(1\\). \\(\\mathbb{R}\\) is uncountable because infinitely-many \\(x \\in \\mathbb{R}\\) between \\(0\\) and \\(1\\).‚Äù (\\(\\implies \\mathbb{Q}\\) uncountable)\nAnd yet, \\(\\mathbb{Q}\\) is countable‚Ä¶\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\begin{array}{ll}\ns: \\mathbb{N} \\leftrightarrow \\mathbb{Z} & s(n) = (-1)^n \\left\\lfloor \\frac{n+1}{2} \\right\\rfloor \\\\\nh_+: \\mathbb{Z}^+ \\leftrightarrow \\mathbb{Q}^+ & p_1^{a_1}p_2^{a_2}\\cdots \\mapsto p_1^{s(a_1)}p_2^{s(a_2)}\\cdots \\\\\nh: \\mathbb{Z} \\leftrightarrow \\mathbb{Q} & h(n) = \\begin{cases}h_+(n) &n &gt; 0 \\\\ 0 & n = 0 \\\\\n-h_+(-n) & n &lt; 0\\end{cases} \\\\\n(h \\circ s): \\mathbb{N} \\leftrightarrow \\mathbb{Q} & ‚úÖü§Ø\n\\end{array}\n\\end{align*}\n\\]\n\n\n\n\n\n\nImage credit: Rebecca J. Stones, Math StackExchange. Math credit: Thomas Andrews, Math StackExchange",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#footnotes",
    "href": "w04/index.html#footnotes",
    "title": "Week 4: Discrete Distributions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe method used in this proof, if you haven‚Äôt seen it before, is called Cantor diagonalization, and it is extremely fun and applicable to a wide variety of levels-of-infinity proofs‚Ü©Ô∏é\nFor intuition: \\(X \\sim U[0,10] \\implies \\Pr(X = \\pi) = \\frac{|\\{v \\in \\mathbb{R}:\\; v = \\pi\\}|}{|\\mathbb{R}|} = \\frac{1}{2^{\\aleph_0}} \\approx 0\\). That is, finding the \\(\\pi\\) needle in the \\(\\mathbb{R}\\) haystack is a one-in-\\(\\left(\\infty^\\infty\\right)\\) event. A similar issue occurs if \\(S\\) is countably-infinite, like \\(S = \\mathbb{N}\\): \\(\\Pr(X = 3) = \\frac{|\\{x \\in \\mathbb{N} : \\; x = 3\\}|}{|\\mathbb{N}|} = \\frac{1}{\\aleph_0}\\).‚Ü©Ô∏é\nA fun way to never have to memorize or compute these: imagine a pyramid like \\(\\genfrac{}{}{0pt}{}{}{\\boxed{\\phantom{1}}}\\genfrac{}{}{0pt}{}{\\boxed{\\phantom{1}}}{}\\genfrac{}{}{0pt}{}{}{\\boxed{\\phantom{1}}}\\), where the boxes are slots for numbers, and put a \\(1\\) in the box at the top. In the bottom row, fill each slot with the sum of the two numbers above-left and above-right of it. Since \\(1 + \\text{(nothing)} = 1\\), this looks like: \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\). Continue filling in the pyramid this way, so the next row looks like \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{2}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\), then \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{3}\\genfrac{}{}{0pt}{}{2}{}\\genfrac{}{}{0pt}{}{}{3}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\), and so on. The \\(k\\)th number in the \\(N\\)th row (counting from \\(0\\)) is \\(\\binom{N}{k}\\). For the triangle written out to the 7th row, see Appendix I at end of slideshow.‚Ü©Ô∏é",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/slides.html#summarizing-what-we-know-so-far",
    "href": "w04/slides.html#summarizing-what-we-know-so-far",
    "title": "Week 4: Discrete Distributions",
    "section": "Summarizing What We Know So Far",
    "text": "Summarizing What We Know So Far\n\nLogic \\(\\rightarrow\\) Set Theory \\(\\rightarrow\\) Probability Theory\nEntirety of probability theory can be derived from two axioms:\n\n\n\n\n\nThe Entirety of Probability Theory Follows From‚Ä¶\n\n\nAxiom 1 (Unitarity): \\(\\Pr(\\Omega) = 1\\) (The probability that something happens is 1)\nAxiom 2 (\\(\\sigma\\)-additivity): For mutually-exclusive events \\(E_1, E_2, \\ldots\\),\n\\[\n\\underbrace{\\Pr\\left(\\bigcup_{i=1}^{\\infty}E_i\\right)}_{\\Pr(E_1\\text{ occurs }\\vee E_2\\text{ occurs } \\vee \\cdots)} = \\underbrace{\\sum_{i=1}^{\\infty}\\Pr(E_i)}_{\\Pr(E_1\\text{ occurs}) + \\Pr(E_2\\text{ occurs}) + \\cdots}\n\\]\n\n\n\n\n\nBut what does ‚Äúmutually exclusive‚Äù mean‚Ä¶?"
  },
  {
    "objectID": "w04/slides.html#venn-diagrams-sets",
    "href": "w04/slides.html#venn-diagrams-sets",
    "title": "Week 4: Discrete Distributions",
    "section": "Venn Diagrams: Sets",
    "text": "Venn Diagrams: Sets\n\n\n\\[\n\\begin{align*}\n&A = \\{1, 2, 3\\}, \\; B = \\{4, 5, 6\\} \\\\\n&\\implies A \\cap B = \\varnothing\n\\end{align*}\n\\]\n\n\n\nMutually-exclusive (disjoint) sets\n\n\n\n\\[\n\\begin{align*}\n&A = \\{1, 2, 3, 4\\}, \\; B = \\{3, 4, 5, 6\\} \\\\\n&\\implies A \\cap B = \\{3, 4\\}\n\\end{align*}\n\\]\n\n\n\nNon-mutually-exclusive sets"
  },
  {
    "objectID": "w04/slides.html#venn-diagrams-events-dice",
    "href": "w04/slides.html#venn-diagrams-events-dice",
    "title": "Week 4: Discrete Distributions",
    "section": "Venn Diagrams: Events (Dice)",
    "text": "Venn Diagrams: Events (Dice)\n\\[\n\\begin{align*}\nA &= \\{\\text{Roll is even}\\} = \\{2, 4, 6\\} \\\\\nB &= \\{\\text{Roll is odd}\\} = \\{1, 3, 5\\} \\\\\nC &= \\{\\text{Roll is in Fibonnaci sequence}\\} = \\{1, 2, 3, 5\\}\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\n\n\nSet 1\nSet 2\nIntersection\nMutually Exclusive?\nCan Happen Simultaneously?\n\n\n\n\n\\(A\\)\n\\(B\\)\n\\(A \\cap B = \\varnothing\\)\nYes\nNo\n\n\n\\(A\\)\n\\(C\\)\n\\(A \\cap C = \\{2\\}\\)\nNo\nYes\n\n\n\\(B\\)\n\\(C\\)\n\\(B \\cap C = \\{1, 3, 5\\}\\)\nNo\nYes"
  },
  {
    "objectID": "w04/slides.html#rules-of-probability-1",
    "href": "w04/slides.html#rules-of-probability-1",
    "title": "Week 4: Discrete Distributions",
    "section": "‚ÄúRules‚Äù of Probability",
    "text": "‚ÄúRules‚Äù of Probability\n(Remember: not ‚Äúrules‚Äù but ‚Äúfacts resulting from the logic \\(\\leftrightarrow\\) probability connection‚Äù)\n\n\n\n\n‚ÄúRules‚Äù of Probability\n\n\nFor logical predicates \\(p, q \\in \\{T, F\\}\\), events \\(P, Q\\) defined so \\(P\\) = event that \\(p\\) becomes true, \\(Q\\) = event that \\(q\\) becomes true,\n\nLogical AND = Probabilistic Multiplication\n\n\\[\n\\Pr(p \\wedge q) = \\Pr(P \\cap Q) = \\Pr(P) \\cdot \\Pr(Q)\n\\]\n\nLogical OR = Probabilistic Addition\n\n\\[\n\\Pr(p \\vee q) = \\Pr(P \\cup Q) = \\Pr(P) + \\Pr(Q) - \\underbrace{\\Pr(P \\cap Q)}_{\\text{(see rule 1)}}\n\\]\n\nLogical NOT = Probabilistic Complement\n\n\\[\n\\Pr(\\neg p) = \\Pr(P^c) = 1 - \\Pr(P)\n\\]"
  },
  {
    "objectID": "w04/slides.html#conditional-probability",
    "href": "w04/slides.html#conditional-probability",
    "title": "Week 4: Discrete Distributions",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\nUsually if someone asks you probabilistic questions, like\n\n‚ÄúWhat is the likelihood that [our team] wins?‚Äù\n‚ÄúDo you think it will rain tomorrow?‚Äù\n\nYou don‚Äôt guess a random number, you consider and incorporate evidence.\nExample: \\(\\Pr(\\text{rain})\\) on its own, no other info? Tough question‚Ä¶ maybe \\(0.5\\)?\nIn reality, we would think about\n\n\\(\\Pr(\\text{rain} \\mid \\text{month of the year})\\)\n\\(\\Pr(\\text{rain} \\mid \\text{where we live})\\)\n\\(\\Pr(\\text{rain} \\mid \\text{did it rain yesterday?})\\)\n\nPsychologically, breaks down into two steps: (1) Think of baseline probability, (2) Update baseline to incorporate relevant evidence (more on this in a bit‚Ä¶)\nAlso recall: all probability is conditional probability, even if just conditioned on ‚Äúsomething happened‚Äù (\\(\\Omega\\), the thing defined so \\(\\Pr(\\Omega) = 1\\))"
  },
  {
    "objectID": "w04/slides.html#na√Øve-definition-2.0",
    "href": "w04/slides.html#na√Øve-definition-2.0",
    "title": "Week 4: Discrete Distributions",
    "section": "Na√Øve Definition 2.0",
    "text": "Na√Øve Definition 2.0\n\n\n\n\n[Slightly Less] Na√Øve Definition of Probability\n\n\n\\[\n\\Pr(A \\mid B) = \\frac{\\text{\\# of Desired Outcomes in world where }B\\text{ happened}}{\\text{\\# Total outcomes in world where }B\\text{ happened}} = \\frac{|B \\cap A|}{|B|}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\nWorld Name\nWeather in World\nLikelihood of Rain Today\n\n\n\n\n\\(R\\)\nRained for the past 5 days\n\\(\\Pr(\\text{rain} \\mid R) &gt; 0.5\\)\n\n\n\\(M\\)\nMix of rain and non-rain over past 5 days\n\\(\\Pr(\\text{rain} \\mid M) \\approx 0.5\\)\n\n\n\\(S\\)\nSunny for the past 5 days\n\\(\\Pr(\\text{rain} \\mid S) &lt; 0.5\\)"
  },
  {
    "objectID": "w04/slides.html#law-of-total-probability",
    "href": "w04/slides.html#law-of-total-probability",
    "title": "Week 4: Discrete Distributions",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\nSuppose the events \\(B_1, \\ldots, B_k\\) form a partition of the space \\(\\Omega\\) and \\(\\Pr(B_j) &gt; 0 \\forall j\\).\nThen, for every event \\(A\\) in \\(\\Omega\\),\n\\[\n  \\Pr(A) = \\sum_{i=1}^k \\Pr(B_j)\\Pr(A \\mid B_j)\n  \\]\nProbability of an event is the sum of its conditional probabilities across all conditions.\nIn other words: \\(A\\) is some event, \\(B_1, \\ldots, B_n\\) are mutually exclusive events filling entire sample-space, then\n\\[\n  \\Pr(A) = \\Pr(A \\mid B_1)\\Pr(B_1) + \\Pr(A \\mid B_2)\\Pr(B_2) + \\cdots + \\Pr(A \\mid B_n)\\Pr(B_n)\n  \\]\ni.e.¬†Compute the probability by summing over all possible cases.\n\n\nDraw pic on board!"
  },
  {
    "objectID": "w04/slides.html#example",
    "href": "w04/slides.html#example",
    "title": "Week 4: Discrete Distributions",
    "section": "Example",
    "text": "Example\n\nProbability of completing job on time with and without rain: 0.42 and 0.9.\nProbability of rain is 0.45. What is probability job will be completed on time?\n\\(A\\) = job will be completed on time, \\(B\\) = rain\n\n\\[\n\\Pr(B) = 0.45 \\implies \\Pr(B^c) = 1 - \\Pr(B) = 0.55.\n\\]\n\nNote: Events \\(B\\) and \\(B^c\\) are exclusive and form partitions of the sample space \\(S\\)\nWe know \\(\\Pr(A \\mid B) = 0.24\\), \\(\\Pr(A \\mid B^c) = 0.9\\).\nBy the Law of Total Probability, we have\n\n\\[\n\\begin{align*}\n\\Pr(A) &= \\Pr(B)\\Pr(A \\mid B) + \\Pr(B^c)\\Pr(A \\mid B^c) \\\\\n&= 0.45(0.42) + 0.55(0.9) = 0.189 + 0.495 = 0684.\n\\end{align*}\n\\]\nSo, the probability that the job will be completed on time is 0.684. (source)"
  },
  {
    "objectID": "w04/slides.html#deriving-bayes-theorem",
    "href": "w04/slides.html#deriving-bayes-theorem",
    "title": "Week 4: Discrete Distributions",
    "section": "Deriving Bayes‚Äô Theorem",
    "text": "Deriving Bayes‚Äô Theorem\n\nLiterally just a re-writing of the conditional probability definition (don‚Äôt be scared)!\n\n\n\n\nFor two events \\(A\\) and \\(B\\), definition of conditional probability says that\n\n\\[\n\\begin{align*}\n\\Pr(A \\mid B) &= \\frac{\\Pr(A \\cap B)}{\\Pr(B)} \\tag{1} \\\\\n\\Pr(B \\mid A) &= \\frac{\\Pr(B \\cap A)}{\\Pr(A)} \\tag{2}\n\\end{align*}\n\\]\n\nMultiply to get rid of fractions\n\n\\[\n\\begin{align*}\n\\Pr(A \\mid B)\\Pr(B) &= \\Pr(A \\cap B) \\tag{1*} \\\\\n\\Pr(B \\mid A)\\Pr(A) &= \\Pr(B \\cap A) \\tag{2*}\n\\end{align*}\n\\]\n\n\nBut set intersection is associative (just like multiplication‚Ä¶), \\(A \\cap B = B \\cap A\\)! So, we know LHS of \\((\\text{1*})\\) = LHS of \\((\\text{2*})\\):\n\n\\[\n\\Pr(A \\mid B)\\Pr(B) = \\Pr(B \\mid A)\\Pr(A)\n\\]\n\nDivide both sides by \\(\\Pr(B)\\) to get a new definition of \\(\\Pr(A \\mid B)\\), Bayes‚Äô Theorem!\n\n\n\n\n\\[\n\\boxed{\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)}}\n\\]\n\n\nFigure¬†1: Bayes‚Äô Theorem"
  },
  {
    "objectID": "w04/slides.html#why-is-this-helpful",
    "href": "w04/slides.html#why-is-this-helpful",
    "title": "Week 4: Discrete Distributions",
    "section": "Why Is This Helpful?",
    "text": "Why Is This Helpful?\n\n\n\n\nBayes‚Äô Theorem\n\n\nFor any two events \\(A\\) and \\(B\\), \\[\n\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)}\n\\]\n\n\n\n\n\nIn words (as exciting as I can make it, for now): Bayes‚Äô Theorem allows us to take information about \\(B \\mid A\\) and use it to infer information about \\(A \\mid B\\)\nIt isn‚Äôt until you work through some examples that this becomes mind-blowing, the most powerful equation we have for inferring unknowns from knowns‚Ä¶\nConsider \\(A = \\{\\text{person has disease}\\}\\), \\(B = \\{\\text{person tests positive for disease}\\}\\)\n\nIs \\(A\\) observable on its own? No, but‚Ä¶\n\nIs \\(B\\) observable on its own? Yes, and\nCan we infer info about \\(A\\) from knowing \\(B\\)? Also Yes, thx Bayes!\n\nTherefore, we can use \\(B\\) to infer information about \\(A\\), i.e., calculate \\(\\Pr(A \\mid B)\\)"
  },
  {
    "objectID": "w04/slides.html#why-is-this-helpful-for-data-science",
    "href": "w04/slides.html#why-is-this-helpful-for-data-science",
    "title": "Week 4: Discrete Distributions",
    "section": "Why Is This Helpful for Data Science?",
    "text": "Why Is This Helpful for Data Science?\n\nIt merges probability theory and hypothesis testing into a single framework:\n\n\\[\n\\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{\\Pr(\\text{data} \\mid \\text{hypothesis})\\Pr(\\text{hypothesis})}{\\Pr(\\text{data})}\n\\]"
  },
  {
    "objectID": "w04/slides.html#probability-forwards-and-backwards",
    "href": "w04/slides.html#probability-forwards-and-backwards",
    "title": "Week 4: Discrete Distributions",
    "section": "Probability Forwards and Backwards",
    "text": "Probability Forwards and Backwards\n\nTwo discrete RVs:\n\nWeather on a given day, \\(W \\in \\{\\textsf{Rain},\\textsf{Sun}\\}\\)\nAction that day, \\(A \\in \\{\\textsf{Go}, \\textsf{Stay}\\}\\): go to party or stay in and watch movie\n\nData-generating process: if \\(\\textsf{Sun}\\), rolls a die \\(R\\) and goes out unless \\(R = 6\\). If \\(\\textsf{Rain}\\), flips a coin and goes out if \\(\\textsf{H}\\).\nProbabilistic Graphical Model (PGM):"
  },
  {
    "objectID": "w04/slides.html#probability-forwards-and-backwards-1",
    "href": "w04/slides.html#probability-forwards-and-backwards-1",
    "title": "Week 4: Discrete Distributions",
    "section": "Probability Forwards and Backwards",
    "text": "Probability Forwards and Backwards\n\nSo, if we know \\(W = \\textsf{Sun}\\), what is \\(P(A = \\textsf{Go})\\)? \\[\n\\begin{align*}\nP(A = \\textsf{Go} \\mid W) &= 1 - P(R = 6) \\\\\n&= 1 - \\frac{1}{6} = \\frac{5}{6}\n\\end{align*}\n\\]\nConditional probability lets us go forwards (left to right):\n\n\n\n\n\n\n\nBut what if we want to perform inference going backwards?"
  },
  {
    "objectID": "w04/slides.html#probability-forwards-and-backwards-2",
    "href": "w04/slides.html#probability-forwards-and-backwards-2",
    "title": "Week 4: Discrete Distributions",
    "section": "Probability Forwards and Backwards",
    "text": "Probability Forwards and Backwards\n\n\n\nIf we see Ana at the party, we know \\(A = \\textsf{Go}\\)\nWhat does this tell us about the weather?\nIntuitively, we should increase our degree of belief that \\(W = \\textsf{Sun}\\). But, by how much?\nWe don‚Äôt know \\(P(W \\mid A)\\), only \\(P(A \\mid W)\\)‚Ä¶"
  },
  {
    "objectID": "w04/slides.html#probability-forwards-and-backwards-3",
    "href": "w04/slides.html#probability-forwards-and-backwards-3",
    "title": "Week 4: Discrete Distributions",
    "section": "Probability Forwards and Backwards",
    "text": "Probability Forwards and Backwards\n\\[\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) = \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sun})}^{5/6~ ‚úÖ}\\overbrace{P(W = \\textsf{Sun})}^{‚ùì}}{\\underbrace{P(A = \\textsf{Go})}_{‚ùì}}\n\\]\n\nWe‚Äôve seen \\(P(W = \\textsf{Sun})\\) before, it‚Äôs our prior: the probability without having any additional relevant knowledge. So, let‚Äôs say 50/50. \\(P(W = \\textsf{Sun}) = \\frac{1}{2}\\)\nIf we lived in Seattle, we could pick \\(P(W = \\textsf{Sun}) = \\frac{1}{4}\\)"
  },
  {
    "objectID": "w04/slides.html#probability-forwards-and-backwards-4",
    "href": "w04/slides.html#probability-forwards-and-backwards-4",
    "title": "Week 4: Discrete Distributions",
    "section": "Probability Forwards and Backwards",
    "text": "Probability Forwards and Backwards\n\\[\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) = \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sunny})}^{5/6~ ‚úÖ}\\overbrace{P(W = \\textsf{Sun})}^{1/2~ ‚úÖ}}{\\underbrace{P(A = \\textsf{Go})}_{‚ùì}}\n\\]\n\n\\(P(A = \\textsf{Go})\\) is trickier: the probability that Ana goes out regardless of what the weather is. But there are only two possible weather outcomes! So we just compute\n\n\\[\n\\begin{align*}\n&P(A = \\textsf{Go}) = \\sum_{\\omega \\in S(W)}P(A = \\textsf{Go}, \\omega) = \\sum_{\\omega \\in S(W)}P(A = \\textsf{Go} \\mid \\omega)P(\\omega) \\\\\n&= P(A = \\textsf{Go} \\mid W = \\textsf{Rain})P(W = \\textsf{Rain}) + P(A = \\textsf{Go} \\mid W = \\textsf{Sun})P(W = \\textsf{Sun}) \\\\\n&= \\left( \\frac{1}{2} \\right)\\left( \\frac{1}{2} \\right) + \\left( \\frac{5}{6} \\right)\\left( \\frac{1}{2} \\right) = \\frac{1}{4} + \\frac{5}{12} = \\frac{2}{3}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w04/slides.html#putting-it-all-together",
    "href": "w04/slides.html#putting-it-all-together",
    "title": "Week 4: Discrete Distributions",
    "section": "Putting it All Together",
    "text": "Putting it All Together\n\\[\n\\begin{align*}\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) &= \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sunny})}^{3/4~ ‚úÖ}\\overbrace{P(W = \\textsf{Sun})}^{1/2~ ‚úÖ}}{\\underbrace{P(A = \\textsf{Go})}_{1/2~ ‚úÖ}} \\\\\n&= \\frac{\\left(\\frac{3}{4}\\right)\\left(\\frac{1}{2}\\right)}{\\frac{1}{2}} = \\frac{\\frac{3}{8}}{\\frac{1}{2}} = \\frac{3}{4}.\n\\end{align*}\n\\]\n\nGiven that we see Ana at the party, we should update our beliefs, so that \\(P(W = \\textsf{Sun}) = \\frac{3}{4}, P(W = \\textsf{Rain}) = \\frac{1}{4}\\)."
  },
  {
    "objectID": "w04/slides.html#a-scarier-example",
    "href": "w04/slides.html#a-scarier-example",
    "title": "Week 4: Discrete Distributions",
    "section": "A Scarier Example",
    "text": "A Scarier Example\n\nBo worries he has a rare disease. He takes a test with 99% accuracy and tests positive. What‚Äôs the probability Bo has the disease? (Intuition: 99%? ‚Ä¶Let‚Äôs do the math!)\n\n\n\n\n\\(H \\in \\{\\textsf{sick}, \\textsf{healthy}\\}, T \\in \\{\\textsf{T}^+, \\textsf{T}^-\\}\\)\nThe test: 99% accurate. \\(\\Pr(T = \\textsf{T}^+ \\mid H = \\textsf{sick}) = 0.99\\), \\(\\Pr(T = \\textsf{T}^- \\mid H = \\textsf{healthy}) = 0.99\\).\nThe disease: 1 in 10K. \\(\\Pr(H = \\textsf{sick}) = \\frac{1}{10000}\\)\nWhat do we want to know? \\(\\Pr(H = \\textsf{sick} \\mid T = \\textsf{T}^+)\\)\nHow do we get there?\n\n\n\n\n\nThis photo, originally thought to be of Thomas Bayes, turns out to be probably someone else‚Ä¶ \\(\\Pr(\\textsf{Bayes})\\)?\n\n\n\n\n\\(H\\) for health, \\(T\\) for test result\nPhoto credit: https://thedatascientist.com/wp-content/uploads/2019/04/reverend-thomas-bayes.jpg"
  },
  {
    "objectID": "w04/slides.html#a-scarier-example-1",
    "href": "w04/slides.html#a-scarier-example-1",
    "title": "Week 4: Discrete Distributions",
    "section": "A Scarier Example",
    "text": "A Scarier Example\n\\[\n\\begin{align*}\n\\Pr(H = \\textsf{sick} \\mid T = \\textsf{T}^+) &= \\frac{\\Pr(T = \\textsf{T}^+ \\mid H = \\textsf{sick})\\Pr(H = \\textsf{sick})}{\\Pr(T = \\textsf{T}^+)} \\\\\n&= \\frac{(0.99)\\left(\\frac{1}{10000}\\right)}{(0.99)\\left( \\frac{1}{10000} \\right) + (0.01)\\left( \\frac{9999}{10000} \\right)}\n\\end{align*}\n\\]\n\n\nCode\np_sick &lt;- 1 / 10000\np_healthy &lt;- 1 - p_sick\np_pos_given_sick &lt;- 0.99\np_neg_given_sick &lt;- 1 - p_pos_given_sick\np_neg_given_healthy &lt;- 0.99\np_pos_given_healthy &lt;- 1 - p_neg_given_healthy\nnumer &lt;- p_pos_given_sick * p_sick\ndenom1 &lt;- numer\ndenom2 &lt;- p_pos_given_healthy * p_healthy\nfinal_prob &lt;- numer / (denom1 + denom2)\nfinal_prob\n\n\n[1] 0.009803922\n\n\n\n‚Ä¶ Less than 1% üò±"
  },
  {
    "objectID": "w04/slides.html#proof-in-the-pudding",
    "href": "w04/slides.html#proof-in-the-pudding",
    "title": "Week 4: Discrete Distributions",
    "section": "Proof in the Pudding",
    "text": "Proof in the Pudding\n\nLet‚Äôs generate a dataset of 5,000 people, using \\(\\Pr(\\textsf{Disease}) = \\frac{1}{10000}\\)\n\n\n\nCode\nlibrary(tibble)\nlibrary(dplyr)\n# Disease rarity\np_disease &lt;- 1 / 10000\n# 1K people\nnum_people &lt;- 10000\n# Give them ids\nppl_df &lt;- tibble(id=seq(1,num_people))\n# Whether they have the disease or not\nhas_disease &lt;- rbinom(num_people, 1, p_disease)\nppl_df &lt;- ppl_df %&gt;% mutate(has_disease=has_disease)\nppl_df |&gt; head()\n\n\n\n\n\n\nid\nhas_disease\n\n\n\n\n1\n0\n\n\n2\n0\n\n\n3\n0\n\n\n4\n0\n\n\n5\n0\n\n\n6\n0"
  },
  {
    "objectID": "w04/slides.html#binary-variable-trick",
    "href": "w04/slides.html#binary-variable-trick",
    "title": "Week 4: Discrete Distributions",
    "section": "Binary Variable Trick",
    "text": "Binary Variable Trick\n\nSince has_disease \\(\\in \\{0, 1\\}\\), we can use\n\nsum(has_disease) to obtain the count of people with the disease, or\nmean(has_disease) to obtain the proportion of people who have the disease\n\nTo see this (or, if you forget in the future), just make a fake dataset with a binary variable and 3 rows, and think about sums vs.¬†means of that variable:\n\n\n\n\n\nCode\nbinary_df &lt;- tibble(\n  id=c(1,2,3),\n  x=c(0,1,0)\n)\nbinary_df\n\n\n\n\n\n\nid\nx\n\n\n\n\n1\n0\n\n\n2\n1\n\n\n3\n0\n\n\n\n\n\n\n\nTaking the sum tells us: one row where x == 1:\n\n\nCode\nsum(binary_df$x)\n\n\n[1] 1\n\n\nTaking the mean tells us: 1/3 of rows have x == 1:\n\n\nCode\nmean(binary_df$x)\n\n\n[1] 0.3333333"
  },
  {
    "objectID": "w04/slides.html#applying-this-to-the-disease-data",
    "href": "w04/slides.html#applying-this-to-the-disease-data",
    "title": "Week 4: Discrete Distributions",
    "section": "Applying This to the Disease Data",
    "text": "Applying This to the Disease Data\n\nIf we want the number of people who have the disease:\n\n\n\nCode\n# Compute the *number* of people who have the disease\nsum(ppl_df$has_disease)\n\n\n[1] 0\n\n\n\nIf we want the proportion of people who have the disease:\n\n\n\nCode\n# Compute the *proportion* of people who have the disease\nmean(ppl_df$has_disease)\n\n\n[1] 0\n\n\n\n(And if you dislike scientific notation like I do‚Ä¶)\n\n\n\nCode\nformat(mean(ppl_df$has_disease), scientific = FALSE)\n\n\n[1] \"0\"\n\n\n\n(Foreshadowing Monte Carlo methods)"
  },
  {
    "objectID": "w04/slides.html#data-generating-process-test-results",
    "href": "w04/slides.html#data-generating-process-test-results",
    "title": "Week 4: Discrete Distributions",
    "section": "Data-Generating Process: Test Results",
    "text": "Data-Generating Process: Test Results\n\n\nCode\nlibrary(dplyr)\n# Data Generating Process\ntake_test &lt;- function(is_sick) {\n  if (is_sick) {\n    return(rbinom(1,1,p_pos_given_sick))\n  } else {\n    return(rbinom(1,1,p_pos_given_healthy))\n  }\n}\nppl_df['test_result'] &lt;- unlist(lapply(ppl_df$has_disease, take_test))\nnum_positive &lt;- sum(ppl_df$test_result)\np_positive &lt;- mean(ppl_df$test_result)\nwriteLines(paste0(num_positive,\" positive tests / \",num_people,\" total = \",p_positive))\n\n\n110 positive tests / 10000 total = 0.011\n\n\n\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n1\n0\n0\n\n\n2\n0\n1\n\n\n3\n0\n0\n\n\n4\n0\n0\n\n\n5\n0\n0\n\n\n6\n0\n0"
  },
  {
    "objectID": "w04/slides.html#zooming-in-on-positive-tests",
    "href": "w04/slides.html#zooming-in-on-positive-tests",
    "title": "Week 4: Discrete Distributions",
    "section": "Zooming In On Positive Tests",
    "text": "Zooming In On Positive Tests\n\n\n\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n2\n0\n1\n\n\n72\n0\n1\n\n\n160\n0\n1\n\n\n185\n0\n1\n\n\n201\n0\n1\n\n\n283\n0\n1\n\n\n\n\n\n\n\n\nBo doesn‚Äôt have it, and neither do 110 of the 111 total people who tested positive!\nBut, in the real world, we only observe \\(T\\)"
  },
  {
    "objectID": "w04/slides.html#zooming-in-on-disease-havers",
    "href": "w04/slides.html#zooming-in-on-disease-havers",
    "title": "Week 4: Discrete Distributions",
    "section": "Zooming In On Disease-Havers",
    "text": "Zooming In On Disease-Havers\n\nWhat if we look at only those who actually have the disease? Maybe the cost of 111 people panicking is worth it if we correctly catch those who do have it?\n\n\n\nCode\n#disp(ppl_df[ppl_df$has_disease == 1,])\nppl_df[ppl_df$has_disease == 1,]\n\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n\n\n\n\nIs this always going to be the case?\n\n\n\n\nNum with disease: 0\nProportion with disease: 0\nNumber of positive tests: 61\n\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n\n\n\n\n\n\n\nNum with disease: 1\nProportion with disease: 0.0002\nNumber of positive tests: 61\n\n\n\n\n\n\nid\nhas_disease\ntest_result\n\n\n\n\n4432\n1\n1"
  },
  {
    "objectID": "w04/slides.html#worst-case-worlds",
    "href": "w04/slides.html#worst-case-worlds",
    "title": "Week 4: Discrete Distributions",
    "section": "Worst-Case Worlds",
    "text": "Worst-Case Worlds\n\n\n\n\nWorld #127 / 1000 (5000 people):\n# A tibble: 2 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  3475           1           1\n2  4716           1           0\n\n\nWorld #371 / 1000 (5000 people):\n# A tibble: 1 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  4165           1           0\n\n\nWorld #483 / 1000 (5000 people):\n# A tibble: 2 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  2454           1           1\n2  3245           1           0\n\n\nWorld #810 / 1000 (5000 people):\n# A tibble: 2 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1   833           1           0\n2  1505           1           1\n\n\nWorld #961 / 1000 (5000 people):\n# A tibble: 3 √ó 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1   281           1           1\n2   800           1           1\n3  2358           1           0\n\n\n[1] \"0.0000008\"\n\n\n\nHow unlikely is this? Math:\n\\[\n\\begin{align*}\n\\Pr(\\textsf{T}^- \\cap \\textsf{Sick}) &= \\Pr(\\textsf{T}^- \\mid \\textsf{Sick})\\Pr(\\textsf{Sick}) \\\\\n&= (0.01)\\frac{1}{10000} \\\\\n&= \\frac{1}{1000000}\n\\end{align*}\n\\]\nComputers:\n\n\nFalse Negatives: 0, Total Cases: 1000000\n\n\nFalse Negative Rate: 0\n\n\n(Perfect match!)"
  },
  {
    "objectID": "w04/slides.html#bayes-takeaway",
    "href": "w04/slides.html#bayes-takeaway",
    "title": "Week 4: Discrete Distributions",
    "section": "Bayes: Takeaway",
    "text": "Bayes: Takeaway\n\nBayesian approach allows new evidence to be weighed against existing evidence, with statistically principled way to derive these weights:\n\n\\[\n\\begin{array}{ccccc}\n\\Pr_{\\text{post}}(\\mathcal{H}) &\\hspace{-6mm}\\propto &\\hspace{-6mm} \\Pr(X \\mid \\mathcal{H}) &\\hspace{-6mm} \\times &\\hspace{-6mm} \\Pr_{\\text{pre}}(\\mathcal{H}) \\\\\n\\text{Posterior} &\\hspace{-6mm}\\propto &\\hspace{-6mm}\\text{Evidence} &\\hspace{-6mm} \\times &\\hspace{-6mm} \\text{Prior}\n\\end{array}\n\\]"
  },
  {
    "objectID": "w04/slides.html#monte-carlo-methods-overview",
    "href": "w04/slides.html#monte-carlo-methods-overview",
    "title": "Week 4: Discrete Distributions",
    "section": "Monte Carlo Methods: Overview",
    "text": "Monte Carlo Methods: Overview\n\nYou already saw an example, in our rare disease simulation!\nGenerally, using computers (rather than math, ‚Äúby hand‚Äù) to estimate probabilistic quantities\n\n\n\nPros:\n\nMost real-world processes have no analytic solution\nStep-by-step breakdown of complex processes\n\n\nCons:\n\nCan require immense computing power\n‚ö†Ô∏è Can generate incorrect answers ‚ö†Ô∏è\n\n\n\nBy step-by-step I mean, a lot of the time you are just walking through, generating the next column using previously-generated columns. Like we did in the example above, generating test_result based on has_disease."
  },
  {
    "objectID": "w04/slides.html#birthday-problem",
    "href": "w04/slides.html#birthday-problem",
    "title": "Week 4: Discrete Distributions",
    "section": "Birthday Problem",
    "text": "Birthday Problem\n\n\n\n30 people gather in a room together. What is the probability that two of them share the same birthday?\nAnalytic solution is fun, but requires some thought‚Ä¶ Monte Carlo it!\n\n\n\n\nCode\ngen_bday_room &lt;- function(room_num=NULL) {\n  num_people &lt;- 30\n  num_days &lt;- 366\n  ppl_df &lt;- tibble(id=seq(1,num_people))\nbirthdays &lt;- sample(1:num_days, num_people,replace = T)\n  ppl_df['birthday'] &lt;- birthdays\n  if (!is.null(room_num)) {\n    ppl_df &lt;- ppl_df %&gt;% mutate(room_num=room_num) %&gt;% relocate(room_num)\n  }\n  return(ppl_df)\n}\nppl_df &lt;- gen_bday_room(1)\n#disp(ppl_df %&gt;% head())\nppl_df |&gt; head()\n\n\n\n\n\n\nroom_num\nid\nbirthday\n\n\n\n\n1\n1\n53\n\n\n1\n2\n25\n\n\n1\n3\n111\n\n\n1\n4\n191\n\n\n1\n5\n207\n\n\n1\n6\n18"
  },
  {
    "objectID": "w04/slides.html#birthday-problem-1",
    "href": "w04/slides.html#birthday-problem-1",
    "title": "Week 4: Discrete Distributions",
    "section": "Birthday Problem",
    "text": "Birthday Problem\n\n\n\n\n\n\ni\nj\nbday\n\n\n\n\n11\n25\n157"
  },
  {
    "objectID": "w04/slides.html#section",
    "href": "w04/slides.html#section",
    "title": "Week 4: Discrete Distributions",
    "section": "",
    "text": "Let‚Äôs try more rooms‚Ä¶\n\n\n\n\nCode\n# Get tibbles for each room\nlibrary(purrr)\ngen_bday_rooms &lt;- function(num_rooms) {\n  rooms_df &lt;- tibble()\n  for (r in seq(1, num_rooms)) {\n      cur_room &lt;- gen_bday_room(r)\n      rooms_df &lt;- bind_rows(rooms_df, cur_room)\n  }\n  return(rooms_df)\n}\nnum_rooms &lt;- 10\nrooms_df &lt;- gen_bday_rooms(num_rooms)\nrooms_df %&gt;% group_by(room_num) %&gt;% group_map(~ get_shared_bdays(.x, is_grouped=TRUE))\n\n\n[[1]]\n# A tibble: 0 √ó 0\n\n[[2]]\n# A tibble: 3 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1    11    19   301\n2    11    24   301\n3    19    24   301\n\n[[3]]\n# A tibble: 3 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     2     7   210\n2     3    13    39\n3    12    20   290\n\n[[4]]\n# A tibble: 0 √ó 0\n\n[[5]]\n# A tibble: 2 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     9    14   359\n2    15    24   334\n\n[[6]]\n# A tibble: 2 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     2    12   281\n2     3    30   140\n\n[[7]]\n# A tibble: 3 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     6   293\n2     5    20    32\n3     7    28   133\n\n[[8]]\n# A tibble: 2 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     2    30   141\n2     6    18    53\n\n[[9]]\n# A tibble: 3 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     6    15    29\n2     7    11   280\n3    14    18   232\n\n[[10]]\n# A tibble: 2 √ó 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1    16    22   332\n2    17    20   226\n\n\n\nNumber of shared birthdays per room:\n\n\nCode\n# Now just get the # shared bdays\nshared_per_room &lt;- rooms_df %&gt;%\n    group_by(room_num) %&gt;%\n    group_map(~ get_shared_bdays(.x, is_grouped = TRUE, return_num=TRUE))\nshared_per_room &lt;- unlist(shared_per_room)\nshared_per_room\n\n\n [1] 0 3 3 0 2 2 3 2 3 2\n\n\n\n\\(\\widehat{\\Pr}(\\text{shared})\\)\n\n\n\n[1] 0.8"
  },
  {
    "objectID": "w04/slides.html#section-1",
    "href": "w04/slides.html#section-1",
    "title": "Week 4: Discrete Distributions",
    "section": "",
    "text": "How about A THOUSAND ROOMS?\n\n\n\n  [1] 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1\n [38] 1 1 0 1 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1\n [75] 1 0 1 1 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 1 1\n\n\n\n\\(\\widehat{\\Pr}(\\text{shared bday})\\)?\n\n\n\n[1] 0.7\n\n\n\nThe analytic solution: \\(\\Pr(\\text{shared} \\mid k\\text{ people in room}) = 1 - \\frac{366!}{366^{k}(366-k)!}\\)\nIn our case: \\(1 - \\frac{366!}{366^{30}(366-30)!} = 1 - \\frac{366!}{366^{30}336!} = 1 - \\frac{\\prod_{i=337}^{366}i}{366^{30}}\\)\nR can juust barely handle these numbers:\n\n\n\n[1] 0.7053034"
  },
  {
    "objectID": "w04/slides.html#wrapping-up",
    "href": "w04/slides.html#wrapping-up",
    "title": "Week 4: Discrete Distributions",
    "section": "Wrapping Up",
    "text": "Wrapping Up"
  },
  {
    "objectID": "w04/slides.html#final-note-functions-of-random-variables",
    "href": "w04/slides.html#final-note-functions-of-random-variables",
    "title": "Week 4: Discrete Distributions",
    "section": "Final Note: Functions of Random Variables",
    "text": "Final Note: Functions of Random Variables\n\n\\(X \\sim U[0,1], Y \\sim U[0,1]\\).\n\\(P(Y &lt; X^2)\\)?\nThe hard way: solve analytically\nThe easy way: simulate!"
  },
  {
    "objectID": "w04/slides.html#discrete-vs.-continuous",
    "href": "w04/slides.html#discrete-vs.-continuous",
    "title": "Week 4: Discrete Distributions",
    "section": "Discrete vs.¬†Continuous",
    "text": "Discrete vs.¬†Continuous\n\n\n\nDiscrete = ‚ÄúEasy mode‚Äù: Based (intuitively) on sets\n\\(\\Pr(A)\\): Four marbles \\(\\{A, B, C, D\\}\\) in box, all equally likely, what is the probability I pull out \\(A\\)?\n\n\n\n\n\n\n\n\n\n\n\\[\n\\Pr(A) = \\underbrace{\\frac{|\\{A\\}|}{|\\Omega|}}_{\\mathclap{\\small \\text{Probability }\\textbf{mass}}} = \\frac{1}{|\\{A,B,C,D\\}|} = \\frac{1}{4}\n\\]\n\n\nContinuous = ‚ÄúHard mode‚Äù: Based (intuitively) on areas\n\\(\\Pr(A)\\): If I throw a dart at this square, what is the probability that I hit region \\(A\\)?\n\n\n\n\n\n\n\n\n\n\n\\[\n\\Pr(A) = \\underbrace{\\frac{\\text{Area}(\\{A\\})}{\\text{Area}(\\Omega)}}_{\\mathclap{\\small \\text{Probability }\\textbf{density}}} = \\frac{\\pi r^2}{s^2} = \\frac{\\pi \\left(\\frac{1}{4}\\right)^2}{4} = \\frac{\\pi}{64}\n\\]"
  },
  {
    "objectID": "w04/slides.html#the-technical-difference-tldr",
    "href": "w04/slides.html#the-technical-difference-tldr",
    "title": "Week 4: Discrete Distributions",
    "section": "The Technical Difference tl;dr",
    "text": "The Technical Difference tl;dr\n\nCountable Sets: Can be put into 1-to-1 correspondence with the natural numbers \\(\\mathbb{N}\\)\n\nWhat are you doing when you‚Äôre counting? Saying ‚Äúfirst‚Äù, ‚Äúsecond‚Äù, ‚Äúthird‚Äù, ‚Ä¶\nYou‚Äôre pairing each object with a natural number! \\(\\{(\\texttt{a},1),(\\texttt{b},2),\\ldots,(\\texttt{z},26)\\}\\) \n\nUncountable Sets: Cannot be put into 1-to-1 correspondence with the natural numbers.\n\n\\(\\mathbb{R}\\) is uncountable. Intuition: Try counting the real numbers. Proof1 \\[\n\\text{Assume }\\exists (f: \\mathbb{R} \\leftrightarrow \\mathbb{N}) =\n\\begin{array}{|c|c|c|c|c|c|c|}\\hline\n\\mathbb{R} & & & & & & \\Leftrightarrow \\mathbb{N} \\\\ \\hline\n\\color{orange}{3} & . & 1 & 4 & 1 & \\cdots & \\Leftrightarrow 1 \\\\\\hline\n4 & . & \\color{orange}{9} & 9 & 9 & \\cdots & \\Leftrightarrow 2 \\\\\\hline\n0 & . & 1 & \\color{orange}{2} & 3 & \\cdots &\\Leftrightarrow 3 \\\\\\hline\n1 & . & 2 & 3 & \\color{orange}{4} & \\cdots & \\Leftrightarrow 4 \\\\\\hline\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\\hline\n\\end{array} \\overset{\\color{blue}{y_{[i]}} = \\color{orange}{x_{[i]}} \\overset{\\mathbb{Z}_{10}}{+} 1}{\\longrightarrow} \\color{blue}{y = 4.035 \\ldots} \\Leftrightarrow \\; ?\n\\]\n\n\n\n\nFun math challenge: Is \\(\\mathbb{Q}\\) countable? See this appendix slide for why the answer is yes, despite the fact that \\(\\forall x, y \\in \\mathbb{Q} \\left[ \\frac{x+y}{2} \\in \\mathbb{Q} \\right]\\)\nThe method used in this proof, if you haven‚Äôt seen it before, is called Cantor diagonalization, and it is extremely fun and applicable to a wide variety of levels-of-infinity proofs"
  },
  {
    "objectID": "w04/slides.html#the-practical-difference",
    "href": "w04/slides.html#the-practical-difference",
    "title": "Week 4: Discrete Distributions",
    "section": "The Practical Difference",
    "text": "The Practical Difference\n\nThis part of the course (discrete probability): \\(\\Pr(X = v), v \\in \\mathcal{R}_X \\subseteq \\mathbb{N}\\)\n\nExample: \\(\\Pr(\\)\\() = \\Pr(X = 3), 3 \\in \\{1,2,3,4,5,6\\} \\subseteq \\mathbb{N}\\)\n\nNext part of the course (continuous probability): \\(\\Pr(X \\in V), v \\subseteq \\mathbb{R}\\)\n\nExample: \\(\\Pr(X \\geq 2\\pi) = \\Pr(X \\in [\\pi,\\infty)), [\\pi,\\infty) \\subseteq \\mathbb{R}\\)\n\nWhy do they have to be in separate parts?\n\n\\[\n\\Pr(X = 2\\pi) = \\frac{\\text{Area}(\\overbrace{2\\pi}^{\\mathclap{\\small \\text{Single point}}})}{\\text{Area}(\\underbrace{\\mathbb{R}}_{\\mathclap{\\small \\text{(Uncountably) Infinite set of points}}})} = 0\n\\]"
  },
  {
    "objectID": "w04/slides.html#probability-mass-vs.-probability-density",
    "href": "w04/slides.html#probability-mass-vs.-probability-density",
    "title": "Week 4: Discrete Distributions",
    "section": "Probability Mass vs.¬†Probability Density",
    "text": "Probability Mass vs.¬†Probability Density\n\nCumulative Distribution Function (CDF): \\(F_X(v) = \\Pr(X \\leq v)\\)\nFor discrete RV \\(X\\), Probability Mass Function (pmf) \\(p_X(v)\\): \\[\n\\begin{align*}\np_X(v) &= \\Pr(X = v) = F_X(v) - F_X(v-1) \\\\\n\\implies F_X(v) &= \\sum_{\\{w \\in \\mathcal{R}_X: \\; w \\leq v\\}}p_X(w)\n\\end{align*}\n\\]\nFor continuous RV \\(X\\) (\\(\\mathcal{R}_X \\subseteq \\mathbb{R}\\)), Probability Density Function (pdf) \\(f_X(v)\\): \\[\n\\begin{align*}\nf_X(v) &= \\frac{d}{dx}F_X(v) \\\\\n\\implies F_X(v) &= \\int_{-\\infty}^v f_X(w)dw\n\\end{align*}\n\\]\n\n\n\nFrustratingly, the CDF/pmf/pdf is usually written using \\(X\\) and \\(x\\), like \\(F_X(x) = \\Pr(X \\leq x)\\). To me this is extremely confusing, since the capitalized \\(X\\) is a random variable (not a number) while the lowercase \\(x\\) is some particular value, like \\(3\\). So, to emphasize this difference, I use \\(X\\) for the RV and \\(v\\) for the value at which we‚Äôre checking the CDF/pmf/pdf.\nAlso note the capitalized CDF but lowercase pmf/pdf, matching the mathematical notation where \\(f_X(v)\\) is the derivative of \\(F_X(v)\\)."
  },
  {
    "objectID": "w04/slides.html#probability-density-neq-probability",
    "href": "w04/slides.html#probability-density-neq-probability",
    "title": "Week 4: Discrete Distributions",
    "section": "Probability Density \\(\\neq\\) Probability",
    "text": "Probability Density \\(\\neq\\) Probability\n\nBEWARE: \\(f_X(v) \\neq \\Pr(X = v)\\)!\nLong story short, for continuous variables, \\(\\Pr(X = v) = 0\\)1\nHence, we instead construct a PDF \\(f_X(v)\\) that enables us to calculate \\(\\Pr(X \\in [a,b])\\) by integrating: \\(f_X(v)\\) is whatever function satisfies \\(\\Pr(X \\in [a,b]) = \\int_{a}^bf_X(v)dv\\).\ni.e., instead of \\(p_X(v) = \\Pr(X = v)\\) from discrete world, the relevant function here is \\(f_X(v)\\), the probability density of \\(X\\) at \\(v\\).\nIf we really want to get something like the ‚Äúprobability of a value‚Äù in a continuous space üò™, we can get something kind of like this by using fancy limits \\[\nf_X(v) = \\lim_{\\varepsilon \\to 0}\\frac{P(X \\in [v-\\varepsilon, v + \\varepsilon])}{2\\varepsilon} = \\lim_{\\varepsilon \\to 0}\\frac{F(v + \\varepsilon) - F(v - \\varepsilon)}{2\\varepsilon} = \\frac{d}{dx}F_X(v)\n\\]\n\nFor intuition: \\(X \\sim U[0,10] \\implies \\Pr(X = \\pi) = \\frac{|\\{v \\in \\mathbb{R}:\\; v = \\pi\\}|}{|\\mathbb{R}|} = \\frac{1}{2^{\\aleph_0}} \\approx 0\\). That is, finding the \\(\\pi\\) needle in the \\(\\mathbb{R}\\) haystack is a one-in-\\(\\left(\\infty^\\infty\\right)\\) event. A similar issue occurs if \\(S\\) is countably-infinite, like \\(S = \\mathbb{N}\\): \\(\\Pr(X = 3) = \\frac{|\\{x \\in \\mathbb{N} : \\; x = 3\\}|}{|\\mathbb{N}|} = \\frac{1}{\\aleph_0}\\)."
  },
  {
    "objectID": "w04/slides.html#bernoulli-distribution",
    "href": "w04/slides.html#bernoulli-distribution",
    "title": "Week 4: Discrete Distributions",
    "section": "Bernoulli Distribution",
    "text": "Bernoulli Distribution\n\nSingle trial with two outcomes, ‚Äúsuccess‚Äù (1) or ‚Äúfailure‚Äù (0): basic model of a coin flip (heads = 1, tails = 0)\n\\(X \\sim \\text{Bern}({\\color{purple} p}) \\implies \\mathcal{R}_X = \\{0,1\\}, \\; \\Pr(X = 1) = {\\color{purple}p}\\)."
  },
  {
    "objectID": "w04/slides.html#binomial-distribution",
    "href": "w04/slides.html#binomial-distribution",
    "title": "Week 4: Discrete Distributions",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nNumber of successes in \\({\\color{purple}N}\\) Bernoulli trials. \\(X \\sim \\text{Binom}({\\color{purple}N},{\\color{purple}k},{\\color{purple}p}) \\implies \\mathcal{R}_X = \\{0, 1, \\ldots, N\\}\\)\n\n\\(P(X = k)  = \\binom{N}{k}p^k(1-p)^{N-k}\\): probability of \\(k\\) successes out of \\(N\\) trials.\n\\(\\binom{N}{k} = \\frac{N!}{k!(N-k)!}\\): ‚ÄúBinomial coefficient‚Äù. How many groups of size \\(k\\) can be formed?1\n\n\nA fun way to never have to memorize or compute these: imagine a pyramid like \\(\\genfrac{}{}{0pt}{}{}{\\boxed{\\phantom{1}}}\\genfrac{}{}{0pt}{}{\\boxed{\\phantom{1}}}{}\\genfrac{}{}{0pt}{}{}{\\boxed{\\phantom{1}}}\\), where the boxes are slots for numbers, and put a \\(1\\) in the box at the top. In the bottom row, fill each slot with the sum of the two numbers above-left and above-right of it. Since \\(1 + \\text{(nothing)} = 1\\), this looks like: \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\). Continue filling in the pyramid this way, so the next row looks like \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{2}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\), then \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{3}\\genfrac{}{}{0pt}{}{2}{}\\genfrac{}{}{0pt}{}{}{3}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\), and so on. The \\(k\\)th number in the \\(N\\)th row (counting from \\(0\\)) is \\(\\binom{N}{k}\\). For the triangle written out to the 7th row, see Appendix I at end of slideshow."
  },
  {
    "objectID": "w04/slides.html#visualizing-the-binomial",
    "href": "w04/slides.html#visualizing-the-binomial",
    "title": "Week 4: Discrete Distributions",
    "section": "Visualizing the Binomial",
    "text": "Visualizing the Binomial\n\n\nCode\nk &lt;- seq(0, 10)\nprob &lt;- dbinom(k, 10, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x=k, y=prob)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title=\"Binomial Distribution, N = 10, p = 0.5\",\n    y=\"Probability Mass\"\n  ) +\n  scale_x_continuous(breaks=seq(0,10)) +\n  dsan_theme(\"half\")\n\n\n\n\nSo who can tell me, from this plot, the approximate probability of getting 4 heads when flipping a coin 10 times?"
  },
  {
    "objectID": "w04/slides.html#multiple-classes-multinomial-distribution",
    "href": "w04/slides.html#multiple-classes-multinomial-distribution",
    "title": "Week 4: Discrete Distributions",
    "section": "Multiple Classes: Multinomial Distribution",
    "text": "Multiple Classes: Multinomial Distribution\n\nBernoulli only allows two outcomes: success or failure.\nWhat if we‚Äôre predicting soccer match outcomes?\n\n\\(X_i \\in \\{\\text{Win}, \\text{Loss}, \\text{Draw}\\}\\)\n\nCategorical Distribution: Generalization of Bernoulli to \\(k\\) outcomes. \\(X \\sim \\text{Categorical}(\\mathbf{p} = \\{p_1, p_2, \\ldots, p_k\\}), \\sum_{i=1}^kp_i = 1\\).\n\n\\(P(X = k) = p_k\\)\n\nMultinomial Distribution: Generalization of Binomial to \\(k\\) outcomes.\n\\(\\mathbf{X} \\sim \\text{Multinom}(N,k,\\mathbf{p}=\\{p_1,p_2,\\ldots,p_k\\}), \\sum_{i=1}^kp_i=1\\)\n\n\\(P(\\mathbf{X} = \\{x_1,x_2\\ldots,x_k\\}) = \\frac{N!}{x_1!x_2!\\cdots x_k!}p_1^{x_1}p_2^{x_2}\\cdots p_k^{x_k}\\)\n\\(P(\\text{30 wins}, \\text{4 losses}, \\text{4 draws}) = \\frac{38!}{30!4!4!}p_{\\text{win}}^{30}p_{\\text{lose}}^4p_{\\text{draw}}^4\\)."
  },
  {
    "objectID": "w04/slides.html#geometric-distribution",
    "href": "w04/slides.html#geometric-distribution",
    "title": "Week 4: Discrete Distributions",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nGeometric: Likelihood that we need \\({\\color{purple}k}\\) trials to get our first success. \\(X \\sim \\text{Geom}({\\color{purple}k},{\\color{purple}p}) \\implies \\mathcal{R}_X = \\{0, 1, \\ldots\\}\\)\n\n\\(P(X = k) = \\underbrace{(1-p)^{k-1}}_{\\small k - 1\\text{ failures}}\\cdot \\underbrace{p}_{\\mathclap{\\small \\text{success}}}\\)\nProbability of \\(k-1\\) failures followed by a success"
  },
  {
    "objectID": "w04/slides.html#less-common-but-important-distributions",
    "href": "w04/slides.html#less-common-but-important-distributions",
    "title": "Week 4: Discrete Distributions",
    "section": "Less Common (But Important) Distributions",
    "text": "Less Common (But Important) Distributions\n\nDiscrete Uniform: \\(N\\) equally-likely outcomes\n\n\\(X \\sim U\\{{\\color{purple}a},{\\color{purple}b}\\} \\implies \\mathcal{R}_X = \\{a, a+1, \\ldots, b\\}, P(X = k) = \\frac{1}{{\\color{purple}b} - {\\color{purple}a} + 1}\\)\n\nBeta: \\(X \\sim \\text{Beta}({\\color{purple}\\alpha}, {\\color{purple}\\beta})\\): conjugate prior for Bernoulli, Binomial, and Geometric dists.\n\nIntuition: If we use Beta to encode our prior hypothesis, then observe data drawn from Binomial, distribution of our updated hypothesis is still Beta.\n\\(\\underbrace{\\Pr(\\text{biased}) = \\Pr(\\text{unbiased})}_{\\text{Prior: }\\text{Beta}({\\color{purple}\\alpha}, {\\color{purple}\\beta})} \\rightarrow\\) Observe \\(\\underbrace{\\frac{8}{10}\\text{ heads}}_{\\text{Data}} \\rightarrow \\underbrace{\\Pr(\\text{biased}) = 0.65}_{\\text{Posterior: }\\text{Beta}({\\color{purple}\\alpha + 8}, {\\color{purple}\\beta + 2})}\\)\n\nDirichlet: \\(\\mathbf{X} = (X_1, X_2, \\ldots, X_K) \\sim \\text{Dir}({\\color{purple} \\boldsymbol\\alpha})\\)\n\n\\(K\\)-dimensional extension of Beta (thus, conjugate prior for Multinomial)\n\n\n\n\nWe can now use \\(\\text{Beta}(\\alpha + 8, \\beta + 2)\\) as a prior for our next set of trials (encoding our knowledge up to that point), and update further once we know the results (to yet another Beta distribution)."
  },
  {
    "objectID": "w04/slides.html#interactive-visualizations",
    "href": "w04/slides.html#interactive-visualizations",
    "title": "Week 4: Discrete Distributions",
    "section": "Interactive Visualizations!",
    "text": "Interactive Visualizations!\nSeeing Theory, Brown University"
  },
  {
    "objectID": "w04/slides.html#appendix-countability-of-mathbbq",
    "href": "w04/slides.html#appendix-countability-of-mathbbq",
    "title": "Week 4: Discrete Distributions",
    "section": "Appendix: Countability of \\(\\mathbb{Q}\\)",
    "text": "Appendix: Countability of \\(\\mathbb{Q}\\)\n\nBad definition: ‚Äú\\(\\mathbb{N}\\) is countable because no \\(x \\in \\mathbb{N}\\) between \\(0\\) and \\(1\\). \\(\\mathbb{R}\\) is uncountable because infinitely-many \\(x \\in \\mathbb{R}\\) between \\(0\\) and \\(1\\).‚Äù (\\(\\implies \\mathbb{Q}\\) uncountable)\nAnd yet, \\(\\mathbb{Q}\\) is countable‚Ä¶\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\begin{array}{ll}\ns: \\mathbb{N} \\leftrightarrow \\mathbb{Z} & s(n) = (-1)^n \\left\\lfloor \\frac{n+1}{2} \\right\\rfloor \\\\\nh_+: \\mathbb{Z}^+ \\leftrightarrow \\mathbb{Q}^+ & p_1^{a_1}p_2^{a_2}\\cdots \\mapsto p_1^{s(a_1)}p_2^{s(a_2)}\\cdots \\\\\nh: \\mathbb{Z} \\leftrightarrow \\mathbb{Q} & h(n) = \\begin{cases}h_+(n) &n &gt; 0 \\\\ 0 & n = 0 \\\\\n-h_+(-n) & n &lt; 0\\end{cases} \\\\\n(h \\circ s): \\mathbb{N} \\leftrightarrow \\mathbb{Q} & ‚úÖü§Ø\n\\end{array}\n\\end{align*}\n\\]\n\n\n\n\n\nDSAN 5100-03 W04: Discrete Distributions\n\n\n\nImage credit: Rebecca J. Stones, Math StackExchange. Math credit: Thomas Andrews, Math StackExchange"
  },
  {
    "objectID": "recordings-archive/index.html",
    "href": "recordings-archive/index.html",
    "title": "Lecture Recordings Archive",
    "section": "",
    "text": "Use the listing below to view lecture recordings for previous iterations of DSAN 5100!\n\n\n\n\n\n\n\n\n\nWeek\n\n\nTitle\n\n\nLast Updated\n\n\n\n\n\n\n14\n\n\nWeek 14 Presentation Recordings\n\n\nThursday Nov 30, 2023\n\n\n\n\n13\n\n\nWeek 13 Lecture Recording\n\n\nThursday Nov 16, 2023\n\n\n\n\n13\n\n\nWeek 13 Guest Lecture: Dr.¬†Kerrie Carfagno\n\n\nThursday Nov 16, 2023\n\n\n\n\n12\n\n\nWeek 12 Lecture Recording\n\n\nThursday Nov 9, 2023\n\n\n\n\n11\n\n\nWeek 11 Lecture Recording\n\n\nThursday Nov 2, 2023\n\n\n\n\n10\n\n\nWeek 10 Lecture Recording\n\n\nThursday Oct 26, 2023\n\n\n\n\n9\n\n\nWeek 09 Lecture Recording\n\n\nThursday Oct 19, 2023\n\n\n\n\n8\n\n\nWeek 08 Lecture Recording\n\n\nThursday Oct 12, 2023\n\n\n\n\n7\n\n\nWeek 07 Lecture Recording\n\n\nThursday Oct 5, 2023\n\n\n\n\n6\n\n\nWeek 06 Lecture Recording\n\n\nThursday Sep 28, 2023\n\n\n\n\n5\n\n\nWeek 05 Lecture Recording\n\n\nThursday Sep 21, 2023\n\n\n\n\n4\n\n\nWeek 04 Lecture Recording\n\n\nThursday Sep 14, 2023\n\n\n\n\n3\n\n\nWeek 03 Lecture Recording\n\n\nTuesday Sep 5, 2023\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "recordings/index.html",
    "href": "recordings/index.html",
    "title": "Lecture Recordings",
    "section": "",
    "text": "The lecture recordings for Fall 2024 will be added here as soon as possible after the end of class.\nYou can view recordings of my lectures from previous semesters here\n\n\n\n\n\n\n\n\n\nWeek\n\n\nTitle\n\n\nLast Updated\n\n\n\n\n\n\n1\n\n\nWeek 01 Lecture Recording\n\n\nMonday Sep 30, 2024\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "writeups/marginalization/index.html",
    "href": "writeups/marginalization/index.html",
    "title": "Marginal Distributions and ‚ÄúMarginalizing Out‚Äù A Variable",
    "section": "",
    "text": "My last writeup was focused on how to get started on Problem 1 of your Lab 5 Assignment, so in this one we will focus on how to do the parts towards the end of this problem: namely, figuring out what marginal distributions are, and what it means to ‚Äúmarginalize out‚Äù a variable, to go from some joint pdf \\(f_{X,Y}(x,y)\\) to a marginal pdf \\(f_X(x)\\) (by ‚Äúmarginalizing out‚Äù the variable \\(Y\\)) or \\(f_Y(y)\\) (by ‚Äúmarginalizing out‚Äù the variable \\(X\\))."
  },
  {
    "objectID": "writeups/marginalization/index.html#marginalization-in-discrete-world",
    "href": "writeups/marginalization/index.html#marginalization-in-discrete-world",
    "title": "Marginal Distributions and ‚ÄúMarginalizing Out‚Äù A Variable",
    "section": "Marginalization In Discrete World",
    "text": "Marginalization In Discrete World\nMarginalization provides an example of where, unlike the case for some topics in the course, having a good intuition for the discrete case will actually help us a ton even when considering the continuous case. So, let‚Äôs start out by thinking through a joint discrete distribution, and thinking about what a marginal distribution derived from this joint discrete distribution actually represents.\nConsider a case where we are the principal at a ‚Äúsenior high school‚Äù (in the US, this means a high school/secondary school that students attend for grades 10, 11, and 12), where each student is in some grade but also has an honor student status which is 1 if the student is an honor student and 0 otherwise. We can represent the discrete frequency distribution (not that it is not a probability distribution, since the numbers in each ‚Äúbin‚Äù are not between 0 and 1) using the following raw frequency table:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\\(G = 11\\)\n6\n4\n\n\n\\(G = 12\\)\n7\n1\n\n\n\nSo far, we can‚Äôt use this table for much of anything, since it doesn‚Äôt contain probabilities and we also don‚Äôt (yet) know the total number of students, so that we don‚Äôt know what proportions of all students fall into each bin.\nSo now let‚Äôs say someone asks us the probability that, if we randomly select a student from the school (at uniform), the randomly-selected student will be an honor student in 11th grade.\nBy thinking about what specifically they‚Äôre asking for here, we can see that they‚Äôre asking us a question about the joint distribution of \\(G\\) and \\(H\\) at the school: specifically, they‚Äôre asking us for \\(\\Pr(G = 11, H = 1)\\), a question we can answer if we know the joint distribution \\(f_{G,H}(v_G, v_H)\\).\nUsing our na√Øve definition of probability, we can compute this probability using the frequencies in the table as\n\\[\n\\Pr(G = 11, H = 1) = \\frac{\\#(G = 11, H = 1)}{\\#\\text{ Students Total}}\n\\]\nand, plugging in the values from the above table, we obtain the answer\n\\[\n\\Pr(G = 11, H = 1) = \\frac{4}{33} \\approx 0.121\n\\]\nFollowing the same logic for all remaining cells in the table, we can convert our frequency table into a probability table by normalizing the counts to be proportions of the total. But, let‚Äôs think about two different ways we could compute the total number of students, since we‚Äôll need to think about these two ways later on:\n\nComputing Overall Total by Column (Honors-Status Totals)\nStarting from our original frequency table:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\\(G = 11\\)\n6\n4\n\n\n\\(G = 12\\)\n7\n1\n\n\n\nWe could start computing the total number of students by summing columns, to obtain:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\\(G = 11\\)\n6\n4\n\n\n\\(G = 12\\)\n7\n1\n\n\nTotal\n23\n10\n\n\n\nAnd then we could total these two numbers in the totals row to obtain the overall total:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\n\\(G = 11\\)\n6\n4\n\n\n\n\\(G = 12\\)\n7\n1\n\n\n\nTotal\n23\n10\n33\n\n\n\n\n\nComputing Overall Total by Row (Grade)\nAs an alternative to starting our computation of the overall totals by summing columns, we could start by summing rows.\nStarting from our original frequency table:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\\(G = 11\\)\n6\n4\n\n\n\\(G = 12\\)\n7\n1\n\n\n\nWe could first sum each row, to obtain:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n10\n5\n15\n\n\n\\(G = 11\\)\n6\n4\n10\n\n\n\\(G = 12\\)\n7\n1\n8\n\n\n\nAnd then we could total the three partial sums in the totals column to obtain the overall total:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n10\n5\n15\n\n\n\\(G = 11\\)\n6\n4\n10\n\n\n\\(G = 12\\)\n7\n1\n8\n\n\nTotal\n\n\n33\n\n\n\n\n\nBringing Both Methods Together\nNotice how we obtained the same overall total, the total number of students, regardless of which dimension we chose to sum over first. So, let‚Äôs make a complete frequency table, where we have not only the frequencies of each bin but also the row totals, column totals, and a cell in the bottom-right representing the overall total:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n10\n5\n15\n\n\n\\(G = 11\\)\n6\n4\n10\n\n\n\\(G = 12\\)\n7\n1\n8\n\n\nTotal\n23\n10\n33\n\n\n\n\n\nConverting Frequencies into Probabilities\nNow, before we think about the totals row/column, let‚Äôs use the overall total (33) to convert our counts into probabilities:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{5}{33}\\)\n\\(\\frac{15}{33}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{33}\\)\n\\(\\frac{4}{33}\\)\n\\(\\frac{10}{33}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{33}\\)\n\\(\\frac{1}{33}\\)\n\\(\\frac{8}{33}\\)\n\n\nTotal\n\\(\\frac{23}{33}\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{33}{33}\\)\n\n\n\n\n\nMore Than One Distribution Can Be Derived From This Table!\nNow that we see the normalized counts, we can see the different ways we can look at this table to obtain probability distributions:\n\nFirst, there‚Äôs the distribution we were originally thinking about: the entries in each non-total cell form a probabiltiy distribution called the joint distribution of \\(G\\) and \\(H\\), since each entry is between 0 and 1 and the entries sum to 1:\n\n\\[\n\\begin{align*}\n&\\underbrace{\\Pr(G = 10, H = 0)}_{10 / 33} + \\underbrace{\\Pr(G = 10, H = 1)}_{5 / 33} + \\\\\n&\\underbrace{\\Pr(G = 11, H = 0)}_{6 / 33} + \\underbrace{\\Pr(G = 11, H = 1)}_{4 / 33} + \\\\\n&\\underbrace{\\Pr(G = 12, H = 0)}_{7 / 33} + \\underbrace{\\Pr(G = 12, H = 1)}_{1 / 33} = 1\n\\end{align*}\n\\]\n\nBut, we can also notice that the two entries in the totals row (excluding the overall total) form a probability distribution, called the marginal distribution of \\(H\\):\n\n\\[\n\\begin{align*}\n\\underbrace{\\Pr(H = 0)}_{23 / 33} + \\underbrace{\\Pr(H = 1)}_{10 / 33} = 1\n\\end{align*}\n\\]\n\nAnd, the three entries in the totals column (excluding the overall total) form a probability distribution, called the marginal distribution of \\(G\\):\n\n\\[\n\\underbrace{\\Pr(G = 10)}_{15 / 33} + \\underbrace{\\Pr(G = 11)}_{10 / 33} + \\underbrace{\\Pr(G = 12)}_{8 / 33} = 1\n\\]\nLet‚Äôs consider in a little more detail how we used the joint distribution‚Äîthe full set of entries in the original table‚Äîto derive two different marginal distributions:\nSumming the values in each column:\nWhen we summed up the values in each column, we were summing up all possible pdf values \\(f_{G,H}(v_G, v_H)\\) where \\(v_H = 0\\) and then all possible pdf values \\(f_{G,H}(v_G, v_H)\\) where \\(v_H = 1\\). This gave us two new counts (or probabilities, if used the probability table rather than the frequency table) representing the marginal distribution of \\(H\\), a distribution where the variable \\(G\\) no longer appeared!\nSumming the values in each row:\nWhen we instead summed the values in each row, we summed all possible pdf values \\(f_{G,H}(v_G, v_H)\\) where \\(v_G = 10\\), then all possible pdf values \\(f_{G,H}(v_G, v_H)\\) where \\(v_G = 11\\), and finally all possible pdf values \\(f_{G,H}(v_G, v_H)\\) where \\(v_G = 12\\). This gave us three new counts/probabilities representing the marginal distribution of \\(G\\), a distribution where the variable \\(H\\) no longer appeared!"
  },
  {
    "objectID": "writeups/marginalization/index.html#whats-missing-conditional-distributions",
    "href": "writeups/marginalization/index.html#whats-missing-conditional-distributions",
    "title": "Marginal Distributions and ‚ÄúMarginalizing Out‚Äù A Variable",
    "section": "What‚Äôs Missing? Conditional Distributions",
    "text": "What‚Äôs Missing? Conditional Distributions\nSo far we‚Äôve discussed the interrelationship between joint distributions and marginal distributions: the latter was obtained from the former by summing.\nHowever, there is one type of distribution that is mentioned on your Lab assignment that we haven‚Äôt seen yet. The conditional distribution is a bit different from the joint and marginal distributions, in the sense that the conditional distribution does not represent a sum across some dimension of the table but a slice of the table: that is, it represents the new distribution which ‚Äúpops out‚Äù when we consider one particular row or one particular column of the table.\nHowever, just like how above we figured out the marginal distributions by summing over columns and summing over rows separately, and seeing what resulted, let‚Äôs explore what conditional distributions look like by slicing the table by column first, then slicing the table by row:\n\nComputing Conditional Distributions as Columns (Honors-Status Values)\nLet‚Äôs consider what the table would look like if we just selected a single column: for example, let‚Äôs select just the column of values for which \\(H = 1\\). Throwing away all of the other columns in the table, this would give us a one-column table that looks like:\n\n\n\n\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n5\n\n\n\\(G = 11\\)\n4\n\n\n\\(G = 12\\)\n1\n\n\nTotal\n10\n\n\n\nNow notice that, just like how we were able to convert our frequency table into a probability table representing joint probabilities by dividing each of these values by 33 (the overall total of students across all possible grades and honors-status values), now we can convert this slice of the full table into its own distribution by dividing each of these individual values in the \\(H = 1\\) column by the total number of students in the \\(H = 1\\) column:\n\n\n\n\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{5}{10}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{4}{10}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{1}{10}\\)\n\n\nTotal\n\\(\\frac{10}{10}\\)\n\n\n\nNotice how, unlike in the above two cases, we now have to interpret the numeric value of the probabilities in each cell differently:\n\nJoint and marginal distributions represented some count relative to the total number of students in the school, hence the denominator of all probabilities in either of these cases was 33\nConditional distributions, however, represent a count relative to the number of students within the category we are conditioning on: the denominator is now 10 in each case, since we‚Äôre considering the number of students represented by each cell within the column as a proportion of the total number of students across the entire column."
  },
  {
    "objectID": "writeups/marginalization/index.html#discrete-world-summary",
    "href": "writeups/marginalization/index.html#discrete-world-summary",
    "title": "Marginal Distributions and ‚ÄúMarginalizing Out‚Äù A Variable",
    "section": "Discrete World Summary",
    "text": "Discrete World Summary\nSo, as long as we notice that conditional distributions are weird in the sense that they require us to renormalize all of our probabilities from our table of joint and marginal distributions, we now have the link between all three types of distributions that get talked about when working with multivariate probability distributions:\n\nA single joint distribution: The normalized counts in each cell of the full 2D table; in other words, the probability that a randomly-selected student from across the entire school will be in a particular bin (when students are binned by grade and honors status).\n\nFor example, the bin in the upper-left corner of our original table represents non-honors students in 10th grade (\\(G = 10, H = 0\\)).\n\nTwo marginal distributions: The normalized totals across each row, or across each column, of the full 2D table; in other words, the probability that a randomly-selected student from across the entire school will be in a particular aggregated bin.\n\nIf we aggregated by summing columns, for example, our first aggregated bin represents all non-honors students, students for whom \\(H = 0\\) (regardless of grade), and our second aggregated bin contains all honors students, students for whom \\(H = 1\\) (regardless of grade).\n\nSix possible conditional distributions: The re-normalized counts within a particular column or a particular row; in other words, the probability that a randomly-selected student from a particular category (the category we‚Äôre conditioning on) will be in one of the bins represented by individual slots within this row/column.\n\nIf we conditioned on the \\(H = 1\\) column, for example, then once we renormalize the counts in this column, the first entry represents the probability of a randomly-selected honors student being in grade 10: \\(\\Pr(G = 10 \\mid H = 1)\\)\n\n\nNotice, lastly, how we could use this intuition built from frequency tables to figure out how to go in opposite directions from the directions we derived things above: for example, if we were only given marginal distributions and conditional distributions, we could use this information to derive the full-on joint distribution table. Since we know the definition of conditional probability for example, that\n\\[\n\\Pr(B \\mid A) = \\frac{\\Pr(B, A)}{\\Pr(A)},\n\\]\nwe could re-arrange terms in this equality to obtain\n\\[\n\\Pr(B, A) = \\Pr(B \\mid A)\\Pr(A),\n\\]\nfrom which we can see that if we know the conditional distribution \\(\\Pr(B \\mid A)\\) and the marginal distribution \\(\\Pr(A)\\), we can combine these (via multiplication) to obtain the joint distribution \\(\\Pr(B,A)\\)."
  },
  {
    "objectID": "writeups/marginalization/index.html#moving-to-continuous-world",
    "href": "writeups/marginalization/index.html#moving-to-continuous-world",
    "title": "Marginal Distributions and ‚ÄúMarginalizing Out‚Äù A Variable",
    "section": "Moving to Continuous World",
    "text": "Moving to Continuous World\nThe reason I‚Äôve spent so much time focusing on the discrete case here is because the intuitions we just built do indeed translate naturally into good intuitions for reasoning about continuous distributions!\nTaking our discrete table, for example, we can imagine moving into continuous space the same way that we learned how to take discrete rectangles approximating the the space underneath a curve and convert them into integrals: by taking the limit of the area of these rectangles as they got skinnier and skinnier:\n\n\n\n\n\nIn the above figure, we see how we can imagine summing the area of rectangles approximating the area ‚Äúunder‚Äù the curve (really, between the curve and the \\(x\\)-axis), then imagine the rectangles becoming skinnier and skinnier such that the sum of the rectangles‚Äô areas converges to the integral of the function.\nSimilarly, now imagine taking the above table and continuizing our variables: imagine that instead of a student‚Äôs progress in school being recorded by a discrete random variable \\(G\\) such that \\(\\mathcal{R}_G = \\{10, 11, 12\\}\\), now we record a student‚Äôs progress using a continuous random variable \\(G\\) such that \\(\\mathcal{R}_G = [10,12] \\subset \\mathbb{R}\\).\nBy the same logic, rather than tracking each student‚Äôs honor status using a discrete random variable \\(H\\) such that \\(\\mathcal{R}_H = \\{0, 1\\}\\), now we keep track of a student‚Äôs honor status using a continuous random variable \\(H\\) such that \\(\\mathcal{R}_H = [0, 1] \\subset \\mathbb{R}\\).\nIn this new continuous world, therefore, we might say that a student near the beginning of 10th grade who is towards the ‚Äúhigh end‚Äù of the ‚Äúhonors spectrum‚Äù might be represented by a pair of values \\(G = 10.03\\) and \\(H = 0.95\\), for example.\nHowever, in this case we can still derive all of the distributions from other distributions in the same way, by:\n\nReplacing the sums we computed above with integrals, and\nReplacing the operation of re-normalization (which we performed to ensure that our probability mass values summed to 1) with the operation of ensuring that our probability density values integrate to 1.\n\nSo, for example, now rather than being given a frequency table, we may just be given the information that students‚Äô \\(G\\) values are distributed according to the continuous uniform distribution, \\(G \\sim \\mathcal{U}(10, 12)\\), that their \\(H\\) values are distributed according to the truncated normal distribution \\(\\mathcal{TN}(\\mu = 0.5, \\sigma = 0.1, a = 0, b = 1)\\)1, and that these two variables are independent, which means that \\(\\Pr(G \\mid H) = \\Pr(G)\\) and \\(\\Pr(H \\mid G) = \\Pr(H)\\) (the conditional distributions are the marginal distributions).\nIn this case, then, we know (by the definition of independence) that we can obtain the joint pdf \\(f_{G,H}(v_G, v_H)\\) by just multiplying the pdf of the marginal distribution of \\(G\\), \\(f_G(v_G)\\) and the pdf of the marginal distribution of \\(H\\), \\(f_H(v_H)\\):\n\\[\nf_{G,H}(v_G, v_H) = f_G(v_G) \\cdot f_H(v_H).\n\\]\nSince we know that \\(G\\) has a continuous uniform distribution, \\(G \\sim \\mathcal{U}(10,12)\\), we know (or we could look up) that \\(G\\) has pdf\n\\[\nf_G(v_G) = \\frac{1}{12 - 10} = \\frac{1}{2}.\n\\]\nSince we know that \\(H\\) has a truncated normal distribution, \\(H \\sim \\mathcal{TN}(0.5, 0.1, 0, 1)\\), we know (or we could look up) that \\(H\\) has the pdf\n\\[\nf_H(v_H) = \\frac{1}{\\sigma}\\frac{\\varphi(\\frac{v_H-\\mu}{\\sigma})}{\\Phi(\\frac{b-\\mu}{\\sigma}) - \\Phi(\\frac{a - \\mu}{\\sigma})},\n\\]\nwhere \\(\\varphi\\) is the pdf of the standard normal distribution \\(\\mathcal{N}(0,1)\\) and \\(\\Phi\\) is the CDF of the standard normal distribution \\(\\mathcal{N}(0,1)\\) (note the consistent usage of lowercase letters to describe pdfs and capital letters to describe CDFs, even in Greek!).\nTherefore, given the independence condition, we can obtain the joint pdf \\(f_{G,H}(v_G, v_H)\\) by just multiplying these pdfs:\n\\[\nf_{G,H}(v_G, v_H) = \\frac{1}{2\\sigma}\\frac{\\varphi(\\frac{v_H-\\mu}{\\sigma})}{\\Phi(\\frac{b-\\mu}{\\sigma}) - \\Phi(\\frac{a - \\mu}{\\sigma})}.\n\\]\nAnd, given this joint pdf, we can integrate wherever we took sums in the discrete case to obtain the marginal pdfs:\n\\[\nf_G(v_G) = \\int_{0}^{1}f_{G,H}(v_G,v_H)dv_H\n\\]\nor\n\\[\nf_H(v_H) = \\int_{10}^{12}f_{G,H}(v_G, v_H)dv_G\n\\]\nAnd we can compute conditional pdfs by renormalizing so that the denominator is no longer the integral of the distribution over all its possible values (hence just the number \\(1\\)) but a ratio of joint distribution to marginal distribution values like the following:\n\\[\nf_{H \\mid G}(v_H | v_G) = \\frac{f_{G,H}(v_G, v_H)}{f_G(v_G)}.\n\\]\nSo, while the continuous case does have scarier math than the discrete case, I hope that rather than ‚Äúlingering‚Äù in the continuous world, trying to churn through the meaning of the above equations on their own, you can instead try to link the continuous equations back to their simpler discrete forms given in the previous section, then just convert sums to integrals to complete the picture. That way, you never have to just stare at an integral-filled equation again.\nFor example, given two continuous variables with confusing-looking pdfs or CDFs, start by discretizing (‚Äúbinning‚Äù) the possible values of these continuous values, to obtain a discrete distribution, and build up your intuitions about the relationships between the variables in discrete world.\nIn the previous case, for example, if you were asked to start with the continuous version where \\(G\\) ranges continuously across \\([10,12]\\) and \\(H\\) ranges continuously across \\([0,1]\\), you could start by discretizing these continuous distributions to obtain a table very similar to the table presented at the very beginning of this writeup: if you split the range \\([10,12]\\) into three bins of equal length, and the range \\([0,1]\\) into two bins of equal length, you can start by sampling (say) 1000 \\(G\\) and \\(H\\) values using code, sorting these 1000 samples into these equal-length bins, and reasoning through what the joint/marginal/conditional distributions of this binned distribution look like, before moving back over into continuous world to complete the various portions of the problem‚Ä¶"
  },
  {
    "objectID": "writeups/marginalization/index.html#footnotes",
    "href": "writeups/marginalization/index.html#footnotes",
    "title": "Marginal Distributions and ‚ÄúMarginalizing Out‚Äù A Variable",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis may look scary, but \\(\\mathcal{TN}(\\mu, \\sigma, a, b)\\) just says: start by sampling a value \\(x\\) from the normal distribution \\(\\mathcal{N}(\\mu, \\sigma)\\), but then: if \\(x &lt; a\\) transform this value to just be \\(a\\), and if \\(x &gt; b\\) then transform this value to just be \\(b\\). In other words, if \\(x \\sim \\mathcal{N}(\\mu, \\sigma)\\), we can obtain a truncated-normal-distributed variable \\(x'\\) from the normally-distributed variable \\(x\\) as \\(x' = \\begin{cases}x &\\text{if }a &lt; x &lt; b \\\\a &\\text{if }x &lt; a \\\\ b &\\text{if }x &gt; b\\end{cases}\\)‚Ü©Ô∏é"
  },
  {
    "objectID": "writeups/order-of-integration/index.html",
    "href": "writeups/order-of-integration/index.html",
    "title": "Continuous Probability and the Order of Integration",
    "section": "",
    "text": "Code\nsource(\"../../dsan-globals/_globals.r\")\nProblem 2e on your Lab 5 Assignment, which asks you to:\nis trickier than most of the other parts/problems, in the sense that it really requires us to think carefully about what exactly we‚Äôre doing when we take integrals to obtain probabilities from probability density functions. So, in this writeup, I want to walk through that problem step-by-step, showing where the ‚Äútrickiness‚Äù enters into the problem."
  },
  {
    "objectID": "writeups/order-of-integration/index.html#using-our-intuition-without-geometry",
    "href": "writeups/order-of-integration/index.html#using-our-intuition-without-geometry",
    "title": "Continuous Probability and the Order of Integration",
    "section": "Using Our Intuition (Without Geometry)",
    "text": "Using Our Intuition (Without Geometry)\nIn this part I‚Äôm going to show how, if we ignore some of the details of the problem, we might think of the two following ways to go about obtaining the answer, which on the surface seem like equally ‚Äúgood‚Äù ways to go about it:\n\nApproach 1: Inner integral over \\(Y\\), outer integral over \\(X\\)\n\nIntegrate the joint pdf \\(f_{X,Y}(x,y)\\) from \\(y = x\\) to the maximum value that \\(y\\) can take on, that is, from \\(y = x\\) to \\(y = 3\\), then\nIntegrate the result from (1) over the full range of values \\(x\\) can take on, that is, from \\(x = 0\\) to \\(x = 2\\).\n\nApproach 2: Inner integral over \\(X\\), outer integral over \\(Y\\)\n\nIntegrate the joint pdf \\(f_{X,Y}(x,y)\\) from \\(x = 0\\) to \\(x = y\\), then\nIntegrate the result from (1) over the full range of values \\(y\\) can take on, that is, from \\(y = 0\\) to \\(y = 3\\)\n\n\nUsing the joint pdf \\(f_{X,Y}(x,y)\\) that we obtained in earlier parts of the problem,\n\\[\nf_{X,Y}(x,y) = 3C(x^2 + 2xy^2) = \\frac{1}{44}(x^2 + 2xy^2),\n\\]\ncarrying out the math for Approach 1 gives us the following result (skipping many many steps):\n\\[\n\\begin{align*}\n\\Pr(X \\leq Y) &= \\int_{0}^{2}\\int_{x}^{3}f_{X,Y}(x,y)~dy~dx \\\\\n&= \\frac{1}{132} \\int_0^2 (9x^2 + 54x - 3x^3 - 2x^4)~dx \\\\\n&= \\frac{1}{132}\\cdot \\frac{536}{5} \\approx 0.812~‚úÖ\n\\end{align*}\n\\]\nSo far, we can at least be a bit assured by the fact that we‚Äôve obtained a value between 0 and 1, hence a valid probability value1.\nCarrying out the math for Approach 2 in the same way, however, gives us something strange:\n\\[\n\\begin{align*}\n\\Pr(X \\leq Y) &= \\int_{0}^{3}\\int_{0}^{y}f_{X,Y}(x,y)~dx~dy \\\\\n&= \\frac{1}{132}\\int_{0}^{3} y^3 + 3y^4 \\\\\n&= \\frac{1}{132}\\cdot \\frac{3321}{20} \\approx 1.258~üò≥\n\\end{align*}\n\\]\nSo what happened?"
  },
  {
    "objectID": "writeups/order-of-integration/index.html#finding-the-issue-by-thinking-geometrically",
    "href": "writeups/order-of-integration/index.html#finding-the-issue-by-thinking-geometrically",
    "title": "Continuous Probability and the Order of Integration",
    "section": "Finding The Issue By Thinking Geometrically",
    "text": "Finding The Issue By Thinking Geometrically\nThere are a lot of ways we could stop and try to diagnose what‚Äôs going on here, but the approach that helped me most in thinking through this problem was to plot out the space over which we‚Äôre integrating the joint pdf, geometrically:\nHere I create what is sometimes called a ‚Äúmesh grid‚Äù, by running the expand_grid() function (from tidyverse, which replaces the base-R expand.grid() function you have already seen, but isn‚Äôt very different) to create a grid of points, where these points‚Äô \\(x\\) values are drawn from x and their \\(y\\) values are drawn from y:\n\n\nCode\nlibrary(tidyverse)\nx &lt;- seq(from = 0, to = 2, by = 0.01)\ny &lt;- seq(from = 0, to = 3, by = 0.01)\nxy_df &lt;- expand_grid(x, y)\n# Display the first and last 6 rows\nxy_df |&gt; head(); xy_df |&gt; tail()\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n0.00\n\n\n0\n0.01\n\n\n0\n0.02\n\n\n0\n0.03\n\n\n0\n0.04\n\n\n0\n0.05\n\n\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n2\n2.95\n\n\n2\n2.96\n\n\n2\n2.97\n\n\n2\n2.98\n\n\n2\n2.99\n\n\n2\n3.00\n\n\n\n\n\n\nNext I use the mutate() function to create a new variable, x_leq_y, on the basis of this grid, and look at the count of the number of points in my grid which do and do not satisfy the boolean expression x &lt;= y:\n\n\nCode\nxy_df &lt;- xy_df |&gt; mutate(\n  x_leq_y = as.numeric(x &lt;= y)\n)\nxy_df |&gt; group_by(x_leq_y) |&gt; count(.drop=FALSE)\n\n\n\n\n\n\nx_leq_y\nn\n\n\n\n\n0\n20100\n\n\n1\n40401\n\n\n\n\n\n\nFinally, I use ggplot with the geom_tile() geometry to create a simple but helpful visualization of the subset of \\([0,2] \\times [0,3]\\) within which the boolean condition is true (and where I have explicitly drawn lines showing the boundaries within which the point \\((x,y)\\) has a non-zero probability density, as well as the function \\(f(x) = x\\), which will both come in handy later):\n\n\nCode\nlibrary(latex2exp)\nggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  stat_function(fun = function(x) x) +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    fill = TeX(\"$X \\\\leq Y$\"),\n    title = \"The Integration Space, in 2D\"\n  ) +\n  scale_fill_discrete(labels=c(\"False\",\"True\"))\n\n\n\n\n\n\n\n\n\nAnd now let‚Äôs use this plot to think about what we‚Äôre doing in both Approach 1 and Approach 2.\n\nApproach 1\nTo think through the double integral in this case, visually, I like to imagine ‚Äúsweeping‚Äù over the space across one dimension when computing the inner integral, then ‚Äúsweeping‚Äù over the space across the other dimension when computing the outer integral.\nRemember that the double integral in Approach 1 was set up as follows:\n\\[\n\\begin{align*}\n\\Pr(X \\leq Y) &= \\int_{0}^{2}\\int_{x}^{3}f_{X,Y}(x,y)~dy~dx\n\\end{align*}\n\\]\nSo, in this case, we can add some arrows to our plot to show the ‚Äúsweeping‚Äù which is occurring when we compute the inner integral. Since the inner integral is from \\(y = x\\) to \\(y = 3\\), I think of arrows sweeping upwards from the line \\(y = x\\) to the (horizontal) line \\(y = 3\\).\nSo, to make the diagram on the left side of the figure below, which represents the inner integral, I use:\n\nDashed yellow lines to represent the bounds between which we‚Äôre ‚Äúsweeping‚Äù, and\nDashed arrows to represent the direction of the sweeping\n\nThen to make the diagram on the right, which represents the outer integral, I use:\n\nSolid yellow lines to represent the bounds between which we‚Äôre sweeping, and\nSolid arrows to represent the direction of the sweeping\n\nWhich means that ultimately, after computing the two integrals, we have integrated over the region of the \\(xy\\)-plane bounded by the dashed and solid yellow lines.\n\n\nCode\nlibrary(patchwork)\nlibrary(latex2exp)\n# blw = Boundary line width\nblw &lt;- 1\n# blc = Boundary line color\nblc &lt;- 'yellow'\na1_inner_xvals &lt;- c(0.05, 0.5, 1, 1.5, 1.95)\na1_inner_df &lt;- tibble(x=a1_inner_xvals)\na1_inner_df &lt;- a1_inner_df |&gt; mutate(\n    xend = x,\n    y = x,\n    yend = 3\n)\na1_inner_plot &lt;- ggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  stat_function(fun = function(x) x) +\n  geom_segment(data=a1_inner_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='dashed', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  # Inner integral, lower bound\n  geom_segment(x=0, y=0, xend=2, yend=2, color=blc, linewidth=blw, linetype='dashed') +\n  # Inner integral, upper bound\n  geom_segment(x=0, y=3, xend=2, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    title = \"A1.1: Inner Integral\"\n  ) +\n  remove_legend()\n\na1_outer_yvals &lt;- c(0.05, 0.5, 1, 1.5, 2, 2.5, 2.95)\na1_outer_df &lt;- tibble(y=a1_outer_yvals)\na1_outer_df &lt;- a1_outer_df |&gt; mutate(\n    yend = y,\n    x = 0,\n    xend = 2\n)\n\na1_outer_plot &lt;- ggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(data=a1_inner_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='dashed', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_segment(data=a1_outer_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='solid', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  stat_function(fun = function(x) x) +\n  # Inner integral, lower bound\n  geom_segment(x=0, y=0, xend=2, yend=2, color=blc, linewidth=blw, linetype='dashed') +\n  # Inner integral, upper bound\n  geom_segment(x=0, y=3, xend=2, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  # Outer integral, lower bound\n  geom_segment(x=0, y=0, xend=0, yend=3, color=blc, linewidth=blw, linetype='solid') +\n  # Outer integral, upper bound\n  geom_segment(x=2, y=0, xend=2, yend=3, color=blc, linewidth=blw, linetype='solid') +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    title = \"A1.2: Outer Integral\"\n  ) +\n  remove_legend()\na1_inner_plot + a1_outer_plot\n\n\n\n\n\n\n\n\n\nNote how, since the inner integral in this case already excluded all points lying beneath the line \\(y = x\\) (the dashed yellow diagonal line), it actually didn‚Äôt matter that our outer integral went over this ‚Äúboundary line‚Äù: the overall result of the double-integration only sums up the values of the pdf in the range bounded by the yellow lines. In other words, even though the outer integral does ‚Äúsweep‚Äù over the dashed yellow diagonal \\(y = x\\) line, thus sweeping outside of the range of valid values of \\(x\\), it did not have any density here to sum up, since all of the probability density in this red triangle had been left out of the inner integral.\n(If that last paragraph didn‚Äôt make sense to you, don‚Äôt worry about it! Just stick to the pictures for intuition)\n\n\nApproach 2\nOn the other hand, recall that the double integral in Approach 2 was set up as follows:\n\\[\n\\begin{align*}\n\\Pr(X \\leq Y) &= \\int_{0}^{3}\\int_{0}^{y}f_{X,Y}(x,y)~dx~dy\n\\end{align*}\n\\]\nGiven this double integral setup, we can employ this same way of thinking about integration (as ‚Äúsweeping‚Äù across a dimension) to obtain the following diagram, which helps illustrate why we obtain a value greater than 1 in this case:\n\n\nCode\na2_inner_yvals &lt;- c(0.5, 1, 1.5, 2, 2.5, 2.95)\na2_inner_df &lt;- tibble(y=a2_inner_yvals)\na2_inner_df &lt;- a2_inner_df |&gt; mutate(\n    yend = y,\n    x = 0.05,\n    xend = y\n)\nribbon_xvals &lt;- seq(from = 2, to = 3, by = 0.01)\nribbon_df &lt;- tibble(x=ribbon_xvals, y=ribbon_xvals)\na2_inner_plot &lt;- ggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(data=a2_inner_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='dashed', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_ribbon(data=ribbon_df, aes(x=x, ymin=y, ymax=3), alpha=0.333) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  stat_function(fun=function(x) x) +\n  # Inner integral, lower bound\n  geom_segment(x=0, y=0, xend=0, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  # Inner integral, upper bound\n  geom_segment(x=0, y=0, xend=3, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    title = \"A2.1: Inner Integral\"\n  ) +\n  remove_legend()\n\na2_outer_xvals &lt;- c(0.05, 0.5, 1, 1.5, 1.95, 2.5, 2.95)\na2_outer_df &lt;- tibble(x=a2_outer_xvals)\na2_outer_df &lt;- a2_outer_df |&gt; mutate(\n    xend = x,\n    y = 0,\n    yend = 2.95\n)\n\na2_outer_plot &lt;- ggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(data=a2_inner_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='dashed', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_segment(data=a2_outer_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='solid', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_ribbon(data=ribbon_df, aes(x=x, ymin=y, ymax=3), alpha=0.333) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  stat_function(fun=function(x) x) +\n  # Inner integral, lower bound\n  geom_segment(x=0, y=0, xend=0, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  # Inner integral, upper bound\n  geom_segment(x=0, y=0, xend=3, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  # Outer integral, lower bound\n  geom_segment(x=0, y=0, xend=3, yend=0, color=blc, linewidth=blw, linetype='solid') +\n  # Outer integral, upper bound\n  geom_segment(x=0, y=3, xend=3, yend=3, color=blc, linewidth=blw, linetype='solid') +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    title = \"A2.2: Outer Integral\"\n  ) +\n  remove_legend()\na2_inner_plot + a2_outer_plot\n\n\n\n\n\n\n\n\n\nSo we see that, whereas in Approach 1 everything worked out since the line \\(y = x\\) was suitable as a mathematical representation of the entire lower bound of \\(y\\), here in Approach 2 we cannot use the line \\(y = x\\) on its own to characterize the upper bound on \\(x\\), since this will include the grey triangle in the diagram above as part of the region over which we‚Äôre integrating the joint pdf."
  },
  {
    "objectID": "writeups/order-of-integration/index.html#fixing-the-issue",
    "href": "writeups/order-of-integration/index.html#fixing-the-issue",
    "title": "Continuous Probability and the Order of Integration",
    "section": "Fixing The Issue",
    "text": "Fixing The Issue\n\nA Technically-Correct Fix\nThinking through the above statement a bit further: if we want to ‚Äúintegrate out‚Äù the \\(x\\) variable, the upper bound on \\(x\\) should instead be \\(\\min(2, y)\\). In other words, by looking at the above diagram, we can see that the following modification to our integral in Approach 2 would technically ‚Äúwork‚Äù to fix the problem, if it was easy to compute:\n\\[\n\\begin{align*}\n\\Pr(X \\leq Y) &= \\int_{0}^{3}\\int_{0}^{\\min(2, y)}f_{X,Y}(x,y)~dx~dy\n\\end{align*}\n\\]\nOne way of thinking about this is, if we had set our upper bounds in Approach 2 this way, the diagram showing the ‚Äúsweeping‚Äù over the \\(x\\) dimension would instead look like the following, where the yellow line traces out \\(x = \\min(2,y)\\) instead of \\(x = y\\) (the black line):\n\n\nCode\na2_inner_df_fixed &lt;- a2_inner_df |&gt; mutate(\n  xend = ifelse(xend &gt;= 2, 2, xend)\n)\na2_fixed_inner_plot &lt;- ggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(data=a2_inner_df_fixed, aes(x=x, y=y, xend=xend, yend=yend), linetype='dashed', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_ribbon(data=ribbon_df, aes(x=x, ymin=y, ymax=3), alpha=0.333) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  stat_function(fun=function(x) x) +\n  # Inner integral, lower bound\n  geom_segment(x=0, y=0, xend=0, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  # Inner integral, upper bound, segment 1\n  geom_segment(x=2, y=2, xend=2, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  # Inner integral, upper bound, segment 2\n  geom_segment(x=0, y=0, xend=2, yend=2, color=blc, linewidth=blw, linetype='dashed') +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    title = \"A2.1: Inner Integral\"\n  ) +\n  remove_legend()\n\na2_outer_df_fixed &lt;- a2_outer_df |&gt; filter(x &lt;= 2)\n\na2_fixed_outer_plot &lt;- ggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(data=a2_inner_df_fixed, aes(x=x, y=y, xend=xend, yend=yend), linetype='dashed', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_segment(data=a2_outer_df_fixed, aes(x=x, y=y, xend=xend, yend=yend), linetype='solid', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_ribbon(data=ribbon_df, aes(x=x, ymin=y, ymax=3), alpha=0.333) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  stat_function(fun=function(x) x) +\n  # Inner integral, lower bound\n  geom_segment(x=0, y=0, xend=0, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  # Inner integral, upper bound, segment 1\n  geom_segment(x=2, y=2, xend=2, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  # Inner integral, upper bound, segment 2\n  geom_segment(x=0, y=0, xend=2, yend=2, color=blc, linewidth=blw, linetype='dashed') +\n  # Outer integral, lower bound\n  geom_segment(x=0, y=0, xend=2, yend=0, color=blc, linewidth=blw, linetype='solid') +\n  # Outer integral, upper bound\n  geom_segment(x=0, y=3, xend=2, yend=3, color=blc, linewidth=blw, linetype='solid') +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    title = \"A2.2: Outer Integral\"\n  ) +\n  remove_legend()\na2_fixed_inner_plot + a2_fixed_outer_plot\n\n\n\n\n\n\n\n\n\n\n\nAvoiding \\(\\min()\\): A Quick Fix\nSince including fancy functions like \\(\\min()\\) and/or \\(\\max()\\) in our integral bounds makes things more complicated (to me, at least), one ‚Äúquick fix‚Äù way to handle this would be to just take the result of the original Approach 2 integral and subtract out the integral of the joint pdf within the grey triangle in the above diagrams.\n\n\nA More Practical/‚ÄúCorrect‚Äù Approach\nHowever, the more ‚Äúcorrect‚Äù way in a sense would be to ensure that we are never integrating over an area that is not in the support of \\((X,Y)\\). To accomplish this, we can observe that our Approach 2 integral would have worked and would have integrated only over the support of \\((X,Y)\\) if we had broken it up as follows:\n\\[\n\\Pr(X \\leq Y) = \\int_{0}^{2}\\int_{0}^{y}f_{X,Y}(x,y)~dx~dy + \\int_{2}^{3}\\int_{0}^{2}f_{X,Y}(x,y)~dx~dy\n\\]\nThus we‚Äôll call this way of integrating Approach 3, which can be visualized as follows:\n\n\nCode\na31_inner_yvals &lt;- c(0.5, 1, 1.5, 1.95)\na31_inner_df &lt;- tibble(y=a31_inner_yvals)\na31_inner_df &lt;- a31_inner_df |&gt; mutate(\n    yend = y,\n    x = 0.05,\n    xend = y\n)\na31_outer_xvals &lt;- c(0.05, 0.5, 1, 1.5, 1.95)\na31_outer_df &lt;- tibble(x=a31_outer_xvals)\na31_outer_df &lt;- a31_outer_df |&gt; mutate(\n    xend = x,\n    y = 0.05,\n    yend = 2\n)\na31_plot &lt;- ggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(data=a31_inner_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='dashed', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_segment(data=a31_outer_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='solid', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  stat_function(fun=function(x) x) +\n  # Lower bound, inner integral\n  geom_segment(x=0, y=0, xend=0, yend=2, color=\"yellow\", linewidth=1, linetype='dashed') +\n  # Upper bound, inner integral\n  geom_segment(x=0, y=0, xend=2, yend=2, color=\"yellow\", linewidth=1, linetype='dashed') +\n  # Lower bound, outer integral\n  geom_segment(x=0, y=0, xend=2, yend=0, color=\"yellow\", linewidth=1, linetype='solid') +\n  geom_segment(x=0, y=2, xend=2, yend=2, color=\"yellow\", linewidth=1, linetype='solid') +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    title = \"A3.1: First Integral\"\n  ) +\n  remove_legend()\n\na32_inner_yvals &lt;- c(2.05, 2.5, 2.95)\na32_inner_df &lt;- tibble(y=a32_inner_yvals)\na32_inner_df &lt;- a32_inner_df |&gt; mutate(\n    yend = y,\n    x = 0,\n    xend = 1.95\n)\na32_outer_xvals &lt;- c(0.05, 0.5, 1, 1.5, 1.95)\na32_outer_df &lt;- tibble(x=a32_outer_xvals)\na32_outer_df &lt;- a32_outer_df |&gt; mutate(\n    xend = x,\n    y = 2,\n    yend = 2.95\n)\n\na32_plot &lt;- ggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(data=a32_inner_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='dashed', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_segment(data=a32_outer_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='solid', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  # Lower bound of inner integral\n  geom_segment(x=0, y=2, xend=0, yend=3, color=\"yellow\", linewidth=1, linetype='dashed') +\n  geom_segment(x=2, y=2, xend=2, yend=3, color=\"yellow\", linewidth=1, linetype='dashed') +\n  geom_segment(x=0, y=3, xend=2, yend=3, color=\"yellow\", linewidth=1, linetype='solid') +\n  geom_segment(x=0, y=2, xend=2, yend=2, color='yellow', linewidth=1, linetype='solid') +\n  stat_function(fun=function(x) x) +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    title = \"A3.2: Second Integral\"\n  ) +\n  remove_legend()\na31_plot + a32_plot\n\n\n\n\n\n\n\n\n\nSo we see that the following steps give us the correct result:\n\nWe first integrate the joint pdf over the region displayed on the left: the triangle with vertices at \\((0,0)\\), \\((0,2)\\), and \\((2,2)\\))\nWe then integrate the joint pdf separately over the region displayed on the right: the square with vertices at \\((0,2)\\), \\((0,3)\\), \\((2,2)\\), and \\((2,3)\\)\nAnd then we obtain the total density of the pdf within the admissible (green) region by adding these two results together\n\nMathematically, this gives us (skipping many steps like we did before):\n\\[\n\\begin{align*}\n\\Pr(X \\leq Y) &= \\int_{0}^{2}\\int_{0}^{y}f_{X,Y}(x,y)~dx~dy + \\int_{2}^{3}\\int_{0}^{2}f_{X,Y}(x,y)~dx~dy \\\\\n&= \\frac{29}{165} + \\frac{7}{11} = \\frac{134}{165} \\approx 0.812,\n\\end{align*}\n\\]\nmatching the result from our original integral, performed in the opposite order.\nHopefully this way of breaking down the relationship between integration and probability can help you out: if you find yourself staring at a problem for too long, try breaking your brain out of the rut by seeing if diagrams like the above can help you reason through what the bounds of your integrals should be üòé"
  },
  {
    "objectID": "writeups/order-of-integration/index.html#footnotes",
    "href": "writeups/order-of-integration/index.html#footnotes",
    "title": "Continuous Probability and the Order of Integration",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that this does not mean we are necessarily correct! It just means that our result doesn‚Äôt ‚Äúbreak‚Äù any laws of probability.‚Ü©Ô∏é"
  },
  {
    "objectID": "writeups/sample-space-tibbles/index.html",
    "href": "writeups/sample-space-tibbles/index.html",
    "title": "Simulating Sample Spaces With Tibbles",
    "section": "",
    "text": "After working with a good number of students trying to set up a tibble (and/or data.frame) in R to represent the sample space of phone users problem in Quiz 1, and sort of winging it with a bunch of different approaches each time it came up, I decided to try and figure out some ‚Äústandardized‚Äù way to generate a tibble which will represent a given sample space, with minimal headaches, that will work every time! This is the result."
  },
  {
    "objectID": "writeups/sample-space-tibbles/index.html#step-0-what-do-i-mean-by-simulating-a-sample-space",
    "href": "writeups/sample-space-tibbles/index.html#step-0-what-do-i-mean-by-simulating-a-sample-space",
    "title": "Simulating Sample Spaces With Tibbles",
    "section": "Step 0: What Do I Mean By ‚ÄúSimulating‚Äù a Sample Space?",
    "text": "Step 0: What Do I Mean By ‚ÄúSimulating‚Äù a Sample Space?\nWhat I‚Äôm referring to here is, for example, the information you are given at the top of Quiz 1, stating that a random sample contained:\n\n340 people currently using an iPhone,\n185 people using a different phone who don‚Äôt want to switch phones ever, and\n232 people using a different phone but hoping to switch to an iPhone in the future.\n\nThe idea is that we can generate a tibble which ‚Äúencodes‚Äù this information in its rows, by allowing us to use the na√Øve definition of probability to compute probabilities of particular types of people: for example, say we are interested in the probability that a person in our sample uses an iPhone. Mathematically (by the na√Øve definition), if we construct a random variable \\(F\\) (for iFone, of course) representing the outcome of a randomly-selected person‚Äôs phone type (so that \\(F = 1\\) if the person we ask ends up being an iPhone user, and \\(F = 0\\) otherwise), then we can use the information from our sample to compute \\(\\Pr(F = 1)\\) as\n\\[\n\\Pr(F = 1) = \\frac{\\#\\text{ iPhone users in sample}}{\\#\\text{ People in sample}}\n\\tag{1}\\]\nThis means, therefore, that if we had a tibble called df where each row contained information on one particular person from our sample, then we could ‚Äútranslate‚Äù this naive definition formula into code as something like\nprob_F &lt;- nrow(df[df$iphone == 1,]) / nrow(df)\nSince here df[df$iphone == 1,] would subset the full df to keep only those rows corresponding to people with iPhones, while df itself (without any filters applied) would contain a row for each person. Literally, we are applying the following ‚Äútranslation‚Äù of the na√Øve definition-based formula (Equation¬†1) into code:\n\\[\n\\Pr(F = 1) = \\frac{\\overbrace{\\#}^{\\texttt{nrow}}\\overbrace{\\text{ iPhone users in sample}}^{\\texttt{df[df\\$iphone == 1]}}}{\\underbrace{\\#}_{\\texttt{nrow}}\\underbrace{\\text{ People in sample}}_{\\texttt{df}}}\n\\tag{2}\\]\nSimilarly, say we wanted to compute a conditional probability on the basis of our sample, like the probability of a person liking the feature (the feature mentioned in the quiz) given that they are an iPhone user. In this case, let \\(L\\) be an RV such that \\(L = 1\\) if the person likes the feature and \\(L = 0\\) otherwise. Then we can represent the probability we want in this case mathematically using the definition of conditional probability:\n\\[\n\\Pr(L = 1 \\mid F = 1) = \\frac{\\Pr(L = 1 \\cap F = 1)}{\\Pr(F = 1)}\n\\tag{3}\\]\nAnd then we can interpret this ratio (of \\(\\Pr(L = 1 \\cap F = 1)\\) to \\(\\Pr(F = 1)\\) using the na√Øve definition of probability to derive a new ‚Äúna√Øve definition-based equation for the same conditional probability‚Äù written mathematically in Equation¬†3:\n\\[\n\\Pr(L = 1 \\mid F = 1) = \\frac{\\#\\text{ iPhone users in sample who like feature}}{\\#\\text{ iPhone users in sample}}\n\\tag{4}\\]\nIn this case, since both the numerator and denominator are restricted to only those people in our sample who are iPhone users, we can make our lives easy by creating a new ‚Äúonly iPhone users‚Äù tibble, using code like\niphone_df &lt;- df[df$iphone == 1,]\nAnd, with this iPhone-users-only tibble now available to us, Equation¬†4 can be translated into code similarly to how we translated Equation¬†1 into code, as\nprob_L_given_F &lt;- nrow(iphone_df[iphone_df$like_feature == 1]) / nrow(iphone_df)\nWhere once again we have just applied the following set of ‚Äútranslations‚Äù to the na√Øve definition (this time the ‚Äúconditional na√Øve definition‚Äù):\n\\[\n\\Pr(L = 1 \\mid F = 1) = \\frac{\\overbrace{\\#}^{\\texttt{nrow}}\\overbrace{\\text{ iPhone users in sample who like feature}}^{\\texttt{iphone\\_df[iphone\\_df\\$likes\\_feature == 1]}}}{\\underbrace{\\#}_{\\texttt{nrow}}\\underbrace{\\text{ iPhone users in sample}}_{\\texttt{iphone\\_df}}}\n\\tag{5}\\]\nSo, all of the above shows you how to work with a sample-space-simulating tibble, once you have created it. The following steps will show you how to create such a sample-space-simulating tibble using functions from the tidyverse."
  },
  {
    "objectID": "writeups/sample-space-tibbles/index.html#step-1-identifying-types-of-people-in-the-sample",
    "href": "writeups/sample-space-tibbles/index.html#step-1-identifying-types-of-people-in-the-sample",
    "title": "Simulating Sample Spaces With Tibbles",
    "section": "Step 1: Identifying ‚ÄúTypes‚Äù of People in the Sample",
    "text": "Step 1: Identifying ‚ÄúTypes‚Äù of People in the Sample\nIn the case of the quiz, since each person in our sample is characterized by their values for 3 binary variables (\\(F\\) for iPhone, \\(W\\) for wants-to-switch, and \\(L\\) for likes-feature), we know that there are \\(2^3 = 8\\) possible types of people that could appear in the dataset:\n\n\n\nTable¬†1: The 8 possible types of people in our sample, sorted in terms of their binary representations (so that 000 corresponds to the non-iPhone, doesn‚Äôt-want-to-switch, and doesn‚Äôt-like-the-feature type; 001 corresponds to the non-iPhone, doesn‚Äôt-want-to-switch, and does-like-the-feature type; and so on.)\n\n\n\n\n\n\n\n\n\n\n\nType\n\\(F\\)(iPhone)\n\\(W\\)(Wants to switch)\n\\(L\\)(Likes feature)\n\n\n\n\n1\n0\n0\n0\n\n\n2\n0\n0\n1\n\n\n3\n0\n1\n0\n\n\n4\n0\n1\n1\n\n\n5\n1\n0\n0\n\n\n6\n1\n0\n1\n\n\n7\n1\n1\n0\n\n\n8\n1\n1\n1\n\n\n\n\n\n\nWe‚Äôll see why we are splitting people into these types in the next section, but here our next task is to fill out the missing ‚Äúnumber in sample‚Äù column with the number of people who have each of these combinations of properties, using the information given in the problem.\nFor example, since we know that there are 340 iPhone users in the sample, and we know that the probability of an iPhone user liking the feature is \\(0.8\\), we can compute the number of iPhone users who like the feature as\n\\[\n\\begin{align*}\n\\#\\text{ iPhone users who like feature} &= \\#\\text{ iPhone users} \\cdot 0.8 \\\\\n&= 340 \\cdot 0.8 = 272.\n\\end{align*}\n\\]\nWorking out the numbers for all the other types in a similar way (rounding to the nearest integer in cases where we don‚Äôt get integers, and also assuming that all iPhone users just have a \\(W\\) value of \\(0\\), since they don‚Äôt want to switch to an iPhone because they already have an iPhone), we arrive at the following counts [see the Appendix below for full details of the computations]:\n\n\n\nTable¬†2: The same list of types as in Table¬†1, now with an additional column where we‚Äôve computed the number of times that each type appears in our sample (on the basis of the info given in the assignment)\n\n\n\n\n\n\n\n\n\n\n\n\nType\n\\(F\\)(iPhone)\n\\(W\\)(Wants to switch)\n\\(L\\)(Likes feature)\nNumber in Sample\n\n\n\n\n1\n0\n0\n0\n89\n\n\n2\n0\n0\n1\n96\n\n\n3\n0\n1\n0\n121\n\n\n4\n0\n1\n1\n111\n\n\n5\n1\n0\n0\n68\n\n\n6\n1\n0\n1\n272\n\n\n7\n1\n1\n0\n0\n\n\n8\n1\n1\n1\n0"
  },
  {
    "objectID": "writeups/sample-space-tibbles/index.html#step-2-encoding-each-type-as-a-tibble_row",
    "href": "writeups/sample-space-tibbles/index.html#step-2-encoding-each-type-as-a-tibble_row",
    "title": "Simulating Sample Spaces With Tibbles",
    "section": "Step 2: Encoding Each Type as a tibble_row",
    "text": "Step 2: Encoding Each Type as a tibble_row\nOne nice thing about the tibble library is it explicitly provides a function just for creating individual rows of a full tibble, called tibble_row(). It has the same syntax as the more general tibble() function, but in this case you can just provide a set of key=value pairs as arguments, so that (for example) to create a row representing the first ‚Äútype‚Äù in our dataset \\((F = 0, W = 0, L = 0)\\), we can run\n\nlibrary(tibble)\ntype1 &lt;- tibble_row(iphone=0, wants_switch=0, likes_feature=0)\ntype1\n\n\n\n\n\niphone\nwants_switch\nlikes_feature\n\n\n\n\n0\n0\n0\n\n\n\n\n\n\nNow we can do the same thing for the other 5 non-zero types (we don‚Äôt have to explicitly make row objects for the \\((F = 0, W = 1, L = 0)\\) or \\((F = 0, W = 1, L = 1)\\) types, since we‚Äôre not going to need any of these in our sample-space-simulating tibble, though we could make these tibble_row objects if we really wanted to for some reason):\n\ntype2 &lt;- tibble_row(iphone=0, wants_switch=0, likes_feature=1)\ntype3 &lt;- tibble_row(iphone=0, wants_switch=1, likes_feature=0)\ntype4 &lt;- tibble_row(iphone=0, wants_switch=1, likes_feature=1)\ntype5 &lt;- tibble_row(iphone=1, wants_switch=0, likes_feature=0)\ntype6 &lt;- tibble_row(iphone=1, wants_switch=0, likes_feature=1)\n\nWith these ‚Äútypes‚Äù set up as rows, all that‚Äôs left to do is to duplicate these rows however many times we need to in order to reflect the number of each type in our sample (Step 3), and then combine these duplicated rows together into one big tibble (Step 4)!"
  },
  {
    "objectID": "writeups/sample-space-tibbles/index.html#step-3-replicating-types-to-form-subsets-of-the-sample-space",
    "href": "writeups/sample-space-tibbles/index.html#step-3-replicating-types-to-form-subsets-of-the-sample-space",
    "title": "Simulating Sample Spaces With Tibbles",
    "section": "Step 3: Replicating Types To Form Subsets of the Sample Space",
    "text": "Step 3: Replicating Types To Form Subsets of the Sample Space\nThis is the part that I found most difficult‚Äîhonestly, unless there‚Äôs some secret easy way that I don‚Äôt know about (please tell me if there is!), the best method I could find for duplicating a given tibble_row object k times was to utilize the following code snippet (which uses the slice() function from the dplyr library) as a template:\ntype |&gt; slice(rep(1:n(), k))\nfor taking the individual tibble_row variable type and repeating it k times.\nSo, using this to make 89 ‚Äúcopies‚Äù of the type encoded as the tibble_row called type_1, to represent the 89 people in our sample who are of this type, I used:\n\nlibrary(dplyr) # So we can use slice()\ntype1_rows &lt;- type1 |&gt; slice(rep(1:n(), 89))\n\nWhich produces output that looks as follows (I‚Äôm using head() to avoid printing out rows with the exact same values 89 times, but you can see that it worked by glancing at the result of head() that follows along with the result of dim() below that)\n\ntype1_rows |&gt; head()\n\n\n\n\n\niphone\nwants_switch\nlikes_feature\n\n\n\n\n0\n0\n0\n\n\n0\n0\n0\n\n\n0\n0\n0\n\n\n0\n0\n0\n\n\n0\n0\n0\n\n\n0\n0\n0\n\n\n\n\n\n\n\ndim(type1_rows)\n\n[1] 89  3\n\n\nGiven that this approach worked to make 89 copies of the first type, I just use the same approach 5 more times, to make the appropriate number of copies of each type based on the ‚ÄúNumber in Sample‚Äù column from Table¬†2:\n\ntype2_rows &lt;- type2 |&gt; slice(rep(1:n(), 96))\ntype3_rows &lt;- type3 |&gt; slice(rep(1:n(), 121))\ntype4_rows &lt;- type4 |&gt; slice(rep(1:n(), 111))\ntype5_rows &lt;- type5 |&gt; slice(rep(1:n(), 68))\ntype6_rows &lt;- type6 |&gt; slice(rep(1:n(), 272))\n\nThis leaves only one remaining step of combining these individual collections of rows into a giant tibble."
  },
  {
    "objectID": "writeups/sample-space-tibbles/index.html#step-4-combining-the-type-rows",
    "href": "writeups/sample-space-tibbles/index.html#step-4-combining-the-type-rows",
    "title": "Simulating Sample Spaces With Tibbles",
    "section": "Step 4: Combining the Type-Rows",
    "text": "Step 4: Combining the Type-Rows\nNow that we have these six objects, each representing a particular type of person that could be in our sample, replicated the correct number of times based on our calculations from the information given in the problem, we can combine them to form a single, combined tibble by using the bind_rows() function from dplyr as follows (sorry this line looks so packed/scary: we could have done all this in a loop or something that looks a bit ‚Äúnicer‚Äù, but here I thought writing it all out could help with understanding, especially since there are only 6, rather than 8, possible types):\n\nsample_df &lt;- bind_rows(\n    type1_rows, type2_rows, type3_rows,\n    type4_rows, type5_rows, type6_rows\n)\n\nEven though printing the head() or tail() of this dataset will not be that helpful for ensuring that we created everything correctly, we can at least check that the dimensions are correct, as we‚Äôre expecting the sample to contain 757 people (rows) in total, with 3 pieces of information (columns) for each person:\n\ndim(sample_df)\n\n[1] 757   3\n\n\nWe could also check, as a way of starting the type of computations mentioned in Step 0, the number of people within the full sample_df dataset who match some filter‚Äîin this case, for example, the number of people who are iPhone users:\n\niphone_df &lt;- sample_df[sample_df$iphone == 1,]\ndim(iphone_df)\n\n[1] 340   3\n\n\nAnd this tells us that again, the number of rows in this subset matches what we expected‚Äîmore evidence that we‚Äôve constructed things correctly.\nNow that we‚Äôve created the iphone_df that was mentioned as part of Step 0, we can carry out the one final step of computing a conditional probability using this iphone_df object, in precisely the way described in Step 0: to get the conditional probability that someone in the sample likes the feature given that they are an iPhone user, \\(\\Pr(L = 1 \\mid F = 1)\\), we just compute\n\nnrow(iphone_df[iphone_df$likes_feature == 1,]) / nrow(iphone_df)\n\n[1] 0.8\n\n\nwhich once again matches the information given in the problem. To compute the quantities the problem asks you to compute, you can use a similar pattern to this example."
  },
  {
    "objectID": "writeups/sample-space-tibbles/index.html#optional-step-5-wrapping-the-row-duplication-in-a-function",
    "href": "writeups/sample-space-tibbles/index.html#optional-step-5-wrapping-the-row-duplication-in-a-function",
    "title": "Simulating Sample Spaces With Tibbles",
    "section": "(Optional) Step 5: Wrapping the Row Duplication in a Function",
    "text": "(Optional) Step 5: Wrapping the Row Duplication in a Function\nIf you‚Äôre like me, and you find that typing slice(rep(1:n(), k)) over and over again is scary and could easily lead to mistakes, you can wrap this whole process in a function to make your life easier. For example, we can define a function called duplicate_row which takes an argument tr representing a tibble_row object and another argument num_reps specifying how many times that tibble_row should be repeated:\n\nduplicate_row &lt;- function(tr, num_reps) {\n    return(tr |&gt; slice(rep(1:n(), num_reps)))\n}\n\nAnd now rather than writing the whole operation over and over again, we can just call duplicate_row as often as needed. If you wanted a tibble which contained the numbers 1 through 5 repeated that many times, for example (that is, the number 1 repeated 1 time, the number 2 repeated 2 times, and so on), this could be done in a loop using our duplicate_row function as follows:\n\n# Create a single row containing the number 1\nfull_tibble &lt;- tibble_row(n = 1)\n# Create 2 rows containing the number 2 and add\n# those 2 rows to full_tibble, then create 3 rows\n# containing the number 3 and add those 3 rows\n# to full_tibble, and so on\nfor (i in 2:5) {\n    row_containing_i &lt;- tibble_row(n = i)\n    repeated_rows &lt;- duplicate_row(row_containing_i, i)\n    full_tibble &lt;- bind_rows(full_tibble, repeated_rows)\n}\ndim(full_tibble)\n\n[1] 15  1\n\nfull_tibble\n\n\n\n\n\nn\n\n\n\n\n1\n\n\n2\n\n\n2\n\n\n3\n\n\n3\n\n\n3\n\n\n4\n\n\n4\n\n\n4\n\n\n4\n\n\n5\n\n\n5\n\n\n5\n\n\n5\n\n\n5\n\n\n\n\n\n\nI hope that helps a bit, in case this scenario ever comes up again on a homework or quiz, or it comes up on your project or at some point in your future data science career!"
  },
  {
    "objectID": "writeups/sample-space-tibbles/index.html#appendix-computing-counts-for-each-type",
    "href": "writeups/sample-space-tibbles/index.html#appendix-computing-counts-for-each-type",
    "title": "Simulating Sample Spaces With Tibbles",
    "section": "Appendix: Computing Counts For Each Type",
    "text": "Appendix: Computing Counts For Each Type\nWe already computed the number of iPhone users who like the feature as 272: \\(\\#(F = 1, W = 0, L = 1) = 272\\). This lets us compute, using the complement rule, that there are\n\\[\n340 - 272 = 68\n\\]\nremaining iPhone users, who do not like the feature: \\(\\#(F = 1, W = 0, L = 0) = 68\\). The counts for the final two rows, \\(\\#(F = 1, W = 1, L = 0)\\) and \\(\\#(F = 1, W = 1, L = 1)\\) are both zero, since we defined \\(W\\) for iPhone users to always be \\(0\\), since they already have the iPhone so cannot want to switch to the iPhone. This gives us the bottom half of the count column.\nFor the top half, we compute as follows: the top half (first four rows) represent all of the non-iPhone users. Since there are\n\\[\n340 + 185 + 232 = 757\n\\]\npeople in total, and 340 are iPhone users, this means that\n\\[\n757 - 340 = 417\n\\]\nmust be non-iPhone users (which we also could have computed by adding the 185 and 232 given in the problem): \\(\\#(F = 0) = 417\\).\nOf these 417, we are also given that 185 don‚Äôt want to switch, while 232 do want to switch, so\n\n\\(\\#(F = 0, W = 0) = 185\\) and\n\\(\\#(F = 0, W = 1) = 232\\).\n\nThe final piece of info we need is the info given in the problem that 52% of the no-switch people like the feature, while only 48% of the hope-to-switch people like the feature.\nSince ‚Äúno-switch people‚Äù are people with the properties \\((F = 0, W = 0)\\), and ‚Äúhope-to-switch people‚Äù are people with the properties \\((F = 0, W = 1)\\), we can use these given conditional probabilities to compute the remaining counts in our table as follows:\nNo-switch people who like the feature:\nWe are given the info that, among no-switch people, 52% like the feature. So,\n\\[\n\\begin{align}\n\\#(F = 0, W = 0, L = 1) &= 0.52 \\cdot \\#(F = 0, W = 0) \\\\\n&= 0.52 \\cdot 185 = 96.2,\n\\end{align}\n\\]\nwhich we round to 96 to get an integer number of people.\nNo-switch people who don‚Äôt like the feature:\nSince 52% of no-switch people like the feature, this must mean that (100% - 52% = 48%) of no-switch people must not like the feature:\n\\[\n\\begin{align}\n\\#(F = 0, W = 0, L = 0) &= (1 - 0.52) \\cdot \\#(F = 0, W = 0) \\\\\n&= 0.48 \\cdot 185 = 88.8,\n\\end{align}\n\\]\nwhich we round to 89 to get an integer number of people.\nHope-to-switch people who like the feature:\nWe are given the info that, among hope-to-switch people, 48% like the feature. So,\n\\[\n\\begin{align}\n\\#(F = 0, W = 1, L = 1) &= 0.48 \\cdot \\#(F = 0, W = 1) \\\\\n&= 0.48 \\cdot 232 = 111.36,\n\\end{align}\n\\]\nwhich we round to 111 to get an integer number of people.\nHope-to-switch people who don‚Äôt like the feature\nSince we are given that 48% of hope-to-switch people like the feature, this must mean that (100% - 48% = 52%) of hope-to-switch people do not like the feature. So,\n\\[\n\\begin{align}\n\\#(F = 0, W = 1, L = 0) &= 0.52 \\cdot \\#(F = 0, W = 1) \\\\\n&= 0.52 \\cdot 232 = 120.64,\n\\end{align}\n\\]\nwhich we round to 121 to get an integer number of people.\nI may have made a mistake in one or more of those calculations, so please let me know if you find one. As a sanity check, however, I did sum the numbers in the ‚Äúnumber in sample‚Äù column, and the sum does come out to 757 as expected."
  },
  {
    "objectID": "writeups/sampling-from-df/index.html",
    "href": "writeups/sampling-from-df/index.html",
    "title": "Two Ways of Sampling from a Data Frame",
    "section": "",
    "text": "A few students have run into issues when trying to use the sample() function, from base-R, to sample from a full data.frame or tibble. In this writeup I‚Äôll argue that this is a case where using a function from the tidyverse called slice_sample() will make your life much easier, but I will also show how to do this sampling using only base-R functions.\nBefore we start, we make sure to use set.seed(5100) at the beginning, so that your grader gets the same results as you do even when working with random processes!\nset.seed(5100)"
  },
  {
    "objectID": "writeups/sampling-from-df/index.html#creating-a-deck-of-cards-using-expand.grid",
    "href": "writeups/sampling-from-df/index.html#creating-a-deck-of-cards-using-expand.grid",
    "title": "Two Ways of Sampling from a Data Frame",
    "section": "Creating a Deck of Cards Using expand.grid()",
    "text": "Creating a Deck of Cards Using expand.grid()\nThis is done as was introduced in the Bootcamp:\n\n\nCode\nranks &lt;- c(\"Ace\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\",\n           \"Nine\", \"Ten\", \"Jack\", \"Queen\", \"King\")\nsuits &lt;- c(\"Hearts\", \"Diamonds\", \"Clubs\", \"Spades\")\ndeck_df &lt;- expand.grid(ranks, suits)\ncolnames(deck_df) &lt;- c(\"Rank\", \"Suit\")\nhead(deck_df)\n\n\n\n\n\n\nRank\nSuit\n\n\n\n\nAce\nHearts\n\n\nTwo\nHearts\n\n\nThree\nHearts\n\n\nFour\nHearts\n\n\nFive\nHearts\n\n\nSix\nHearts\n\n\n\n\n\n\nAnd we can check the dimensions of deck_df just to make sure it created the right number of cards:\n\ndim(deck_df)\n\n[1] 52  2\n\n\nNow, since sampling without replacement is the default case for both sample functions, to illustrate how to use parameters to these functions I will be sampling with replacement."
  },
  {
    "objectID": "writeups/sampling-from-df/index.html#using-tidyverse-to-sample-with-replacement",
    "href": "writeups/sampling-from-df/index.html#using-tidyverse-to-sample-with-replacement",
    "title": "Two Ways of Sampling from a Data Frame",
    "section": "Using tidyverse to Sample WITH Replacement",
    "text": "Using tidyverse to Sample WITH Replacement\nThe following code uses the pipe operator %&gt;% to take the data.frame, deck_df, and ‚Äúpipe it into‚Äù the slice_sample() function from the tidyverse. We have to provide two arguments:\n\nn: The number of samples we‚Äôd like to take, and\nreplace: If set to TRUE, the sampling is performed with replacement. Otherwise (the default), the sampling is performed without replacement.\n\n\n\nCode\nlibrary(tidyverse)\ndeck_sample_df &lt;- deck_df |&gt; slice_sample(n = 12, replace = TRUE)\ndeck_sample_df\n\n\n\n\n\n\nRank\nSuit\n\n\n\n\nSeven\nSpades\n\n\nTwo\nClubs\n\n\nAce\nHearts\n\n\nEight\nDiamonds\n\n\nAce\nClubs\n\n\nFive\nDiamonds\n\n\nFive\nClubs\n\n\nNine\nSpades\n\n\nEight\nSpades\n\n\nSeven\nClubs\n\n\nFive\nSpades\n\n\nKing\nDiamonds\n\n\n\n\n\n\nHere we can confirm that it sampled with replacement since we see that it selected the Jack of Spades twice (once in slot 4 and once in slot 12).\nNote that, although using the pipe operator %&gt;% is the ‚Äústandard‚Äù way to use tidyverse functions, you can still use the functions without using the pipe operator (long story short, the pipe operator just takes whatever comes before the %&gt;% and ‚Äúplugs it in‚Äù as the first argument to the function that comes after the %&gt;%), by specifying the first argument to the slice_sample() function explicitly:\n\ndeck_sample_df &lt;- slice_sample(deck_df, n = 12, replace = TRUE)\ndeck_sample_df\n\n\n\n\n\nRank\nSuit\n\n\n\n\nNine\nHearts\n\n\nTen\nDiamonds\n\n\nNine\nHearts\n\n\nJack\nHearts\n\n\nJack\nClubs\n\n\nKing\nSpades\n\n\nEight\nSpades\n\n\nAce\nClubs\n\n\nEight\nDiamonds\n\n\nFive\nDiamonds\n\n\nAce\nHearts\n\n\nFour\nClubs\n\n\n\n\n\n\nTo me, one nice aspect of slice_sample() over other base-R functions is (among other things) it ensures that the column names are maintained when you sample, which is not always true for the base-R functions. It‚Äôs also possible to do in base-R (without using tidyverse libraries/functions), though, just less straightforwardly."
  },
  {
    "objectID": "writeups/sampling-from-df/index.html#using-base-r-to-sample-with-replacement",
    "href": "writeups/sampling-from-df/index.html#using-base-r-to-sample-with-replacement",
    "title": "Two Ways of Sampling from a Data Frame",
    "section": "Using Base-R to Sample WITH Replacement",
    "text": "Using Base-R to Sample WITH Replacement\nFirst off, note that just applying sample() to the deck will not produce the outcome we expect, or want, which probably unfortunately goes against our intuitions for how this function should work:\n\nsample(deck_df, 5, replace = TRUE)\n\n\n\n\n\nSuit\nSuit.1\nRank\nSuit.2\nSuit.3\n\n\n\n\nHearts\nHearts\nAce\nHearts\nHearts\n\n\nHearts\nHearts\nTwo\nHearts\nHearts\n\n\nHearts\nHearts\nThree\nHearts\nHearts\n\n\nHearts\nHearts\nFour\nHearts\nHearts\n\n\nHearts\nHearts\nFive\nHearts\nHearts\n\n\nHearts\nHearts\nSix\nHearts\nHearts\n\n\nHearts\nHearts\nSeven\nHearts\nHearts\n\n\nHearts\nHearts\nEight\nHearts\nHearts\n\n\nHearts\nHearts\nNine\nHearts\nHearts\n\n\nHearts\nHearts\nTen\nHearts\nHearts\n\n\nHearts\nHearts\nJack\nHearts\nHearts\n\n\nHearts\nHearts\nQueen\nHearts\nHearts\n\n\nHearts\nHearts\nKing\nHearts\nHearts\n\n\nDiamonds\nDiamonds\nAce\nDiamonds\nDiamonds\n\n\nDiamonds\nDiamonds\nTwo\nDiamonds\nDiamonds\n\n\nDiamonds\nDiamonds\nThree\nDiamonds\nDiamonds\n\n\nDiamonds\nDiamonds\nFour\nDiamonds\nDiamonds\n\n\nDiamonds\nDiamonds\nFive\nDiamonds\nDiamonds\n\n\nDiamonds\nDiamonds\nSix\nDiamonds\nDiamonds\n\n\nDiamonds\nDiamonds\nSeven\nDiamonds\nDiamonds\n\n\nDiamonds\nDiamonds\nEight\nDiamonds\nDiamonds\n\n\nDiamonds\nDiamonds\nNine\nDiamonds\nDiamonds\n\n\nDiamonds\nDiamonds\nTen\nDiamonds\nDiamonds\n\n\nDiamonds\nDiamonds\nJack\nDiamonds\nDiamonds\n\n\nDiamonds\nDiamonds\nQueen\nDiamonds\nDiamonds\n\n\nDiamonds\nDiamonds\nKing\nDiamonds\nDiamonds\n\n\nClubs\nClubs\nAce\nClubs\nClubs\n\n\nClubs\nClubs\nTwo\nClubs\nClubs\n\n\nClubs\nClubs\nThree\nClubs\nClubs\n\n\nClubs\nClubs\nFour\nClubs\nClubs\n\n\nClubs\nClubs\nFive\nClubs\nClubs\n\n\nClubs\nClubs\nSix\nClubs\nClubs\n\n\nClubs\nClubs\nSeven\nClubs\nClubs\n\n\nClubs\nClubs\nEight\nClubs\nClubs\n\n\nClubs\nClubs\nNine\nClubs\nClubs\n\n\nClubs\nClubs\nTen\nClubs\nClubs\n\n\nClubs\nClubs\nJack\nClubs\nClubs\n\n\nClubs\nClubs\nQueen\nClubs\nClubs\n\n\nClubs\nClubs\nKing\nClubs\nClubs\n\n\nSpades\nSpades\nAce\nSpades\nSpades\n\n\nSpades\nSpades\nTwo\nSpades\nSpades\n\n\nSpades\nSpades\nThree\nSpades\nSpades\n\n\nSpades\nSpades\nFour\nSpades\nSpades\n\n\nSpades\nSpades\nFive\nSpades\nSpades\n\n\nSpades\nSpades\nSix\nSpades\nSpades\n\n\nSpades\nSpades\nSeven\nSpades\nSpades\n\n\nSpades\nSpades\nEight\nSpades\nSpades\n\n\nSpades\nSpades\nNine\nSpades\nSpades\n\n\nSpades\nSpades\nTen\nSpades\nSpades\n\n\nSpades\nSpades\nJack\nSpades\nSpades\n\n\nSpades\nSpades\nQueen\nSpades\nSpades\n\n\nSpades\nSpades\nKing\nSpades\nSpades\n\n\n\n\n\n\nA way to avoid this is to make sure that you are using the sample() function NOT on the entire data.frame object, but just to select a subset of the rows of the data.frame, like the following:\n\ndeck_df[sample(nrow(deck_df), 15, replace = TRUE),]\n\n\n\n\n\n\nRank\nSuit\n\n\n\n\n15\nTwo\nDiamonds\n\n\n16\nThree\nDiamonds\n\n\n37\nJack\nClubs\n\n\n8\nEight\nHearts\n\n\n32\nSix\nClubs\n\n\n51\nQueen\nSpades\n\n\n42\nThree\nSpades\n\n\n34\nEight\nClubs\n\n\n26\nKing\nDiamonds\n\n\n10\nTen\nHearts\n\n\n19\nSix\nDiamonds\n\n\n14\nAce\nDiamonds\n\n\n7\nSeven\nHearts\n\n\n49\nTen\nSpades\n\n\n22\nNine\nDiamonds\n\n\n\n\n\n\nFirst off, notice how here we can again confirm that it sampled with replacement since it had to create additional ids like 34.1 and 34.2 to represent the fact that card #34 (the Eight of Clubs) ended up in our sample 3 times.\nAlso note how, rather than sampling from the data.frame, which may be intuitively/linguistically how we would describe what we want, we are actually sampling from the set of indices of the data.frame, then asking R to give us the rows corresponding to those sampled indices. Concretely, to see what‚Äôs going on, let‚Äôs just look at the row filter we‚Äôve provided (the portion of the full code that is within the square brackets [], before the comma):\n\nsample(nrow(deck_df), 15, replace = TRUE)\n\n [1] 37 42 28 29 45 16 20 41 34 25 44 37 35 29 48\n\n\nWe see that, in fact, we are not really sampling from the data.frame itself, so much as sampling from a list of its indices (from 1 to 52), and then after performing this sample we are going and asking R to give us the rows at the indices that ended up in this sample. Keeping this distinction in mind (between the rows themselves and their indices) can be helpful for debugging code like this."
  },
  {
    "objectID": "writeups/lab-6-clarifications/index.html",
    "href": "writeups/lab-6-clarifications/index.html",
    "title": "Lab 6 Clarifications",
    "section": "",
    "text": "This document contains clarifications for the Lab 6 assignment, based on details and/or hints that I‚Äôve found helpful during office hours and email discussions about the assignment!"
  },
  {
    "objectID": "writeups/lab-6-clarifications/index.html#images-and-assignment-files",
    "href": "writeups/lab-6-clarifications/index.html#images-and-assignment-files",
    "title": "Lab 6 Clarifications",
    "section": "Images and Assignment Files",
    "text": "Images and Assignment Files\nFor the core assignment that you‚Äôll need to complete, please make sure that you download:\n\nThe Lab6_assignment.qmd file, as well as\nThe images folder,\n\nand make sure to download these into the same directory. For example, I usually have a directory on my laptop structured so that I can download each assignment into its own subfolder within a folder called dsan5100, so that the path to the .qmd file looks something like (this is the partial output from running tree dsan5100):\n‚îú‚îÄ‚îÄ lab06\n ¬†¬† ‚îú‚îÄ‚îÄ Lab6_assignment.html\n ¬†¬† ‚îú‚îÄ‚îÄ Lab6_assignment.qmd\n ¬†¬† ‚îî‚îÄ‚îÄ images\n ¬†¬†     ‚îú‚îÄ‚îÄ 2023-10-04-16-53-42.png\n ¬†¬†     ‚îú‚îÄ‚îÄ 2023-10-11-08-55-38.png\n ¬†¬†     ‚îú‚îÄ‚îÄ 2023-10-11-08-55-48.png\n ¬†¬†     ‚îú‚îÄ‚îÄ 2023-10-11-08-55-59.png\n ¬†¬†     ‚îú‚îÄ‚îÄ 2023-10-11-08-56-16.png\n ¬†¬†     ‚îî‚îÄ‚îÄ 2023-10-11-08-56-36.png"
  },
  {
    "objectID": "writeups/lab-6-clarifications/index.html#problem-2",
    "href": "writeups/lab-6-clarifications/index.html#problem-2",
    "title": "Lab 6 Clarifications",
    "section": "Problem 2",
    "text": "Problem 2\nSince the ‚ÄúShopping Example‚Äù image displays kind of fuzzily, on my screen at least, here is the problem (including the image) just re-written to use HTML rather than image files:\n\nShopping Example\n\nSuppose there are two types of items [My understanding is that this should be three types of items] and \\(n = 3\\) customers.\nPossible values are \\(\\{(3,0,0),(2,1,0),(2,0,1), \\ldots, (0,1,2), (0,0,3)\\}\\)\nSome values of the joint pmf:\n\n\\(\\Pr((3,0,0)) = 1 \\cdot (p_1)^3\\)\n\\(\\Pr((1,2,0)) = 3 \\cdot (p_1)(p_2)^2\\)\n\\(\\Pr((1,1,1)) = 6 \\cdot (p_1)(p_2)(p_3)\\)\n\n(The factors 1, 3, 6 count the number of ways in which these events can occur)\n\n\n\n\nTable¬†1: The example table given in the image, showing\n\n\n\n\n\nBeer\nBread\nCoke\n\n\n\n\n3\n0\n0\n\n\n2\n1\n0\n\n\n2\n0\n1\n\n\n0\n3\n0\n\n\n0\n2\n1\n\n\n0\n1\n2\n\n\n1\n0\n2\n\n\n1\n2\n0\n\n\n1\n1\n1\n\n\n0\n0\n3\n\n\n\n\n\n\nLet‚Äôs say that Molly, Ryan, and Mr.¬†Bob are buying Beer (\\(X_1\\)), Bread (\\(X_2\\)), and Coke (\\(X_3\\)) with probabilities \\(\\left(3/5, 1/5, 1/5\\right)\\).\n\nWhat is the probability that only one of them will buy Beer, two of them will buy Bread, and none of them will buy Coke? Compare the result with the theoretical probability.\nDo a simulation for this scenario and plot the marginal distribution of \\(X_1\\)."
  },
  {
    "objectID": "writeups/lab-6-clarifications/index.html#problem-3",
    "href": "writeups/lab-6-clarifications/index.html#problem-3",
    "title": "Lab 6 Clarifications",
    "section": "Problem 3",
    "text": "Problem 3\nHere, from what I understand, the problem letters jump from (c) to (e), so that there is no Part (d) for Problem 3."
  },
  {
    "objectID": "final-presentations.html",
    "href": "final-presentations.html",
    "title": "Final Presentation Info",
    "section": "",
    "text": "The information here, on the order for the final presentations, is loaded from a Google Sheets document so that student names are not included in the site‚Äôs html code itself (and the Sheets document will be removed at the end of the semester). But, if you would like your name removed from the Sheets document for safety/security reasons please let me know!\nClick to open sheet in new tab ‚Üí"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DSAN 5100, Section 03 (Tuesdays)",
    "section": "",
    "text": "This page collects slides and relevant links for students in Prof.¬†Jeff‚Äôs Tuesday section (Section 03) of DSAN 5100: Probabilistic Modeling and Statistical Computing, Fall 2024 at Georgetown University.\nSections take place in Car Barn 309 on Tuesdays from 6:30pm to 9:00pm.\nThis page is not a replacement for the Main Course Page or the sections‚Äôs Canvas Page!\nUse the menu on the left, or the table below, to view resources for a specific week.\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nWeek 1: Welcome to DSAN 5100!\n\n\nFriday, August 30, 2024\n\n\n\n\nWeek 2: Introduction to Probabilistic Modeling\n\n\nTuesday, September 3, 2024\n\n\n\n\nWeek 3: Random Variables\n\n\nTuesday, September 10, 2024\n\n\n\n\nWeek 4: Discrete Distributions\n\n\nTuesday, September 17, 2024\n\n\n\n\nWeek 5: Continuous Distributions\n\n\nTuesday, September 24, 2024\n\n\n\n\nWeek 6: Moments and Covariance\n\n\nTuesday, October 1, 2024\n\n\n\n\nWeek 7: Joint, Marginal, and Conditional Distributions\n\n\nTuesday, October 8, 2024\n\n\n\n\nWeek 8: Markov Models\n\n\nTuesday, October 15, 2024\n\n\n\n\nWeek 9: Statistical Inference\n\n\nTuesday, October 22, 2024\n\n\n\n\nWeek 10: Parameter Estimation\n\n\nTuesday, October 29, 2024\n\n\n\n\nWeek 11: Method of Moments and Bootstrap\n\n\nTuesday, November 5, 2024\n\n\n\n\nWeek 12: Hypothesis Testing\n\n\nTuesday, November 12, 2024\n\n\n\n\nWeek 14: Non-Parametric Statistics\n\n\nTuesday, December 10, 2024\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "w09/index.html",
    "href": "w09/index.html",
    "title": "Week 9: Statistical Inference",
    "section": "",
    "text": "Open slides in new window ‚Üí",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#finite-state-automata",
    "href": "w09/index.html#finite-state-automata",
    "title": "Week 9: Statistical Inference",
    "section": "Finite-State Automata",
    "text": "Finite-State Automata\n(Deterministic!) Only ‚Äúaccepts‚Äù strings with even number of 1s:\n\n\n\n\n\n\n\n\n\n\n\nInput String\nResult\nInput String\nResult\n\n\n\n\n\\(\\varepsilon\\)\n‚úÖ\n01\n\n\n\n0\n‚úÖ\n10\n\n\n\n1\n\n1000000\n\n\n\n00\n‚úÖ\n10000001\n‚úÖ\n\n\n\n\n\n\n\n‚Ä¶But we‚Äôre trying to model probabilistic evolution!",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#enter-markov-chains",
    "href": "w09/index.html#enter-markov-chains",
    "title": "Week 9: Statistical Inference",
    "section": "Enter Markov Chains",
    "text": "Enter Markov Chains\n\n\n\nGraphically\n\n\n\n\n\n\n\n\n\n\n\n\n\nMathematically\n\n\\[\n\\begin{array}{c c}\n& \\begin{array}{c c c} 1\\phantom{1} & \\phantom{1}2\\phantom{1} & \\phantom{1}3 \\\\ \\end{array} \\\\\n\\begin{array}{c c c}1 \\\\ 2 \\\\ 3 \\end{array} &\n\\left[\n\\begin{array}{c c c}\n0 & 1/2 & 1/2 \\\\\n1/3 & 0 & 2/3 \\\\\n1/3 & 2/3 & 0\n\\end{array}\n\\right]\n\\end{array}\n\\]\n\n\\[\n\\begin{array}{c c}\n& \\begin{array}{c c c} 1\\phantom{1} & \\phantom{2}2\\phantom{2} & \\phantom{1}3 \\\\ \\end{array} \\\\\n\\begin{array}{c c c}1 \\\\ 2 \\\\ 3 \\end{array} &\n\\left[\n\\begin{array}{c c c}\n1/2 & 1/3 & 1/6 \\\\\n1/10 & 1/2 & 2/5 \\\\\n1/8 & 3/8 & 1/2\n\\end{array}\n\\right]\n\\end{array}\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#hidden-markov-models",
    "href": "w09/index.html#hidden-markov-models",
    "title": "Week 9: Statistical Inference",
    "section": "Hidden Markov Models",
    "text": "Hidden Markov Models\n\nUse observed data to infer unobserved variables\n\n\n\n\n\n\n\n(What our brains are doing, most of the time!)",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#pagerank-matrix-magic",
    "href": "w09/index.html#pagerank-matrix-magic",
    "title": "Week 9: Statistical Inference",
    "section": "PageRank (Matrix Magic)",
    "text": "PageRank (Matrix Magic)\n\nWhat is the relevance of this abstract topic? ‚Ä¶ü§ë\n\n\nlibrary(readr)\nlibrary(ggplot2)\ngoog_df &lt;- read_csv(\"assets/google_yearly_revenue.csv\")\nggplot(goog_df, aes(x=year, y=revenue_billions)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title = \"Google Yearly Revenue, 2002-2022\",\n    x = \"Year\",\n    y = \"Revenue (Billion USD)\"\n  ) +\n  dsan_theme(\"full\")\n\n\n\n\n\n\n\n\n\nPageRank = The ‚Äúspark‚Äù that ignited the Google flame",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#pagerank-visualized",
    "href": "w09/index.html#pagerank-visualized",
    "title": "Week 9: Statistical Inference",
    "section": "PageRank Visualized",
    "text": "PageRank Visualized\n\nNodes = Webpages, Edges = Links\n\n\n\n\n\n\n\nGoal: Rank the relative ‚Äúimportance‚Äù of a site \\(S_i\\), taking into account the importance of other sites that link to \\(S_i\\)\n\n‚ÄúImportant‚Äù sites: linked to often, and linked to often by other important sites",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#chickens-and-eggs",
    "href": "w09/index.html#chickens-and-eggs",
    "title": "Week 9: Statistical Inference",
    "section": "Chickens and Eggs",
    "text": "Chickens and Eggs\n\nParadoxical at first: how are we supposed to figure out the importance of a site \\(S_i\\), when that‚Äôs determined by\n\nthe importance of sites \\(S_j\\) that link to \\(S_i\\), which is determined by\n\nthe importance of sites \\(S_k\\) that link to sites \\(S_j\\), which is determined by\n\nthe importance of the sites \\(S_\\ell\\) that link to those sites \\(S_k\\), which is determined by‚Ä¶\n\n\n\n\n\\[\n\\begin{align*}\n\\mathsf{Importance}(S_i) &= f(\\mathsf{Importance}(S_{j \\rightarrow i})) = f(f(\\mathsf{Importance}(S_{k \\rightarrow j \\rightarrow i}))) \\\\\n&= f(f(f(\\mathsf{Importance}(S_{\\ell \\rightarrow k \\rightarrow j \\rightarrow i})))) = \\cdots\n\\end{align*}\n\\]\n\n\nSanity hint: Remember infinite sums from calculus! They can converge, despite having infinitely-many terms‚Ä¶ This is something like that, but for recursion (the mathematical term for an object whose definition refers to itself)",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#resolving-recursive-definitions",
    "href": "w09/index.html#resolving-recursive-definitions",
    "title": "Week 9: Statistical Inference",
    "section": "Resolving Recursive Definitions",
    "text": "Resolving Recursive Definitions\n\nWe can compute this importance ranking, despite its recursive definition!\nRecall, for example, the Fibonacci sequence: \\(1, 1, 2, 3, 5, 8, 13, 21, \\ldots\\)\nDefined recursively!\n\n\\[\nf(n) = \\begin{cases}\n1 & n = 1\\text{ or }n = 2 \\\\\nf(n-2) + f(n-1) & n &gt; 2\n\\end{cases}\n\\]\n\nAnd yet, a guy named Bernoulli figured out\n\\[\nf(n) = \\frac{\\varphi^n - \\psi^n}{\\varphi - \\psi} = \\frac{\\varphi^n - \\psi^n}{\\sqrt{5}},\n\\]\nwhere \\(\\varphi\\) is the ‚ÄúGolden Ratio‚Äù \\(\\frac{1 + \\sqrt{5}}{2}\\) and \\(\\psi\\) its conjugate \\(\\frac{1 - \\sqrt{5}}{2}\\).",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#the-pagerank-process",
    "href": "w09/index.html#the-pagerank-process",
    "title": "Week 9: Statistical Inference",
    "section": "The PageRank Process",
    "text": "The PageRank Process\n\nEvery site starts with equal PageRank score: \\(r^{(0)}_1 = r^{(0)}_2 = r^{(0)}_3 = \\frac{1}{3}\\).\nEach link \\(S_i \\rightarrow S_j\\) is a vote of confidence that \\(S_i\\) is giving to \\(S_j\\)\nAt each time \\(t\\), a site \\(S_i\\) ‚Äúspends‚Äù whatever voting power it currently has (\\(r^{(t)}_i\\)) on the sites it links to.\n\n\\(S_1\\) casts one vote for itself and one vote for \\(S_2\\), thus spending \\(\\frac{1}{2}\\) of its total PageRank on itself and \\(\\frac{1}{2}\\) of its total PageRank on \\(S_2\\).\n\nState of the process at time \\(t\\): \\(\\mathbf{r}^{(t)} = \\begin{bmatrix}r^{(t)}_1 & r^{(t)}_2 & r^{(t)}_3\\end{bmatrix}^\\top\\)\nCan form a matrix specifying how this state evolves from time \\(t\\) to time \\(t+1\\)!\n\n\\[\n\\mathbf{E} = \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix} \\; \\leadsto \\; \\mathbf{r}^{(t+1)} = \\mathbf{E}\\mathbf{r}^{(t)}\n\\]\n\n\nGiven the ‚Äú\\(S_1\\) casts one vote for itself‚Ä¶‚Äù part, can you say exactly what \\(S_1\\) will ‚Äúspend‚Äù on itself and on \\(S_2\\) at time \\(t = 0\\) (in the first round)?",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#section",
    "href": "w09/index.html#section",
    "title": "Week 9: Statistical Inference",
    "section": "",
    "text": "We can use \\(\\mathbf{E}\\) to figure out the state at each step, starting from \\(t = 0\\)!\n\n\\[\n\\begin{array}{c@{}c@{}c@{}c@{}c@{}c@{}c}\n\\mathbf{r}^{(1)} & = & \\mathbf{E}\\mathbf{r}^{(0)} & = & \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix}\\begin{bmatrix}\n\\frac{1}{3} \\\\\n\\frac{1}{3} \\\\\n\\frac{1}{3}\\end{bmatrix} & = & \\begin{bmatrix}\n\\frac{1}{3} \\\\\n\\frac{1}{2} \\\\\n\\frac{1}{6}\n\\end{bmatrix} \\\\\n~ & ~ & ~ & ~ & ~ & \\swarrow & ~ \\\\\n\\mathbf{r}^{(2)} & = & \\mathbf{E}\\mathbf{r}^{(1)} & = & \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix}\\begin{bmatrix}\\frac{1}{3} \\\\ \\frac{1}{2} \\\\ \\frac{1}{6}\\end{bmatrix} & = & \\begin{bmatrix}\\frac{5}{12} \\\\ \\frac{1}{3} \\\\ \\frac{1}{4}\\end{bmatrix} \\\\\n~ & ~ & ~ & ~ & ~ & \\swarrow & ~ \\\\\n\\mathbf{r}^{(3)} & = & \\mathbf{E}\\mathbf{r}^{(2)} & = & \\cdots & ~ & ~\n\\end{array}\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#matrix-magic",
    "href": "w09/index.html#matrix-magic",
    "title": "Week 9: Statistical Inference",
    "section": "Matrix Magic",
    "text": "Matrix Magic\n\n(1) Won‚Äôt we just have to run this forever? (2) How do we know it‚Äôll converge to something?\nAnswers: (1) No! (2) because Markov matrix magic!\n‚ÄúSteady state‚Äù = state where \\(\\mathbf{r}^{(t)} = \\mathbf{r}^{(t+1)} = \\mathbf{r}^{(t+2)} = \\cdots \\definedas \\mathbf{r}^*\\). But this means\n\n\\[\n\\mathbf{r}^{(t+1)} = \\mathbf{r}^{(t)} \\iff \\mathbf{E}\\mathbf{r}^{(t)} = \\mathbf{r}^{(t)} \\iff \\mathbf{E}\\mathbf{r}^* = \\mathbf{r}^*\n\\]\n\nThis \\(\\mathbf{r}^*\\) is (by definition!) an Eigenvector of \\(\\mathbf{E}\\) with Eigenvalue \\(\\lambda = 1\\)!1\n\n\n\nIn my opinion, along with e.g.¬†insolubility of the quintic, this is maybe the most mind-blowing case of math magic :3",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#solving-the-matrix-magic",
    "href": "w09/index.html#solving-the-matrix-magic",
    "title": "Week 9: Statistical Inference",
    "section": "Solving the Matrix Magic",
    "text": "Solving the Matrix Magic\n\nSince we already know the Eigenvalue of interest, \\(\\lambda = 1\\), all that‚Äôs left is solving for its corresponding Eigenvector:\n\\[\n  \\mathbf{E}\\mathbf{r}^* = \\mathbf{r}^* \\iff \\mathbf{E}\\mathbf{r}^* - \\mathbf{r}^* = \\mathbf{0} \\iff (\\mathbf{E} - \\mathbf{I})\\mathbf{r}^* = \\mathbf{0}\n  \\]\nWritten out, we see that this gives us a system of linear equations:\n\\[\n  \\begin{bmatrix}\n  \\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n  \\frac{1}{2} & 0 & 1 \\\\\n  0 & \\frac{1}{2} & 0\n  \\end{bmatrix}\\begin{bmatrix}r^*_1 \\\\ r^*_2 \\\\ r^*_3\\end{bmatrix} = \\begin{bmatrix}0 \\\\ 0 \\\\ 0\\end{bmatrix} \\iff \\begin{array}{ccccccc}\\frac{1}{2}r^*_1 & + & \\frac{1}{2}r^*_2 & ~ & ~ & = & 0 \\\\ \\frac{1}{2}r^*_1 & ~ & ~ & + & r^*_3 & = & 0 \\\\ ~ & ~ & \\frac{1}{2}r^*_2 & ~ & ~ & = & 0\\end{array}\n  \\]\nwhich we can solve however we want!\nTo handle the fact that this system is underspecified, impose additional restriction that \\(r^*_1 + r^*_2 + r^*_3 = 1\\), so that the ranks form a probability distribution",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#the-point-of-all-this",
    "href": "w09/index.html#the-point-of-all-this",
    "title": "Week 9: Statistical Inference",
    "section": "The Point of All This",
    "text": "The Point of All This\n\nThe final restriction \\(r^*_1 + r^*_2 + r^*_3 = 1\\) ensures that the resulting PageRank values form a probability distribution\nThis is called the Stationary Distribution of the Markov chain: represents the probability that a random walker through the chain will be at page \\(S_i\\) at a given time!\n\nEquivalently: expected proportion of total walking time a random-walker will spend at each node\n\nEvery Markov chain has a Stationary Distribution! This fact has cool implications even above and beyond the Google $$$ implications üòú",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#statistical-inference-vs.-statistics",
    "href": "w09/index.html#statistical-inference-vs.-statistics",
    "title": "Week 9: Statistical Inference",
    "section": "Statistical Inference vs.¬†Statistics",
    "text": "Statistical Inference vs.¬†Statistics\n\n\nMoving from understanding probability to getting things done using probability!\nEverything up to this point: understanding the ‚Äúrules‚Äù of stochastic processes\nNow: Using what we know to allow us to draw inferences about populations without having to carry out a census",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#samples-vs.-populations",
    "href": "w09/index.html#samples-vs.-populations",
    "title": "Week 9: Statistical Inference",
    "section": "Samples vs.¬†Populations",
    "text": "Samples vs.¬†Populations\n\nSample = The data you have\nPopulation = The thing you want to learn about, by looking at the sample\nLike ‚Äúsuccess‚Äù vs.¬†‚Äúfailure‚Äù in Bernoulli trials, no exact definition of what counts as sample vs.¬†population\nWhat we call the ‚Äúsample‚Äù and the ‚Äúpopulation‚Äù is vocabulary there to help us know what to do",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#inference-statistical-and-otherwise",
    "href": "w09/index.html#inference-statistical-and-otherwise",
    "title": "Week 9: Statistical Inference",
    "section": "Inference (Statistical and Otherwise)",
    "text": "Inference (Statistical and Otherwise)\nWhat are we doing when we do science?\n\n\n\nScience in General\n\n\n\n\n\n\n\n\ngrid\n\n\ncluster_01\n\n\"Nature\"\n\n\ncluster_02\n\n\"Science\"\n\n\n\nObs\n\nThing(s) we can see\n\n\n\nUnd\n\nUnderlying processes\n\n\n\nUnd-&gt;Obs\n\n\n\n\n\nModel\n\nModel\n\n\n\nUnd-&gt;Model\n\n\n\n\n\nModel-&gt;Obs\n\n\n\n\n\n\n\n\n\n\n\n\nExample: Newton\n\n\n\n\n\n\n\n\ngrid\n\n\ncluster_03\n\nIsaac Newton\n\n\ncluster_04\n\n\nWoolsthorpe Manor\n\n\n\n\n\nTree\n\n\nFalling Apple\n\n\n\n\n\nPhysics\n\n\nParticle Interactions\n\n\n\n\n\nPhysics-&gt;Tree\n\n\n\n\n\nNewton\n\nNewton's Laws\n\n\n\nPhysics-&gt;Newton\n\n\n\n\n\nNewton-&gt;Tree\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRemember that the filled-in nodes represent things we can observe, while the non-filled nodes represent things we have to infer from the observable data.",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#examples-abound",
    "href": "w09/index.html#examples-abound",
    "title": "Week 9: Statistical Inference",
    "section": "Examples Abound!",
    "text": "Examples Abound!\n\n\n\nDarwinian Evolution\n\n\n\n\n\n\n\n\ngrid\n\n\ncluster_04\n\nGal√°pagos Islands\n\n\ncluster_03\n\nCharles Darwin\n\n\n\nTree\n\n\nFinches\n\n\n\n\n\nPhysics\n\nNatural selection\n\n\n\nPhysics-&gt;Tree\n\n\n\n\n\nNewton\n\nTheory of Evolution\n\n\n\nPhysics-&gt;Newton\n\n\n\n\n\nNewton-&gt;Tree\n\n\n\n\n\n\n\n\n\n\n\n\nEuclidean Geometry\n\n\n\n\n\n\n\n\ngrid\n\n\ncluster_04\n\n\nAlexandria\n\n\n\n\ncluster_03\n\nEuclid\n\n\n\nActual\n\nActual Triangles\n\n\n\nPlatonic\n\nPlatonic Ideal Triangle\n\n\n\nPlatonic-&gt;Actual\n\n\n\n\n\nEuclid\n\nEuclidean Geometry\n\n\n\nPlatonic-&gt;Euclid\n\n\n\n\n\nEuclid-&gt;Actual",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#zooming-in-on-euclid",
    "href": "w09/index.html#zooming-in-on-euclid",
    "title": "Week 9: Statistical Inference",
    "section": "Zooming in on Euclid",
    "text": "Zooming in on Euclid\n\n\nObservations\n\n\n\n\n\n\n\n\n\nSource: Emily Pierce\n\n\n\n\n\n\n\nSource: Wikimedia\n\n\n\n\n\n\n\n\nInteractive visualization from UNC Archaeology\n\n\n\n\n\n‚Üí\n\n\n\nInference\n\n\n\n13th-Century Arabic Elements, from Sotheby‚Äôs\n\n\n\n\n\n\nFor an absolutely beautiful visual presentation of Elements see here",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#inference-in-the-diagram",
    "href": "w09/index.html#inference-in-the-diagram",
    "title": "Week 9: Statistical Inference",
    "section": "Inference in the Diagram",
    "text": "Inference in the Diagram\n\n\n\n\n\n\n\ngrid\n\n\ncluster_03\n\nEuclid\n\n\ncluster_04\n\n\nAlexandria\n\n\n\n\n\nActual\n\nActual Triangles\n\n\n\nEuclid\n\nEuclidean Geometry\n\n\n\nActual-&gt;Euclid\n\n\nObserve\n\n\n\nPlatonic\n\nPlatonic Ideal Triangle\n\n\n\nPlatonic-&gt;Actual\n\n\n\nWhat goes here? \n\n\n\nPlatonic-&gt;Euclid\n\n\nInfer",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#completing-the-cycle",
    "href": "w09/index.html#completing-the-cycle",
    "title": "Week 9: Statistical Inference",
    "section": "Completing the Cycle",
    "text": "Completing the Cycle\n\n\n\n\n\n\n\ngrid\n\n\ncluster_04\n\n\nAlexandria\n\n\n\n\ncluster_03\n\nEuclid\n\n\n\nActual\n\nActual Triangles\n\n\n\nEuclid\n\nEuclidean Geometry\n\n\n\nActual-&gt;Euclid\n\n\nObserve\n\n\n\nPlatonic\n\nPlatonic Ideal Triangle\n\n\n\nPlatonic-&gt;Actual\n\n\n\nHypothesis Testing! \n\n\n\nPlatonic-&gt;Euclid\n\n\nInfer",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#our-case",
    "href": "w09/index.html#our-case",
    "title": "Week 9: Statistical Inference",
    "section": "Our Case",
    "text": "Our Case\n\n\n\n\n\n\n\ngrid\n\n\ncluster_04\n\nThe World\n\n\ncluster_03\n\nUs\n\n\n\nSample\n\nSample\n\n\n\nPopulation\n\nPopulation\n\n\n\nPopulation-&gt;Sample\n\n\nTake Sample \n\n\n\nStats\n\nStatistics\n\n\n\nPopulation-&gt;Stats\n\n\nInfer\n\n\n\nStats-&gt;Sample\n\n\nObserve\n\n\n\n\n\n\n\n\n\n\nIf you‚Äôre wondering, ‚Äúwhat happened to Hypothesis Testing?‚Äù, don‚Äôt worry, we‚Äôll dive back into that over the next 2 weeks!",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#stability-out-of-randomness",
    "href": "w09/index.html#stability-out-of-randomness",
    "title": "Week 9: Statistical Inference",
    "section": "Stability out of Randomness",
    "text": "Stability out of Randomness\n\n\\(X\\) = result of coin flip\nRemembering that \\(X\\) is a random variable, so it maps outcomes to numbers: \\(X(\\)\\() = 0\\), \\(X(\\)\\() = 1\\)\nWe have no idea what the result of some single coin flip will be, yet we can be sure that the mean of many trials will converge to the expected value of \\(0.5\\)!\n\n\n\nTo check that you understand: what value would the mean of many dice rolls converge to?",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#interactive-visualization",
    "href": "w09/index.html#interactive-visualization",
    "title": "Week 9: Statistical Inference",
    "section": "Interactive Visualization",
    "text": "Interactive Visualization\n\n\n\nSeeing Theory, Brown University",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#how-many-is-many",
    "href": "w09/index.html#how-many-is-many",
    "title": "Week 9: Statistical Inference",
    "section": "How Many is ‚ÄúMany‚Äù?",
    "text": "How Many is ‚ÄúMany‚Äù?\n\n\nCode\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(dplyr)\nset.seed(5100)\nn_vals &lt;- c(ceiling(sqrt(10)), 10, ceiling(10*sqrt(10)), 100, ceiling(100*sqrt(10)), 1000, ceiling(1000*sqrt(10)), 10000, ceiling(10000*sqrt(10)), 100000)\nheads_data &lt;- c()\ntotal_data &lt;- c()\nfor (n in n_vals) {\n  coin_flips &lt;- rbinom(n, 1, 0.5)\n  num_heads &lt;- sum(coin_flips)\n  heads_data &lt;- c(heads_data, num_heads)\n  num_flipped &lt;- length(coin_flips)\n  total_data &lt;- c(total_data, num_flipped)\n}\nresults &lt;- tibble(n = n_vals, heads=heads_data, total=total_data)\nresults &lt;- results %&gt;% mutate(head_prop = heads / total)\n#results\nggplot(results, aes(x=n, y=head_prop)) +\n  geom_hline(aes(yintercept=0.5, linetype='dashed'), color=cbPalette[2]) +\n  geom_line(aes(color='black'), fill=cbPalette[1], linewidth=g_linewidth, color=cbPalette[1]) +\n  geom_point(aes(color='black'), size=g_pointsize*0.9) +\n  scale_color_manual(\"\", values=c(\"black\",\"purple\"), labels=c(\"Mean of n samples\",\"Expected Value\")) +\n  scale_linetype_manual(\"\", values=\"dashed\", labels=\"Expected Value\") +\n  scale_fill_manual(\"\", values=cbPalette[1], labels=\"95% CI\") +\n  dsan_theme(\"full\") +\n  theme(\n      legend.title = element_blank(),\n      legend.spacing.y = unit(0, \"mm\")\n  ) +\n      labs(\n          title = \"Estimates of Population Mean for Increasing Sample Sizes\",\n          x = \"n (Sample Size)\",\n          y = \"Sample Mean\"\n      ) +\n  scale_x_log10(breaks = c(10, 100, 1000, 10000, 100000), labels = c(\"10\", \"100\", \"1000\", \"10000\", \"100000\"))",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#the-sample-mean",
    "href": "w09/index.html#the-sample-mean",
    "title": "Week 9: Statistical Inference",
    "section": "The Sample Mean",
    "text": "The Sample Mean\n\nLike the median we saw earlier (along with lots of other examples), sample mean is just a function of RVs\nUnlike the median, though, it is a function of a vector-valued RV \\(\\mathbf{X}_N\\) (containing \\(N\\) scalar RVs)!2\nLet \\(\\mathbf{X}_N = \\{X_1, X_2, \\ldots, X_n\\}\\), where \\(X_1\\) is first observation, \\(X_2\\) second observation, and so on. Then:\n\n\\[\n\\overline{X}_N = f(\\mathbf{X}_N) = \\frac{1}{n}\\sum_{i=1}^{n}X_i\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#weak-law-of-large-numbers-wlln",
    "href": "w09/index.html#weak-law-of-large-numbers-wlln",
    "title": "Week 9: Statistical Inference",
    "section": "Weak Law of Large Numbers (WLLN)",
    "text": "Weak Law of Large Numbers (WLLN)\n\nLet \\(\\mathbf{X}_N = \\{X_1, \\ldots, X_n\\} \\iid \\mathcal{D}\\) be a random sample from a distribution \\(\\mathcal{D}\\) with mean \\(\\mu\\), finite variance. Let \\(\\overline{X}_N\\) denote the sample mean from previous slide. Then\n\n\\[\n\\overline{X}_N \\stackrel{p}{\\longrightarrow} \\mu\n\\]\n\n\\(\\mathfrak{X}(N) \\stackrel{p}{\\longrightarrow} c\\) means the Random Variable \\(\\mathfrak{X}(N)\\) (a function of the sample size \\(N\\)) ‚Äúconverges in probability‚Äù to the scalar value \\(c\\). Formally:\n\n\\[\n\\mathfrak{X}(N) \\overset{p}{\\longrightarrow} c \\iff \\forall \\varepsilon &gt; 0 \\left[ \\lim_{N \\rightarrow \\infty}\\Pr\\left( | \\mathfrak{X}(N) - c | &lt; \\varepsilon \\right) = 1 \\right]\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#strong-law-of-large-numbers-slln",
    "href": "w09/index.html#strong-law-of-large-numbers-slln",
    "title": "Week 9: Statistical Inference",
    "section": "Strong Law of Large Numbers (SLLN)",
    "text": "Strong Law of Large Numbers (SLLN)\n\nSame setup as last slide, but\n\n\\[\n\\overline{X}_N \\convergesAS \\mu\n\\]\n\n\\(\\mathfrak{X}(N) \\convergesAS c\\) means the Random Variable \\(\\mathfrak{X}(N)\\) (a function of the sample size \\(N\\)) ‚Äúconverges almost surely‚Äù to the scalar value \\(c\\). Formally:\n\n\\[\n\\mathfrak{X}(N) \\convergesAS c \\iff \\Pr\\left( \\lim_{N \\rightarrow \\infty} \\mathfrak{X}(N) = c \\right) = 1\n\\]\n\nSLLN \\(\\implies\\) WLLN, but WLLN \\(~\\nimplies\\) SLLN!\nWLLN easy to prove, SLLN very un-easy to prove",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#central-limit-theorem",
    "href": "w09/index.html#central-limit-theorem",
    "title": "Week 9: Statistical Inference",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nWe‚Äôll never actually reach \\(N = \\infty\\), so we zoom in on how close our sample-based estimate gets to the true value\nCentral Limit Theorem says: these ‚Äúcloseness‚Äù values are normally distributed!\nLLN guarantees that \\(X_N \\; \\; \\eqeventual \\; \\; \\mu\\)\nCLT tells us what the gap \\((X_N - \\mu)\\) looks like",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#formal-clt",
    "href": "w09/index.html#formal-clt",
    "title": "Week 9: Statistical Inference",
    "section": "Formal CLT",
    "text": "Formal CLT\n\nSampled observations: \\(\\mathbf{X}_N = \\{X_1, \\ldots, X_n\\}\\)\n\\(\\expect{X_i} = \\mu, \\Var{X_i} = \\sigma^2 &lt; \\infty\\)\n\\(\\overline{X}_N \\definedas M_1(\\mathbf{X}_N) = \\frac{X_1 + \\cdots + X_n}{N}\\)\n\n\\[\n\\frac{\\overline{X}_N - \\mu}{\\sigma / \\sqrt{N}} \\overset{\\text{asymp}}{\\sim} \\mathcal{N}(0,1)\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#when-is-mathcaln0-1-a-good-approximation",
    "href": "w09/index.html#when-is-mathcaln0-1-a-good-approximation",
    "title": "Week 9: Statistical Inference",
    "section": "When is \\(\\mathcal{N}(0, 1)\\) a ‚Äúgood‚Äù approximation?",
    "text": "When is \\(\\mathcal{N}(0, 1)\\) a ‚Äúgood‚Äù approximation?\n\n\nCode\n# Prepare data for all plots\nmax_n &lt;- 10000\nnum_reps &lt;- 1000\nall_rolls &lt;- replicate(\n  num_reps,\n  sample(1:6, size = max_n, replace = TRUE, prob = rep(1 / 6, 6))\n)\ngen_clt_plot &lt;- function(n) {\n  exp_val &lt;- 3.5\n  sigma &lt;- sqrt(35/12)\n  denom &lt;- sigma / sqrt(n)\n  # Get the slice of all_rolls for this n\n  n_rolls &lt;- all_rolls[1:n,]\n  sample_means &lt;- colMeans(n_rolls)\n  norm_gaps &lt;- (sample_means - exp_val) / denom\n  n_df &lt;- tibble(norm_gap=norm_gaps)\n  #if (n == 5) {\n  #  print(sample_means)\n  #  print(n_df)\n  #}\n  ggplot(n_df, aes(x = norm_gap)) +\n  geom_histogram(aes(y = after_stat(density)), binwidth = 1/2) +\n  #geom_density() +\n  stat_function(fun=dnorm, size=g_linesize) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title = paste0(\"n = \",n),\n    x = \"Normalized Sample Gap\"\n  )\n}",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#q-q-plots",
    "href": "w09/index.html#q-q-plots",
    "title": "Week 9: Statistical Inference",
    "section": "Q-Q Plots",
    "text": "Q-Q Plots\n\n\nCode\ngen_qq &lt;- function(n) {\n  n_rolls &lt;- all_rolls[1:n,]\n  sample_means &lt;- colMeans(n_rolls)\n  qq_df &lt;- tibble(smean = sample_means)\n  qq_plot &lt;- ggplot(qq_df, aes(sample = smean)) +\n  stat_qq() + stat_qq_line() +\n  dsan_theme(\"quarter\") +\n  labs(\n    title = paste0(\"n = \",n)\n  )\n  return(qq_plot)\n}",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#maximum-likelihood-estimation",
    "href": "w09/index.html#maximum-likelihood-estimation",
    "title": "Week 9: Statistical Inference",
    "section": "Maximum Likelihood Estimation",
    "text": "Maximum Likelihood Estimation\n\nCreating a model \\(\\mathcal{M}\\) w/parameters \\(\\param{\\theta}\\) means specifying\n\n\\[\n\\mathcal{M} = \\Pr(\\underbrace{x_1, \\ldots, x_n}_{\\text{Observed Data}} \\mid \\underbrace{\\param{\\theta}}_{\\text{Model Parameters}})\n\\]\n\nWhen we view this as a function of \\(\\param{\\theta}\\), given the observed data, we call it the likelihood function \\(\\mathcal{L}_{\\mathcal{M}}(\\param{\\theta} \\mid x_1, \\ldots, x_n)\\)\nRead this as ‚Äúthe likelihood that our model \\(\\mathcal{M}\\), with parameters \\(\\param{\\theta}\\), produced the data \\(x_1, \\ldots, x_n\\)‚Äù",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#probability-models-are-generative-models",
    "href": "w09/index.html#probability-models-are-generative-models",
    "title": "Week 9: Statistical Inference",
    "section": "Probability Models are Generative Models",
    "text": "Probability Models are Generative Models\n\nA given choice of model parameters \\(\\param{\\theta}\\) can be used to generate simulated datapoints!\nSimple example: \\(X \\sim \\text{Bern}(\\param{p})\\). Just one parameter, \\(\\param{\\theta} = \\{\\param{p}\\}\\)\nWe observe 10 coin flips: 8 heads, 2 tails. Of all possible Bernoulli distributions (parameterized by \\(\\param{p}\\)), which is most likely to generate this data?",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#generative-models",
    "href": "w09/index.html#generative-models",
    "title": "Week 9: Statistical Inference",
    "section": "Generative Models",
    "text": "Generative Models\n\n\n\nGiven a choice of \\(\\param{\\theta}\\), we can generate simulated datasets (here 10 for each labeled value of \\(\\param{p}\\)), then compute likelihood as proportion of datasets with 8 heads, 2 tails\nFrom plot: (Among these vals) \\(\\param{p} = 0.8\\) is maximum likelihood estimate\n\n\n\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(dplyr)\nset.seed(1948)\nobs_heads &lt;- 8\nnum_flips &lt;- 10\nnum_reps &lt;- 10\np_vals &lt;- c(0.01, 0.2, 0.4, 0.6, 0.8, 0.99)\nobs_matches &lt;- c()\nfor (i in 1:length(p_vals)) {\n  cur_p &lt;- p_vals[i]\n  theta_str &lt;- sprintf(\"%.2f\", cur_p)\n  sim_data &lt;- replicate(\n    num_reps,\n    rbinom(num_flips, 1, cur_p)\n  )\n  #print(sim_data)\n  #data_str &lt;- paste0(sim_data, collapse=\", \")\n  num_heads &lt;- colSums(sim_data)\n  #print(num_heads)\n  num_matches &lt;- sum(num_heads == obs_heads)\n  obs_matches &lt;- c(obs_matches, num_matches)\n  #print(num_matches)\n  #print(num_heads)\n  num_tails &lt;- num_flips - num_heads\n  #print(num_tails)\n  data_strs &lt;- paste0(\"[\",num_heads,\" heads, \",num_tails,\" tails]\")\n  data_str &lt;- paste0(data_strs, collapse=\", \")\n  #writeLines(paste0(\"p = \",theta_str,\": \",data_str))\n}\n#print(obs_matches)\nresult_df &lt;- tibble(p=as.character(p_vals), num_matches=obs_matches)\nresult_df &lt;- result_df %&gt;% mutate(prop_matches = obs_matches / num_reps)\nggplot(result_df, aes(x=p, y=prop_matches)) +\n  geom_bar(stat = 'identity', fill=cbPalette[1]) +\n  dsan_theme(\"quarter\") +\n  # theme(\n  #   axis.title.y = element_text(size = 12)\n  # ) +\n  labs(\n    title = \"Likelihood of data (8 heads, 2 tails) given p\",\n    y = \"Proportion of times (8,2) generated\"\n  )",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#simulations-rightarrow-math",
    "href": "w09/index.html#simulations-rightarrow-math",
    "title": "Week 9: Statistical Inference",
    "section": "Simulations \\(\\rightarrow\\) Math",
    "text": "Simulations \\(\\rightarrow\\) Math\nPrev example was overkill: we can solve for optimal \\(\\param{p}\\) value‚Ä¶\n\\[\n\\begin{align*}\np^* &\\overset{\\phantom{x_i\\text{ indep}}}{=} \\argmax_{\\param{p}} \\mathcal{L}(x_1, \\ldots, x_n \\mid \\param{p}) \\\\\n&\\overset{x_i\\text{ indep}}{=} \\argmax_{\\param{p}} \\mathcal{L}(x_1 \\mid \\param{p})\\mathcal{L}(x_2 \\mid \\param{p}) \\cdots \\mathcal{L}(x_n \\mid \\param{p})\n\\end{align*}\n\\]\n\nWhat are the individual \\(\\mathcal{L}(x_i \\mid \\param{p})\\) terms?\nHow do we maximize the product \\(\\mathcal{L}(x_1 \\mid \\param{p}) \\cdots \\mathcal{L}(x_n \\mid \\param{p})\\)?\n\n\nTime for some Math Magic‚Ä¶",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#math-magic-1",
    "href": "w09/index.html#math-magic-1",
    "title": "Week 9: Statistical Inference",
    "section": "Math Magic 1",
    "text": "Math Magic 1\n1. What are the individual \\(\\Pr(x_i \\mid \\param{p})\\) terms?\n\\(X \\sim \\text{Bern}(\\param{p})\\), so\n\\[\n\\begin{align*}\n\\Pr(X = x_i \\mid \\param{p}) &= \\begin{cases}1 - \\param{p} & x_i = 0 \\\\ \\param{p} & x_i = 1\\end{cases} \\; \\leftarrow \\genfrac{}{}{0pt}{}{\\text{ Non-differentiable}}{üò≠} \\\\\n&\\overset{\\text{math}}{\\underset{\\text{magic}}{=}} (1-\\param{p})^{1-x_i}\\param{p}^{x_i} \\; \\leftarrow \\text{ Differentiable! üò≤}\n\\end{align*}\n\\]\nWhy do we need it to be differentiable? Stay tuned‚Ä¶",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#math-magic-2",
    "href": "w09/index.html#math-magic-2",
    "title": "Week 9: Statistical Inference",
    "section": "Math Magic 2",
    "text": "Math Magic 2\n\n\n\n\n\n\n2. How do we maximize the product?\n\\[\np^* = \\argmax_{\\param{p}} f(\\param{p}) \\implies f'(p^*) = 0\n\\]\nTo maximize likelihood, we need to find its derivative3, set equal to 0, and solve:\n\n\n\n\n\n\n\\[\n\\begin{align*}\n&\\frac{d}{d\\param{p}}\\lik(x \\mid \\param{p}) = 0 \\iff \\\\\n&\\frac{d}{d\\param{p}}\\left[\\lik(x_1 \\mid \\param{p})\\lik(x_2 \\mid \\param{p})\\cdots \\lik(x_n \\mid \\param{p})\\right] = 0\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#obstacle-products-vs.-sums",
    "href": "w09/index.html#obstacle-products-vs.-sums",
    "title": "Week 9: Statistical Inference",
    "section": "Obstacle: Products vs.¬†Sums",
    "text": "Obstacle: Products vs.¬†Sums\n\nFinding \\(\\frac{d}{d\\param{p}}\\left[ \\lik(x_1)\\lik(x_2)\\cdots \\lik(x_n)\\right]\\) is a doozy, even with just \\(n = 2\\) datapoints:\n\n\\[\n\\begin{align*}\n&\\frac{d}{d\\param{p}}\\left[ \\lik(x_1)\\lik(x_2) \\right] = \\left( \\frac{d}{d\\param{p}}\\lik(x_1)\\right) \\cdot \\lik(x_2) + \\lik(x_1)\\cdot \\left( \\frac{d}{d\\param{p}}\\lik(x_2) \\right) \\\\\n&= (1-\\param{p})^{-x_1}\\param{p}^{x_1-1}(x_1-\\param{p})\\cdot (1-\\param{p})^{1-x_2}\\param{p}^{x_2} \\\\\n&+ (1-\\param{p})^{1-x_1}\\param{p}^{x_1} \\cdot (1-\\param{p})^{-x_2}\\param{p}^{x_2-1}(x_2 - \\param{p})\n%&= \\frac{d}{d\\theta}\\left[ (1-p)^{1-x_1}p^{x_1}(1-p)^{1-x_2}p^{x_2} \\right]\n\\end{align*}\n\\]\n\nComplicating factor: \\(\\lik(x_i)\\) terms are all multiplied together, forcing us to use product rule: \\(\\frac{d}{d\\param{p}}\\left[\\lik(x_1)\\lik(x_2)\\right] = \\left(\\frac{d}{d\\param{p}}\\lik(x_1)\\right)\\cdot \\lik(x_2) + \\lik(x_1)\\cdot \\left(\\frac{d}{d\\param{p}}\\lik(x_2)\\right)\\)\nIf we had terms that were added rather than multiplied, we‚Äôd have a much easier time: \\(\\frac{d}{d\\param{p}}\\left[ \\lik(x_1) + \\lik(x_2)\\right] = \\frac{d}{d\\param{p}}\\lik(x_1) + \\frac{d}{d\\param{p}} \\lik(x_2)\\)4\nSo, what math operation do we know that turns multiplications into additions?",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#math-magic-3-log-likelihood",
    "href": "w09/index.html#math-magic-3-log-likelihood",
    "title": "Week 9: Statistical Inference",
    "section": "Math Magic 3: Log-Likelihood",
    "text": "Math Magic 3: Log-Likelihood\n\\[\n\\log(a\\cdot b) = \\log(a) + \\log(b)\n\\]\nBingo! So, can we maximize \\(\\loglik(x_i) = \\log(\\mathcal{L}(x_i))\\) rather than \\(\\mathcal{L}(x_i)\\)? Bingo again! Because logarithms are monotonic,\n\\[\nx^* = \\argmax_x \\left[ \\log\\left(f(x)\\right) \\right] \\iff x^* = \\argmax_x \\left[ f(x) \\right]\n\\]\nSo, we can just solve\n\\[\np^* = \\argmax_{\\param{p}} \\left[ \\ell(x_1, \\ldots, x_n)\\right]\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#simplifying",
    "href": "w09/index.html#simplifying",
    "title": "Week 9: Statistical Inference",
    "section": "Simplifying",
    "text": "Simplifying\nOur problem simplifies to figuring out\n\\[\n\\begin{align*}\n\\frac{d}{d\\param{p}}\\left[ \\log \\left( \\lik(x_1)\\cdots \\lik(x_n) \\right) \\right] &= \\frac{d}{d\\param{p}}\\left[ \\log \\lik(x_1) + \\log\\lik(x_2) + \\cdots + \\log\\lik(x_n) \\right] \\\\\n&= \\frac{d}{d\\param{p}}\\left[ \\ell(x_1) + \\ell(x_2) + \\cdots + \\ell(x_n) \\right] = \\frac{d}{d\\param{p}}\\left[ \\sum_{i=1}^n \\ell(x_i)\\right]\n\\end{align*}\n\\]\nBut since the derivative is an additive operator, \\(\\frac{d}{d\\param{p}}\\left[ \\sum_{i=1}^n \\ell(x_i) \\right] = \\sum_{i=1}^n \\frac{d}{d\\param{p}}\\left[ \\ell(x_i) \\right]\\), so we just have to compute \\(\\frac{d}{d\\param{p}}\\ell(x_i)\\)! No product rule required (we still need chain rule):\n\\[\n\\begin{align*}\n\\frac{d}{d\\param{p}}\\left[ \\ell(x_i) \\right] &= \\frac{d}{d\\param{p}}\\left[ \\log((1-\\param{p})^{1-x_i}\\param{p}^{x_i}) \\right] = \\frac{d}{d\\param{p}}\\left[(1-x_i)\\log(1-\\param{p}) + x_i\\log(\\param{p})\\right] \\\\\n&= (1-x_i)\\frac{d}{d\\param{p}}\\log(1-\\param{p}) + x_i\\frac{d}{d\\param{p}}\\log(\\param{p}) = -\\frac{1-x_i}{1-\\param{p}} + \\frac{x_i}{\\param{p}} \\\\\n&= \\frac{\\param{p} - x_i}{(\\param{p}-1)\\param{p}}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#maximizing",
    "href": "w09/index.html#maximizing",
    "title": "Week 9: Statistical Inference",
    "section": "Maximizing",
    "text": "Maximizing\nNow that we know \\(\\frac{d}{d\\param{p}}\\ell(x_i)\\), we set our log-likelihood equation equal to zero to find the likelihood-maximizing \\(\\param{p}\\) value, \\(p^*\\):\n\\[\n\\begin{align*}\n&\\sum_{i=1}^n\\frac{d}{d\\param{p}}\\ell(x_i) = 0 \\iff \\sum_{i=1}^n \\frac{p^* - x_i}{(p^*-1)p^*} = 0 \\\\\n&\\iff -\\frac{1}{(p^*-1)p^*}\\sum_{i=1}^nx_i - np^* = 0 \\\\\n&\\iff \\sum_{i=1}^nx_i = np^* \\iff \\boxed{p^* = \\frac{\\sum_{i=1}^nx_i}{n}}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#mle-intuition",
    "href": "w09/index.html#mle-intuition",
    "title": "Week 9: Statistical Inference",
    "section": "MLE Intuition",
    "text": "MLE Intuition\n\\[\np^* = \\frac{\\sum_{i=1}^nx_i}{n} = \\frac{\\sum_{i=1}^n \\mathbf{1}[x_i = 1]}{n} \\genfrac{}{}{0pt}{}{\\leftarrow \\text{\\# Heads}}{\\leftarrow \\text{\\# Flips }}\n\\]\n\nMLE almost always matches intuition! Example: given data \\(x_1, \\ldots, x_n\\), what Normal distribution best fits this data?\nSame as asking: what parameter settings for \\(\\mathcal{N}(\\param{\\mu}, \\param{\\sigma^2})\\) are most likely to produce \\(x_1, \\ldots, x_n\\)? The answer:\n\n\\[\n\\mu^* = \\frac{\\sum_{i=1}^n x_i}{n} \\; \\; \\; \\sigma^2_* = \\frac{\\sum_{i=1}^n (x_i-\\mu^*)^2}{n}\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#the-dark-side-of-mle",
    "href": "w09/index.html#the-dark-side-of-mle",
    "title": "Week 9: Statistical Inference",
    "section": "The Dark Side of MLE",
    "text": "The Dark Side of MLE\n\nSometimes steers us in the wrong direction!\nConsider values from previous slide, as estimators for population \\(\\mu\\) and \\(\\sigma^2\\): \\(\\mu^*\\) unbiased if \\(\\expect{\\mu^*} = \\mu\\):\n\n\\[\n\\begin{align*}\n\\expect{\\mu^*} &= \\bigexpect{\\frac{\\sum_{i=1}^nx_i}{n}} = \\frac{1}{n}\\sum_{i=1}^n\\expect{x_i} \\\\\n&= \\frac{1}{n}\\sum_{i=1}^n\\mu = \\frac{n\\mu}{n} = \\mu \\; ‚úÖ\n\\end{align*}\n\\]\n\nSo far so good. How about \\(\\sigma^2_*\\)?",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#mle-as-biased-estimator",
    "href": "w09/index.html#mle-as-biased-estimator",
    "title": "Week 9: Statistical Inference",
    "section": "MLE as Biased Estimator",
    "text": "MLE as Biased Estimator\n\nBefore we think about \\(\\expect{\\sigma^2_*}\\), let‚Äôs rewrite \\(\\sigma^2_*\\):\n\n\\[\n\\begin{align*}\n\\sigma^2_* &= \\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu^*)^2 = \\frac{1}{n}\\sum_{i=1}^n \\left( x_i^2 - 2 \\mu^* x_i + (\\mu^*)^2 \\right) \\\\\n&= \\frac{1}{n}\\sum_{i=1}^nx_i^2 - 2\\mu^*\\underbrace{\\frac{\\sum_{i=1}^nx_i}{n}}_{\\mu^*} + (\\mu^*)^2 = \\frac{1}{n}\\sum_{i=1}^nx_i^2 - (\\mu^*)^2 \\\\\n&= \\frac{1}{n}\\sum_{i=1}^nx_i^2 - (\\mu^*)^2\n\\end{align*}\n\\]\n\nNow we‚Äôre ready to compute \\(\\expect{\\sigma^2_*}\\)!",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#computing-mathbbesigma2_",
    "href": "w09/index.html#computing-mathbbesigma2_",
    "title": "Week 9: Statistical Inference",
    "section": "Computing \\(\\mathbb{E}[\\sigma^2_*]\\)",
    "text": "Computing \\(\\mathbb{E}[\\sigma^2_*]\\)\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\bigexpect{\\frac{1}{n}\\sum_{i=1}^nx_i^2 - (\\mu^*)^2} = \\frac{1}{n}\\sum_{i=1}^n \\expect{x_i^2} - \\expect{(\\mu^*)^2}\n\\end{align*}\n\\]\n\nWhat do we know about \\(\\expect{x_i^2}\\)? Remember the (alternate) definition of variance: \\(\\Var{X} = \\expect{X^2} - \\left(\\expect{X}\\right)^2\\). Then\n\n\\[\n\\expect{X^2} = \\Var{X} + \\left(\\expect{X}\\right)^2\n\\]\nSo let‚Äôs plug in the right side when we see \\(\\expect{X^2}\\) or \\(\\expect{(\\mu^*)^2}\\):\n\\[\n\\begin{align*}\n\\frac{1}{n}\\sum_{i=1}^n \\expect{x_i^2} - \\expect{(\\mu^*)^2} &= \\frac{1}{n}\\sum_{i=1}^n\\left(\\Var{X} + \\left(\\expect{X}\\right)^2\\right) - \\expect{(\\mu^*)^2} \\\\\n&= (\\sigma^2 + \\mu^2) - \\left(\\Var{\\mu^*} + \\left(\\expect{\\mu^*}\\right)^2\\right)\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#almost-there",
    "href": "w09/index.html#almost-there",
    "title": "Week 9: Statistical Inference",
    "section": "Almost There!",
    "text": "Almost There!\nWe know that \\(\\expect{\\mu^*} = \\mu\\), but what is \\(\\Var{\\mu^*}\\)? Remember that \\(\\Var{aX} = a^2\\Var{X}\\)!\n\\[\n\\Var{\\mu^*} = \\bigVar{\\frac{1}{n}\\sum_{i=1}^nx_i} = \\frac{1}{n^2}\\sum_{i=1}^n\\Var{x_i} = \\frac{n\\sigma^2}{n^2} = \\frac{\\sigma^2}{n}\n\\]\nAnd we plug back in to get:\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\sigma^2 + \\mu^2 - \\Var{\\mu^*} - \\left(\\expect{\\mu^*}\\right)^2 \\\\\n&= \\sigma^2 + \\mu^2 - \\frac{\\sigma^2}{n} - \\mu^2 = \\sigma^2 - \\frac{\\sigma^2}{n} \\\\\n&= \\frac{n\\sigma^2 - \\sigma^2}{n} = \\frac{\\sigma^2(n-1)}{n} \\\\\n&= \\color{red}{\\left(\\frac{n-1}{n}\\right)\\sigma^2} \\neq \\sigma^2 \\; üíÄ\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#why-does-this-happen-handwaving",
    "href": "w09/index.html#why-does-this-happen-handwaving",
    "title": "Week 9: Statistical Inference",
    "section": "Why Does This Happen?: Handwaving",
    "text": "Why Does This Happen?: Handwaving\n\nLong story short, we underpredict the population variance because we already used some of the data to compute \\(\\mu^*\\)!\nThis is where the degrees of freedom heuristic comes in:\n\nWhen we construct an estimate \\(e\\), \\(df(e) = n - k_e\\)\n\\(k_e =\\) number of other estimates used to calculate \\(e\\)!",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#handwavy-intuition",
    "href": "w09/index.html#handwavy-intuition",
    "title": "Week 9: Statistical Inference",
    "section": "Handwavy Intuition",
    "text": "Handwavy Intuition\n\nConsider \\(X_1, X_2 \\sim \\mathcal{N}(0,1)\\): \\(\\mu = 0\\), \\(\\sigma^2 = 1\\).\n\n\\[\n\\expect{\\mu^*} = \\bigexpect{\\frac{X_1 + X_2}{2}} = \\frac{1}{2}\\left(\\expect{X_1} + \\expect{X_2}\\right) = 0 = \\mu \\; ‚úÖ\n\\]\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\frac{1}{2}\\bigexpect{(X_1 - \\mu^*)^2 + (X_2 - \\mu^*)^2} \\\\\n&= \\frac{1}{2}\\bigexpect{\\left(X_1^2 + \\mu^2_* -2\\mu^*X_1\\right) + \\left(X_2^2 + \\mu^2_* - 2X_2\\mu^*\\right)} \\\\\n&= \\frac{1}{2}\\expect{X_1^2 + X_2^2 + 2\\mu_*^2 - 2\\mu^*X_1 - 2\\mu^*X_2} \\\\\n&= \\frac{1}{2}\\left(\\expect{X_1^2} + \\expect{X_2^2} + 2\\expect{\\mu_*^2} - 2\\expect{\\mu^*X_1} - 2\\expect{\\mu^*X_2}\\right) \\\\\n&\\implies \\boxed{\\expect{\\sigma^2_*} = \\frac{1}{2}\\sigma^2}\n\\end{align*}\n\\]\n\nWe‚Äôre off by \\(\\frac{1}{2}\\)! What to do?",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#handwavy-solution",
    "href": "w09/index.html#handwavy-solution",
    "title": "Week 9: Statistical Inference",
    "section": "Handwavy Solution",
    "text": "Handwavy Solution\n\nWe can account for degrees of freedom, correcting the MLE by a factor of \\(\\frac{n}{df(e^*)}\\)!\n\n\\(e^\\circledast = \\frac{n}{df(e^*)}e^*\\)\n\nEx: Since \\(\\expect{\\sigma_*^2} = \\frac{n-1}{n}\\sigma^2\\), we can instead use \\(\\sigma^2_\\circledast = \\frac{n}{n-1}\\sigma^2_*\\). This gives us:\n\n\\[\n\\expect{\\sigma^2_\\circledast} = \\bigexpect{\\frac{n}{n-1}\\sigma^2_*} = \\frac{n}{n-1}\\frac{n-1}{n}\\sigma^2 = \\color{green}{\\sigma^2} \\; ‚úÖ\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#st-century-solution",
    "href": "w09/index.html#st-century-solution",
    "title": "Week 9: Statistical Inference",
    "section": "21st-Century Solution",
    "text": "21st-Century Solution\n\nBe Bayesian, use priors on parameters (creating hyperparameters)!\nPretend we know \\(\\sigma^2\\), but want to find the ‚Äúbest‚Äù value of \\(\\mu\\):\n\n\\[\n\\begin{array}{rlccc}\nX_1, X_2 \\overset{iid}{\\sim} \\mathcal{N}( &\\hspace{-5mm}\\mu\\hspace{0.5mm}, &\\hspace{-8mm}\\overbrace{\\sigma^2}^{\\large\\text{known}}\\hspace{-2mm}) & & \\\\\n&\\hspace{-4mm}\\downarrow & ~ &\\hspace{-10mm}{\\small\\text{estimate}} & \\hspace{-6mm} & \\hspace{-8mm}{\\small\\text{uncertainty}} \\\\[-5mm]\n&\\hspace{-5mm}\\mu &\\hspace{-5mm}\\sim \\mathcal{N}&\\hspace{-7mm}(\\overbrace{m}&\\hspace{-12mm}, &\\hspace{-16mm}\\overbrace{s})\n\\end{array}\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#single-datapoint",
    "href": "w09/index.html#single-datapoint",
    "title": "Week 9: Statistical Inference",
    "section": "Single Datapoint",
    "text": "Single Datapoint\n\nLet‚Äôs consider the estimate of \\(\\mu\\) from a single datapoint \\(X_i\\). MLE just gives us \\(\\mu^* = X_i\\). How about MAP estimate?\n\n\\[\n\\lik\\left(X_i, \\mu, m, s\\right) \\overset{\\text{factors}}{\\underset{\\text{into}}{=}} P(X_i \\mid \\mu)P(\\mu \\mid m, s)P(m, s)\n\\]\n\nRemembering the pdf of the Normal distribution, we have:\n\n\\[\n\\lik\\left(X_i, \\mu, m, s\\right) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left[-\\frac{(X_i-\\mu)^2}{2\\sigma^2}\\right]\\frac{1}{s\\sqrt{2\\pi}}\\exp\\left[-\\frac{(\\mu - m)^2}{2s^2}\\right]\n\\]\n\nThen, remembering that we can maximize the log-likelihood rather than the likelihood:\n\n\\[\n\\ell(X_i, \\mu, m, s) = \\log\\left[\\frac{1}{\\sigma\\sqrt{2\\pi}}\\right] - \\frac{(X_i-\\mu)^2}{2\\sigma^2} + \\log\\left[\\frac{1}{s\\sqrt{2\\pi}}\\right] - \\frac{(\\mu - m)^2}{2s^2}\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#taking-the-derivative",
    "href": "w09/index.html#taking-the-derivative",
    "title": "Week 9: Statistical Inference",
    "section": "Taking the Derivative",
    "text": "Taking the Derivative\n\nTaking the derivative gives us:\n\n\\[\n\\begin{align*}\n\\frac{\\partial\\ell}{\\partial \\mu} &= \\frac{\\partial}{\\partial\\mu}\\left[ {\\color{red}\\cancel{\\color{black}\\log\\left[\\frac{1}{\\sigma\\sqrt{2\\pi}}\\right]}} - \\frac{(X_i-\\mu)^2}{2\\sigma^2} + {\\color{red}\\cancel{\\color{black}\\log\\left[\\frac{1}{s\\sqrt{2\\pi}}\\right]}} - \\frac{(\\mu - m)^2}{2s^2}\\right] \\\\\n&= - \\frac{1}{2\\sigma^2}\\cdot\\frac{\\partial}{\\partial\\mu}\\left[{\\color{red}\\cancel{\\color{black}X_i^2}} + \\mu^2 - 2X_i\\mu\\right] - \\frac{1}{2s^2}\\cdot\\frac{\\partial}{\\partial\\mu}\\left[\\mu^2 + {\\color{red}\\cancel{\\color{black}m^2}} - 2\\mu m\\right] \\\\\n&= -\\frac{1}{2\\sigma^2}\\cdot (2\\mu -2X_i) - \\frac{1}{2s^2}\\cdot (2\\mu - 2m) = \\frac{X_i-\\mu}{\\sigma^2} + \\frac{m - \\mu}{s^2}\n\\end{align*}\n\\]\n\nAnd we set equal to zero and solve to obtain the MAP estimate:\n\n\\[\n\\begin{align*}\n&\\frac{X_i - \\mu^*}{\\sigma^2} + \\frac{m - \\mu^*}{s^2} = 0 \\iff \\frac{\\mu^*}{\\sigma^2} + \\frac{\\mu^*}{s^2} = \\frac{X_i}{\\sigma^2} + \\frac{m}{s^2} \\iff \\\\\n&\\frac{s^2\\mu^* + \\sigma^2\\mu^*}{\\sigma^2s^2} = \\frac{s^2X_i + \\sigma^2m}{\\sigma^2s^2} \\iff \\mu^*(s^2+\\sigma^2) = s^2X_i + \\sigma^2m \\\\\n&\\iff \\boxed{\\mu^* = \\left(\\frac{s^2}{s^2 + \\sigma^2}\\right)X_i + \\left(\\frac{\\sigma^2}{s^2 + \\sigma^2}\\right)m}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#the-takeaway",
    "href": "w09/index.html#the-takeaway",
    "title": "Week 9: Statistical Inference",
    "section": "The Takeaway",
    "text": "The Takeaway\n\nBayesian approach allows new evidence to be weighed against existing evidence, with statistically principled way to derive these weights:\n\n\\[\n\\begin{array}{ccccc}\n\\Pr_{\\text{post}}(\\mathcal{H}) &\\hspace{-6mm}\\propto &\\hspace{-6mm} \\Pr(X \\mid \\mathcal{H}) &\\hspace{-6mm} \\times &\\hspace{-6mm} \\Pr_{\\text{pre}}(\\mathcal{H}) \\\\\n\\text{Posterior} &\\hspace{-6mm}\\propto &\\hspace{-6mm}\\text{Evidence} &\\hspace{-6mm} \\times &\\hspace{-6mm} \\text{Prior}\n\\end{array}\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#generalized-method-of-moments-gmm-estimation",
    "href": "w09/index.html#generalized-method-of-moments-gmm-estimation",
    "title": "Week 9: Statistical Inference",
    "section": "Generalized Method of Moments (GMM) Estimation",
    "text": "Generalized Method of Moments (GMM) Estimation\n\nRecall that the \\(k\\)th moment of an RV \\(X\\) is \\(\\mu_k = \\expect{X^k}\\)\ne.g., \\(\\mu_1 = \\expect{X}\\), \\(\\mu_2 = \\Var{X} + \\expect{X}^2\\)\nAlso recall (I rambled on about) how the MGF contains all information about a distribution. This means we can estimate distributions from data:\nDefine \\(k\\)th sample moment of \\(\\mathbf{X}_N\\): \\(\\widehat{\\mu}_k = \\frac{1}{N}\\sum_{i=1}^nX_i^k\\). Then:\n\\[\n  \\begin{align*}\n  \\mu_1(\\param{\\theta}) &= \\widehat{\\mu}_1 \\\\\n  \\mu_2(\\param{\\theta}) &= \\widehat{\\mu}_2 \\\\\n  &~\\vdots \\\\\n  \\mu_N(\\param{\\theta}) &= \\widehat{\\mu}_N\n  \\end{align*}\n  \\]\nGives us a system of equations, allowing us to solve for parameters \\(\\param{\\theta}\\) of our distribution!",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#intuition",
    "href": "w09/index.html#intuition",
    "title": "Week 9: Statistical Inference",
    "section": "Intuition",
    "text": "Intuition\n\n\n\n\n\n\n\n\n\nLow Variance\nHigh Variance\n\n\n\n\nLow Bias\n\n\n\n\nHigh Bias\n\n\n\n\n\n\n\nAdapted from Fortmann-Roe (2012), ‚ÄúUnderstanding the Bias-Variance Tradeoff‚Äù",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#components-of-the-error-term",
    "href": "w09/index.html#components-of-the-error-term",
    "title": "Week 9: Statistical Inference",
    "section": "Components of the Error Term",
    "text": "Components of the Error Term\n\nWe estimate ‚Äútrue‚Äù DGP \\(Y = f(X)\\) with model \\(\\widehat{f}(X)\\)5, and then we use \\(\\widehat{f}\\) to predict the value of \\(Y\\) for a point \\(x_0\\).\nWhat is our expected error at this point, \\(\\Err(x_0)\\)?\n\n\\[\n\\begin{align*}\n\\Err(x_0) &= \\bigexpect{\\left.(Y ‚àí \\widehat{f}(x_0))^2 \\right| X = x_0} \\\\\n&= \\sigma^2_{\\varepsilon} + \\left( \\bigexpect{\\widehat{f}(x_0)} ‚àí f(x_0) \\right)^2 + \\mathbb{E}\\left[\\widehat{f}(x_0) ‚àí \\bigexpect{\\widehat{f}(x_0)}\\right]^2 \\\\\n&= \\sigma^2_{\\varepsilon} + \\left( \\text{Bias}(\\widehat{f}(x_0)\\right)^2 + \\bigVar{\\widehat{f}(x_0)} \\\\\n&= \\text{Irreducible Error} + \\text{Bias}^2 + \\text{Variance}.\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#in-practice",
    "href": "w09/index.html#in-practice",
    "title": "Week 9: Statistical Inference",
    "section": "In Practice",
    "text": "In Practice\n\n\n\nFigure from (tharwat_parameter_2019?)",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#appendix-1-derivation-of-mathbbemu_2",
    "href": "w09/index.html#appendix-1-derivation-of-mathbbemu_2",
    "title": "Week 9: Statistical Inference",
    "section": "Appendix 1: Derivation of \\(\\mathbb{E}[\\mu_*^2]\\)",
    "text": "Appendix 1: Derivation of \\(\\mathbb{E}[\\mu_*^2]\\)\n\\[\n\\begin{align*}\n\\expect{\\mu_*^2} &= \\bigexpect{\\left(\\frac{X_1 + X_2}{2}\\right)^2} = \\frac{1}{4}\\expect{(X_1+X_2)^2} \\\\\n&= \\frac{1}{4}\\expect{X_1^2 + X_2^2 + 2X_1X_2} = \\frac{1}{4}\\left(\\expect{X_1^2} + \\expect{X_2^2} + 2\\expect{X_1X_2}\\right) \\\\\n&= \\frac{1}{4}\\left(\\Var{X_1} + \\expect{X_1}^2 + \\Var{X_2} + \\expect{X_2}^2 + 2\\expect{X_1X_2}\\right) \\\\\n&= \\frac{1}{4}\\left(2\\sigma^2 + 2\\mu^2 + 2\\expect{X_1X_2}\\right) \\\\\n&= \\frac{1}{2}\\left(\\sigma^2 + \\mu^2 + \\expect{X_1X_2}\\right) \\overset{iid}{=} \\frac{1}{2}\\left(\\sigma^2 + \\mu^2 + \\mu^2\\right) \\\\\n&\\implies \\boxed{\\expect{\\mu^2_*} = \\mu^2 + \\frac{\\sigma^2}{2}} \\; \\; \\left(\\therefore \\; \\expect{\\mu_*^2} \\neq \\mu^2 \\right)\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#appendix-2-derivation-of-mathbbemux_i",
    "href": "w09/index.html#appendix-2-derivation-of-mathbbemux_i",
    "title": "Week 9: Statistical Inference",
    "section": "Appendix 2: Derivation of \\(\\mathbb{E}[\\mu^*X_i]\\)",
    "text": "Appendix 2: Derivation of \\(\\mathbb{E}[\\mu^*X_i]\\)\n\\[\n\\begin{align*}\n\\expect{\\mu^*X_1} &= \\bigexpect{\\left(\\frac{X_1 + X_2}{2}\\right)X_1} = \\frac{1}{2}\\expect{X_1^2 + X_1X_2} \\\\\n&= \\frac{1}{2}\\expect{X_1^2} + \\frac{1}{2}\\expect{X_1X_2} = \\frac{1}{2}\\left(\\sigma^2 + \\mu^2\\right) + \\frac{1}{2}\\mu^2 \\\\\n&\\implies \\expect{\\mu^*X_1} = \\mu^2 + \\frac{\\sigma^2}{2}\n\\end{align*}\n\\]\nAnd since \\(X_1\\) was chosen without loss of generality,\n\\[\n\\boxed{\\expect{\\mu^*X_i} = \\mu^2 + \\frac{\\sigma^2}{2}}\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#appendix-3-derivation-of-mathbbesigma2_",
    "href": "w09/index.html#appendix-3-derivation-of-mathbbesigma2_",
    "title": "Week 9: Statistical Inference",
    "section": "Appendix 3: Derivation of \\(\\mathbb{E}[\\sigma^2_*]\\)",
    "text": "Appendix 3: Derivation of \\(\\mathbb{E}[\\sigma^2_*]\\)\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\frac{1}{2}\\bigexpect{(X_1 - \\mu^*)^2 + (X_2 - \\mu^*)^2} \\\\\n&= \\frac{1}{2}\\bigexpect{\\left(X_1^2 + \\mu^2_* -2\\mu^*X_1\\right) + \\left(X_2^2 + \\mu^2_* - 2X_2\\mu^*\\right)} \\\\\n&= \\frac{1}{2}\\expect{X_1^2 + X_2^2 + 2\\mu_*^2 - 2\\mu^*X_1 - 2\\mu^*X_2} \\\\\n&= \\frac{1}{2}\\left(\\expect{X_1^2} + \\expect{X_2^2} + 2\\expect{\\mu_*^2} - 2\\expect{\\mu^*X_1} - 2\\expect{\\mu^*X_2}\\right) \\\\\n&= \\frac{1}{2}\\left( 2\\sigma^2 + 2\\mu^2 + 2\\left(\\mu^2 + \\frac{\\sigma^2}{2}\\right) - 2\\left(\\mu^2 + s/2\\right) - 2\\left(\\mu^2 + s/2\\right) \\right) \\\\\n&= \\sigma^2 + \\mu^2 + \\mu^2 + \\frac{\\sigma^2}{2} - \\mu^2 - \\frac{\\sigma^2}{2} - \\mu^2 - \\frac{\\sigma^2}{2} = \\sigma^2 - \\frac{\\sigma^2}{2} \\\\\n&\\implies \\boxed{\\expect{\\sigma^2_*} = \\frac{1}{2}\\sigma^2}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#references",
    "href": "w09/index.html#references",
    "title": "Week 9: Statistical Inference",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#week-9-lab",
    "href": "w09/index.html#week-9-lab",
    "title": "Week 9: Statistical Inference",
    "section": "Week 9 Lab",
    "text": "Week 9 Lab\n\nLink here",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#footnotes",
    "href": "w09/index.html#footnotes",
    "title": "Week 9: Statistical Inference",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is because an Eigenvalue-Eigenvector pair for a matrix \\(\\mathbf{M}\\) is a vector \\(\\mathbf{v}\\) and scalar value \\(\\lambda\\) which satisfy \\(\\mathbf{M}\\mathbf{v} = \\lambda \\mathbf{v}\\). In words: the result of (left) matrix-multiplying \\(\\mathbf{v}\\) by \\(\\mathbf{M}\\) is the same as scalar-multiplying \\(\\mathbf{v}\\) by a factor of \\(\\lambda\\). In our case the Eigenvector is \\(\\mathbf{r}^*\\) and the Eigenvalue is \\(\\lambda = 1\\), since \\(\\mathbf{E}\\mathbf{r}^* = 1 \\cdot \\mathbf{r}^*\\).For the math-curious, there are lots of fun results from matrix theory which assure us that \\(\\mathbf{E}\\) is guaranteed to have principal eigenvalue \\(\\lambda = 1\\) üíÜ‚Ü©Ô∏é\nNote the capital \\(N\\) for cardinality of observations, vs.¬†(lowercase) \\(1, 2, \\ldots, n\\) for ordinal labels on each observation. This will spare you many headaches!‚Ü©Ô∏é\nAnd that‚Äôs why we used math magic to make \\(\\Pr(x_i \\mid \\param{p})\\) differentiable, in the previous slide!‚Ü©Ô∏é\nWe achieve this simplification because the derivative operator is additive: \\(\\frac{d}{dx}\\left[ f(x) + g(x) \\right] = \\frac{d}{dx}f(x) + \\frac{d}{dx}g(x)\\)‚Ü©Ô∏é\nIt‚Äôs even more complicated, since we don‚Äôt even know whether the features \\(X\\) we‚Äôve chosen are actually the features in the world that causally affect \\(Y\\), but that‚Äôs for later classes‚Ä¶ Or see (hastie_elements_2013?)!‚Ü©Ô∏é",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/slides.html#finite-state-automata",
    "href": "w09/slides.html#finite-state-automata",
    "title": "Week 9: Statistical Inference",
    "section": "Finite-State Automata",
    "text": "Finite-State Automata\n(Deterministic!) Only ‚Äúaccepts‚Äù strings with even number of 1s:\n\n\n\n\n\n\n\n\n\n\n\nInput String\nResult\nInput String\nResult\n\n\n\n\n\\(\\varepsilon\\)\n‚úÖ\n01\n\n\n\n0\n‚úÖ\n10\n\n\n\n1\n\n1000000\n\n\n\n00\n‚úÖ\n10000001\n‚úÖ\n\n\n\n\n\n\n‚Ä¶But we‚Äôre trying to model probabilistic evolution!"
  },
  {
    "objectID": "w09/slides.html#enter-markov-chains",
    "href": "w09/slides.html#enter-markov-chains",
    "title": "Week 9: Statistical Inference",
    "section": "Enter Markov Chains",
    "text": "Enter Markov Chains\n\n\n\nGraphically\n\n\n\n\n\n\n\n\n\n\n\n\n\nMathematically\n\n\\[\n\\begin{array}{c c}\n& \\begin{array}{c c c} 1\\phantom{1} & \\phantom{1}2\\phantom{1} & \\phantom{1}3 \\\\ \\end{array} \\\\\n\\begin{array}{c c c}1 \\\\ 2 \\\\ 3 \\end{array} &\n\\left[\n\\begin{array}{c c c}\n0 & 1/2 & 1/2 \\\\\n1/3 & 0 & 2/3 \\\\\n1/3 & 2/3 & 0\n\\end{array}\n\\right]\n\\end{array}\n\\]\n\n\\[\n\\begin{array}{c c}\n& \\begin{array}{c c c} 1\\phantom{1} & \\phantom{2}2\\phantom{2} & \\phantom{1}3 \\\\ \\end{array} \\\\\n\\begin{array}{c c c}1 \\\\ 2 \\\\ 3 \\end{array} &\n\\left[\n\\begin{array}{c c c}\n1/2 & 1/3 & 1/6 \\\\\n1/10 & 1/2 & 2/5 \\\\\n1/8 & 3/8 & 1/2\n\\end{array}\n\\right]\n\\end{array}\n\\]"
  },
  {
    "objectID": "w09/slides.html#hidden-markov-models",
    "href": "w09/slides.html#hidden-markov-models",
    "title": "Week 9: Statistical Inference",
    "section": "Hidden Markov Models",
    "text": "Hidden Markov Models\n\nUse observed data to infer unobserved variables\n\n\n\n(What our brains are doing, most of the time!)"
  },
  {
    "objectID": "w09/slides.html#pagerank-matrix-magic",
    "href": "w09/slides.html#pagerank-matrix-magic",
    "title": "Week 9: Statistical Inference",
    "section": "PageRank (Matrix Magic)",
    "text": "PageRank (Matrix Magic)\n\nWhat is the relevance of this abstract topic? ‚Ä¶ü§ë\n\n\n\nCode\nlibrary(readr)\nlibrary(ggplot2)\ngoog_df &lt;- read_csv(\"assets/google_yearly_revenue.csv\")\nggplot(goog_df, aes(x=year, y=revenue_billions)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title = \"Google Yearly Revenue, 2002-2022\",\n    x = \"Year\",\n    y = \"Revenue (Billion USD)\"\n  ) +\n  dsan_theme(\"full\")\n\n\n\n\nPageRank = The ‚Äúspark‚Äù that ignited the Google flame"
  },
  {
    "objectID": "w09/slides.html#pagerank-visualized",
    "href": "w09/slides.html#pagerank-visualized",
    "title": "Week 9: Statistical Inference",
    "section": "PageRank Visualized",
    "text": "PageRank Visualized\n\nNodes = Webpages, Edges = Links\n\n\n\nGoal: Rank the relative ‚Äúimportance‚Äù of a site \\(S_i\\), taking into account the importance of other sites that link to \\(S_i\\)\n\n‚ÄúImportant‚Äù sites: linked to often, and linked to often by other important sites"
  },
  {
    "objectID": "w09/slides.html#chickens-and-eggs",
    "href": "w09/slides.html#chickens-and-eggs",
    "title": "Week 9: Statistical Inference",
    "section": "Chickens and Eggs",
    "text": "Chickens and Eggs\n\nParadoxical at first: how are we supposed to figure out the importance of a site \\(S_i\\), when that‚Äôs determined by\n\nthe importance of sites \\(S_j\\) that link to \\(S_i\\), which is determined by\n\nthe importance of sites \\(S_k\\) that link to sites \\(S_j\\), which is determined by\n\nthe importance of the sites \\(S_\\ell\\) that link to those sites \\(S_k\\), which is determined by‚Ä¶\n\n\n\n\n\\[\n\\begin{align*}\n\\mathsf{Importance}(S_i) &= f(\\mathsf{Importance}(S_{j \\rightarrow i})) = f(f(\\mathsf{Importance}(S_{k \\rightarrow j \\rightarrow i}))) \\\\\n&= f(f(f(\\mathsf{Importance}(S_{\\ell \\rightarrow k \\rightarrow j \\rightarrow i})))) = \\cdots\n\\end{align*}\n\\]\n\n\nSanity hint: Remember infinite sums from calculus! They can converge, despite having infinitely-many terms‚Ä¶ This is something like that, but for recursion (the mathematical term for an object whose definition refers to itself)"
  },
  {
    "objectID": "w09/slides.html#resolving-recursive-definitions",
    "href": "w09/slides.html#resolving-recursive-definitions",
    "title": "Week 9: Statistical Inference",
    "section": "Resolving Recursive Definitions",
    "text": "Resolving Recursive Definitions\n\nWe can compute this importance ranking, despite its recursive definition!\nRecall, for example, the Fibonacci sequence: \\(1, 1, 2, 3, 5, 8, 13, 21, \\ldots\\)\nDefined recursively!\n\n\\[\nf(n) = \\begin{cases}\n1 & n = 1\\text{ or }n = 2 \\\\\nf(n-2) + f(n-1) & n &gt; 2\n\\end{cases}\n\\]\n\nAnd yet, a guy named Bernoulli figured out\n\\[\nf(n) = \\frac{\\varphi^n - \\psi^n}{\\varphi - \\psi} = \\frac{\\varphi^n - \\psi^n}{\\sqrt{5}},\n\\]\nwhere \\(\\varphi\\) is the ‚ÄúGolden Ratio‚Äù \\(\\frac{1 + \\sqrt{5}}{2}\\) and \\(\\psi\\) its conjugate \\(\\frac{1 - \\sqrt{5}}{2}\\)."
  },
  {
    "objectID": "w09/slides.html#the-pagerank-process",
    "href": "w09/slides.html#the-pagerank-process",
    "title": "Week 9: Statistical Inference",
    "section": "The PageRank Process",
    "text": "The PageRank Process\n\nEvery site starts with equal PageRank score: \\(r^{(0)}_1 = r^{(0)}_2 = r^{(0)}_3 = \\frac{1}{3}\\).\nEach link \\(S_i \\rightarrow S_j\\) is a vote of confidence that \\(S_i\\) is giving to \\(S_j\\)\nAt each time \\(t\\), a site \\(S_i\\) ‚Äúspends‚Äù whatever voting power it currently has (\\(r^{(t)}_i\\)) on the sites it links to.\n\n\\(S_1\\) casts one vote for itself and one vote for \\(S_2\\), thus spending \\(\\frac{1}{2}\\) of its total PageRank on itself and \\(\\frac{1}{2}\\) of its total PageRank on \\(S_2\\).\n\nState of the process at time \\(t\\): \\(\\mathbf{r}^{(t)} = \\begin{bmatrix}r^{(t)}_1 & r^{(t)}_2 & r^{(t)}_3\\end{bmatrix}^\\top\\)\nCan form a matrix specifying how this state evolves from time \\(t\\) to time \\(t+1\\)!\n\n\\[\n\\mathbf{E} = \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix} \\; \\leadsto \\; \\mathbf{r}^{(t+1)} = \\mathbf{E}\\mathbf{r}^{(t)}\n\\]\n\n\nGiven the ‚Äú\\(S_1\\) casts one vote for itself‚Ä¶‚Äù part, can you say exactly what \\(S_1\\) will ‚Äúspend‚Äù on itself and on \\(S_2\\) at time \\(t = 0\\) (in the first round)?"
  },
  {
    "objectID": "w09/slides.html#section",
    "href": "w09/slides.html#section",
    "title": "Week 9: Statistical Inference",
    "section": "",
    "text": "We can use \\(\\mathbf{E}\\) to figure out the state at each step, starting from \\(t = 0\\)!\n\n\\[\n\\begin{array}{c@{}c@{}c@{}c@{}c@{}c@{}c}\n\\mathbf{r}^{(1)} & = & \\mathbf{E}\\mathbf{r}^{(0)} & = & \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix}\\begin{bmatrix}\n\\frac{1}{3} \\\\\n\\frac{1}{3} \\\\\n\\frac{1}{3}\\end{bmatrix} & = & \\begin{bmatrix}\n\\frac{1}{3} \\\\\n\\frac{1}{2} \\\\\n\\frac{1}{6}\n\\end{bmatrix} \\\\\n~ & ~ & ~ & ~ & ~ & \\swarrow & ~ \\\\\n\\mathbf{r}^{(2)} & = & \\mathbf{E}\\mathbf{r}^{(1)} & = & \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix}\\begin{bmatrix}\\frac{1}{3} \\\\ \\frac{1}{2} \\\\ \\frac{1}{6}\\end{bmatrix} & = & \\begin{bmatrix}\\frac{5}{12} \\\\ \\frac{1}{3} \\\\ \\frac{1}{4}\\end{bmatrix} \\\\\n~ & ~ & ~ & ~ & ~ & \\swarrow & ~ \\\\\n\\mathbf{r}^{(3)} & = & \\mathbf{E}\\mathbf{r}^{(2)} & = & \\cdots & ~ & ~\n\\end{array}\n\\]"
  },
  {
    "objectID": "w09/slides.html#matrix-magic",
    "href": "w09/slides.html#matrix-magic",
    "title": "Week 9: Statistical Inference",
    "section": "Matrix Magic",
    "text": "Matrix Magic\n\n(1) Won‚Äôt we just have to run this forever? (2) How do we know it‚Äôll converge to something?\nAnswers: (1) No! (2) because Markov matrix magic!\n‚ÄúSteady state‚Äù = state where \\(\\mathbf{r}^{(t)} = \\mathbf{r}^{(t+1)} = \\mathbf{r}^{(t+2)} = \\cdots \\definedas \\mathbf{r}^*\\). But this means\n\n\\[\n\\mathbf{r}^{(t+1)} = \\mathbf{r}^{(t)} \\iff \\mathbf{E}\\mathbf{r}^{(t)} = \\mathbf{r}^{(t)} \\iff \\mathbf{E}\\mathbf{r}^* = \\mathbf{r}^*\n\\]\n\nThis \\(\\mathbf{r}^*\\) is (by definition!) an Eigenvector of \\(\\mathbf{E}\\) with Eigenvalue \\(\\lambda = 1\\)!1\n\n\n\nIn my opinion, along with e.g.¬†insolubility of the quintic, this is maybe the most mind-blowing case of math magic :3\n\n\nThis is because an Eigenvalue-Eigenvector pair for a matrix \\(\\mathbf{M}\\) is a vector \\(\\mathbf{v}\\) and scalar value \\(\\lambda\\) which satisfy \\(\\mathbf{M}\\mathbf{v} = \\lambda \\mathbf{v}\\). In words: the result of (left) matrix-multiplying \\(\\mathbf{v}\\) by \\(\\mathbf{M}\\) is the same as scalar-multiplying \\(\\mathbf{v}\\) by a factor of \\(\\lambda\\). In our case the Eigenvector is \\(\\mathbf{r}^*\\) and the Eigenvalue is \\(\\lambda = 1\\), since \\(\\mathbf{E}\\mathbf{r}^* = 1 \\cdot \\mathbf{r}^*\\).For the math-curious, there are lots of fun results from matrix theory which assure us that \\(\\mathbf{E}\\) is guaranteed to have principal eigenvalue \\(\\lambda = 1\\) üíÜ"
  },
  {
    "objectID": "w09/slides.html#solving-the-matrix-magic",
    "href": "w09/slides.html#solving-the-matrix-magic",
    "title": "Week 9: Statistical Inference",
    "section": "Solving the Matrix Magic",
    "text": "Solving the Matrix Magic\n\nSince we already know the Eigenvalue of interest, \\(\\lambda = 1\\), all that‚Äôs left is solving for its corresponding Eigenvector:\n\\[\n  \\mathbf{E}\\mathbf{r}^* = \\mathbf{r}^* \\iff \\mathbf{E}\\mathbf{r}^* - \\mathbf{r}^* = \\mathbf{0} \\iff (\\mathbf{E} - \\mathbf{I})\\mathbf{r}^* = \\mathbf{0}\n  \\]\nWritten out, we see that this gives us a system of linear equations:\n\\[\n  \\begin{bmatrix}\n  \\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n  \\frac{1}{2} & 0 & 1 \\\\\n  0 & \\frac{1}{2} & 0\n  \\end{bmatrix}\\begin{bmatrix}r^*_1 \\\\ r^*_2 \\\\ r^*_3\\end{bmatrix} = \\begin{bmatrix}0 \\\\ 0 \\\\ 0\\end{bmatrix} \\iff \\begin{array}{ccccccc}\\frac{1}{2}r^*_1 & + & \\frac{1}{2}r^*_2 & ~ & ~ & = & 0 \\\\ \\frac{1}{2}r^*_1 & ~ & ~ & + & r^*_3 & = & 0 \\\\ ~ & ~ & \\frac{1}{2}r^*_2 & ~ & ~ & = & 0\\end{array}\n  \\]\nwhich we can solve however we want!\nTo handle the fact that this system is underspecified, impose additional restriction that \\(r^*_1 + r^*_2 + r^*_3 = 1\\), so that the ranks form a probability distribution"
  },
  {
    "objectID": "w09/slides.html#the-point-of-all-this",
    "href": "w09/slides.html#the-point-of-all-this",
    "title": "Week 9: Statistical Inference",
    "section": "The Point of All This",
    "text": "The Point of All This\n\nThe final restriction \\(r^*_1 + r^*_2 + r^*_3 = 1\\) ensures that the resulting PageRank values form a probability distribution\nThis is called the Stationary Distribution of the Markov chain: represents the probability that a random walker through the chain will be at page \\(S_i\\) at a given time!\n\nEquivalently: expected proportion of total walking time a random-walker will spend at each node\n\nEvery Markov chain has a Stationary Distribution! This fact has cool implications even above and beyond the Google $$$ implications üòú"
  },
  {
    "objectID": "w09/slides.html#statistical-inference-vs.-statistics",
    "href": "w09/slides.html#statistical-inference-vs.-statistics",
    "title": "Week 9: Statistical Inference",
    "section": "Statistical Inference vs.¬†Statistics",
    "text": "Statistical Inference vs.¬†Statistics\n\n\nMoving from understanding probability to getting things done using probability!\nEverything up to this point: understanding the ‚Äúrules‚Äù of stochastic processes\nNow: Using what we know to allow us to draw inferences about populations without having to carry out a census"
  },
  {
    "objectID": "w09/slides.html#samples-vs.-populations",
    "href": "w09/slides.html#samples-vs.-populations",
    "title": "Week 9: Statistical Inference",
    "section": "Samples vs.¬†Populations",
    "text": "Samples vs.¬†Populations\n\nSample = The data you have\nPopulation = The thing you want to learn about, by looking at the sample\nLike ‚Äúsuccess‚Äù vs.¬†‚Äúfailure‚Äù in Bernoulli trials, no exact definition of what counts as sample vs.¬†population\nWhat we call the ‚Äúsample‚Äù and the ‚Äúpopulation‚Äù is vocabulary there to help us know what to do"
  },
  {
    "objectID": "w09/slides.html#inference-statistical-and-otherwise",
    "href": "w09/slides.html#inference-statistical-and-otherwise",
    "title": "Week 9: Statistical Inference",
    "section": "Inference (Statistical and Otherwise)",
    "text": "Inference (Statistical and Otherwise)\nWhat are we doing when we do science?\n\n\n\nScience in General\n\n\n\n\n\n\n\n\ngrid\n\n\ncluster_01\n\n\"Nature\"\n\n\ncluster_02\n\n\"Science\"\n\n\n\nObs\n\nThing(s) we can see\n\n\n\nUnd\n\nUnderlying processes\n\n\n\nUnd-&gt;Obs\n\n\n\n\n\nModel\n\nModel\n\n\n\nUnd-&gt;Model\n\n\n\n\n\nModel-&gt;Obs\n\n\n\n\n\n\n\n\n\n\n\n\nExample: Newton\n\n\n\n\n\n\n\n\ngrid\n\n\ncluster_04\n\n\nWoolsthorpe Manor\n\n\n\n\ncluster_03\n\nIsaac Newton\n\n\n\nTree\n\n\nFalling Apple\n\n\n\n\n\nPhysics\n\n\nParticle Interactions\n\n\n\n\n\nPhysics-&gt;Tree\n\n\n\n\n\nNewton\n\nNewton's Laws\n\n\n\nPhysics-&gt;Newton\n\n\n\n\n\nNewton-&gt;Tree\n\n\n\n\n\n\n\n\n\n\n\n\n\nRemember that the filled-in nodes represent things we can observe, while the non-filled nodes represent things we have to infer from the observable data."
  },
  {
    "objectID": "w09/slides.html#examples-abound",
    "href": "w09/slides.html#examples-abound",
    "title": "Week 9: Statistical Inference",
    "section": "Examples Abound!",
    "text": "Examples Abound!\n\n\n\nDarwinian Evolution\n\n\n\n\n\n\n\n\ngrid\n\n\ncluster_04\n\nGal√°pagos Islands\n\n\ncluster_03\n\nCharles Darwin\n\n\n\nTree\n\n\nFinches\n\n\n\n\n\nPhysics\n\nNatural selection\n\n\n\nPhysics-&gt;Tree\n\n\n\n\n\nNewton\n\nTheory of Evolution\n\n\n\nPhysics-&gt;Newton\n\n\n\n\n\nNewton-&gt;Tree\n\n\n\n\n\n\n\n\n\n\n\n\nEuclidean Geometry\n\n\n\n\n\n\n\n\ngrid\n\n\ncluster_03\n\nEuclid\n\n\ncluster_04\n\n\nAlexandria\n\n\n\n\n\nActual\n\nActual Triangles\n\n\n\nPlatonic\n\nPlatonic Ideal Triangle\n\n\n\nPlatonic-&gt;Actual\n\n\n\n\n\nEuclid\n\nEuclidean Geometry\n\n\n\nPlatonic-&gt;Euclid\n\n\n\n\n\nEuclid-&gt;Actual"
  },
  {
    "objectID": "w09/slides.html#zooming-in-on-euclid",
    "href": "w09/slides.html#zooming-in-on-euclid",
    "title": "Week 9: Statistical Inference",
    "section": "Zooming in on Euclid",
    "text": "Zooming in on Euclid\n\n\nObservations\n\n\n\n\n\n\n\n\n\nSource: Emily Pierce\n\n\n\n\n\n\n\nSource: Wikimedia\n\n\n\n\n\n\n\n\nInteractive visualization from UNC Archaeology\n\n\n\n\n\n‚Üí\n\n\n\nInference\n\n\n\n13th-Century Arabic Elements, from Sotheby‚Äôs\n\n\n\n\n\nFor an absolutely beautiful visual presentation of Elements see here"
  },
  {
    "objectID": "w09/slides.html#inference-in-the-diagram",
    "href": "w09/slides.html#inference-in-the-diagram",
    "title": "Week 9: Statistical Inference",
    "section": "Inference in the Diagram",
    "text": "Inference in the Diagram\n\n\n\n\n\n\n\ngrid\n\n\ncluster_03\n\nEuclid\n\n\ncluster_04\n\n\nAlexandria\n\n\n\n\n\nActual\n\nActual Triangles\n\n\n\nEuclid\n\nEuclidean Geometry\n\n\n\nActual-&gt;Euclid\n\n\nObserve\n\n\n\nPlatonic\n\nPlatonic Ideal Triangle\n\n\n\nPlatonic-&gt;Actual\n\n\n\nWhat goes here? \n\n\n\nPlatonic-&gt;Euclid\n\n\nInfer"
  },
  {
    "objectID": "w09/slides.html#completing-the-cycle",
    "href": "w09/slides.html#completing-the-cycle",
    "title": "Week 9: Statistical Inference",
    "section": "Completing the Cycle",
    "text": "Completing the Cycle\n\n\n\n\n\n\n\ngrid\n\n\ncluster_04\n\n\nAlexandria\n\n\n\n\ncluster_03\n\nEuclid\n\n\n\nActual\n\nActual Triangles\n\n\n\nEuclid\n\nEuclidean Geometry\n\n\n\nActual-&gt;Euclid\n\n\nObserve\n\n\n\nPlatonic\n\nPlatonic Ideal Triangle\n\n\n\nPlatonic-&gt;Actual\n\n\n\nHypothesis Testing! \n\n\n\nPlatonic-&gt;Euclid\n\n\nInfer"
  },
  {
    "objectID": "w09/slides.html#our-case",
    "href": "w09/slides.html#our-case",
    "title": "Week 9: Statistical Inference",
    "section": "Our Case",
    "text": "Our Case\n\n\n\n\n\n\n\ngrid\n\n\ncluster_04\n\nThe World\n\n\ncluster_03\n\nUs\n\n\n\nSample\n\nSample\n\n\n\nPopulation\n\nPopulation\n\n\n\nPopulation-&gt;Sample\n\n\nTake Sample \n\n\n\nStats\n\nStatistics\n\n\n\nPopulation-&gt;Stats\n\n\nInfer\n\n\n\nStats-&gt;Sample\n\n\nObserve\n\n\n\n\n\n\n\n\n\n\nIf you‚Äôre wondering, ‚Äúwhat happened to Hypothesis Testing?‚Äù, don‚Äôt worry, we‚Äôll dive back into that over the next 2 weeks!"
  },
  {
    "objectID": "w09/slides.html#stability-out-of-randomness",
    "href": "w09/slides.html#stability-out-of-randomness",
    "title": "Week 9: Statistical Inference",
    "section": "Stability out of Randomness",
    "text": "Stability out of Randomness\n\n\\(X\\) = result of coin flip\nRemembering that \\(X\\) is a random variable, so it maps outcomes to numbers: \\(X(\\)\\() = 0\\), \\(X(\\)\\() = 1\\)\nWe have no idea what the result of some single coin flip will be, yet we can be sure that the mean of many trials will converge to the expected value of \\(0.5\\)!\n\n\n\nTo check that you understand: what value would the mean of many dice rolls converge to?"
  },
  {
    "objectID": "w09/slides.html#interactive-visualization",
    "href": "w09/slides.html#interactive-visualization",
    "title": "Week 9: Statistical Inference",
    "section": "Interactive Visualization",
    "text": "Interactive Visualization\n\nSeeing Theory, Brown University"
  },
  {
    "objectID": "w09/slides.html#how-many-is-many",
    "href": "w09/slides.html#how-many-is-many",
    "title": "Week 9: Statistical Inference",
    "section": "How Many is ‚ÄúMany‚Äù?",
    "text": "How Many is ‚ÄúMany‚Äù?\n\n\nCode\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(dplyr)\nset.seed(5100)\nn_vals &lt;- c(ceiling(sqrt(10)), 10, ceiling(10*sqrt(10)), 100, ceiling(100*sqrt(10)), 1000, ceiling(1000*sqrt(10)), 10000, ceiling(10000*sqrt(10)), 100000)\nheads_data &lt;- c()\ntotal_data &lt;- c()\nfor (n in n_vals) {\n  coin_flips &lt;- rbinom(n, 1, 0.5)\n  num_heads &lt;- sum(coin_flips)\n  heads_data &lt;- c(heads_data, num_heads)\n  num_flipped &lt;- length(coin_flips)\n  total_data &lt;- c(total_data, num_flipped)\n}\nresults &lt;- tibble(n = n_vals, heads=heads_data, total=total_data)\nresults &lt;- results %&gt;% mutate(head_prop = heads / total)\n#results\nggplot(results, aes(x=n, y=head_prop)) +\n  geom_hline(aes(yintercept=0.5, linetype='dashed'), color=cbPalette[2]) +\n  geom_line(aes(color='black'), fill=cbPalette[1], linewidth=g_linewidth, color=cbPalette[1]) +\n  geom_point(aes(color='black'), size=g_pointsize*0.9) +\n  scale_color_manual(\"\", values=c(\"black\",\"purple\"), labels=c(\"Mean of n samples\",\"Expected Value\")) +\n  scale_linetype_manual(\"\", values=\"dashed\", labels=\"Expected Value\") +\n  scale_fill_manual(\"\", values=cbPalette[1], labels=\"95% CI\") +\n  dsan_theme(\"full\") +\n  theme(\n      legend.title = element_blank(),\n      legend.spacing.y = unit(0, \"mm\")\n  ) +\n      labs(\n          title = \"Estimates of Population Mean for Increasing Sample Sizes\",\n          x = \"n (Sample Size)\",\n          y = \"Sample Mean\"\n      ) +\n  scale_x_log10(breaks = c(10, 100, 1000, 10000, 100000), labels = c(\"10\", \"100\", \"1000\", \"10000\", \"100000\"))"
  },
  {
    "objectID": "w09/slides.html#the-sample-mean",
    "href": "w09/slides.html#the-sample-mean",
    "title": "Week 9: Statistical Inference",
    "section": "The Sample Mean",
    "text": "The Sample Mean\n\nLike the median we saw earlier (along with lots of other examples), sample mean is just a function of RVs\nUnlike the median, though, it is a function of a vector-valued RV \\(\\mathbf{X}_N\\) (containing \\(N\\) scalar RVs)!1\nLet \\(\\mathbf{X}_N = \\{X_1, X_2, \\ldots, X_n\\}\\), where \\(X_1\\) is first observation, \\(X_2\\) second observation, and so on. Then:\n\n\\[\n\\overline{X}_N = f(\\mathbf{X}_N) = \\frac{1}{n}\\sum_{i=1}^{n}X_i\n\\]\nNote the capital \\(N\\) for cardinality of observations, vs.¬†(lowercase) \\(1, 2, \\ldots, n\\) for ordinal labels on each observation. This will spare you many headaches!"
  },
  {
    "objectID": "w09/slides.html#weak-law-of-large-numbers-wlln",
    "href": "w09/slides.html#weak-law-of-large-numbers-wlln",
    "title": "Week 9: Statistical Inference",
    "section": "Weak Law of Large Numbers (WLLN)",
    "text": "Weak Law of Large Numbers (WLLN)\n\nLet \\(\\mathbf{X}_N = \\{X_1, \\ldots, X_n\\} \\iid \\mathcal{D}\\) be a random sample from a distribution \\(\\mathcal{D}\\) with mean \\(\\mu\\), finite variance. Let \\(\\overline{X}_N\\) denote the sample mean from previous slide. Then\n\n\\[\n\\overline{X}_N \\stackrel{p}{\\longrightarrow} \\mu\n\\]\n\n\\(\\mathfrak{X}(N) \\stackrel{p}{\\longrightarrow} c\\) means the Random Variable \\(\\mathfrak{X}(N)\\) (a function of the sample size \\(N\\)) ‚Äúconverges in probability‚Äù to the scalar value \\(c\\). Formally:\n\n\\[\n\\mathfrak{X}(N) \\overset{p}{\\longrightarrow} c \\iff \\forall \\varepsilon &gt; 0 \\left[ \\lim_{N \\rightarrow \\infty}\\Pr\\left( | \\mathfrak{X}(N) - c | &lt; \\varepsilon \\right) = 1 \\right]\n\\]"
  },
  {
    "objectID": "w09/slides.html#strong-law-of-large-numbers-slln",
    "href": "w09/slides.html#strong-law-of-large-numbers-slln",
    "title": "Week 9: Statistical Inference",
    "section": "Strong Law of Large Numbers (SLLN)",
    "text": "Strong Law of Large Numbers (SLLN)\n\nSame setup as last slide, but\n\n\\[\n\\overline{X}_N \\convergesAS \\mu\n\\]\n\n\\(\\mathfrak{X}(N) \\convergesAS c\\) means the Random Variable \\(\\mathfrak{X}(N)\\) (a function of the sample size \\(N\\)) ‚Äúconverges almost surely‚Äù to the scalar value \\(c\\). Formally:\n\n\\[\n\\mathfrak{X}(N) \\convergesAS c \\iff \\Pr\\left( \\lim_{N \\rightarrow \\infty} \\mathfrak{X}(N) = c \\right) = 1\n\\]\n\nSLLN \\(\\implies\\) WLLN, but WLLN \\(~\\nimplies\\) SLLN!\nWLLN easy to prove, SLLN very un-easy to prove"
  },
  {
    "objectID": "w09/slides.html#central-limit-theorem",
    "href": "w09/slides.html#central-limit-theorem",
    "title": "Week 9: Statistical Inference",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nWe‚Äôll never actually reach \\(N = \\infty\\), so we zoom in on how close our sample-based estimate gets to the true value\nCentral Limit Theorem says: these ‚Äúcloseness‚Äù values are normally distributed!\nLLN guarantees that \\(X_N \\; \\; \\eqeventual \\; \\; \\mu\\)\nCLT tells us what the gap \\((X_N - \\mu)\\) looks like"
  },
  {
    "objectID": "w09/slides.html#formal-clt",
    "href": "w09/slides.html#formal-clt",
    "title": "Week 9: Statistical Inference",
    "section": "Formal CLT",
    "text": "Formal CLT\n\nSampled observations: \\(\\mathbf{X}_N = \\{X_1, \\ldots, X_n\\}\\)\n\\(\\expect{X_i} = \\mu, \\Var{X_i} = \\sigma^2 &lt; \\infty\\)\n\\(\\overline{X}_N \\definedas M_1(\\mathbf{X}_N) = \\frac{X_1 + \\cdots + X_n}{N}\\)\n\n\\[\n\\frac{\\overline{X}_N - \\mu}{\\sigma / \\sqrt{N}} \\overset{\\text{asymp}}{\\sim} \\mathcal{N}(0,1)\n\\]"
  },
  {
    "objectID": "w09/slides.html#when-is-mathcaln0-1-a-good-approximation",
    "href": "w09/slides.html#when-is-mathcaln0-1-a-good-approximation",
    "title": "Week 9: Statistical Inference",
    "section": "When is \\(\\mathcal{N}(0, 1)\\) a ‚Äúgood‚Äù approximation?",
    "text": "When is \\(\\mathcal{N}(0, 1)\\) a ‚Äúgood‚Äù approximation?\n\n\nCode\n# Prepare data for all plots\nmax_n &lt;- 10000\nnum_reps &lt;- 1000\nall_rolls &lt;- replicate(\n  num_reps,\n  sample(1:6, size = max_n, replace = TRUE, prob = rep(1 / 6, 6))\n)\ngen_clt_plot &lt;- function(n) {\n  exp_val &lt;- 3.5\n  sigma &lt;- sqrt(35/12)\n  denom &lt;- sigma / sqrt(n)\n  # Get the slice of all_rolls for this n\n  n_rolls &lt;- all_rolls[1:n,]\n  sample_means &lt;- colMeans(n_rolls)\n  norm_gaps &lt;- (sample_means - exp_val) / denom\n  n_df &lt;- tibble(norm_gap=norm_gaps)\n  #if (n == 5) {\n  #  print(sample_means)\n  #  print(n_df)\n  #}\n  ggplot(n_df, aes(x = norm_gap)) +\n  geom_histogram(aes(y = after_stat(density)), binwidth = 1/2) +\n  #geom_density() +\n  stat_function(fun=dnorm, size=g_linesize) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title = paste0(\"n = \",n),\n    x = \"Normalized Sample Gap\"\n  )\n}"
  },
  {
    "objectID": "w09/slides.html#q-q-plots",
    "href": "w09/slides.html#q-q-plots",
    "title": "Week 9: Statistical Inference",
    "section": "Q-Q Plots",
    "text": "Q-Q Plots\n\n\nCode\ngen_qq &lt;- function(n) {\n  n_rolls &lt;- all_rolls[1:n,]\n  sample_means &lt;- colMeans(n_rolls)\n  qq_df &lt;- tibble(smean = sample_means)\n  qq_plot &lt;- ggplot(qq_df, aes(sample = smean)) +\n  stat_qq() + stat_qq_line() +\n  dsan_theme(\"quarter\") +\n  labs(\n    title = paste0(\"n = \",n)\n  )\n  return(qq_plot)\n}"
  },
  {
    "objectID": "w09/slides.html#maximum-likelihood-estimation",
    "href": "w09/slides.html#maximum-likelihood-estimation",
    "title": "Week 9: Statistical Inference",
    "section": "Maximum Likelihood Estimation",
    "text": "Maximum Likelihood Estimation\n\nCreating a model \\(\\mathcal{M}\\) w/parameters \\(\\param{\\theta}\\) means specifying\n\n\\[\n\\mathcal{M} = \\Pr(\\underbrace{x_1, \\ldots, x_n}_{\\text{Observed Data}} \\mid \\underbrace{\\param{\\theta}}_{\\text{Model Parameters}})\n\\]\n\nWhen we view this as a function of \\(\\param{\\theta}\\), given the observed data, we call it the likelihood function \\(\\mathcal{L}_{\\mathcal{M}}(\\param{\\theta} \\mid x_1, \\ldots, x_n)\\)\nRead this as ‚Äúthe likelihood that our model \\(\\mathcal{M}\\), with parameters \\(\\param{\\theta}\\), produced the data \\(x_1, \\ldots, x_n\\)‚Äù"
  },
  {
    "objectID": "w09/slides.html#probability-models-are-generative-models",
    "href": "w09/slides.html#probability-models-are-generative-models",
    "title": "Week 9: Statistical Inference",
    "section": "Probability Models are Generative Models",
    "text": "Probability Models are Generative Models\n\nA given choice of model parameters \\(\\param{\\theta}\\) can be used to generate simulated datapoints!\nSimple example: \\(X \\sim \\text{Bern}(\\param{p})\\). Just one parameter, \\(\\param{\\theta} = \\{\\param{p}\\}\\)\nWe observe 10 coin flips: 8 heads, 2 tails. Of all possible Bernoulli distributions (parameterized by \\(\\param{p}\\)), which is most likely to generate this data?"
  },
  {
    "objectID": "w09/slides.html#generative-models",
    "href": "w09/slides.html#generative-models",
    "title": "Week 9: Statistical Inference",
    "section": "Generative Models",
    "text": "Generative Models\n\n\n\nGiven a choice of \\(\\param{\\theta}\\), we can generate simulated datasets (here 10 for each labeled value of \\(\\param{p}\\)), then compute likelihood as proportion of datasets with 8 heads, 2 tails\nFrom plot: (Among these vals) \\(\\param{p} = 0.8\\) is maximum likelihood estimate"
  },
  {
    "objectID": "w09/slides.html#simulations-rightarrow-math",
    "href": "w09/slides.html#simulations-rightarrow-math",
    "title": "Week 9: Statistical Inference",
    "section": "Simulations \\(\\rightarrow\\) Math",
    "text": "Simulations \\(\\rightarrow\\) Math\nPrev example was overkill: we can solve for optimal \\(\\param{p}\\) value‚Ä¶\n\\[\n\\begin{align*}\np^* &\\overset{\\phantom{x_i\\text{ indep}}}{=} \\argmax_{\\param{p}} \\mathcal{L}(x_1, \\ldots, x_n \\mid \\param{p}) \\\\\n&\\overset{x_i\\text{ indep}}{=} \\argmax_{\\param{p}} \\mathcal{L}(x_1 \\mid \\param{p})\\mathcal{L}(x_2 \\mid \\param{p}) \\cdots \\mathcal{L}(x_n \\mid \\param{p})\n\\end{align*}\n\\]\n\nWhat are the individual \\(\\mathcal{L}(x_i \\mid \\param{p})\\) terms?\nHow do we maximize the product \\(\\mathcal{L}(x_1 \\mid \\param{p}) \\cdots \\mathcal{L}(x_n \\mid \\param{p})\\)?\n\n\nTime for some Math Magic‚Ä¶"
  },
  {
    "objectID": "w09/slides.html#math-magic-1",
    "href": "w09/slides.html#math-magic-1",
    "title": "Week 9: Statistical Inference",
    "section": "Math Magic 1",
    "text": "Math Magic 1\n1. What are the individual \\(\\Pr(x_i \\mid \\param{p})\\) terms?\n\\(X \\sim \\text{Bern}(\\param{p})\\), so\n\\[\n\\begin{align*}\n\\Pr(X = x_i \\mid \\param{p}) &= \\begin{cases}1 - \\param{p} & x_i = 0 \\\\ \\param{p} & x_i = 1\\end{cases} \\; \\leftarrow \\genfrac{}{}{0pt}{}{\\text{ Non-differentiable}}{üò≠} \\\\\n&\\overset{\\text{math}}{\\underset{\\text{magic}}{=}} (1-\\param{p})^{1-x_i}\\param{p}^{x_i} \\; \\leftarrow \\text{ Differentiable! üò≤}\n\\end{align*}\n\\]\nWhy do we need it to be differentiable? Stay tuned‚Ä¶"
  },
  {
    "objectID": "w09/slides.html#math-magic-2",
    "href": "w09/slides.html#math-magic-2",
    "title": "Week 9: Statistical Inference",
    "section": "Math Magic 2",
    "text": "Math Magic 2\n\n\n\n\n\n\n2. How do we maximize the product?\n\\[\np^* = \\argmax_{\\param{p}} f(\\param{p}) \\implies f'(p^*) = 0\n\\]\nTo maximize likelihood, we need to find its derivative1, set equal to 0, and solve:\n\n\n\n\n\n\n\\[\n\\begin{align*}\n&\\frac{d}{d\\param{p}}\\lik(x \\mid \\param{p}) = 0 \\iff \\\\\n&\\frac{d}{d\\param{p}}\\left[\\lik(x_1 \\mid \\param{p})\\lik(x_2 \\mid \\param{p})\\cdots \\lik(x_n \\mid \\param{p})\\right] = 0\n\\end{align*}\n\\]\nAnd that‚Äôs why we used math magic to make \\(\\Pr(x_i \\mid \\param{p})\\) differentiable, in the previous slide!"
  },
  {
    "objectID": "w09/slides.html#obstacle-products-vs.-sums",
    "href": "w09/slides.html#obstacle-products-vs.-sums",
    "title": "Week 9: Statistical Inference",
    "section": "Obstacle: Products vs.¬†Sums",
    "text": "Obstacle: Products vs.¬†Sums\n\nFinding \\(\\frac{d}{d\\param{p}}\\left[ \\lik(x_1)\\lik(x_2)\\cdots \\lik(x_n)\\right]\\) is a doozy, even with just \\(n = 2\\) datapoints:\n\n\\[\n\\begin{align*}\n&\\frac{d}{d\\param{p}}\\left[ \\lik(x_1)\\lik(x_2) \\right] = \\left( \\frac{d}{d\\param{p}}\\lik(x_1)\\right) \\cdot \\lik(x_2) + \\lik(x_1)\\cdot \\left( \\frac{d}{d\\param{p}}\\lik(x_2) \\right) \\\\\n&= (1-\\param{p})^{-x_1}\\param{p}^{x_1-1}(x_1-\\param{p})\\cdot (1-\\param{p})^{1-x_2}\\param{p}^{x_2} \\\\\n&+ (1-\\param{p})^{1-x_1}\\param{p}^{x_1} \\cdot (1-\\param{p})^{-x_2}\\param{p}^{x_2-1}(x_2 - \\param{p})\n%&= \\frac{d}{d\\theta}\\left[ (1-p)^{1-x_1}p^{x_1}(1-p)^{1-x_2}p^{x_2} \\right]\n\\end{align*}\n\\]\n\nComplicating factor: \\(\\lik(x_i)\\) terms are all multiplied together, forcing us to use product rule: \\(\\frac{d}{d\\param{p}}\\left[\\lik(x_1)\\lik(x_2)\\right] = \\left(\\frac{d}{d\\param{p}}\\lik(x_1)\\right)\\cdot \\lik(x_2) + \\lik(x_1)\\cdot \\left(\\frac{d}{d\\param{p}}\\lik(x_2)\\right)\\)\nIf we had terms that were added rather than multiplied, we‚Äôd have a much easier time: \\(\\frac{d}{d\\param{p}}\\left[ \\lik(x_1) + \\lik(x_2)\\right] = \\frac{d}{d\\param{p}}\\lik(x_1) + \\frac{d}{d\\param{p}} \\lik(x_2)\\)1\nSo, what math operation do we know that turns multiplications into additions?\n\n\nWe achieve this simplification because the derivative operator is additive: \\(\\frac{d}{dx}\\left[ f(x) + g(x) \\right] = \\frac{d}{dx}f(x) + \\frac{d}{dx}g(x)\\)"
  },
  {
    "objectID": "w09/slides.html#math-magic-3-log-likelihood",
    "href": "w09/slides.html#math-magic-3-log-likelihood",
    "title": "Week 9: Statistical Inference",
    "section": "Math Magic 3: Log-Likelihood",
    "text": "Math Magic 3: Log-Likelihood\n\\[\n\\log(a\\cdot b) = \\log(a) + \\log(b)\n\\]\nBingo! So, can we maximize \\(\\loglik(x_i) = \\log(\\mathcal{L}(x_i))\\) rather than \\(\\mathcal{L}(x_i)\\)? Bingo again! Because logarithms are monotonic,\n\\[\nx^* = \\argmax_x \\left[ \\log\\left(f(x)\\right) \\right] \\iff x^* = \\argmax_x \\left[ f(x) \\right]\n\\]\nSo, we can just solve\n\\[\np^* = \\argmax_{\\param{p}} \\left[ \\ell(x_1, \\ldots, x_n)\\right]\n\\]"
  },
  {
    "objectID": "w09/slides.html#simplifying",
    "href": "w09/slides.html#simplifying",
    "title": "Week 9: Statistical Inference",
    "section": "Simplifying",
    "text": "Simplifying\nOur problem simplifies to figuring out\n\\[\n\\begin{align*}\n\\frac{d}{d\\param{p}}\\left[ \\log \\left( \\lik(x_1)\\cdots \\lik(x_n) \\right) \\right] &= \\frac{d}{d\\param{p}}\\left[ \\log \\lik(x_1) + \\log\\lik(x_2) + \\cdots + \\log\\lik(x_n) \\right] \\\\\n&= \\frac{d}{d\\param{p}}\\left[ \\ell(x_1) + \\ell(x_2) + \\cdots + \\ell(x_n) \\right] = \\frac{d}{d\\param{p}}\\left[ \\sum_{i=1}^n \\ell(x_i)\\right]\n\\end{align*}\n\\]\nBut since the derivative is an additive operator, \\(\\frac{d}{d\\param{p}}\\left[ \\sum_{i=1}^n \\ell(x_i) \\right] = \\sum_{i=1}^n \\frac{d}{d\\param{p}}\\left[ \\ell(x_i) \\right]\\), so we just have to compute \\(\\frac{d}{d\\param{p}}\\ell(x_i)\\)! No product rule required (we still need chain rule):\n\\[\n\\begin{align*}\n\\frac{d}{d\\param{p}}\\left[ \\ell(x_i) \\right] &= \\frac{d}{d\\param{p}}\\left[ \\log((1-\\param{p})^{1-x_i}\\param{p}^{x_i}) \\right] = \\frac{d}{d\\param{p}}\\left[(1-x_i)\\log(1-\\param{p}) + x_i\\log(\\param{p})\\right] \\\\\n&= (1-x_i)\\frac{d}{d\\param{p}}\\log(1-\\param{p}) + x_i\\frac{d}{d\\param{p}}\\log(\\param{p}) = -\\frac{1-x_i}{1-\\param{p}} + \\frac{x_i}{\\param{p}} \\\\\n&= \\frac{\\param{p} - x_i}{(\\param{p}-1)\\param{p}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w09/slides.html#maximizing",
    "href": "w09/slides.html#maximizing",
    "title": "Week 9: Statistical Inference",
    "section": "Maximizing",
    "text": "Maximizing\nNow that we know \\(\\frac{d}{d\\param{p}}\\ell(x_i)\\), we set our log-likelihood equation equal to zero to find the likelihood-maximizing \\(\\param{p}\\) value, \\(p^*\\):\n\\[\n\\begin{align*}\n&\\sum_{i=1}^n\\frac{d}{d\\param{p}}\\ell(x_i) = 0 \\iff \\sum_{i=1}^n \\frac{p^* - x_i}{(p^*-1)p^*} = 0 \\\\\n&\\iff -\\frac{1}{(p^*-1)p^*}\\sum_{i=1}^nx_i - np^* = 0 \\\\\n&\\iff \\sum_{i=1}^nx_i = np^* \\iff \\boxed{p^* = \\frac{\\sum_{i=1}^nx_i}{n}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w09/slides.html#mle-intuition",
    "href": "w09/slides.html#mle-intuition",
    "title": "Week 9: Statistical Inference",
    "section": "MLE Intuition",
    "text": "MLE Intuition\n\\[\np^* = \\frac{\\sum_{i=1}^nx_i}{n} = \\frac{\\sum_{i=1}^n \\mathbf{1}[x_i = 1]}{n} \\genfrac{}{}{0pt}{}{\\leftarrow \\text{\\# Heads}}{\\leftarrow \\text{\\# Flips }}\n\\]\n\nMLE almost always matches intuition! Example: given data \\(x_1, \\ldots, x_n\\), what Normal distribution best fits this data?\nSame as asking: what parameter settings for \\(\\mathcal{N}(\\param{\\mu}, \\param{\\sigma^2})\\) are most likely to produce \\(x_1, \\ldots, x_n\\)? The answer:\n\n\\[\n\\mu^* = \\frac{\\sum_{i=1}^n x_i}{n} \\; \\; \\; \\sigma^2_* = \\frac{\\sum_{i=1}^n (x_i-\\mu^*)^2}{n}\n\\]"
  },
  {
    "objectID": "w09/slides.html#the-dark-side-of-mle",
    "href": "w09/slides.html#the-dark-side-of-mle",
    "title": "Week 9: Statistical Inference",
    "section": "The Dark Side of MLE",
    "text": "The Dark Side of MLE\n\nSometimes steers us in the wrong direction!\nConsider values from previous slide, as estimators for population \\(\\mu\\) and \\(\\sigma^2\\): \\(\\mu^*\\) unbiased if \\(\\expect{\\mu^*} = \\mu\\):\n\n\\[\n\\begin{align*}\n\\expect{\\mu^*} &= \\bigexpect{\\frac{\\sum_{i=1}^nx_i}{n}} = \\frac{1}{n}\\sum_{i=1}^n\\expect{x_i} \\\\\n&= \\frac{1}{n}\\sum_{i=1}^n\\mu = \\frac{n\\mu}{n} = \\mu \\; ‚úÖ\n\\end{align*}\n\\]\n\nSo far so good. How about \\(\\sigma^2_*\\)?"
  },
  {
    "objectID": "w09/slides.html#mle-as-biased-estimator",
    "href": "w09/slides.html#mle-as-biased-estimator",
    "title": "Week 9: Statistical Inference",
    "section": "MLE as Biased Estimator",
    "text": "MLE as Biased Estimator\n\nBefore we think about \\(\\expect{\\sigma^2_*}\\), let‚Äôs rewrite \\(\\sigma^2_*\\):\n\n\\[\n\\begin{align*}\n\\sigma^2_* &= \\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu^*)^2 = \\frac{1}{n}\\sum_{i=1}^n \\left( x_i^2 - 2 \\mu^* x_i + (\\mu^*)^2 \\right) \\\\\n&= \\frac{1}{n}\\sum_{i=1}^nx_i^2 - 2\\mu^*\\underbrace{\\frac{\\sum_{i=1}^nx_i}{n}}_{\\mu^*} + (\\mu^*)^2 = \\frac{1}{n}\\sum_{i=1}^nx_i^2 - (\\mu^*)^2 \\\\\n&= \\frac{1}{n}\\sum_{i=1}^nx_i^2 - (\\mu^*)^2\n\\end{align*}\n\\]\n\nNow we‚Äôre ready to compute \\(\\expect{\\sigma^2_*}\\)!"
  },
  {
    "objectID": "w09/slides.html#computing-mathbbesigma2_",
    "href": "w09/slides.html#computing-mathbbesigma2_",
    "title": "Week 9: Statistical Inference",
    "section": "Computing \\(\\mathbb{E}[\\sigma^2_*]\\)",
    "text": "Computing \\(\\mathbb{E}[\\sigma^2_*]\\)\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\bigexpect{\\frac{1}{n}\\sum_{i=1}^nx_i^2 - (\\mu^*)^2} = \\frac{1}{n}\\sum_{i=1}^n \\expect{x_i^2} - \\expect{(\\mu^*)^2}\n\\end{align*}\n\\]\n\nWhat do we know about \\(\\expect{x_i^2}\\)? Remember the (alternate) definition of variance: \\(\\Var{X} = \\expect{X^2} - \\left(\\expect{X}\\right)^2\\). Then\n\n\\[\n\\expect{X^2} = \\Var{X} + \\left(\\expect{X}\\right)^2\n\\]\nSo let‚Äôs plug in the right side when we see \\(\\expect{X^2}\\) or \\(\\expect{(\\mu^*)^2}\\):\n\\[\n\\begin{align*}\n\\frac{1}{n}\\sum_{i=1}^n \\expect{x_i^2} - \\expect{(\\mu^*)^2} &= \\frac{1}{n}\\sum_{i=1}^n\\left(\\Var{X} + \\left(\\expect{X}\\right)^2\\right) - \\expect{(\\mu^*)^2} \\\\\n&= (\\sigma^2 + \\mu^2) - \\left(\\Var{\\mu^*} + \\left(\\expect{\\mu^*}\\right)^2\\right)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w09/slides.html#almost-there",
    "href": "w09/slides.html#almost-there",
    "title": "Week 9: Statistical Inference",
    "section": "Almost There!",
    "text": "Almost There!\nWe know that \\(\\expect{\\mu^*} = \\mu\\), but what is \\(\\Var{\\mu^*}\\)? Remember that \\(\\Var{aX} = a^2\\Var{X}\\)!\n\\[\n\\Var{\\mu^*} = \\bigVar{\\frac{1}{n}\\sum_{i=1}^nx_i} = \\frac{1}{n^2}\\sum_{i=1}^n\\Var{x_i} = \\frac{n\\sigma^2}{n^2} = \\frac{\\sigma^2}{n}\n\\]\nAnd we plug back in to get:\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\sigma^2 + \\mu^2 - \\Var{\\mu^*} - \\left(\\expect{\\mu^*}\\right)^2 \\\\\n&= \\sigma^2 + \\mu^2 - \\frac{\\sigma^2}{n} - \\mu^2 = \\sigma^2 - \\frac{\\sigma^2}{n} \\\\\n&= \\frac{n\\sigma^2 - \\sigma^2}{n} = \\frac{\\sigma^2(n-1)}{n} \\\\\n&= \\color{red}{\\left(\\frac{n-1}{n}\\right)\\sigma^2} \\neq \\sigma^2 \\; üíÄ\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w09/slides.html#why-does-this-happen-handwaving",
    "href": "w09/slides.html#why-does-this-happen-handwaving",
    "title": "Week 9: Statistical Inference",
    "section": "Why Does This Happen?: Handwaving",
    "text": "Why Does This Happen?: Handwaving\n\nLong story short, we underpredict the population variance because we already used some of the data to compute \\(\\mu^*\\)!\nThis is where the degrees of freedom heuristic comes in:\n\nWhen we construct an estimate \\(e\\), \\(df(e) = n - k_e\\)\n\\(k_e =\\) number of other estimates used to calculate \\(e\\)!"
  },
  {
    "objectID": "w09/slides.html#handwavy-intuition",
    "href": "w09/slides.html#handwavy-intuition",
    "title": "Week 9: Statistical Inference",
    "section": "Handwavy Intuition",
    "text": "Handwavy Intuition\n\nConsider \\(X_1, X_2 \\sim \\mathcal{N}(0,1)\\): \\(\\mu = 0\\), \\(\\sigma^2 = 1\\).\n\n\\[\n\\expect{\\mu^*} = \\bigexpect{\\frac{X_1 + X_2}{2}} = \\frac{1}{2}\\left(\\expect{X_1} + \\expect{X_2}\\right) = 0 = \\mu \\; ‚úÖ\n\\]\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\frac{1}{2}\\bigexpect{(X_1 - \\mu^*)^2 + (X_2 - \\mu^*)^2} \\\\\n&= \\frac{1}{2}\\bigexpect{\\left(X_1^2 + \\mu^2_* -2\\mu^*X_1\\right) + \\left(X_2^2 + \\mu^2_* - 2X_2\\mu^*\\right)} \\\\\n&= \\frac{1}{2}\\expect{X_1^2 + X_2^2 + 2\\mu_*^2 - 2\\mu^*X_1 - 2\\mu^*X_2} \\\\\n&= \\frac{1}{2}\\left(\\expect{X_1^2} + \\expect{X_2^2} + 2\\expect{\\mu_*^2} - 2\\expect{\\mu^*X_1} - 2\\expect{\\mu^*X_2}\\right) \\\\\n&\\implies \\boxed{\\expect{\\sigma^2_*} = \\frac{1}{2}\\sigma^2}\n\\end{align*}\n\\]\n\nWe‚Äôre off by \\(\\frac{1}{2}\\)! What to do?"
  },
  {
    "objectID": "w09/slides.html#handwavy-solution",
    "href": "w09/slides.html#handwavy-solution",
    "title": "Week 9: Statistical Inference",
    "section": "Handwavy Solution",
    "text": "Handwavy Solution\n\nWe can account for degrees of freedom, correcting the MLE by a factor of \\(\\frac{n}{df(e^*)}\\)!\n\n\\(e^\\circledast = \\frac{n}{df(e^*)}e^*\\)\n\nEx: Since \\(\\expect{\\sigma_*^2} = \\frac{n-1}{n}\\sigma^2\\), we can instead use \\(\\sigma^2_\\circledast = \\frac{n}{n-1}\\sigma^2_*\\). This gives us:\n\n\\[\n\\expect{\\sigma^2_\\circledast} = \\bigexpect{\\frac{n}{n-1}\\sigma^2_*} = \\frac{n}{n-1}\\frac{n-1}{n}\\sigma^2 = \\color{green}{\\sigma^2} \\; ‚úÖ\n\\]"
  },
  {
    "objectID": "w09/slides.html#st-century-solution",
    "href": "w09/slides.html#st-century-solution",
    "title": "Week 9: Statistical Inference",
    "section": "21st-Century Solution",
    "text": "21st-Century Solution\n\nBe Bayesian, use priors on parameters (creating hyperparameters)!\nPretend we know \\(\\sigma^2\\), but want to find the ‚Äúbest‚Äù value of \\(\\mu\\):\n\n\\[\n\\begin{array}{rlccc}\nX_1, X_2 \\overset{iid}{\\sim} \\mathcal{N}( &\\hspace{-5mm}\\mu\\hspace{0.5mm}, &\\hspace{-8mm}\\overbrace{\\sigma^2}^{\\large\\text{known}}\\hspace{-2mm}) & & \\\\\n&\\hspace{-4mm}\\downarrow & ~ &\\hspace{-10mm}{\\small\\text{estimate}} & \\hspace{-6mm} & \\hspace{-8mm}{\\small\\text{uncertainty}} \\\\[-5mm]\n&\\hspace{-5mm}\\mu &\\hspace{-5mm}\\sim \\mathcal{N}&\\hspace{-7mm}(\\overbrace{m}&\\hspace{-12mm}, &\\hspace{-16mm}\\overbrace{s})\n\\end{array}\n\\]"
  },
  {
    "objectID": "w09/slides.html#single-datapoint",
    "href": "w09/slides.html#single-datapoint",
    "title": "Week 9: Statistical Inference",
    "section": "Single Datapoint",
    "text": "Single Datapoint\n\nLet‚Äôs consider the estimate of \\(\\mu\\) from a single datapoint \\(X_i\\). MLE just gives us \\(\\mu^* = X_i\\). How about MAP estimate?\n\n\\[\n\\lik\\left(X_i, \\mu, m, s\\right) \\overset{\\text{factors}}{\\underset{\\text{into}}{=}} P(X_i \\mid \\mu)P(\\mu \\mid m, s)P(m, s)\n\\]\n\nRemembering the pdf of the Normal distribution, we have:\n\n\\[\n\\lik\\left(X_i, \\mu, m, s\\right) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left[-\\frac{(X_i-\\mu)^2}{2\\sigma^2}\\right]\\frac{1}{s\\sqrt{2\\pi}}\\exp\\left[-\\frac{(\\mu - m)^2}{2s^2}\\right]\n\\]\n\nThen, remembering that we can maximize the log-likelihood rather than the likelihood:\n\n\\[\n\\ell(X_i, \\mu, m, s) = \\log\\left[\\frac{1}{\\sigma\\sqrt{2\\pi}}\\right] - \\frac{(X_i-\\mu)^2}{2\\sigma^2} + \\log\\left[\\frac{1}{s\\sqrt{2\\pi}}\\right] - \\frac{(\\mu - m)^2}{2s^2}\n\\]"
  },
  {
    "objectID": "w09/slides.html#taking-the-derivative",
    "href": "w09/slides.html#taking-the-derivative",
    "title": "Week 9: Statistical Inference",
    "section": "Taking the Derivative",
    "text": "Taking the Derivative\n\nTaking the derivative gives us:\n\n\\[\n\\begin{align*}\n\\frac{\\partial\\ell}{\\partial \\mu} &= \\frac{\\partial}{\\partial\\mu}\\left[ {\\color{red}\\cancel{\\color{black}\\log\\left[\\frac{1}{\\sigma\\sqrt{2\\pi}}\\right]}} - \\frac{(X_i-\\mu)^2}{2\\sigma^2} + {\\color{red}\\cancel{\\color{black}\\log\\left[\\frac{1}{s\\sqrt{2\\pi}}\\right]}} - \\frac{(\\mu - m)^2}{2s^2}\\right] \\\\\n&= - \\frac{1}{2\\sigma^2}\\cdot\\frac{\\partial}{\\partial\\mu}\\left[{\\color{red}\\cancel{\\color{black}X_i^2}} + \\mu^2 - 2X_i\\mu\\right] - \\frac{1}{2s^2}\\cdot\\frac{\\partial}{\\partial\\mu}\\left[\\mu^2 + {\\color{red}\\cancel{\\color{black}m^2}} - 2\\mu m\\right] \\\\\n&= -\\frac{1}{2\\sigma^2}\\cdot (2\\mu -2X_i) - \\frac{1}{2s^2}\\cdot (2\\mu - 2m) = \\frac{X_i-\\mu}{\\sigma^2} + \\frac{m - \\mu}{s^2}\n\\end{align*}\n\\]\n\nAnd we set equal to zero and solve to obtain the MAP estimate:\n\n\\[\n\\begin{align*}\n&\\frac{X_i - \\mu^*}{\\sigma^2} + \\frac{m - \\mu^*}{s^2} = 0 \\iff \\frac{\\mu^*}{\\sigma^2} + \\frac{\\mu^*}{s^2} = \\frac{X_i}{\\sigma^2} + \\frac{m}{s^2} \\iff \\\\\n&\\frac{s^2\\mu^* + \\sigma^2\\mu^*}{\\sigma^2s^2} = \\frac{s^2X_i + \\sigma^2m}{\\sigma^2s^2} \\iff \\mu^*(s^2+\\sigma^2) = s^2X_i + \\sigma^2m \\\\\n&\\iff \\boxed{\\mu^* = \\left(\\frac{s^2}{s^2 + \\sigma^2}\\right)X_i + \\left(\\frac{\\sigma^2}{s^2 + \\sigma^2}\\right)m}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w09/slides.html#the-takeaway",
    "href": "w09/slides.html#the-takeaway",
    "title": "Week 9: Statistical Inference",
    "section": "The Takeaway",
    "text": "The Takeaway\n\nBayesian approach allows new evidence to be weighed against existing evidence, with statistically principled way to derive these weights:\n\n\\[\n\\begin{array}{ccccc}\n\\Pr_{\\text{post}}(\\mathcal{H}) &\\hspace{-6mm}\\propto &\\hspace{-6mm} \\Pr(X \\mid \\mathcal{H}) &\\hspace{-6mm} \\times &\\hspace{-6mm} \\Pr_{\\text{pre}}(\\mathcal{H}) \\\\\n\\text{Posterior} &\\hspace{-6mm}\\propto &\\hspace{-6mm}\\text{Evidence} &\\hspace{-6mm} \\times &\\hspace{-6mm} \\text{Prior}\n\\end{array}\n\\]"
  },
  {
    "objectID": "w09/slides.html#generalized-method-of-moments-gmm-estimation",
    "href": "w09/slides.html#generalized-method-of-moments-gmm-estimation",
    "title": "Week 9: Statistical Inference",
    "section": "Generalized Method of Moments (GMM) Estimation",
    "text": "Generalized Method of Moments (GMM) Estimation\n\nRecall that the \\(k\\)th moment of an RV \\(X\\) is \\(\\mu_k = \\expect{X^k}\\)\ne.g., \\(\\mu_1 = \\expect{X}\\), \\(\\mu_2 = \\Var{X} + \\expect{X}^2\\)\nAlso recall (I rambled on about) how the MGF contains all information about a distribution. This means we can estimate distributions from data:\nDefine \\(k\\)th sample moment of \\(\\mathbf{X}_N\\): \\(\\widehat{\\mu}_k = \\frac{1}{N}\\sum_{i=1}^nX_i^k\\). Then:\n\\[\n  \\begin{align*}\n  \\mu_1(\\param{\\theta}) &= \\widehat{\\mu}_1 \\\\\n  \\mu_2(\\param{\\theta}) &= \\widehat{\\mu}_2 \\\\\n  &~\\vdots \\\\\n  \\mu_N(\\param{\\theta}) &= \\widehat{\\mu}_N\n  \\end{align*}\n  \\]\nGives us a system of equations, allowing us to solve for parameters \\(\\param{\\theta}\\) of our distribution!"
  },
  {
    "objectID": "w09/slides.html#intuition",
    "href": "w09/slides.html#intuition",
    "title": "Week 9: Statistical Inference",
    "section": "Intuition",
    "text": "Intuition\n\n\n\n\n\n\n\n\n\nLow Variance\nHigh Variance\n\n\n\n\nLow Bias\n\n\n\n\nHigh Bias\n\n\n\n\n\n\n\nAdapted from Fortmann-Roe (2012), ‚ÄúUnderstanding the Bias-Variance Tradeoff‚Äù"
  },
  {
    "objectID": "w09/slides.html#components-of-the-error-term",
    "href": "w09/slides.html#components-of-the-error-term",
    "title": "Week 9: Statistical Inference",
    "section": "Components of the Error Term",
    "text": "Components of the Error Term\n\nWe estimate ‚Äútrue‚Äù DGP \\(Y = f(X)\\) with model \\(\\widehat{f}(X)\\)1, and then we use \\(\\widehat{f}\\) to predict the value of \\(Y\\) for a point \\(x_0\\).\nWhat is our expected error at this point, \\(\\Err(x_0)\\)?\n\n\\[\n\\begin{align*}\n\\Err(x_0) &= \\bigexpect{\\left.(Y ‚àí \\widehat{f}(x_0))^2 \\right| X = x_0} \\\\\n&= \\sigma^2_{\\varepsilon} + \\left( \\bigexpect{\\widehat{f}(x_0)} ‚àí f(x_0) \\right)^2 + \\mathbb{E}\\left[\\widehat{f}(x_0) ‚àí \\bigexpect{\\widehat{f}(x_0)}\\right]^2 \\\\\n&= \\sigma^2_{\\varepsilon} + \\left( \\text{Bias}(\\widehat{f}(x_0)\\right)^2 + \\bigVar{\\widehat{f}(x_0)} \\\\\n&= \\text{Irreducible Error} + \\text{Bias}^2 + \\text{Variance}.\n\\end{align*}\n\\]\nIt‚Äôs even more complicated, since we don‚Äôt even know whether the features \\(X\\) we‚Äôve chosen are actually the features in the world that causally affect \\(Y\\), but that‚Äôs for later classes‚Ä¶ Or see (hastie_elements_2013?)!"
  },
  {
    "objectID": "w09/slides.html#in-practice",
    "href": "w09/slides.html#in-practice",
    "title": "Week 9: Statistical Inference",
    "section": "In Practice",
    "text": "In Practice\n\n\nFigure from (tharwat_parameter_2019?)"
  },
  {
    "objectID": "w09/slides.html#appendix-1-derivation-of-mathbbemu_2",
    "href": "w09/slides.html#appendix-1-derivation-of-mathbbemu_2",
    "title": "Week 9: Statistical Inference",
    "section": "Appendix 1: Derivation of \\(\\mathbb{E}[\\mu_*^2]\\)",
    "text": "Appendix 1: Derivation of \\(\\mathbb{E}[\\mu_*^2]\\)\n\\[\n\\begin{align*}\n\\expect{\\mu_*^2} &= \\bigexpect{\\left(\\frac{X_1 + X_2}{2}\\right)^2} = \\frac{1}{4}\\expect{(X_1+X_2)^2} \\\\\n&= \\frac{1}{4}\\expect{X_1^2 + X_2^2 + 2X_1X_2} = \\frac{1}{4}\\left(\\expect{X_1^2} + \\expect{X_2^2} + 2\\expect{X_1X_2}\\right) \\\\\n&= \\frac{1}{4}\\left(\\Var{X_1} + \\expect{X_1}^2 + \\Var{X_2} + \\expect{X_2}^2 + 2\\expect{X_1X_2}\\right) \\\\\n&= \\frac{1}{4}\\left(2\\sigma^2 + 2\\mu^2 + 2\\expect{X_1X_2}\\right) \\\\\n&= \\frac{1}{2}\\left(\\sigma^2 + \\mu^2 + \\expect{X_1X_2}\\right) \\overset{iid}{=} \\frac{1}{2}\\left(\\sigma^2 + \\mu^2 + \\mu^2\\right) \\\\\n&\\implies \\boxed{\\expect{\\mu^2_*} = \\mu^2 + \\frac{\\sigma^2}{2}} \\; \\; \\left(\\therefore \\; \\expect{\\mu_*^2} \\neq \\mu^2 \\right)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w09/slides.html#appendix-2-derivation-of-mathbbemux_i",
    "href": "w09/slides.html#appendix-2-derivation-of-mathbbemux_i",
    "title": "Week 9: Statistical Inference",
    "section": "Appendix 2: Derivation of \\(\\mathbb{E}[\\mu^*X_i]\\)",
    "text": "Appendix 2: Derivation of \\(\\mathbb{E}[\\mu^*X_i]\\)\n\\[\n\\begin{align*}\n\\expect{\\mu^*X_1} &= \\bigexpect{\\left(\\frac{X_1 + X_2}{2}\\right)X_1} = \\frac{1}{2}\\expect{X_1^2 + X_1X_2} \\\\\n&= \\frac{1}{2}\\expect{X_1^2} + \\frac{1}{2}\\expect{X_1X_2} = \\frac{1}{2}\\left(\\sigma^2 + \\mu^2\\right) + \\frac{1}{2}\\mu^2 \\\\\n&\\implies \\expect{\\mu^*X_1} = \\mu^2 + \\frac{\\sigma^2}{2}\n\\end{align*}\n\\]\nAnd since \\(X_1\\) was chosen without loss of generality,\n\\[\n\\boxed{\\expect{\\mu^*X_i} = \\mu^2 + \\frac{\\sigma^2}{2}}\n\\]"
  },
  {
    "objectID": "w09/slides.html#appendix-3-derivation-of-mathbbesigma2_",
    "href": "w09/slides.html#appendix-3-derivation-of-mathbbesigma2_",
    "title": "Week 9: Statistical Inference",
    "section": "Appendix 3: Derivation of \\(\\mathbb{E}[\\sigma^2_*]\\)",
    "text": "Appendix 3: Derivation of \\(\\mathbb{E}[\\sigma^2_*]\\)\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\frac{1}{2}\\bigexpect{(X_1 - \\mu^*)^2 + (X_2 - \\mu^*)^2} \\\\\n&= \\frac{1}{2}\\bigexpect{\\left(X_1^2 + \\mu^2_* -2\\mu^*X_1\\right) + \\left(X_2^2 + \\mu^2_* - 2X_2\\mu^*\\right)} \\\\\n&= \\frac{1}{2}\\expect{X_1^2 + X_2^2 + 2\\mu_*^2 - 2\\mu^*X_1 - 2\\mu^*X_2} \\\\\n&= \\frac{1}{2}\\left(\\expect{X_1^2} + \\expect{X_2^2} + 2\\expect{\\mu_*^2} - 2\\expect{\\mu^*X_1} - 2\\expect{\\mu^*X_2}\\right) \\\\\n&= \\frac{1}{2}\\left( 2\\sigma^2 + 2\\mu^2 + 2\\left(\\mu^2 + \\frac{\\sigma^2}{2}\\right) - 2\\left(\\mu^2 + s/2\\right) - 2\\left(\\mu^2 + s/2\\right) \\right) \\\\\n&= \\sigma^2 + \\mu^2 + \\mu^2 + \\frac{\\sigma^2}{2} - \\mu^2 - \\frac{\\sigma^2}{2} - \\mu^2 - \\frac{\\sigma^2}{2} = \\sigma^2 - \\frac{\\sigma^2}{2} \\\\\n&\\implies \\boxed{\\expect{\\sigma^2_*} = \\frac{1}{2}\\sigma^2}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w09/slides.html#references",
    "href": "w09/slides.html#references",
    "title": "Week 9: Statistical Inference",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "w09/slides.html#week-9-lab",
    "href": "w09/slides.html#week-9-lab",
    "title": "Week 9: Statistical Inference",
    "section": "Week 9 Lab",
    "text": "Week 9 Lab\n\nLink here\n\n\n\n\nDSAN 5100-03 W09: Statistical Inference"
  },
  {
    "objectID": "w08/index.html",
    "href": "w08/index.html",
    "title": "Week 8: Markov Models",
    "section": "",
    "text": "Open slides in new window ‚Üí",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#the-course-so-far",
    "href": "w08/index.html#the-course-so-far",
    "title": "Week 8: Markov Models",
    "section": "The Course So Far",
    "text": "The Course So Far\n\nLogic: Reasoning about T/F statements using and and or\n\\(\\rightarrow\\) Set Theory: Reasoning about collections of objects and their union and intersection\n\n\nDeterministic\n\n\n\nProbabilistic\n\n\n\\(\\rightarrow\\) Probability: Assigning ‚Äúlikelihood values‚Äù in \\([0,1]\\) to logical/set-theoretic statements about outcomes\n\\(\\rightarrow\\) Random Variables: Doing math (beyond and and or) with the probabilities of these uncertain outcomes\nAll have been reasoning about uncertainty in more and more complex ways!",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#the-new-dimension-evolution-through-time",
    "href": "w08/index.html#the-new-dimension-evolution-through-time",
    "title": "Week 8: Markov Models",
    "section": "The New Dimension: Evolution Through Time",
    "text": "The New Dimension: Evolution Through Time\n\nMarkov models are a stepping-stone towards full-on time series analysis: reasoning about uncertainty over time\nSo why are time series the topic of an entire course, while Markov models only the topic of one week in DSAN5000?",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#recall-definition-of-conditional-probability",
    "href": "w08/index.html#recall-definition-of-conditional-probability",
    "title": "Week 8: Markov Models",
    "section": "Recall: Definition of Conditional Probability",
    "text": "Recall: Definition of Conditional Probability\n\\[\n\\Pr(A \\mid B) \\definedas \\frac{\\Pr(A, B)}{\\Pr(B)} \\genfrac{}{}{0pt}{}{\\leftarrow A\\text{ and }B\\text{ happen}}{\\leftarrow \\text{In world where }\\Omega = B}\n\\]",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#the-markov-property",
    "href": "w08/index.html#the-markov-property",
    "title": "Week 8: Markov Models",
    "section": "The Markov Property",
    "text": "The Markov Property\n\\[\nP(\\text{future} \\mid \\text{present}, {\\color{orange}\\text{past}}) = P(\\text{future} \\mid \\text{present})\n\\]",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#the-markov-assumption",
    "href": "w08/index.html#the-markov-assumption",
    "title": "Week 8: Markov Models",
    "section": "The Markov Assumption",
    "text": "The Markov Assumption\nOften stated in many different (confusing) ways, but think of anterograde amnesia:",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#keeping-track-of-states",
    "href": "w08/index.html#keeping-track-of-states",
    "title": "Week 8: Markov Models",
    "section": "Keeping Track of States",
    "text": "Keeping Track of States\n\nSince Markov models come more from engineering than ‚Äúpure‚Äù math/probability, we have ‚Äúfancier‚Äù objects we‚Äôre keeping track of, rather than just Random Variables\nWe now keep track of the state of a system over time: this could be a single RV, but could be a collection of multiple (potentially dependent) RVs",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#what-information-should-we-keep-track-of",
    "href": "w08/index.html#what-information-should-we-keep-track-of",
    "title": "Week 8: Markov Models",
    "section": "What Information Should We Keep Track Of?",
    "text": "What Information Should We Keep Track Of?\n\nSometimes answer seems ‚Äúobvious‚Äù, lulls us into false sense of confidence (that we don‚Äôt have to think too hard about it)1\n\n\n\n\nSystem\nState Space\n\n\n\n\nChess\nPosition of each piece, whose turn it is\n\n\nIndoor Robot\nModel of room + objects inside it\n\n\nPredator-Prey Ecosystem\nRelative species populations\n\n\nMove Left/Move Right Game\n?\n\n\nWeather Prediction\n?\n\n\nMusic\n?\n\n\n\n\nTension between too little information (cannot model phenomena of interest) vs.¬†too much information (solving model becomes intractable)",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#modeling-music-where-is-the-downbeat",
    "href": "w08/index.html#modeling-music-where-is-the-downbeat",
    "title": "Week 8: Markov Models",
    "section": "Modeling Music: Where is the Downbeat?",
    "text": "Modeling Music: Where is the Downbeat?",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#state-space-choice-rightarrow-information-loss",
    "href": "w08/index.html#state-space-choice-rightarrow-information-loss",
    "title": "Week 8: Markov Models",
    "section": "State Space Choice \\(\\rightarrow\\) Information Loss",
    "text": "State Space Choice \\(\\rightarrow\\) Information Loss\n\nRecall the Move Left/Move Right Game (especially from Lab 4 Prep)\n\n\n\n\n\n\n\n\n\n\nPossible State Spaces:\n\n\n\n\nHistory vector\nPosition\nSteps\n#L\n#R\n\n\n\n\n\\(()\\)\n\\(x = 0\\)\n0\n0\n0\n\n\n\\((L,R)\\)\n\\(x = 0\\)\n2\n1\n1\n\n\n\\((R,L)\\)\n\\(x = 0\\)\n2\n1\n1\n\n\n\\((R,L,R,\\)\\(~L,R,L)\\)\n\\(x = 0\\)\n6\n3\n3\n\n\n\\((L)\\)\n\\(x = -1\\)\n1\n1\n0\n\n\n\\((L,L,R)\\)\n\\(x = -1\\)\n3\n2\n1",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#finite-state-automata",
    "href": "w08/index.html#finite-state-automata",
    "title": "Week 8: Markov Models",
    "section": "Finite-State Automata",
    "text": "Finite-State Automata\n(Deterministic!) Only ‚Äúaccepts‚Äù strings with even number of 1s:\n\n\n\n\n\n\n\n\n\n\n\nInput String\nResult\nInput String\nResult\n\n\n\n\n\\(\\varepsilon\\)\n‚úÖ\n01\n\n\n\n0\n‚úÖ\n10\n\n\n\n1\n\n1000000\n\n\n\n00\n‚úÖ\n10000001\n‚úÖ\n\n\n\n\n\n\n\n‚Ä¶But we‚Äôre trying to model probabilistic evolution!",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#enter-markov-chains",
    "href": "w08/index.html#enter-markov-chains",
    "title": "Week 8: Markov Models",
    "section": "Enter Markov Chains",
    "text": "Enter Markov Chains\n\n\n\nGraphically\n\n\n\n\n\n\n\n\n\n\n\n\n\nMathematically\n\n\\[\n\\begin{array}{c c}\n& \\begin{array}{c c c} 1 & 2 & 3 \\\\ \\end{array} \\\\\n\\begin{array}{c c c}1 \\\\ 2 \\\\ 3 \\end{array} &\n\\left[\n\\begin{array}{c c c}\n0 & 1/2 & 1/2 \\\\\n1/3 & 0 & 2/3 \\\\\n1/3 & 2/3 & 0\n\\end{array}\n\\right]\n\\end{array}\n\\]\n\\[\n\\begin{array}{c c}\n& \\begin{array}{c c c} 1 & 2 & 3 \\\\ \\end{array} \\\\\n\\begin{array}{c c c}1 \\\\ 2 \\\\ 3 \\end{array} &\n\\left[\n\\begin{array}{c c c}\n1/2 & 1/3 & 1/6 \\\\\n1/10 & 1/2 & 2/5 \\\\\n1/8 & 3/8 & 1/2\n\\end{array}\n\\right]\n\\end{array}\n\\]",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#hidden-markov-models",
    "href": "w08/index.html#hidden-markov-models",
    "title": "Week 8: Markov Models",
    "section": "Hidden Markov Models",
    "text": "Hidden Markov Models\n\nUse observed data to infer unobserved variables\n\n\n\n\n\n\n\n(What our brains are doing, most of the time!)",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#pagerank-matrix-magic",
    "href": "w08/index.html#pagerank-matrix-magic",
    "title": "Week 8: Markov Models",
    "section": "PageRank (Matrix Magic)",
    "text": "PageRank (Matrix Magic)\n\nWhat is the relevance of this abstract topic? ‚Ä¶ü§ë\n\n\nlibrary(readr)\nlibrary(ggplot2)\ngoog_df &lt;- read_csv(\"assets/google_yearly_revenue.csv\")\nggplot(goog_df, aes(x=year, y=revenue_billions)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title = \"Google Yearly Revenue, 2002-2022\",\n    x = \"Year\",\n    y = \"Revenue (Billion USD)\"\n  ) +\n  dsan_theme(\"full\")\n\n\n\n\n\n\n\n\n\nPageRank = The ‚Äúspark‚Äù that ignited the Google flame",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#pagerank-visualized",
    "href": "w08/index.html#pagerank-visualized",
    "title": "Week 8: Markov Models",
    "section": "PageRank Visualized",
    "text": "PageRank Visualized\n\nNodes = Webpages, Edges = Links\n\n\n\n\n\n\n\nGoal: Rank the relative ‚Äúimportance‚Äù of a site \\(S_i\\), taking into account the importance of other sites that link to \\(S_i\\)\n\n‚ÄúImportant‚Äù sites: linked to often, and linked to often by other important sites",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#chickens-and-eggs",
    "href": "w08/index.html#chickens-and-eggs",
    "title": "Week 8: Markov Models",
    "section": "Chickens and Eggs",
    "text": "Chickens and Eggs\n\nParadoxical at first: how are we supposed to figure out the importance of a site \\(S_i\\), when that‚Äôs determined by\n\nthe importance of sites \\(S_j\\) that link to \\(S_i\\), which is determined by\n\nthe importance of sites \\(S_k\\) that link to sites \\(S_j\\), which is determined by\n\nthe importance of the sites \\(S_\\ell\\) that link to those sites \\(S_k\\), which is determined by‚Ä¶\n\n\n\n\n\\[\n\\begin{align*}\n\\mathsf{Importance}(S_i) &= f(\\mathsf{Importance}(S_{j \\rightarrow i})) = f(f(\\mathsf{Importance}(S_{k \\rightarrow j \\rightarrow i}))) \\\\\n&= f(f(f(\\mathsf{Importance}(S_{\\ell \\rightarrow k \\rightarrow j \\rightarrow i})))) = \\cdots\n\\end{align*}\n\\]\n\n\nSanity hint: Remember infinite sums from calculus! They can converge, despite having infinitely-many terms‚Ä¶ This is something like that, but for recursion (the mathematical term for an object whose definition refers to itself)",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#resolving-recursive-definitions",
    "href": "w08/index.html#resolving-recursive-definitions",
    "title": "Week 8: Markov Models",
    "section": "Resolving Recursive Definitions",
    "text": "Resolving Recursive Definitions\n\nWe can compute this importance ranking, despite its recursive definition!\nRecall, for example, the Fibonacci sequence: \\(1, 1, 2, 3, 5, 8, 13, 21, \\ldots\\)\nDefined recursively!\n\n\\[\nf(n) = \\begin{cases}\n1 & n = 1\\text{ or }n = 2 \\\\\nf(n-2) + f(n-1) & n &gt; 2\n\\end{cases}\n\\]\n\nAnd yet, a guy named Bernoulli figured out\n\\[\nf(n) = \\frac{\\varphi^n - \\psi^n}{\\varphi - \\psi} = \\frac{\\varphi^n - \\psi^n}{\\sqrt{5}},\n\\]\nwhere \\(\\varphi\\) is the ‚ÄúGolden Ratio‚Äù \\(\\frac{1 + \\sqrt{5}}{2}\\) and \\(\\psi\\) its conjugate \\(\\frac{1 - \\sqrt{5}}{2}\\).",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#the-pagerank-process",
    "href": "w08/index.html#the-pagerank-process",
    "title": "Week 8: Markov Models",
    "section": "The PageRank Process",
    "text": "The PageRank Process\n\nEvery site starts with equal PageRank score: \\(r^{(0)}_1 = r^{(0)}_2 = r^{(0)}_3 = \\frac{1}{3}\\).\nEach link \\(S_i \\rightarrow S_j\\) is a vote of confidence that \\(S_i\\) is giving to \\(S_j\\)\nAt each time \\(t\\), a site \\(S_i\\) ‚Äúspends‚Äù whatever voting power it currently has (\\(r^{(t)}_i\\)) on the sites it links to.\n\n\\(S_1\\) casts one vote for itself and one vote for \\(S_2\\), thus spending \\(\\frac{1}{2}\\) of its total PageRank on itself and \\(\\frac{1}{2}\\) of its total PageRank on \\(S_2\\).\n\nState of the process at time \\(t\\): \\(\\mathbf{r}^{(t)} = \\begin{bmatrix}r^{(t)}_1 & r^{(t)}_2 & r^{(t)}_3\\end{bmatrix}^\\top\\)\nCan form a matrix specifying how this state evolves from time \\(t\\) to time \\(t+1\\)!\n\n\\[\n\\mathbf{E} = \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix} \\; \\leadsto \\; \\mathbf{r}^{(t+1)} = \\mathbf{E}\\mathbf{r}^{(t)}\n\\]\n\n\nGiven the ‚Äú\\(S_1\\) casts one vote for itself‚Ä¶‚Äù part, can you say exactly what \\(S_1\\) will ‚Äúspend‚Äù on itself and on \\(S_2\\) at time \\(t = 0\\) (in the first round)?",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#section",
    "href": "w08/index.html#section",
    "title": "Week 8: Markov Models",
    "section": "",
    "text": "We can use \\(\\mathbf{E}\\) to figure out the state at each step, starting from \\(t = 0\\)!\n\n\\[\n\\begin{array}{c@{}c@{}c@{}c@{}c@{}c@{}c}\n\\mathbf{r}^{(1)} & = & \\mathbf{E}\\mathbf{r}^{(0)} & = & \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix}\\begin{bmatrix}\n\\frac{1}{3} \\\\\n\\frac{1}{3} \\\\\n\\frac{1}{3}\\end{bmatrix} & = & \\begin{bmatrix}\n\\frac{1}{3} \\\\\n\\frac{1}{2} \\\\\n\\frac{1}{6}\n\\end{bmatrix} \\\\\n~ & ~ & ~ & ~ & ~ & \\swarrow & ~ \\\\\n\\mathbf{r}^{(2)} & = & \\mathbf{E}\\mathbf{r}^{(1)} & = & \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix}\\begin{bmatrix}\\frac{1}{3} \\\\ \\frac{1}{2} \\\\ \\frac{1}{6}\\end{bmatrix} & = & \\begin{bmatrix}\\frac{5}{12} \\\\ \\frac{1}{3} \\\\ \\frac{1}{4}\\end{bmatrix} \\\\\n~ & ~ & ~ & ~ & ~ & \\swarrow & ~ \\\\\n\\mathbf{r}^{(3)} & = & \\mathbf{E}\\mathbf{r}^{(2)} & = & \\cdots & ~ & ~\n\\end{array}\n\\]",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#matrix-magic",
    "href": "w08/index.html#matrix-magic",
    "title": "Week 8: Markov Models",
    "section": "Matrix Magic",
    "text": "Matrix Magic\n\n(1) Won‚Äôt we just have to run this forever? (2) How do we know it‚Äôll converge to something?\nAnswers: (1) No! (2) because Markov matrix magic!\n‚ÄúSteady state‚Äù = state where \\(\\mathbf{r}^{(t)} = \\mathbf{r}^{(t+1)} = \\mathbf{r}^{(t+2)} = \\cdots \\definedas \\mathbf{r}^*\\). But this means\n\n\\[\n\\mathbf{r}^{(t+1)} = \\mathbf{r}^{(t)} \\iff \\mathbf{E}\\mathbf{r}^{(t)} = \\mathbf{r}^{(t)} \\iff \\mathbf{E}\\mathbf{r}^* = \\mathbf{r}^*\n\\]\n\nThis \\(\\mathbf{r}^*\\) is (by definition!) an Eigenvector of \\(\\mathbf{E}\\) with Eigenvalue \\(\\lambda = 1\\)!2\n\n\n\nIn my opinion, along with e.g.¬†insolubility of the quintic, this is maybe the most mind-blowing case of math magic :3",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#solving-the-matrix-magic",
    "href": "w08/index.html#solving-the-matrix-magic",
    "title": "Week 8: Markov Models",
    "section": "Solving the Matrix Magic",
    "text": "Solving the Matrix Magic\n\nSince we already know the Eigenvalue of interest, \\(\\lambda = 1\\), all that‚Äôs left is solving for its corresponding Eigenvector:\n\\[\n  \\mathbf{E}\\mathbf{r}^* = \\mathbf{r}^* \\iff \\mathbf{E}\\mathbf{r}^* - \\mathbf{r}^* = \\mathbf{0} \\iff (\\mathbf{E} - \\mathbf{I})\\mathbf{r}^* = \\mathbf{0}\n  \\]\nWritten out, we see that this gives us a system of linear equations:\n\\[\n  \\begin{bmatrix}\n  \\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n  \\frac{1}{2} & 0 & 1 \\\\\n  0 & \\frac{1}{2} & 0\n  \\end{bmatrix}\\begin{bmatrix}r^*_1 \\\\ r^*_2 \\\\ r^*_3\\end{bmatrix} = \\begin{bmatrix}0 \\\\ 0 \\\\ 0\\end{bmatrix} \\iff \\begin{array}{ccccccc}\\frac{1}{2}r^*_1 & + & \\frac{1}{2}r^*_2 & ~ & ~ & = & 0 \\\\ \\frac{1}{2}r^*_1 & ~ & ~ & + & r^*_3 & = & 0 \\\\ ~ & ~ & \\frac{1}{2}r^*_2 & ~ & ~ & = & 0\\end{array}\n  \\]\nwhich we can solve however we want!\nTo handle the fact that this system is underspecified, impose additional restriction that \\(r^*_1 + r^*_2 + r^*_3 = 1\\), so that the ranks form a probability distribution",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#the-point-of-all-this",
    "href": "w08/index.html#the-point-of-all-this",
    "title": "Week 8: Markov Models",
    "section": "The Point of All This",
    "text": "The Point of All This\n\nThe final restriction \\(r^*_1 + r^*_2 + r^*_3 = 1\\) ensures that the resulting PageRank values form a probability distribution\nThis is called the Stationary Distribution of the Markov chain: represents the probability that a random walker through the chain will be at page \\(S_i\\) at a given time!\n\nEquivalently: expected proportion of total walking time a random-walker will spend at each node\n\nEvery Markov chain has a Stationary Distribution! This fact has cool implications even above and beyond the Google $$$ implications üòú",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#footnotes",
    "href": "w08/index.html#footnotes",
    "title": "Week 8: Markov Models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTo snap out of this lull, keep in mind that engineering/nonlinear dynamical systems programs have entire courses just on state space representations‚Ü©Ô∏é\nThis is because an Eigenvalue-Eigenvector pair for a matrix \\(\\mathbf{M}\\) is a vector \\(\\mathbf{v}\\) and scalar value \\(\\lambda\\) which satisfy \\(\\mathbf{M}\\mathbf{v} = \\lambda \\mathbf{v}\\). In words: the result of (left) matrix-multiplying \\(\\mathbf{v}\\) by \\(\\mathbf{M}\\) is the same as scalar-multiplying \\(\\mathbf{v}\\) by a factor of \\(\\lambda\\). In our case the Eigenvector is \\(\\mathbf{r}^*\\) and the Eigenvalue is \\(\\lambda = 1\\), since \\(\\mathbf{E}\\mathbf{r}^* = 1 \\cdot \\mathbf{r}^*\\).For the math-curious, there are lots of fun results from matrix theory which assure us that \\(\\mathbf{E}\\) is guaranteed to have principal eigenvalue \\(\\lambda = 1\\) üíÜ‚Ü©Ô∏é",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/slides.html#the-course-so-far",
    "href": "w08/slides.html#the-course-so-far",
    "title": "Week 8: Markov Models",
    "section": "The Course So Far",
    "text": "The Course So Far\n\nLogic: Reasoning about T/F statements using and and or\n\\(\\rightarrow\\) Set Theory: Reasoning about collections of objects and their union and intersection\n\n\nDeterministic\n\n\n\nProbabilistic\n\n\n\\(\\rightarrow\\) Probability: Assigning ‚Äúlikelihood values‚Äù in \\([0,1]\\) to logical/set-theoretic statements about outcomes\n\\(\\rightarrow\\) Random Variables: Doing math (beyond and and or) with the probabilities of these uncertain outcomes\nAll have been reasoning about uncertainty in more and more complex ways!"
  },
  {
    "objectID": "w08/slides.html#the-new-dimension-evolution-through-time",
    "href": "w08/slides.html#the-new-dimension-evolution-through-time",
    "title": "Week 8: Markov Models",
    "section": "The New Dimension: Evolution Through Time",
    "text": "The New Dimension: Evolution Through Time\n\nMarkov models are a stepping-stone towards full-on time series analysis: reasoning about uncertainty over time\nSo why are time series the topic of an entire course, while Markov models only the topic of one week in DSAN5000?"
  },
  {
    "objectID": "w08/slides.html#recall-definition-of-conditional-probability",
    "href": "w08/slides.html#recall-definition-of-conditional-probability",
    "title": "Week 8: Markov Models",
    "section": "Recall: Definition of Conditional Probability",
    "text": "Recall: Definition of Conditional Probability\n\\[\n\\Pr(A \\mid B) \\definedas \\frac{\\Pr(A, B)}{\\Pr(B)} \\genfrac{}{}{0pt}{}{\\leftarrow A\\text{ and }B\\text{ happen}}{\\leftarrow \\text{In world where }\\Omega = B}\n\\]"
  },
  {
    "objectID": "w08/slides.html#the-markov-property",
    "href": "w08/slides.html#the-markov-property",
    "title": "Week 8: Markov Models",
    "section": "The Markov Property",
    "text": "The Markov Property\n\\[\nP(\\text{future} \\mid \\text{present}, {\\color{orange}\\text{past}}) = P(\\text{future} \\mid \\text{present})\n\\]"
  },
  {
    "objectID": "w08/slides.html#the-markov-assumption",
    "href": "w08/slides.html#the-markov-assumption",
    "title": "Week 8: Markov Models",
    "section": "The Markov Assumption",
    "text": "The Markov Assumption\nOften stated in many different (confusing) ways, but think of anterograde amnesia:"
  },
  {
    "objectID": "w08/slides.html#keeping-track-of-states",
    "href": "w08/slides.html#keeping-track-of-states",
    "title": "Week 8: Markov Models",
    "section": "Keeping Track of States",
    "text": "Keeping Track of States\n\nSince Markov models come more from engineering than ‚Äúpure‚Äù math/probability, we have ‚Äúfancier‚Äù objects we‚Äôre keeping track of, rather than just Random Variables\nWe now keep track of the state of a system over time: this could be a single RV, but could be a collection of multiple (potentially dependent) RVs"
  },
  {
    "objectID": "w08/slides.html#what-information-should-we-keep-track-of",
    "href": "w08/slides.html#what-information-should-we-keep-track-of",
    "title": "Week 8: Markov Models",
    "section": "What Information Should We Keep Track Of?",
    "text": "What Information Should We Keep Track Of?\n\nSometimes answer seems ‚Äúobvious‚Äù, lulls us into false sense of confidence (that we don‚Äôt have to think too hard about it)1\n\n\n\n\nSystem\nState Space\n\n\n\n\nChess\nPosition of each piece, whose turn it is\n\n\nIndoor Robot\nModel of room + objects inside it\n\n\nPredator-Prey Ecosystem\nRelative species populations\n\n\nMove Left/Move Right Game\n?\n\n\nWeather Prediction\n?\n\n\nMusic\n?\n\n\n\n\nTension between too little information (cannot model phenomena of interest) vs.¬†too much information (solving model becomes intractable)\n\nTo snap out of this lull, keep in mind that engineering/nonlinear dynamical systems programs have entire courses just on state space representations"
  },
  {
    "objectID": "w08/slides.html#modeling-music-where-is-the-downbeat",
    "href": "w08/slides.html#modeling-music-where-is-the-downbeat",
    "title": "Week 8: Markov Models",
    "section": "Modeling Music: Where is the Downbeat?",
    "text": "Modeling Music: Where is the Downbeat?"
  },
  {
    "objectID": "w08/slides.html#state-space-choice-rightarrow-information-loss",
    "href": "w08/slides.html#state-space-choice-rightarrow-information-loss",
    "title": "Week 8: Markov Models",
    "section": "State Space Choice \\(\\rightarrow\\) Information Loss",
    "text": "State Space Choice \\(\\rightarrow\\) Information Loss\n\nRecall the Move Left/Move Right Game (especially from Lab 4 Prep)\n\n\n\n\n\n\n\n\n\n\nPossible State Spaces:\n\n\n\n\nHistory vector\nPosition\nSteps\n#L\n#R\n\n\n\n\n\\(()\\)\n\\(x = 0\\)\n0\n0\n0\n\n\n\\((L,R)\\)\n\\(x = 0\\)\n2\n1\n1\n\n\n\\((R,L)\\)\n\\(x = 0\\)\n2\n1\n1\n\n\n\\((R,L,R,\\)\\(~L,R,L)\\)\n\\(x = 0\\)\n6\n3\n3\n\n\n\\((L)\\)\n\\(x = -1\\)\n1\n1\n0\n\n\n\\((L,L,R)\\)\n\\(x = -1\\)\n3\n2\n1"
  },
  {
    "objectID": "w08/slides.html#finite-state-automata",
    "href": "w08/slides.html#finite-state-automata",
    "title": "Week 8: Markov Models",
    "section": "Finite-State Automata",
    "text": "Finite-State Automata\n(Deterministic!) Only ‚Äúaccepts‚Äù strings with even number of 1s:\n\n\n\n\n\n\n\n\n\n\n\nInput String\nResult\nInput String\nResult\n\n\n\n\n\\(\\varepsilon\\)\n‚úÖ\n01\n\n\n\n0\n‚úÖ\n10\n\n\n\n1\n\n1000000\n\n\n\n00\n‚úÖ\n10000001\n‚úÖ\n\n\n\n\n\n\n‚Ä¶But we‚Äôre trying to model probabilistic evolution!"
  },
  {
    "objectID": "w08/slides.html#enter-markov-chains",
    "href": "w08/slides.html#enter-markov-chains",
    "title": "Week 8: Markov Models",
    "section": "Enter Markov Chains",
    "text": "Enter Markov Chains\n\n\n\nGraphically\n\n\n\n\n\n\n\n\n\n\n\n\n\nMathematically\n\n\\[\n\\begin{array}{c c}\n& \\begin{array}{c c c} 1 & 2 & 3 \\\\ \\end{array} \\\\\n\\begin{array}{c c c}1 \\\\ 2 \\\\ 3 \\end{array} &\n\\left[\n\\begin{array}{c c c}\n0 & 1/2 & 1/2 \\\\\n1/3 & 0 & 2/3 \\\\\n1/3 & 2/3 & 0\n\\end{array}\n\\right]\n\\end{array}\n\\]\n\\[\n\\begin{array}{c c}\n& \\begin{array}{c c c} 1 & 2 & 3 \\\\ \\end{array} \\\\\n\\begin{array}{c c c}1 \\\\ 2 \\\\ 3 \\end{array} &\n\\left[\n\\begin{array}{c c c}\n1/2 & 1/3 & 1/6 \\\\\n1/10 & 1/2 & 2/5 \\\\\n1/8 & 3/8 & 1/2\n\\end{array}\n\\right]\n\\end{array}\n\\]"
  },
  {
    "objectID": "w08/slides.html#hidden-markov-models",
    "href": "w08/slides.html#hidden-markov-models",
    "title": "Week 8: Markov Models",
    "section": "Hidden Markov Models",
    "text": "Hidden Markov Models\n\nUse observed data to infer unobserved variables\n\n\n\n(What our brains are doing, most of the time!)"
  },
  {
    "objectID": "w08/slides.html#pagerank-matrix-magic",
    "href": "w08/slides.html#pagerank-matrix-magic",
    "title": "Week 8: Markov Models",
    "section": "PageRank (Matrix Magic)",
    "text": "PageRank (Matrix Magic)\n\nWhat is the relevance of this abstract topic? ‚Ä¶ü§ë\n\n\n\nCode\nlibrary(readr)\nlibrary(ggplot2)\ngoog_df &lt;- read_csv(\"assets/google_yearly_revenue.csv\")\nggplot(goog_df, aes(x=year, y=revenue_billions)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title = \"Google Yearly Revenue, 2002-2022\",\n    x = \"Year\",\n    y = \"Revenue (Billion USD)\"\n  ) +\n  dsan_theme(\"full\")\n\n\n\n\nPageRank = The ‚Äúspark‚Äù that ignited the Google flame"
  },
  {
    "objectID": "w08/slides.html#pagerank-visualized",
    "href": "w08/slides.html#pagerank-visualized",
    "title": "Week 8: Markov Models",
    "section": "PageRank Visualized",
    "text": "PageRank Visualized\n\nNodes = Webpages, Edges = Links\n\n\n\nGoal: Rank the relative ‚Äúimportance‚Äù of a site \\(S_i\\), taking into account the importance of other sites that link to \\(S_i\\)\n\n‚ÄúImportant‚Äù sites: linked to often, and linked to often by other important sites"
  },
  {
    "objectID": "w08/slides.html#chickens-and-eggs",
    "href": "w08/slides.html#chickens-and-eggs",
    "title": "Week 8: Markov Models",
    "section": "Chickens and Eggs",
    "text": "Chickens and Eggs\n\nParadoxical at first: how are we supposed to figure out the importance of a site \\(S_i\\), when that‚Äôs determined by\n\nthe importance of sites \\(S_j\\) that link to \\(S_i\\), which is determined by\n\nthe importance of sites \\(S_k\\) that link to sites \\(S_j\\), which is determined by\n\nthe importance of the sites \\(S_\\ell\\) that link to those sites \\(S_k\\), which is determined by‚Ä¶\n\n\n\n\n\\[\n\\begin{align*}\n\\mathsf{Importance}(S_i) &= f(\\mathsf{Importance}(S_{j \\rightarrow i})) = f(f(\\mathsf{Importance}(S_{k \\rightarrow j \\rightarrow i}))) \\\\\n&= f(f(f(\\mathsf{Importance}(S_{\\ell \\rightarrow k \\rightarrow j \\rightarrow i})))) = \\cdots\n\\end{align*}\n\\]\n\n\nSanity hint: Remember infinite sums from calculus! They can converge, despite having infinitely-many terms‚Ä¶ This is something like that, but for recursion (the mathematical term for an object whose definition refers to itself)"
  },
  {
    "objectID": "w08/slides.html#resolving-recursive-definitions",
    "href": "w08/slides.html#resolving-recursive-definitions",
    "title": "Week 8: Markov Models",
    "section": "Resolving Recursive Definitions",
    "text": "Resolving Recursive Definitions\n\nWe can compute this importance ranking, despite its recursive definition!\nRecall, for example, the Fibonacci sequence: \\(1, 1, 2, 3, 5, 8, 13, 21, \\ldots\\)\nDefined recursively!\n\n\\[\nf(n) = \\begin{cases}\n1 & n = 1\\text{ or }n = 2 \\\\\nf(n-2) + f(n-1) & n &gt; 2\n\\end{cases}\n\\]\n\nAnd yet, a guy named Bernoulli figured out\n\\[\nf(n) = \\frac{\\varphi^n - \\psi^n}{\\varphi - \\psi} = \\frac{\\varphi^n - \\psi^n}{\\sqrt{5}},\n\\]\nwhere \\(\\varphi\\) is the ‚ÄúGolden Ratio‚Äù \\(\\frac{1 + \\sqrt{5}}{2}\\) and \\(\\psi\\) its conjugate \\(\\frac{1 - \\sqrt{5}}{2}\\)."
  },
  {
    "objectID": "w08/slides.html#the-pagerank-process",
    "href": "w08/slides.html#the-pagerank-process",
    "title": "Week 8: Markov Models",
    "section": "The PageRank Process",
    "text": "The PageRank Process\n\nEvery site starts with equal PageRank score: \\(r^{(0)}_1 = r^{(0)}_2 = r^{(0)}_3 = \\frac{1}{3}\\).\nEach link \\(S_i \\rightarrow S_j\\) is a vote of confidence that \\(S_i\\) is giving to \\(S_j\\)\nAt each time \\(t\\), a site \\(S_i\\) ‚Äúspends‚Äù whatever voting power it currently has (\\(r^{(t)}_i\\)) on the sites it links to.\n\n\\(S_1\\) casts one vote for itself and one vote for \\(S_2\\), thus spending \\(\\frac{1}{2}\\) of its total PageRank on itself and \\(\\frac{1}{2}\\) of its total PageRank on \\(S_2\\).\n\nState of the process at time \\(t\\): \\(\\mathbf{r}^{(t)} = \\begin{bmatrix}r^{(t)}_1 & r^{(t)}_2 & r^{(t)}_3\\end{bmatrix}^\\top\\)\nCan form a matrix specifying how this state evolves from time \\(t\\) to time \\(t+1\\)!\n\n\\[\n\\mathbf{E} = \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix} \\; \\leadsto \\; \\mathbf{r}^{(t+1)} = \\mathbf{E}\\mathbf{r}^{(t)}\n\\]\n\n\nGiven the ‚Äú\\(S_1\\) casts one vote for itself‚Ä¶‚Äù part, can you say exactly what \\(S_1\\) will ‚Äúspend‚Äù on itself and on \\(S_2\\) at time \\(t = 0\\) (in the first round)?"
  },
  {
    "objectID": "w08/slides.html#section",
    "href": "w08/slides.html#section",
    "title": "Week 8: Markov Models",
    "section": "",
    "text": "We can use \\(\\mathbf{E}\\) to figure out the state at each step, starting from \\(t = 0\\)!\n\n\\[\n\\begin{array}{c@{}c@{}c@{}c@{}c@{}c@{}c}\n\\mathbf{r}^{(1)} & = & \\mathbf{E}\\mathbf{r}^{(0)} & = & \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix}\\begin{bmatrix}\n\\frac{1}{3} \\\\\n\\frac{1}{3} \\\\\n\\frac{1}{3}\\end{bmatrix} & = & \\begin{bmatrix}\n\\frac{1}{3} \\\\\n\\frac{1}{2} \\\\\n\\frac{1}{6}\n\\end{bmatrix} \\\\\n~ & ~ & ~ & ~ & ~ & \\swarrow & ~ \\\\\n\\mathbf{r}^{(2)} & = & \\mathbf{E}\\mathbf{r}^{(1)} & = & \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix}\\begin{bmatrix}\\frac{1}{3} \\\\ \\frac{1}{2} \\\\ \\frac{1}{6}\\end{bmatrix} & = & \\begin{bmatrix}\\frac{5}{12} \\\\ \\frac{1}{3} \\\\ \\frac{1}{4}\\end{bmatrix} \\\\\n~ & ~ & ~ & ~ & ~ & \\swarrow & ~ \\\\\n\\mathbf{r}^{(3)} & = & \\mathbf{E}\\mathbf{r}^{(2)} & = & \\cdots & ~ & ~\n\\end{array}\n\\]"
  },
  {
    "objectID": "w08/slides.html#matrix-magic",
    "href": "w08/slides.html#matrix-magic",
    "title": "Week 8: Markov Models",
    "section": "Matrix Magic",
    "text": "Matrix Magic\n\n(1) Won‚Äôt we just have to run this forever? (2) How do we know it‚Äôll converge to something?\nAnswers: (1) No! (2) because Markov matrix magic!\n‚ÄúSteady state‚Äù = state where \\(\\mathbf{r}^{(t)} = \\mathbf{r}^{(t+1)} = \\mathbf{r}^{(t+2)} = \\cdots \\definedas \\mathbf{r}^*\\). But this means\n\n\\[\n\\mathbf{r}^{(t+1)} = \\mathbf{r}^{(t)} \\iff \\mathbf{E}\\mathbf{r}^{(t)} = \\mathbf{r}^{(t)} \\iff \\mathbf{E}\\mathbf{r}^* = \\mathbf{r}^*\n\\]\n\nThis \\(\\mathbf{r}^*\\) is (by definition!) an Eigenvector of \\(\\mathbf{E}\\) with Eigenvalue \\(\\lambda = 1\\)!1\n\n\n\nIn my opinion, along with e.g.¬†insolubility of the quintic, this is maybe the most mind-blowing case of math magic :3\n\n\nThis is because an Eigenvalue-Eigenvector pair for a matrix \\(\\mathbf{M}\\) is a vector \\(\\mathbf{v}\\) and scalar value \\(\\lambda\\) which satisfy \\(\\mathbf{M}\\mathbf{v} = \\lambda \\mathbf{v}\\). In words: the result of (left) matrix-multiplying \\(\\mathbf{v}\\) by \\(\\mathbf{M}\\) is the same as scalar-multiplying \\(\\mathbf{v}\\) by a factor of \\(\\lambda\\). In our case the Eigenvector is \\(\\mathbf{r}^*\\) and the Eigenvalue is \\(\\lambda = 1\\), since \\(\\mathbf{E}\\mathbf{r}^* = 1 \\cdot \\mathbf{r}^*\\).For the math-curious, there are lots of fun results from matrix theory which assure us that \\(\\mathbf{E}\\) is guaranteed to have principal eigenvalue \\(\\lambda = 1\\) üíÜ"
  },
  {
    "objectID": "w08/slides.html#solving-the-matrix-magic",
    "href": "w08/slides.html#solving-the-matrix-magic",
    "title": "Week 8: Markov Models",
    "section": "Solving the Matrix Magic",
    "text": "Solving the Matrix Magic\n\nSince we already know the Eigenvalue of interest, \\(\\lambda = 1\\), all that‚Äôs left is solving for its corresponding Eigenvector:\n\\[\n  \\mathbf{E}\\mathbf{r}^* = \\mathbf{r}^* \\iff \\mathbf{E}\\mathbf{r}^* - \\mathbf{r}^* = \\mathbf{0} \\iff (\\mathbf{E} - \\mathbf{I})\\mathbf{r}^* = \\mathbf{0}\n  \\]\nWritten out, we see that this gives us a system of linear equations:\n\\[\n  \\begin{bmatrix}\n  \\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n  \\frac{1}{2} & 0 & 1 \\\\\n  0 & \\frac{1}{2} & 0\n  \\end{bmatrix}\\begin{bmatrix}r^*_1 \\\\ r^*_2 \\\\ r^*_3\\end{bmatrix} = \\begin{bmatrix}0 \\\\ 0 \\\\ 0\\end{bmatrix} \\iff \\begin{array}{ccccccc}\\frac{1}{2}r^*_1 & + & \\frac{1}{2}r^*_2 & ~ & ~ & = & 0 \\\\ \\frac{1}{2}r^*_1 & ~ & ~ & + & r^*_3 & = & 0 \\\\ ~ & ~ & \\frac{1}{2}r^*_2 & ~ & ~ & = & 0\\end{array}\n  \\]\nwhich we can solve however we want!\nTo handle the fact that this system is underspecified, impose additional restriction that \\(r^*_1 + r^*_2 + r^*_3 = 1\\), so that the ranks form a probability distribution"
  },
  {
    "objectID": "w08/slides.html#the-point-of-all-this",
    "href": "w08/slides.html#the-point-of-all-this",
    "title": "Week 8: Markov Models",
    "section": "The Point of All This",
    "text": "The Point of All This\n\nThe final restriction \\(r^*_1 + r^*_2 + r^*_3 = 1\\) ensures that the resulting PageRank values form a probability distribution\nThis is called the Stationary Distribution of the Markov chain: represents the probability that a random walker through the chain will be at page \\(S_i\\) at a given time!\n\nEquivalently: expected proportion of total walking time a random-walker will spend at each node\n\nEvery Markov chain has a Stationary Distribution! This fact has cool implications even above and beyond the Google $$$ implications üòú\n\n\n\n\nDSAN 5100-03 W08: Markov Models"
  },
  {
    "objectID": "w06/index.html",
    "href": "w06/index.html",
    "title": "Week 6: Moments and Covariance",
    "section": "",
    "text": "Open slides in new window ‚Üí",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#the-emergence-of-order",
    "href": "w06/index.html#the-emergence-of-order",
    "title": "Week 6: Moments and Covariance",
    "section": "The Emergence of Order",
    "text": "The Emergence of Order\n\n\n\nWho can guess the state of this process after 10 steps, with 1 person?\n10 people? 50? 100? (If they find themselves on the same spot, they stand on each other‚Äôs heads)\n100 steps? 1000?",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#the-result-16-steps",
    "href": "w06/index.html#the-result-16-steps",
    "title": "Week 6: Moments and Covariance",
    "section": "The Result: 16 Steps",
    "text": "The Result: 16 Steps\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggExtra)\n# From McElreath!\ngen_histo &lt;- function(reps, num_steps) {\n  support &lt;- c(-1,1)\n  pos &lt;-replicate(reps, sum(sample(support,num_steps,replace=TRUE,prob=c(0.5,0.5))))\n  #print(mean(pos))\n  #print(var(pos))\n  pos_df &lt;- tibble::tibble(x=pos)\n  clt_distr &lt;- function(x) dnorm(x, 0, sqrt(num_steps))\n  plot &lt;- ggplot(pos_df, aes(x=x)) +\n    geom_histogram(aes(y = after_stat(density)), fill=cbPalette[1], binwidth = 2) +\n    stat_function(fun = clt_distr) +\n    dsan_theme(\"quarter\") +\n    theme(title=element_text(size=16)) +\n    labs(\n      title=paste0(reps,\" Random Walks, \",num_steps,\" Steps\")\n    )\n  return(plot)\n}\ngen_walkplot &lt;- function(num_people, num_steps, opacity=0.15) {\n  support &lt;- c(-1, 1)\n  # Unique id for each person\n  pid &lt;- seq(1, num_people)\n  pid_tib &lt;- tibble(pid)\n  pos_df &lt;- tibble()\n  end_df &lt;- tibble()\n  all_steps &lt;- t(replicate(num_people, sample(support, num_steps, replace = TRUE, prob = c(0.5, 0.5))))\n  csums &lt;- t(apply(all_steps, 1, cumsum))\n  csums &lt;- cbind(0, csums)\n  # Last col is the ending positions\n  ending_pos &lt;- csums[, dim(csums)[2]]\n  end_tib &lt;- tibble(pid = seq(1, num_people), endpos = ending_pos, x = num_steps)\n  # Now convert to tibble\n  ctib &lt;- as_tibble(csums, name_repair = \"none\")\n  merged_tib &lt;- bind_cols(pid_tib, ctib)\n  long_tib &lt;- merged_tib %&gt;% pivot_longer(!pid)\n  # Convert name -&gt; step_num\n  long_tib &lt;- long_tib %&gt;% mutate(step_num = strtoi(gsub(\"V\", \"\", name)) - 1)\n  # print(end_df)\n  grid_color &lt;- rgb(0, 0, 0, 0.1)\n\n  # And plot!\n  walkplot &lt;- ggplot(\n      long_tib,\n      aes(\n          x = step_num,\n          y = value,\n          group = pid,\n          # color=factor(label)\n      )\n  ) +\n      geom_line(linewidth = g_linesize, alpha = opacity, color = cbPalette[1]) +\n      geom_point(data = end_tib, aes(x = x, y = endpos), alpha = 0) +\n      scale_x_continuous(breaks = seq(0, num_steps, num_steps / 4)) +\n      scale_y_continuous(breaks = seq(-20, 20, 10)) +\n      dsan_theme(\"quarter\") +\n      theme(\n          legend.position = \"none\",\n          title = element_text(size = 16)\n      ) +\n      theme(\n          panel.grid.major.y = element_line(color = grid_color, linewidth = 1, linetype = 1)\n      ) +\n      labs(\n          title = paste0(num_people, \" Random Walks, \", num_steps, \" Steps\"),\n          x = \"Number of Steps\",\n          y = \"Position\"\n      )\n}\nwp1 &lt;- gen_walkplot(500, 16, 0.05)\nggMarginal(wp1, margins = \"y\", type = \"histogram\", yparams = list(binwidth = 1))",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#the-result-64-steps",
    "href": "w06/index.html#the-result-64-steps",
    "title": "Week 6: Moments and Covariance",
    "section": "The Result: 64 Steps",
    "text": "The Result: 64 Steps\n\n\nCode\nlibrary(ggExtra)\nwp2 &lt;- gen_walkplot(5000,64,0.008) +\n  ylim(-30,30)\nggMarginal(wp2, margins = \"y\", type = \"histogram\", yparams = list(binwidth = 1))\n\n\n\n\n\n\n\n\n\n\n\n\np2 &lt;- gen_histo(1000, 16)\np2\n\n\n\n\n\n\n\n\n\np3 &lt;- gen_histo(10000, 32)\np3",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#whats-going-on-here",
    "href": "w06/index.html#whats-going-on-here",
    "title": "Week 6: Moments and Covariance",
    "section": "What‚Äôs Going On Here?",
    "text": "What‚Äôs Going On Here?\n\n\n\n\n\n(Stay tuned for Markov processes \\(\\overset{t \\rightarrow \\infty}{\\leadsto}\\) Stationary distributions!)",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#properties-of-the-normal-distribution",
    "href": "w06/index.html#properties-of-the-normal-distribution",
    "title": "Week 6: Moments and Covariance",
    "section": "Properties of the Normal Distribution",
    "text": "Properties of the Normal Distribution\n\nIf \\(X \\sim \\mathcal{N}(\\param{\\mu}, \\param{\\theta})\\), then \\(X\\) has pdf \\(f_X(v)\\) defined by\n\n\\[\nf_X(v) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\bigexp{-\\frac{1}{2}\\left(\\frac{v - \\mu}{\\sigma}\\right)^2}\n\\]\n\nI hate memorizing as much as you do, I promise ü•¥\nThe important part (imo): this is the most conservative out of all possible (symmetric) prior distributions defined on \\(\\mathbb{R}\\) (defined from \\(-\\infty\\) to \\(\\infty\\))",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#most-conservative-how",
    "href": "w06/index.html#most-conservative-how",
    "title": "Week 6: Moments and Covariance",
    "section": "‚ÄúMost Conservative‚Äù How?",
    "text": "‚ÄúMost Conservative‚Äù How?\n\nOf all possible distributions with mean \\(\\mu\\), variance \\(\\sigma^2\\), \\(\\mathcal{N}(\\mu, \\sigma^2)\\) is the entropy-maximizing distribution\nRoughly: using any other distribution (implicitly/secretly) imports additional information beyond the fact that mean is \\(\\mu\\) and variance is \\(\\sigma^2\\)\nExample: let \\(X\\) be an RV. If we know mean is \\(\\mu\\), variance is \\(\\sigma^2\\), but then we learn that \\(X \\neq 3\\), or \\(X\\) is even, or the 15th digit of \\(X\\) is 7, can update \\(\\mathcal{N}(\\mu,\\sigma^2)\\) to derive a ‚Äúbetter‚Äù distribution (incorporating this additional info)",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#the-takeaway",
    "href": "w06/index.html#the-takeaway",
    "title": "Week 6: Moments and Covariance",
    "section": "The Takeaway",
    "text": "The Takeaway\n\nGiven info we know, we can find a distribution that ‚Äúencodes‚Äù only this info\nMore straightforward example: if we only know that the value is something in the range \\([a,b]\\), entropy-maximizing distribution is the Uniform Distribution\n\n\n\n\n\n\n\n\n\nIf We Know\nAnd We Know\n(Max-Entropy) Distribution Is‚Ä¶\n\n\n\n\n\\(\\text{Mean}[X] = \\mu\\)\n\\(\\text{Var}[X] = \\sigma^2\\)\n\\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\n\n\n\\(\\text{Mean}[X] = \\lambda\\)\n\\(X \\geq 0\\)\n\\(X \\sim \\text{Exp}\\left(\\frac{1}{\\lambda}\\right)\\)\n\n\n\\(X \\geq a\\)\n\\(X \\leq b\\)\n\\(X \\sim \\mathcal{U}[a,b]\\)",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#recall-discrete-uniform-distribution",
    "href": "w06/index.html#recall-discrete-uniform-distribution",
    "title": "Week 6: Moments and Covariance",
    "section": "[Recall] Discrete Uniform Distribution",
    "text": "[Recall] Discrete Uniform Distribution\n\n\nCode\nlibrary(tibble)\nbar_data &lt;- tribble(\n  ~x, ~prob,\n  1, 1/6,\n  2, 1/6,\n  3, 1/6,\n  4, 1/6,\n  5, 1/6,\n  6, 1/6\n)\nggplot(bar_data, aes(x=x, y=prob)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title=\"Discrete Uniform pmf: a = 1, b = 6\",\n    y=\"Probability Mass\",\n    x=\"Value\"\n  ) +\n  scale_x_continuous(breaks=seq(1,6)) +\n  dsan_theme(\"half\")",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#continuous-uniform-distribution",
    "href": "w06/index.html#continuous-uniform-distribution",
    "title": "Week 6: Moments and Covariance",
    "section": "Continuous Uniform Distribution",
    "text": "Continuous Uniform Distribution\n\nIf \\(X \\sim \\mathcal{U}[a,b]\\), then intuitively \\(X\\) is a value randomly selected from within \\([a,b]\\), with all values equally likely.\nDiscrete case: what we‚Äôve been using all along (e.g., dice): if \\(X \\sim \\mathcal{U}\\{1,6\\}\\), then\n\n\\[\n\\Pr(X = 1) = \\Pr(X = 2) = \\cdots = \\Pr(X = 6) = \\frac{1}{6}\n\\]\n\nFor continuous case‚Ä¶ what do we put in the denominator? \\(X \\sim \\mathcal{U}[1,6] \\implies \\Pr(X = \\pi) = \\frac{1}{?}\\)‚Ä¶\n\nAnswer: \\(\\Pr(X = \\pi) = \\frac{1}{|[1,6]|} = \\frac{1}{\\aleph_0} = 0\\)",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#constructing-the-uniform-cdf",
    "href": "w06/index.html#constructing-the-uniform-cdf",
    "title": "Week 6: Moments and Covariance",
    "section": "Constructing the Uniform CDF",
    "text": "Constructing the Uniform CDF\n\nWe were ready for this! We already knew \\(\\Pr(X = v) = 0\\) for continuous \\(X\\)\nSo, we forget about \\(\\Pr(X = v)\\), and focus on \\(\\Pr(X \\in [v_0, v_1])\\).\nIn 2D (dartboard) we had \\(\\Pr(X \\in \\circ) = \\frac{\\text{Area}(\\circ)}{\\text{Area}(\\Omega)}\\), so here we should have\n\n\\[\nP(X \\in [v_0,v_1]) = \\frac{\\text{Length}([v_0,v_1])}{\\text{Length}([1,6])}\n\\]\n\nAnd indeed, the CDF of \\(X\\) is \\(\\boxed{F_X(v) = \\Pr(X \\leq v) = \\frac{v-a}{b-a}}\\), so that\n\n\\[\n\\Pr(X \\in [v_0,v_1]) = F_X(v_1) - F_X(v_0) = \\frac{v_1-a}{b-a} - \\frac{v_0-a}{b-a} = \\frac{v_1 - v_0}{b-a}\n\\]\n\nSince \\(a = 1\\), \\(b = 6\\) in our example, \\(\\Pr(X \\in [v_0,v_1]) = \\frac{v_1-v_0}{6-1} = \\frac{\\text{Length}([v_0,v_1])}{\\text{Length}([1,6])} \\; ‚úÖ\\)",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#exponential-distribution",
    "href": "w06/index.html#exponential-distribution",
    "title": "Week 6: Moments and Covariance",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nRecall the (discrete) Geometric Distribution:\n\n\n\nCode\nlibrary(ggplot2)\nk &lt;- seq(0, 8)\nprob &lt;- dgeom(k, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x = k, y = prob)) +\n    geom_bar(stat = \"identity\", fill = cbPalette[1]) +\n    labs(\n        title = \"Geometric Distribution pmf: p = 0.5\",\n        y = \"Probability Mass\"\n    ) +\n    scale_x_continuous(breaks = seq(0, 8)) +\n    dsan_theme(\"half\")",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#now-in-continuous-form",
    "href": "w06/index.html#now-in-continuous-form",
    "title": "Week 6: Moments and Covariance",
    "section": "Now In Continuous Form!",
    "text": "Now In Continuous Form!\n\n\nCode\nmy_dexp &lt;- function(x) dexp(x, rate = 1/2)\nggplot(data.frame(x=c(0,8)), aes(x=x)) +\n  stat_function(fun=my_dexp, size=g_linesize, fill=cbPalette[1], alpha=0.8) +\n  stat_function(fun=my_dexp, geom='area', fill=cbPalette[1], alpha=0.75) +\n  dsan_theme(\"half\") +\n  labs(\n    title=\"Exponential Distribution pdf: Œª (rate) = 0.5\",\n    x = \"v\",\n    y = \"f_X(v)\"\n  )",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#the-dreaded-cauchy-distribution",
    "href": "w06/index.html#the-dreaded-cauchy-distribution",
    "title": "Week 6: Moments and Covariance",
    "section": "The Dreaded Cauchy Distribution",
    "text": "The Dreaded Cauchy Distribution\n\n\nCode\nggplot(data.frame(x=c(-4,4)), aes(x=x)) +\n  stat_function(fun=dcauchy, size=g_linesize, fill=cbPalette[1], alpha=0.75) +\n  stat_function(fun=dcauchy, geom='area', fill=cbPalette[1], alpha=0.75) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title=\"PDF of R\",\n    x = \"r\",\n    y = \"f(r)\"\n  )\n\n\n\n\n\n\n\n\n\n\nPaxton is a Houston Rockets fan, while Jeff is a Chicago Bulls fan. Paxton creates a RV \\(H\\) modeling how many games above .500 (wins minus losses) the Rockets will be in a season, while Jeff creates a similar RV \\(C\\) for the Bulls\nThey decide to combine their RVs to create a new RV, \\(R = \\frac{H}{C}\\), which now models how much better the Nuggets will be in a season (\\(R\\) for ‚ÄúRatio‚Äù)\nFor example, if the Rockets are \\(10\\) games above .500, while the Bulls are only \\(5\\) above .500, \\(R = \\frac{10}{5} = 2\\). If they‚Äôre both 3 games above .500, \\(R = \\frac{3}{3} = 1\\).",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#so-whats-the-issue",
    "href": "w06/index.html#so-whats-the-issue",
    "title": "Week 6: Moments and Covariance",
    "section": "So What‚Äôs the Issue?",
    "text": "So What‚Äôs the Issue?\n\nSo far so good. It turns out (though Paxton and Jeff don‚Äôt know this) the teams are both mediocre: \\(H \\sim \\mathcal{N}(0,10)\\), \\(B \\sim \\mathcal{N}(0,10)\\)‚Ä¶ What is the distribution of \\(R\\)?\n\n\n\n\\[\n\\begin{gather*}\nR \\sim \\text{Cauchy}\\left( 0, 1 \\right)\n\\end{gather*}\n\\]\n\\[\n\\begin{align*}\n\\expect{R} &= ‚ò†Ô∏è \\\\\n\\Var{R} &= ‚ò†Ô∏è \\\\\nM_R(t) &= ‚ò†Ô∏è\n\\end{align*}\n\\]\n\n\n\n\nFrom (agnesi_analytical_1801?) [Internet Archive]\n\n\n\n\n\nEven worse, this is true regardless of variances: \\(D \\sim \\mathcal{N}(0,d)\\) and \\(W \\sim \\mathcal{N}(0,w)\\) \\(\\implies R \\sim \\text{Cauchy}\\left( 0,\\frac{d}{w} \\right)\\)‚Ä¶",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#expectations-weighted-means",
    "href": "w06/index.html#expectations-weighted-means",
    "title": "Week 6: Moments and Covariance",
    "section": "Expectations = Weighted Means",
    "text": "Expectations = Weighted Means\n\nWe already know how to find the (unweighted) mean of a list of numbers:\n\n\\[\n\\begin{align*}\n\\begin{array}{|p{1cm}||p{1cm}|p{1cm}|p{1cm}|}\\hline X & \\orange{4} & \\orange{10} & \\orange{8} \\\\\\hline\\end{array} \\implies \\overline{X} &= \\frac{\\orange{4} + \\orange{10} + \\orange{8}}{\\purp{3}} = \\purp{\\left(\\frac{1}{3}\\right)} \\cdot \\orange{4} + \\purp{\\left( \\frac{1}{3} \\right)} \\cdot \\orange{10} + \\purp{\\left( \\frac{1}{3} \\right)} \\cdot \\orange{8} \\\\\n&= \\frac{22}{3} \\approx 7.33\n\\end{align*}\n\\]\n\nDiscrete distributions: just lists of numbers and their probability of occurring!\n\n\\[\n\\begin{align*}\n\\begin{array}{|p{1cm}|p{1cm}|p{1cm}|p{1cm}|}\\hline X & \\orange{4} & \\orange{10} & \\orange{8} \\\\\\hline \\Pr(X) & \\purp{0.01} & \\purp{0.01} & \\purp{0.98}\\\\\\hline\\end{array} \\implies \\overline{X} &= \\purp{\\left( \\frac{1}{100} \\right)} \\cdot \\orange{4} + \\purp{\\left( \\frac{1}{100} \\right)} \\cdot \\orange{10} + \\purp{\\left( \\frac{98}{100} \\right)} \\cdot \\orange{8} \\\\\n&= \\left.\\frac{798}{100}\\right.^{1} \\approx 7.98\n\\end{align*}\n\\]\n\n\n\nIt will be helpful for later/life as a data scientist to notice that this is exactly \\(\\frac{4 + 10 + \\overbrace{8 + \\cdots + 8}^{98\\text{ times}}}{100}\\). That is: weighted mean = normal mean where numbers are repeated proportionally to their probabilities. (See Laplace smoothing!).",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#different-types-of-averages",
    "href": "w06/index.html#different-types-of-averages",
    "title": "Week 6: Moments and Covariance",
    "section": "Different Types of ‚ÄúAverages‚Äù",
    "text": "Different Types of ‚ÄúAverages‚Äù\n\n(This will seem like overkill now, but will help us later!)\nTo avoid confusion, we denote the ‚Äúregular‚Äù (arithmetic) mean function as \\(M_1(\\cdot)\\)\n\nIf \\(V = \\{v_1, \\ldots, v_n\\}\\), \\(M_1(V) \\definedas \\frac{v_1+\\cdots+v_n}{n}\\).\n\nThen \\(\\overline{V}\\) will denote the number which results from applying \\(M_1\\) to the set \\(V\\).\nOther common functions which get called ‚Äúaverages‚Äù in Machine Learning: median, harmonic mean (\\(M_{-1}\\)), geometric mean (\\(M_0\\)), the hadamard product \\(\\odot\\), etc.‚Äîpop up surprisingly often in Data Science/Machine Learning!\nThe things we‚Äôre averaging also take on weird forms: bits, logical predicates, vectors, tensors (Hence Google‚Äôs Machine Learning platform, TensorFlow), ‚Ä¶\n\n\n\nFor what these subscripts (\\(M_{-1}\\), \\(M_0\\), \\(M_1\\)) mean, and more on the Hadamard product and its importance to Machine Learning, see Section¬†5.1",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#definition",
    "href": "w06/index.html#definition",
    "title": "Week 6: Moments and Covariance",
    "section": "Definition",
    "text": "Definition\n\nFor a discrete RV \\(X\\):\n\n\\[\n\\expect{X} = \\sum_{x \\in \\mathcal{R}_X}x P(x)\n\\]\n\nFor a continuous RV \\(X\\):\n\n\\[\n\\expect{X} = \\int_{-\\infty}^{\\infty}xf(x)dx\n\\]\n\n\nRemember that \\(\\mathcal{R}_X\\) is the support of the random variable \\(X\\). If \\(X\\) is discrete, this is just \\(\\mathcal{R}_X = \\{x \\in \\mathbb{R} \\given P(X = x) &gt; 0\\}\\). If \\(X\\) is continuous, we can almost always* use the similar definition \\(\\mathcal{R}_X = \\{x \\in \\mathbb{R} \\given f_X(x) &gt; 0\\}\\), remembering that \\(f_X(x) \\neq P(X = x)\\)!!! See Section¬†5.2 for the scarier definition that works for all continuous RVs.",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#important-properties",
    "href": "w06/index.html#important-properties",
    "title": "Week 6: Moments and Covariance",
    "section": "Important Properties",
    "text": "Important Properties\n\n\nFor RVs \\(X\\), \\(Y\\), and \\(a, b \\in \\mathbb{R}\\):\n\n\n\n\n\n\nLinear\n\n\\[\n\\expect{aX} = a\\expect{X}\n\\]\n\n\n\n\nAdditive\n\n\\[\n\\expect{X + Y} = \\expect{X} + \\expect{Y}\n\\]\n\n\n\n\nAffine1\n\n\\[\n\\expect{aX + b} = a\\expect{X} + b\n\\]\n\n\n\n\nLOTUS:\n\n\\[\n\\expect{g(X)} = g(x)f(x)dx\n\\]\n\nNot Multiplicative:\n\n\\[\n\\expect{X \\cdot Y} = \\expect{X} \\cdot \\expect{Y} \\iff X \\perp Y\n\\]\n\nReally these should be called affine functions, but this property is usually just known as ‚Äúlinearity‚Äù, so for the sake of being able to google it I‚Äôm calling it ‚ÄúLinear‚Äù here as well, for now",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#variance-motivation",
    "href": "w06/index.html#variance-motivation",
    "title": "Week 6: Moments and Covariance",
    "section": "Variance: Motivation",
    "text": "Variance: Motivation\n\nWe‚Äôve now got a ‚Äúmeasure of central tendency‚Äù, the expectation \\(\\expect{X}\\), with some nice properties. We can use it to produce point estimates.\nNow, how do we describe and communicate the spread of the data in a dataset? Similarly, how can we describe our uncertainty about a point estimate?\nLet‚Äôs try to develop a function, \\(\\text{Spread}\\), that takes in a set of values and computes how spread out they are\n(Hint: we can use arithmetic mean, applied to differences between points rather than points themselves)",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#first-attempt",
    "href": "w06/index.html#first-attempt",
    "title": "Week 6: Moments and Covariance",
    "section": "First Attempt",
    "text": "First Attempt\n\nWhat properties should \\(\\text{Spread}(\\cdot)\\) have?\n\nShould be \\(0\\) if every data point is identical, then increase as they spread apart\n\nHow about: average difference between each point and the overall (arithmetic) mean? \\[\n\\text{Spread}(X) = M_1(X - \\overline{X}) = \\frac{(x_1 - \\overline{X}) + (x_2 - \\overline{X}) + \\cdots + (x_n - \\overline{X})}{n}\n\\]\n\n\n\n\n\nCode\nlibrary(latex2exp)\nN &lt;- 10\nx &lt;- seq(1,N)\ny &lt;- rnorm(N, 0, 10)\nmean_y &lt;- mean(y)\nspread &lt;- y - mean_y\ndf &lt;- tibble(x=x, y=y, spread=spread)\nggplot(df, aes(x=x, y=y)) +\n  geom_hline(aes(yintercept=mean_y, linetype=\"dashed\"), color=\"purple\", size=g_linesize) +\n  geom_segment(aes(xend=x, yend=mean_y, color=ifelse(y&gt;0,\"Positive\",\"Negative\")), size=g_linesize) +\n  geom_point(size=g_pointsize) +\n  scale_linetype_manual(element_blank(), values=c(\"dashed\"=\"dashed\"), labels=c(\"dashed\"=unname(TeX(c(\"$M_1(X)$\"))))) +\n  dsan_theme(\"half\") +\n  scale_color_manual(\"Spread\", values=c(\"Positive\"=cbPalette[3],\"Negative\"=cbPalette[6]), labels=c(\"Positive\"=\"Positive\",\"Negative\"=\"Negative\")) +\n  scale_x_continuous(breaks=seq(0,10,2)) +\n  #remove_legend_title() +\n  theme(legend.spacing.y=unit(0.1,\"mm\")) +\n  labs(\n    title=paste0(N, \" Randomly-Generated Points, N(0,10)\"),\n    x=\"Index\",\n    y=\"Value\"\n  )\n\n\n\n\n\n\n\n\n\n\nThe result? To ten decimal places:\n\n\nCode\nspread_fmt &lt;- sprintf(\"%0.10f\", mean(df$spread))\nwriteLines(spread_fmt)\n\n\n-0.0000000000\n\n\nüòû What happened?",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#avoiding-cancellation",
    "href": "w06/index.html#avoiding-cancellation",
    "title": "Week 6: Moments and Covariance",
    "section": "Avoiding Cancellation",
    "text": "Avoiding Cancellation\n\nHow to avoid positive and negative deviations cancelling out? Two ideas:\n\nAbsolute value \\(\\left|X - \\overline{X}\\right|\\)\nSquared error \\(\\left( X - \\overline{X} \\right)^2\\)‚Ä¶\n\nGhost of calculus past: which is differentiable everywhere?2\n\n\n\n\n# Could use facet_grid() here, but it doesn't work too nicely with stat_function() :(\nggplot(data.frame(x=c(-4,4)), aes(x=x)) +\n  stat_function(fun=~ .x^2, linewidth = g_linewidth) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title=\"f(x) = x^2\",\n    y=\"f(x)\"\n  )\n\n\n\n\n\n\n\n\n\n\n# Could use facet_grid() here, but it doesn't work too nicely with stat_function() :(\nggplot(data.frame(x=c(-4,4)), aes(x=x)) +\n  stat_function(fun=~ abs(.x), linewidth=g_linewidth) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title=\"f(x) = |x|\",\n    y=\"f(x)\"\n  )",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#weve-arrived-at-variance",
    "href": "w06/index.html#weve-arrived-at-variance",
    "title": "Week 6: Moments and Covariance",
    "section": "We‚Äôve Arrived at Variance!",
    "text": "We‚Äôve Arrived at Variance!\n\\[\n\\Var{X} = \\bigexpect{ \\left(X - \\expect{X}\\right)^2 }\n\\]\n\nAnd, we can apply what we know about \\(\\expect{X}\\) to derive:\n\n\\[\n\\begin{align*}\n\\Var{X} &= \\bigexpect{ \\left(X - \\expect{X}\\right)^2 } = \\bigexpect{ X^2 - 2X\\expect{X} + \\left( \\expect{X} \\right)^2 } \\\\\n&= \\expect{X^2} - \\expect{2 X\\expect{X}} + \\left( \\expect{X} \\right)^2 \\\\\n&= \\expect{X^2} - 2\\expect{X}\\expect{X} + \\left(\\expect{X}\\right)^2 \\\\\n&= \\expect{X^2} - \\left( \\expect{X} \\right)^2 \\; \\; \\green{\\small{\\text{ (we'll need this in a minute)}}}\n\\end{align*}\n\\]\n\n\nWhy does \\(\\expect{2X\\expect{X}} = 2\\expect{X}\\expect{X}\\)? Remember: \\(X\\) is an RV, but \\(\\expect{X}\\) is a number!",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#standard-deviation",
    "href": "w06/index.html#standard-deviation",
    "title": "Week 6: Moments and Covariance",
    "section": "Standard Deviation",
    "text": "Standard Deviation\n\nWhen we squared the deviations, we lost the units of our datapoints!\nTo see spread, but in the same units as the original data, let‚Äôs just undo the squaring!\n\n\\[\n\\text{SD}[X] = \\sqrt{\\Var{X}}\n\\]\n\nBut, computers don‚Äôt care about the unit of this measure (just minimizing it). No reason to do this additional step if humans aren‚Äôt looking at the results!",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#properties-of-variance",
    "href": "w06/index.html#properties-of-variance",
    "title": "Week 6: Moments and Covariance",
    "section": "Properties of Variance",
    "text": "Properties of Variance\n\nRecall that Expectation was an affine function:\n\n\\[\n\\mathbb{E}[aX + b] = a\\mathbb{E}[X] + b\n\\]\n\nVariance has a similar property, but is called homogeneous of degree 2, which means\n\n\\[\n\\Var{aX + b} = a^2\\Var{X} \\; \\underbrace{\\phantom{+ b}}_{\\mathclap{\\text{(Something missing?)}}}\n\\]\n\n\nNote that since the expected value function is linear, it is also homogeneous, of degree 1, even though the \\(b\\) term doesn‚Äôt ‚Äúdisappear‚Äù like it does in the variance equation!",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#what-happened-to-the-b-term",
    "href": "w06/index.html#what-happened-to-the-b-term",
    "title": "Week 6: Moments and Covariance",
    "section": "What Happened to the \\(b\\) Term?",
    "text": "What Happened to the \\(b\\) Term?\nMathematically:\n\\[\n\\begin{align*}\n\\Var{aX + b} \\definedas \\; &\\mathbb{E}[(aX + b - \\mathbb{E}[aX + b])^2] \\\\\n\\definedalign \\; &\\expect{(aX \\color{orange}{+ b} - a\\expect{X} \\color{orange}{- b})^2} \\\\\n\\definedalign \\; &\\expect{a^2X^2 - 2a^2\\expectsq{X} + a^2\\expectsq{X}} \\\\\n\\definedalign \\; &a^2 \\expect{X^2 - \\expectsq{X}} = a^2(\\expect{X^2} - \\expectsq{X})b \\\\\n\\definedas \\; & a^2\\Var{X}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#what-happened-to-the-b-term-1",
    "href": "w06/index.html#what-happened-to-the-b-term-1",
    "title": "Week 6: Moments and Covariance",
    "section": "What Happened to the \\(b\\) Term?",
    "text": "What Happened to the \\(b\\) Term?\n\nVisually (Assuming \\(X \\sim \\mathcal{N}(0,1)\\))\n\n\npdf_alpha &lt;- 0.333\nconst_variance &lt;- 0.25\ndnorm_center &lt;- function(x) dnorm(x, 0, const_variance)\ndnorm_p1 &lt;- function(x) dnorm(x, 1, const_variance)\ndnorm_m3 &lt;- function(x) dnorm(x, -3, const_variance)\nggplot(data.frame(x = c(-4, 2)), aes(x = x)) +\n    # X - 3\n    stat_function(aes(color=cbPalette[1]), fun = dnorm_m3, size=g_linesize) +\n    geom_area(stat = \"function\", fun = dnorm_m3, fill = cbPalette[3], xlim = c(-4, 2), alpha=pdf_alpha) +\n    # X + 1\n    stat_function(aes(color=cbPalette[2]), fun = dnorm_p1, size=g_linesize) +\n    geom_area(stat = \"function\", fun = dnorm_p1, fill = cbPalette[2], xlim = c(-4, 2), alpha=pdf_alpha) +\n    # X\n    stat_function(aes(color=cbPalette[3]), fun = dnorm_center, size = g_linesize) +\n    geom_area(stat = \"function\", fun = dnorm_center, fill = cbPalette[1], xlim = c(-4, 2), alpha=pdf_alpha) +\n    # Scales\n    scale_color_manual(\"RV\", values=c(cbPalette[1], cbPalette[2], cbPalette[3]), labels=c(\"X\", \"X + 1\", \"X - 3\")) +\n    geom_segment(x=0, y=0, xend=0, yend=dnorm_center(0), size = g_linesize, color=cbPalette[1]) +\n    geom_segment(x=1, y=0, xend=1, yend=dnorm_p1(1), size = g_linesize, color=cbPalette[2]) +\n    geom_segment(x=-3, y=0, xend=-3, yend=dnorm_m3(-3), size = g_linesize, color=cbPalette[3]) +\n    dsan_theme(\"quarter\") +\n    theme(\n      title = element_text(size=20)\n    ) +\n    labs(\n        title = \"Normal Distributions with Shifted Means\",\n        y = \"f(x)\"\n    )\n\n\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\expect{{\\color{lightblue}X + 1}} = \\expect{{\\color{orange}X}} + 1, \\; \\; \\Var{{\\color{lightblue}X + 1}} = \\Var{{\\color{orange}X}} \\\\\n\\expect{{\\color{green}X - 3}} = \\expect{{\\color{orange}X}} - 3, \\; \\; \\Var{{\\color{green}X - 3}} = \\Var{{\\color{orange}X}}\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#generalizing-from-expectation-and-variance",
    "href": "w06/index.html#generalizing-from-expectation-and-variance",
    "title": "Week 6: Moments and Covariance",
    "section": "Generalizing from Expectation and Variance",
    "text": "Generalizing from Expectation and Variance\n\nIt turns out that, expectation and variance are just two ‚Äúlevels‚Äù of a hierarchy of information about a distribution!\nIn calculus: knowing \\(f(x)\\) is sufficient information for us to subsequently figure out \\(f'(x)\\), \\(f''(x)\\), ‚Ä¶\nIn probability/statistics: knowing \\(M_X(t)\\) is sufficient information for us to figure out \\(\\expect{X}\\), \\(\\Var{X}\\), ‚Ä¶",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#not-a-metaphor",
    "href": "w06/index.html#not-a-metaphor",
    "title": "Week 6: Moments and Covariance",
    "section": "Not a Metaphor!",
    "text": "Not a Metaphor!\n\nThis calculus \\(\\leftrightarrow\\) statistics connection is not a metaphor: differentiating \\(M_X(t)\\) literally gives us \\(\\expect{X}\\), \\(\\Var{X}\\), ‚Ä¶\nLet‚Äôs look at MGF for \\(X \\sim \\text{Bern}(\\param{p})\\), and try to derive \\(\\expect{X}\\)3.\n\n\\[\n\\begin{align*}\nM_X(t) &= (1 - p) + pe^t \\\\\nM'_X(t) &= pe^t,\\text{ and }\\expect{X} = M'_X(0) = \\green{p} \\; ‚úÖ\n\\end{align*}\n\\]\n\n\\(\\Var{X}\\)?\n\n\\[\n\\begin{align*}\nM''_{X}(t) &= pe^t,\\text{ and }\\expect{X^2} = M''_X(0) = p \\\\\n\\Var{X} &\\definedas{} \\expect{X^2} - (\\expect{X})^2 = p - p^2 = \\green{p(1-p)} \\; ‚úÖ\n\\end{align*}\n\\]",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#mgf-in-econometrics",
    "href": "w06/index.html#mgf-in-econometrics",
    "title": "Week 6: Moments and Covariance",
    "section": "MGF in Econometrics",
    "text": "MGF in Econometrics\n\n\n\n\n\n\n\nOpen in new window\n\n\n\nIn case it doesn‚Äôt load: (hansen_large_1982?) has 17,253 citations as of 2023-05-21",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#beware",
    "href": "w06/index.html#beware",
    "title": "Week 6: Moments and Covariance",
    "section": "BEWARE ‚ò†Ô∏è",
    "text": "BEWARE ‚ò†Ô∏è\nAs we saw last week (the Dreaded Cauchy Distribution):\n\nNot all random variables have moment-generating functions.\nWorse yet, not all random variables have well-defined variances\nWorse yet, not all random variables have well-defined means\n(This happens in non-contrived cases!)",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#multivariate-distributions-w02",
    "href": "w06/index.html#multivariate-distributions-w02",
    "title": "Week 6: Moments and Covariance",
    "section": "Multivariate Distributions (W02)",
    "text": "Multivariate Distributions (W02)\n\nThe bivariate normal distribution represents the distribution of two normally-distributed RVs \\(\\mathbf{X} = [\\begin{smallmatrix} X_1 & X_2\\end{smallmatrix}]\\), which may or may not be correlated:\n\n\n\\[\n\\mathbf{X} = \\begin{bmatrix}X_1 \\\\ X_2\\end{bmatrix}, \\; \\boldsymbol{\\mu} =\n%\\begin{bmatrix}\\mu_1 \\\\ \\mu_2\\end{bmatrix}\n\\begin{bmatrix}\\smash{\\overbrace{\\mu_1}^{\\mathbb{E}[X_1]}} \\\\ \\smash{\\underbrace{\\mu_2}_{\\mathbb{E}[X_2]}}\\end{bmatrix}\n, \\; \\mathbf{\\Sigma} = \\begin{bmatrix}\\smash{\\overbrace{\\sigma_1^2}^{\\text{Var}[X_1]}} & \\smash{\\overbrace{\\rho\\sigma_1\\sigma_2}^{\\text{Cov}[X_1,X_2]}} \\\\ \\smash{\\underbrace{\\rho\\sigma_2\\sigma_1}_{\\text{Cov}[X_2,X_1]}} & \\smash{\\underbrace{\\sigma_2^2}_{\\text{Var}[X_2]}}\\end{bmatrix}\n% \\begin{bmatrix}\\sigma_1^2 & \\rho\\sigma_1\\sigma_2 \\\\ \\rho\\sigma_2\\sigma_1 & \\sigma_2^2 \\end{bmatrix}\n% = \\begin{bmatrix}\\text{Var}[X_1] & \\text{Cov}[X_1,X_2] \\\\ \\text{Cov}[X_2,X_1] & \\text{Var}[X_2] \\end{bmatrix}\n\\]\n\n\nBy squishing all this information intro matrices, we can specify the parameters of multivariate-normally-distributed vectors of RVs similarly to how we specify single-dimensional normally-distributed RVs:\n\n\n\\[\n\\begin{align*}\n\\overbrace{X}^{\\mathclap{\\text{scalar}}} &\\sim \\mathcal{N}\\phantom{_k}(\\overbrace{\\mu}^{\\text{scalar}}, \\overbrace{\\sigma}^{\\text{scalar}}) \\tag{Univariate} \\\\\n\\underbrace{\\mathbf{X}}_{\\text{vector}} &\\sim \\boldsymbol{\\mathcal{N}}_k(\\smash{\\underbrace{\\boldsymbol{\\mu}}_{\\text{vector}}}, \\underbrace{\\mathbf{\\Sigma}}_{\\text{matrix}}) \\tag{Multivariate}\n\\end{align*}\n\\]\n\n\nNote: In the future I‚Äôll use the notation \\(\\mathbf{X}_{[a \\times b]}\\) to denote the dimensions of the vectors/matrices, like \\(\\mathbf{X}_{[k \\times 1]} \\sim \\boldsymbol{\\mathcal{N}}_k(\\boldsymbol{\\mu}_{[k \\times 1]}, \\mathbf{\\Sigma}_{[k \\times k]})\\)",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#visualizing-3d-distributions-projection",
    "href": "w06/index.html#visualizing-3d-distributions-projection",
    "title": "Week 6: Moments and Covariance",
    "section": "Visualizing 3D Distributions: Projection",
    "text": "Visualizing 3D Distributions: Projection\n\nSince most of our intuitions about plots come from 2D plots, it is extremely useful to be able to take a 3D plot like this and imagine ‚Äúprojecting‚Äù it down into different 2D plots:\n\n\n\n\nAdapted (and corrected!) from LaTeX code in this StackExchange thread",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#visualizing-3d-distributions-contours",
    "href": "w06/index.html#visualizing-3d-distributions-contours",
    "title": "Week 6: Moments and Covariance",
    "section": "Visualizing 3D Distributions: Contours",
    "text": "Visualizing 3D Distributions: Contours\n\n\n\nFrom Prof.¬†Hickman‚Äôs slides!",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#visualizing-3d-distributions-contours-1",
    "href": "w06/index.html#visualizing-3d-distributions-contours-1",
    "title": "Week 6: Moments and Covariance",
    "section": "Visualizing 3D Distributions: Contours",
    "text": "Visualizing 3D Distributions: Contours\n\n\n\nAlso from Prof.¬†Hickman‚Äôs slides!",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#bivariate-distributions",
    "href": "w06/index.html#bivariate-distributions",
    "title": "Week 6: Moments and Covariance",
    "section": "Bivariate Distributions",
    "text": "Bivariate Distributions\n(degroot_probability_2013?) | DSPS Sec. 3.4 \n\nWe generalize the concept of the distribution of a random variable to the joint distribution of two random variables.\nIn doing so, we introduce the joint pmf for two discrete random variables, the joint pdf for two continuous variables, and the joint CDF for any two random variables.",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#sec-hadamard",
    "href": "w06/index.html#sec-hadamard",
    "title": "Week 6: Moments and Covariance",
    "section": "Appendix A: The Hadamard Product",
    "text": "Appendix A: The Hadamard Product\n\n\n\nUsed in nearly all neural NLP algorithms, as the basis of LSTM (see LSTM equations on the right)\nThe subscripts for the harmonic mean \\(M_{-1}\\), geometric mean \\(M_0\\), and arithmetic mean \\(M_1\\) come from the definition of the generalized mean:\n\n\\[\nM_p(V) = \\left( \\frac{1}{n} \\sum_{i=1}^n v_i^p \\right)^{1/p}\n\\]\n\n\\[\n\\begin{align*}\nf_t &= \\sigma(W_f [h_{t - 1}, x_t] + b_f) \\\\\ni_t &= \\sigma(W_i [h_{t - 1}, x_t] + b_i) \\\\\n\\tilde{C}_t &= \\tanh(W_C [h_{t - 1}, x_t] + b_C) \\\\\nC_t &= f_t \\odot C_{t - 1} + i_t \\odot \\tilde{C}_t \\\\\no_t &= \\sigma(W_o [h_{t - 1}, x_t] + b_o) \\\\\nh_t &= o_t \\odot \\tanh(C_t) \\\\\n\\hat{y} &= \\text{softmax}(W_y h_t + b_y)\n\\end{align*}\n\\]\n\n\n\nIf you‚Äôre a dork like me, you can read about generalized means, Fr√©chet means, or Stata‚Äôs trimmean function, all of which bring together seemingly-unrelated functions used throughout Machine Learning!",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#sec-continuous-support",
    "href": "w06/index.html#sec-continuous-support",
    "title": "Week 6: Moments and Covariance",
    "section": "Appendix B: Continuous RV Support",
    "text": "Appendix B: Continuous RV Support\nIn most cases, for continuous RVs, the definition\n\\[\n\\mathcal{R}_X = \\{x \\in \\mathsf{Domain}(f_X) \\given f_X(x) &gt; 0\\}\n\\]\nworks fine. But, to fully capture all possible continuous RVs, the following formal definition is necessary:\n\\[\n\\mathcal{R}_X = \\left\\{x \\in \\mathbb{R} \\given \\forall r &gt; 0 \\left[ f_X(B(x,r)) &gt; 0 \\right] \\right\\},\n\\]\nwhere \\(B(x,r)\\) is a ‚Äúband‚Äù4 around \\(x\\) with radius \\(r\\).\n\n\n\n\nFor a full explanation, see this StackExchange discussion.",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#footnotes",
    "href": "w06/index.html#footnotes",
    "title": "Week 6: Moments and Covariance",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMathematically, it‚Äôs important to call \\(aX + b\\) an ‚Äúaffine transformation‚Äù, not a linear transformation. In practice, everyone calls this ‚Äúlinear‚Äù, so I try to use both (for easy Googling!). The reason it matters will come up when we discuss Variance!‚Ü©Ô∏é\nFor why differentiability matters a lot for modern Machine Learning, see the Backpropagation algorithm.‚Ü©Ô∏é\nRecall that, for a Bernoulli-distributed random variable \\(X\\), \\(\\expect{X} = p\\)‚Ü©Ô∏é\nIn one dimension, this would be an interval; in two dimensions, a circle; in three dimensions, a sphere; etc.‚Ü©Ô∏é",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/slides.html#the-emergence-of-order",
    "href": "w06/slides.html#the-emergence-of-order",
    "title": "Week 6: Moments and Covariance",
    "section": "The Emergence of Order",
    "text": "The Emergence of Order\n\n\n\nWho can guess the state of this process after 10 steps, with 1 person?\n10 people? 50? 100? (If they find themselves on the same spot, they stand on each other‚Äôs heads)\n100 steps? 1000?"
  },
  {
    "objectID": "w06/slides.html#the-result-16-steps",
    "href": "w06/slides.html#the-result-16-steps",
    "title": "Week 6: Moments and Covariance",
    "section": "The Result: 16 Steps",
    "text": "The Result: 16 Steps"
  },
  {
    "objectID": "w06/slides.html#the-result-64-steps",
    "href": "w06/slides.html#the-result-64-steps",
    "title": "Week 6: Moments and Covariance",
    "section": "The Result: 64 Steps",
    "text": "The Result: 64 Steps"
  },
  {
    "objectID": "w06/slides.html#whats-going-on-here",
    "href": "w06/slides.html#whats-going-on-here",
    "title": "Week 6: Moments and Covariance",
    "section": "What‚Äôs Going On Here?",
    "text": "What‚Äôs Going On Here?\n\n(Stay tuned for Markov processes \\(\\overset{t \\rightarrow \\infty}{\\leadsto}\\) Stationary distributions!)"
  },
  {
    "objectID": "w06/slides.html#properties-of-the-normal-distribution",
    "href": "w06/slides.html#properties-of-the-normal-distribution",
    "title": "Week 6: Moments and Covariance",
    "section": "Properties of the Normal Distribution",
    "text": "Properties of the Normal Distribution\n\nIf \\(X \\sim \\mathcal{N}(\\param{\\mu}, \\param{\\theta})\\), then \\(X\\) has pdf \\(f_X(v)\\) defined by\n\n\\[\nf_X(v) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\bigexp{-\\frac{1}{2}\\left(\\frac{v - \\mu}{\\sigma}\\right)^2}\n\\]\n\nI hate memorizing as much as you do, I promise ü•¥\nThe important part (imo): this is the most conservative out of all possible (symmetric) prior distributions defined on \\(\\mathbb{R}\\) (defined from \\(-\\infty\\) to \\(\\infty\\))"
  },
  {
    "objectID": "w06/slides.html#most-conservative-how",
    "href": "w06/slides.html#most-conservative-how",
    "title": "Week 6: Moments and Covariance",
    "section": "‚ÄúMost Conservative‚Äù How?",
    "text": "‚ÄúMost Conservative‚Äù How?\n\nOf all possible distributions with mean \\(\\mu\\), variance \\(\\sigma^2\\), \\(\\mathcal{N}(\\mu, \\sigma^2)\\) is the entropy-maximizing distribution\nRoughly: using any other distribution (implicitly/secretly) imports additional information beyond the fact that mean is \\(\\mu\\) and variance is \\(\\sigma^2\\)\nExample: let \\(X\\) be an RV. If we know mean is \\(\\mu\\), variance is \\(\\sigma^2\\), but then we learn that \\(X \\neq 3\\), or \\(X\\) is even, or the 15th digit of \\(X\\) is 7, can update \\(\\mathcal{N}(\\mu,\\sigma^2)\\) to derive a ‚Äúbetter‚Äù distribution (incorporating this additional info)"
  },
  {
    "objectID": "w06/slides.html#the-takeaway",
    "href": "w06/slides.html#the-takeaway",
    "title": "Week 6: Moments and Covariance",
    "section": "The Takeaway",
    "text": "The Takeaway\n\nGiven info we know, we can find a distribution that ‚Äúencodes‚Äù only this info\nMore straightforward example: if we only know that the value is something in the range \\([a,b]\\), entropy-maximizing distribution is the Uniform Distribution\n\n\n\n\n\n\n\n\n\nIf We Know\nAnd We Know\n(Max-Entropy) Distribution Is‚Ä¶\n\n\n\n\n\\(\\text{Mean}[X] = \\mu\\)\n\\(\\text{Var}[X] = \\sigma^2\\)\n\\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\n\n\n\\(\\text{Mean}[X] = \\lambda\\)\n\\(X \\geq 0\\)\n\\(X \\sim \\text{Exp}\\left(\\frac{1}{\\lambda}\\right)\\)\n\n\n\\(X \\geq a\\)\n\\(X \\leq b\\)\n\\(X \\sim \\mathcal{U}[a,b]\\)"
  },
  {
    "objectID": "w06/slides.html#recall-discrete-uniform-distribution",
    "href": "w06/slides.html#recall-discrete-uniform-distribution",
    "title": "Week 6: Moments and Covariance",
    "section": "[Recall] Discrete Uniform Distribution",
    "text": "[Recall] Discrete Uniform Distribution\n\n\nCode\nlibrary(tibble)\nbar_data &lt;- tribble(\n  ~x, ~prob,\n  1, 1/6,\n  2, 1/6,\n  3, 1/6,\n  4, 1/6,\n  5, 1/6,\n  6, 1/6\n)\nggplot(bar_data, aes(x=x, y=prob)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title=\"Discrete Uniform pmf: a = 1, b = 6\",\n    y=\"Probability Mass\",\n    x=\"Value\"\n  ) +\n  scale_x_continuous(breaks=seq(1,6)) +\n  dsan_theme(\"half\")"
  },
  {
    "objectID": "w06/slides.html#continuous-uniform-distribution",
    "href": "w06/slides.html#continuous-uniform-distribution",
    "title": "Week 6: Moments and Covariance",
    "section": "Continuous Uniform Distribution",
    "text": "Continuous Uniform Distribution\n\nIf \\(X \\sim \\mathcal{U}[a,b]\\), then intuitively \\(X\\) is a value randomly selected from within \\([a,b]\\), with all values equally likely.\nDiscrete case: what we‚Äôve been using all along (e.g., dice): if \\(X \\sim \\mathcal{U}\\{1,6\\}\\), then\n\n\\[\n\\Pr(X = 1) = \\Pr(X = 2) = \\cdots = \\Pr(X = 6) = \\frac{1}{6}\n\\]\n\nFor continuous case‚Ä¶ what do we put in the denominator? \\(X \\sim \\mathcal{U}[1,6] \\implies \\Pr(X = \\pi) = \\frac{1}{?}\\)‚Ä¶\n\nAnswer: \\(\\Pr(X = \\pi) = \\frac{1}{|[1,6]|} = \\frac{1}{\\aleph_0} = 0\\)"
  },
  {
    "objectID": "w06/slides.html#constructing-the-uniform-cdf",
    "href": "w06/slides.html#constructing-the-uniform-cdf",
    "title": "Week 6: Moments and Covariance",
    "section": "Constructing the Uniform CDF",
    "text": "Constructing the Uniform CDF\n\nWe were ready for this! We already knew \\(\\Pr(X = v) = 0\\) for continuous \\(X\\)\nSo, we forget about \\(\\Pr(X = v)\\), and focus on \\(\\Pr(X \\in [v_0, v_1])\\).\nIn 2D (dartboard) we had \\(\\Pr(X \\in \\circ) = \\frac{\\text{Area}(\\circ)}{\\text{Area}(\\Omega)}\\), so here we should have\n\n\\[\nP(X \\in [v_0,v_1]) = \\frac{\\text{Length}([v_0,v_1])}{\\text{Length}([1,6])}\n\\]\n\nAnd indeed, the CDF of \\(X\\) is \\(\\boxed{F_X(v) = \\Pr(X \\leq v) = \\frac{v-a}{b-a}}\\), so that\n\n\\[\n\\Pr(X \\in [v_0,v_1]) = F_X(v_1) - F_X(v_0) = \\frac{v_1-a}{b-a} - \\frac{v_0-a}{b-a} = \\frac{v_1 - v_0}{b-a}\n\\]\n\nSince \\(a = 1\\), \\(b = 6\\) in our example, \\(\\Pr(X \\in [v_0,v_1]) = \\frac{v_1-v_0}{6-1} = \\frac{\\text{Length}([v_0,v_1])}{\\text{Length}([1,6])} \\; ‚úÖ\\)"
  },
  {
    "objectID": "w06/slides.html#exponential-distribution",
    "href": "w06/slides.html#exponential-distribution",
    "title": "Week 6: Moments and Covariance",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nRecall the (discrete) Geometric Distribution:\n\n\n\nCode\nlibrary(ggplot2)\nk &lt;- seq(0, 8)\nprob &lt;- dgeom(k, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x = k, y = prob)) +\n    geom_bar(stat = \"identity\", fill = cbPalette[1]) +\n    labs(\n        title = \"Geometric Distribution pmf: p = 0.5\",\n        y = \"Probability Mass\"\n    ) +\n    scale_x_continuous(breaks = seq(0, 8)) +\n    dsan_theme(\"half\")"
  },
  {
    "objectID": "w06/slides.html#now-in-continuous-form",
    "href": "w06/slides.html#now-in-continuous-form",
    "title": "Week 6: Moments and Covariance",
    "section": "Now In Continuous Form!",
    "text": "Now In Continuous Form!\n\n\nCode\nmy_dexp &lt;- function(x) dexp(x, rate = 1/2)\nggplot(data.frame(x=c(0,8)), aes(x=x)) +\n  stat_function(fun=my_dexp, size=g_linesize, fill=cbPalette[1], alpha=0.8) +\n  stat_function(fun=my_dexp, geom='area', fill=cbPalette[1], alpha=0.75) +\n  dsan_theme(\"half\") +\n  labs(\n    title=\"Exponential Distribution pdf: Œª (rate) = 0.5\",\n    x = \"v\",\n    y = \"f_X(v)\"\n  )"
  },
  {
    "objectID": "w06/slides.html#the-dreaded-cauchy-distribution",
    "href": "w06/slides.html#the-dreaded-cauchy-distribution",
    "title": "Week 6: Moments and Covariance",
    "section": "The Dreaded Cauchy Distribution",
    "text": "The Dreaded Cauchy Distribution\n\n\nCode\nggplot(data.frame(x=c(-4,4)), aes(x=x)) +\n  stat_function(fun=dcauchy, size=g_linesize, fill=cbPalette[1], alpha=0.75) +\n  stat_function(fun=dcauchy, geom='area', fill=cbPalette[1], alpha=0.75) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title=\"PDF of R\",\n    x = \"r\",\n    y = \"f(r)\"\n  )\n\n\n\n\nPaxton is a Houston Rockets fan, while Jeff is a Chicago Bulls fan. Paxton creates a RV \\(H\\) modeling how many games above .500 (wins minus losses) the Rockets will be in a season, while Jeff creates a similar RV \\(C\\) for the Bulls\nThey decide to combine their RVs to create a new RV, \\(R = \\frac{H}{C}\\), which now models how much better the Nuggets will be in a season (\\(R\\) for ‚ÄúRatio‚Äù)\nFor example, if the Rockets are \\(10\\) games above .500, while the Bulls are only \\(5\\) above .500, \\(R = \\frac{10}{5} = 2\\). If they‚Äôre both 3 games above .500, \\(R = \\frac{3}{3} = 1\\)."
  },
  {
    "objectID": "w06/slides.html#so-whats-the-issue",
    "href": "w06/slides.html#so-whats-the-issue",
    "title": "Week 6: Moments and Covariance",
    "section": "So What‚Äôs the Issue?",
    "text": "So What‚Äôs the Issue?\n\nSo far so good. It turns out (though Paxton and Jeff don‚Äôt know this) the teams are both mediocre: \\(H \\sim \\mathcal{N}(0,10)\\), \\(B \\sim \\mathcal{N}(0,10)\\)‚Ä¶ What is the distribution of \\(R\\)?\n\n\n\n\\[\n\\begin{gather*}\nR \\sim \\text{Cauchy}\\left( 0, 1 \\right)\n\\end{gather*}\n\\]\n\\[\n\\begin{align*}\n\\expect{R} &= ‚ò†Ô∏è \\\\\n\\Var{R} &= ‚ò†Ô∏è \\\\\nM_R(t) &= ‚ò†Ô∏è\n\\end{align*}\n\\]\n\n\n\n\nFrom (agnesi_analytical_1801?) [Internet Archive]\n\n\n\n\nEven worse, this is true regardless of variances: \\(D \\sim \\mathcal{N}(0,d)\\) and \\(W \\sim \\mathcal{N}(0,w)\\) \\(\\implies R \\sim \\text{Cauchy}\\left( 0,\\frac{d}{w} \\right)\\)‚Ä¶"
  },
  {
    "objectID": "w06/slides.html#expectations-weighted-means",
    "href": "w06/slides.html#expectations-weighted-means",
    "title": "Week 6: Moments and Covariance",
    "section": "Expectations = Weighted Means",
    "text": "Expectations = Weighted Means\n\nWe already know how to find the (unweighted) mean of a list of numbers:\n\n\\[\n\\begin{align*}\n\\begin{array}{|p{1cm}||p{1cm}|p{1cm}|p{1cm}|}\\hline X & \\orange{4} & \\orange{10} & \\orange{8} \\\\\\hline\\end{array} \\implies \\overline{X} &= \\frac{\\orange{4} + \\orange{10} + \\orange{8}}{\\purp{3}} = \\purp{\\left(\\frac{1}{3}\\right)} \\cdot \\orange{4} + \\purp{\\left( \\frac{1}{3} \\right)} \\cdot \\orange{10} + \\purp{\\left( \\frac{1}{3} \\right)} \\cdot \\orange{8} \\\\\n&= \\frac{22}{3} \\approx 7.33\n\\end{align*}\n\\]\n\nDiscrete distributions: just lists of numbers and their probability of occurring!\n\n\\[\n\\begin{align*}\n\\begin{array}{|p{1cm}|p{1cm}|p{1cm}|p{1cm}|}\\hline X & \\orange{4} & \\orange{10} & \\orange{8} \\\\\\hline \\Pr(X) & \\purp{0.01} & \\purp{0.01} & \\purp{0.98}\\\\\\hline\\end{array} \\implies \\overline{X} &= \\purp{\\left( \\frac{1}{100} \\right)} \\cdot \\orange{4} + \\purp{\\left( \\frac{1}{100} \\right)} \\cdot \\orange{10} + \\purp{\\left( \\frac{98}{100} \\right)} \\cdot \\orange{8} \\\\\n&= \\left.\\frac{798}{100}\\right.^{1} \\approx 7.98\n\\end{align*}\n\\]\n\n\n\nIt will be helpful for later/life as a data scientist to notice that this is exactly \\(\\frac{4 + 10 + \\overbrace{8 + \\cdots + 8}^{98\\text{ times}}}{100}\\). That is: weighted mean = normal mean where numbers are repeated proportionally to their probabilities. (See Laplace smoothing!)."
  },
  {
    "objectID": "w06/slides.html#different-types-of-averages",
    "href": "w06/slides.html#different-types-of-averages",
    "title": "Week 6: Moments and Covariance",
    "section": "Different Types of ‚ÄúAverages‚Äù",
    "text": "Different Types of ‚ÄúAverages‚Äù\n\n(This will seem like overkill now, but will help us later!)\nTo avoid confusion, we denote the ‚Äúregular‚Äù (arithmetic) mean function as \\(M_1(\\cdot)\\)\n\nIf \\(V = \\{v_1, \\ldots, v_n\\}\\), \\(M_1(V) \\definedas \\frac{v_1+\\cdots+v_n}{n}\\).\n\nThen \\(\\overline{V}\\) will denote the number which results from applying \\(M_1\\) to the set \\(V\\).\nOther common functions which get called ‚Äúaverages‚Äù in Machine Learning: median, harmonic mean (\\(M_{-1}\\)), geometric mean (\\(M_0\\)), the hadamard product \\(\\odot\\), etc.‚Äîpop up surprisingly often in Data Science/Machine Learning!\nThe things we‚Äôre averaging also take on weird forms: bits, logical predicates, vectors, tensors (Hence Google‚Äôs Machine Learning platform, TensorFlow), ‚Ä¶\n\n\n\nFor what these subscripts (\\(M_{-1}\\), \\(M_0\\), \\(M_1\\)) mean, and more on the Hadamard product and its importance to Machine Learning, see Section¬†5.1"
  },
  {
    "objectID": "w06/slides.html#definition",
    "href": "w06/slides.html#definition",
    "title": "Week 6: Moments and Covariance",
    "section": "Definition",
    "text": "Definition\n\nFor a discrete RV \\(X\\):\n\n\\[\n\\expect{X} = \\sum_{x \\in \\mathcal{R}_X}x P(x)\n\\]\n\nFor a continuous RV \\(X\\):\n\n\\[\n\\expect{X} = \\int_{-\\infty}^{\\infty}xf(x)dx\n\\]\n\n\nRemember that \\(\\mathcal{R}_X\\) is the support of the random variable \\(X\\). If \\(X\\) is discrete, this is just \\(\\mathcal{R}_X = \\{x \\in \\mathbb{R} \\given P(X = x) &gt; 0\\}\\). If \\(X\\) is continuous, we can almost always* use the similar definition \\(\\mathcal{R}_X = \\{x \\in \\mathbb{R} \\given f_X(x) &gt; 0\\}\\), remembering that \\(f_X(x) \\neq P(X = x)\\)!!! See Section¬†5.2 for the scarier definition that works for all continuous RVs."
  },
  {
    "objectID": "w06/slides.html#important-properties",
    "href": "w06/slides.html#important-properties",
    "title": "Week 6: Moments and Covariance",
    "section": "Important Properties",
    "text": "Important Properties\n\n\nFor RVs \\(X\\), \\(Y\\), and \\(a, b \\in \\mathbb{R}\\):\n\n\n\n\n\n\nLinear\n\n\\[\n\\expect{aX} = a\\expect{X}\n\\]\n\n\n\n\nAdditive\n\n\\[\n\\expect{X + Y} = \\expect{X} + \\expect{Y}\n\\]\n\n\n\n\nAffine1\n\n\\[\n\\expect{aX + b} = a\\expect{X} + b\n\\]\n\n\n\nLOTUS:\n\n\\[\n\\expect{g(X)} = g(x)f(x)dx\n\\]\n\nNot Multiplicative:\n\n\\[\n\\expect{X \\cdot Y} = \\expect{X} \\cdot \\expect{Y} \\iff X \\perp Y\n\\]\n\nReally these should be called affine functions, but this property is usually just known as ‚Äúlinearity‚Äù, so for the sake of being able to google it I‚Äôm calling it ‚ÄúLinear‚Äù here as well, for now\n\nMathematically, it‚Äôs important to call \\(aX + b\\) an ‚Äúaffine transformation‚Äù, not a linear transformation. In practice, everyone calls this ‚Äúlinear‚Äù, so I try to use both (for easy Googling!). The reason it matters will come up when we discuss Variance!"
  },
  {
    "objectID": "w06/slides.html#variance-motivation",
    "href": "w06/slides.html#variance-motivation",
    "title": "Week 6: Moments and Covariance",
    "section": "Variance: Motivation",
    "text": "Variance: Motivation\n\nWe‚Äôve now got a ‚Äúmeasure of central tendency‚Äù, the expectation \\(\\expect{X}\\), with some nice properties. We can use it to produce point estimates.\nNow, how do we describe and communicate the spread of the data in a dataset? Similarly, how can we describe our uncertainty about a point estimate?\nLet‚Äôs try to develop a function, \\(\\text{Spread}\\), that takes in a set of values and computes how spread out they are\n(Hint: we can use arithmetic mean, applied to differences between points rather than points themselves)"
  },
  {
    "objectID": "w06/slides.html#first-attempt",
    "href": "w06/slides.html#first-attempt",
    "title": "Week 6: Moments and Covariance",
    "section": "First Attempt",
    "text": "First Attempt\n\nWhat properties should \\(\\text{Spread}(\\cdot)\\) have?\n\nShould be \\(0\\) if every data point is identical, then increase as they spread apart\n\nHow about: average difference between each point and the overall (arithmetic) mean? \\[\n\\text{Spread}(X) = M_1(X - \\overline{X}) = \\frac{(x_1 - \\overline{X}) + (x_2 - \\overline{X}) + \\cdots + (x_n - \\overline{X})}{n}\n\\]\n\n\n\n\n\nCode\nlibrary(latex2exp)\nN &lt;- 10\nx &lt;- seq(1,N)\ny &lt;- rnorm(N, 0, 10)\nmean_y &lt;- mean(y)\nspread &lt;- y - mean_y\ndf &lt;- tibble(x=x, y=y, spread=spread)\nggplot(df, aes(x=x, y=y)) +\n  geom_hline(aes(yintercept=mean_y, linetype=\"dashed\"), color=\"purple\", size=g_linesize) +\n  geom_segment(aes(xend=x, yend=mean_y, color=ifelse(y&gt;0,\"Positive\",\"Negative\")), size=g_linesize) +\n  geom_point(size=g_pointsize) +\n  scale_linetype_manual(element_blank(), values=c(\"dashed\"=\"dashed\"), labels=c(\"dashed\"=unname(TeX(c(\"$M_1(X)$\"))))) +\n  dsan_theme(\"half\") +\n  scale_color_manual(\"Spread\", values=c(\"Positive\"=cbPalette[3],\"Negative\"=cbPalette[6]), labels=c(\"Positive\"=\"Positive\",\"Negative\"=\"Negative\")) +\n  scale_x_continuous(breaks=seq(0,10,2)) +\n  #remove_legend_title() +\n  theme(legend.spacing.y=unit(0.1,\"mm\")) +\n  labs(\n    title=paste0(N, \" Randomly-Generated Points, N(0,10)\"),\n    x=\"Index\",\n    y=\"Value\"\n  )\n\n\n\n\n\n\n\n\n\n\nThe result? To ten decimal places:\n\n\nCode\nspread_fmt &lt;- sprintf(\"%0.10f\", mean(df$spread))\nwriteLines(spread_fmt)\n\n\n0.0000000000\n\n\nüòû What happened?"
  },
  {
    "objectID": "w06/slides.html#avoiding-cancellation",
    "href": "w06/slides.html#avoiding-cancellation",
    "title": "Week 6: Moments and Covariance",
    "section": "Avoiding Cancellation",
    "text": "Avoiding Cancellation\n\nHow to avoid positive and negative deviations cancelling out? Two ideas:\n\nAbsolute value \\(\\left|X - \\overline{X}\\right|\\)\nSquared error \\(\\left( X - \\overline{X} \\right)^2\\)‚Ä¶\n\nGhost of calculus past: which is differentiable everywhere?1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor why differentiability matters a lot for modern Machine Learning, see the Backpropagation algorithm."
  },
  {
    "objectID": "w06/slides.html#weve-arrived-at-variance",
    "href": "w06/slides.html#weve-arrived-at-variance",
    "title": "Week 6: Moments and Covariance",
    "section": "We‚Äôve Arrived at Variance!",
    "text": "We‚Äôve Arrived at Variance!\n\\[\n\\Var{X} = \\bigexpect{ \\left(X - \\expect{X}\\right)^2 }\n\\]\n\nAnd, we can apply what we know about \\(\\expect{X}\\) to derive:\n\n\\[\n\\begin{align*}\n\\Var{X} &= \\bigexpect{ \\left(X - \\expect{X}\\right)^2 } = \\bigexpect{ X^2 - 2X\\expect{X} + \\left( \\expect{X} \\right)^2 } \\\\\n&= \\expect{X^2} - \\expect{2 X\\expect{X}} + \\left( \\expect{X} \\right)^2 \\\\\n&= \\expect{X^2} - 2\\expect{X}\\expect{X} + \\left(\\expect{X}\\right)^2 \\\\\n&= \\expect{X^2} - \\left( \\expect{X} \\right)^2 \\; \\; \\green{\\small{\\text{ (we'll need this in a minute)}}}\n\\end{align*}\n\\]\n\n\nWhy does \\(\\expect{2X\\expect{X}} = 2\\expect{X}\\expect{X}\\)? Remember: \\(X\\) is an RV, but \\(\\expect{X}\\) is a number!"
  },
  {
    "objectID": "w06/slides.html#standard-deviation",
    "href": "w06/slides.html#standard-deviation",
    "title": "Week 6: Moments and Covariance",
    "section": "Standard Deviation",
    "text": "Standard Deviation\n\nWhen we squared the deviations, we lost the units of our datapoints!\nTo see spread, but in the same units as the original data, let‚Äôs just undo the squaring!\n\n\\[\n\\text{SD}[X] = \\sqrt{\\Var{X}}\n\\]\n\nBut, computers don‚Äôt care about the unit of this measure (just minimizing it). No reason to do this additional step if humans aren‚Äôt looking at the results!"
  },
  {
    "objectID": "w06/slides.html#properties-of-variance",
    "href": "w06/slides.html#properties-of-variance",
    "title": "Week 6: Moments and Covariance",
    "section": "Properties of Variance",
    "text": "Properties of Variance\n\nRecall that Expectation was an affine function:\n\n\\[\n\\mathbb{E}[aX + b] = a\\mathbb{E}[X] + b\n\\]\n\nVariance has a similar property, but is called homogeneous of degree 2, which means\n\n\\[\n\\Var{aX + b} = a^2\\Var{X} \\; \\underbrace{\\phantom{+ b}}_{\\mathclap{\\text{(Something missing?)}}}\n\\]\n\n\nNote that since the expected value function is linear, it is also homogeneous, of degree 1, even though the \\(b\\) term doesn‚Äôt ‚Äúdisappear‚Äù like it does in the variance equation!"
  },
  {
    "objectID": "w06/slides.html#what-happened-to-the-b-term",
    "href": "w06/slides.html#what-happened-to-the-b-term",
    "title": "Week 6: Moments and Covariance",
    "section": "What Happened to the \\(b\\) Term?",
    "text": "What Happened to the \\(b\\) Term?\nMathematically:\n\\[\n\\begin{align*}\n\\Var{aX + b} \\definedas \\; &\\mathbb{E}[(aX + b - \\mathbb{E}[aX + b])^2] \\\\\n\\definedalign \\; &\\expect{(aX \\color{orange}{+ b} - a\\expect{X} \\color{orange}{- b})^2} \\\\\n\\definedalign \\; &\\expect{a^2X^2 - 2a^2\\expectsq{X} + a^2\\expectsq{X}} \\\\\n\\definedalign \\; &a^2 \\expect{X^2 - \\expectsq{X}} = a^2(\\expect{X^2} - \\expectsq{X})b \\\\\n\\definedas \\; & a^2\\Var{X}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w06/slides.html#what-happened-to-the-b-term-1",
    "href": "w06/slides.html#what-happened-to-the-b-term-1",
    "title": "Week 6: Moments and Covariance",
    "section": "What Happened to the \\(b\\) Term?",
    "text": "What Happened to the \\(b\\) Term?\n\nVisually (Assuming \\(X \\sim \\mathcal{N}(0,1)\\))\n\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\expect{{\\color{lightblue}X + 1}} = \\expect{{\\color{orange}X}} + 1, \\; \\; \\Var{{\\color{lightblue}X + 1}} = \\Var{{\\color{orange}X}} \\\\\n\\expect{{\\color{green}X - 3}} = \\expect{{\\color{orange}X}} - 3, \\; \\; \\Var{{\\color{green}X - 3}} = \\Var{{\\color{orange}X}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w06/slides.html#generalizing-from-expectation-and-variance",
    "href": "w06/slides.html#generalizing-from-expectation-and-variance",
    "title": "Week 6: Moments and Covariance",
    "section": "Generalizing from Expectation and Variance",
    "text": "Generalizing from Expectation and Variance\n\nIt turns out that, expectation and variance are just two ‚Äúlevels‚Äù of a hierarchy of information about a distribution!\nIn calculus: knowing \\(f(x)\\) is sufficient information for us to subsequently figure out \\(f'(x)\\), \\(f''(x)\\), ‚Ä¶\nIn probability/statistics: knowing \\(M_X(t)\\) is sufficient information for us to figure out \\(\\expect{X}\\), \\(\\Var{X}\\), ‚Ä¶"
  },
  {
    "objectID": "w06/slides.html#not-a-metaphor",
    "href": "w06/slides.html#not-a-metaphor",
    "title": "Week 6: Moments and Covariance",
    "section": "Not a Metaphor!",
    "text": "Not a Metaphor!\n\nThis calculus \\(\\leftrightarrow\\) statistics connection is not a metaphor: differentiating \\(M_X(t)\\) literally gives us \\(\\expect{X}\\), \\(\\Var{X}\\), ‚Ä¶\nLet‚Äôs look at MGF for \\(X \\sim \\text{Bern}(\\param{p})\\), and try to derive \\(\\expect{X}\\)1.\n\n\\[\n\\begin{align*}\nM_X(t) &= (1 - p) + pe^t \\\\\nM'_X(t) &= pe^t,\\text{ and }\\expect{X} = M'_X(0) = \\green{p} \\; ‚úÖ\n\\end{align*}\n\\]\n\n\\(\\Var{X}\\)?\n\n\\[\n\\begin{align*}\nM''_{X}(t) &= pe^t,\\text{ and }\\expect{X^2} = M''_X(0) = p \\\\\n\\Var{X} &\\definedas{} \\expect{X^2} - (\\expect{X})^2 = p - p^2 = \\green{p(1-p)} \\; ‚úÖ\n\\end{align*}\n\\]\nRecall that, for a Bernoulli-distributed random variable \\(X\\), \\(\\expect{X} = p\\)"
  },
  {
    "objectID": "w06/slides.html#mgf-in-econometrics",
    "href": "w06/slides.html#mgf-in-econometrics",
    "title": "Week 6: Moments and Covariance",
    "section": "MGF in Econometrics",
    "text": "MGF in Econometrics\n\n\n\nOpen in new window\n\n\n\nIn case it doesn‚Äôt load: (hansen_large_1982?) has 17,253 citations as of 2023-05-21"
  },
  {
    "objectID": "w06/slides.html#beware",
    "href": "w06/slides.html#beware",
    "title": "Week 6: Moments and Covariance",
    "section": "BEWARE ‚ò†Ô∏è",
    "text": "BEWARE ‚ò†Ô∏è\nAs we saw last week (the Dreaded Cauchy Distribution):\n\nNot all random variables have moment-generating functions.\nWorse yet, not all random variables have well-defined variances\nWorse yet, not all random variables have well-defined means\n(This happens in non-contrived cases!)"
  },
  {
    "objectID": "w06/slides.html#multivariate-distributions-w02",
    "href": "w06/slides.html#multivariate-distributions-w02",
    "title": "Week 6: Moments and Covariance",
    "section": "Multivariate Distributions (W02)",
    "text": "Multivariate Distributions (W02)\n\nThe bivariate normal distribution represents the distribution of two normally-distributed RVs \\(\\mathbf{X} = [\\begin{smallmatrix} X_1 & X_2\\end{smallmatrix}]\\), which may or may not be correlated:\n\n\n\\[\n\\mathbf{X} = \\begin{bmatrix}X_1 \\\\ X_2\\end{bmatrix}, \\; \\boldsymbol{\\mu} =\n%\\begin{bmatrix}\\mu_1 \\\\ \\mu_2\\end{bmatrix}\n\\begin{bmatrix}\\smash{\\overbrace{\\mu_1}^{\\mathbb{E}[X_1]}} \\\\ \\smash{\\underbrace{\\mu_2}_{\\mathbb{E}[X_2]}}\\end{bmatrix}\n, \\; \\mathbf{\\Sigma} = \\begin{bmatrix}\\smash{\\overbrace{\\sigma_1^2}^{\\text{Var}[X_1]}} & \\smash{\\overbrace{\\rho\\sigma_1\\sigma_2}^{\\text{Cov}[X_1,X_2]}} \\\\ \\smash{\\underbrace{\\rho\\sigma_2\\sigma_1}_{\\text{Cov}[X_2,X_1]}} & \\smash{\\underbrace{\\sigma_2^2}_{\\text{Var}[X_2]}}\\end{bmatrix}\n% \\begin{bmatrix}\\sigma_1^2 & \\rho\\sigma_1\\sigma_2 \\\\ \\rho\\sigma_2\\sigma_1 & \\sigma_2^2 \\end{bmatrix}\n% = \\begin{bmatrix}\\text{Var}[X_1] & \\text{Cov}[X_1,X_2] \\\\ \\text{Cov}[X_2,X_1] & \\text{Var}[X_2] \\end{bmatrix}\n\\]\n\n\nBy squishing all this information intro matrices, we can specify the parameters of multivariate-normally-distributed vectors of RVs similarly to how we specify single-dimensional normally-distributed RVs:\n\n\n\\[\n\\begin{align*}\n\\overbrace{X}^{\\mathclap{\\text{scalar}}} &\\sim \\mathcal{N}\\phantom{_k}(\\overbrace{\\mu}^{\\text{scalar}}, \\overbrace{\\sigma}^{\\text{scalar}}) \\tag{Univariate} \\\\\n\\underbrace{\\mathbf{X}}_{\\text{vector}} &\\sim \\boldsymbol{\\mathcal{N}}_k(\\smash{\\underbrace{\\boldsymbol{\\mu}}_{\\text{vector}}}, \\underbrace{\\mathbf{\\Sigma}}_{\\text{matrix}}) \\tag{Multivariate}\n\\end{align*}\n\\]\n\n\nNote: In the future I‚Äôll use the notation \\(\\mathbf{X}_{[a \\times b]}\\) to denote the dimensions of the vectors/matrices, like \\(\\mathbf{X}_{[k \\times 1]} \\sim \\boldsymbol{\\mathcal{N}}_k(\\boldsymbol{\\mu}_{[k \\times 1]}, \\mathbf{\\Sigma}_{[k \\times k]})\\)"
  },
  {
    "objectID": "w06/slides.html#visualizing-3d-distributions-projection",
    "href": "w06/slides.html#visualizing-3d-distributions-projection",
    "title": "Week 6: Moments and Covariance",
    "section": "Visualizing 3D Distributions: Projection",
    "text": "Visualizing 3D Distributions: Projection\n\nSince most of our intuitions about plots come from 2D plots, it is extremely useful to be able to take a 3D plot like this and imagine ‚Äúprojecting‚Äù it down into different 2D plots:\n\n\nAdapted (and corrected!) from LaTeX code in this StackExchange thread"
  },
  {
    "objectID": "w06/slides.html#visualizing-3d-distributions-contours",
    "href": "w06/slides.html#visualizing-3d-distributions-contours",
    "title": "Week 6: Moments and Covariance",
    "section": "Visualizing 3D Distributions: Contours",
    "text": "Visualizing 3D Distributions: Contours\n\nFrom Prof.¬†Hickman‚Äôs slides!"
  },
  {
    "objectID": "w06/slides.html#visualizing-3d-distributions-contours-1",
    "href": "w06/slides.html#visualizing-3d-distributions-contours-1",
    "title": "Week 6: Moments and Covariance",
    "section": "Visualizing 3D Distributions: Contours",
    "text": "Visualizing 3D Distributions: Contours\n\nAlso from Prof.¬†Hickman‚Äôs slides!"
  },
  {
    "objectID": "w06/slides.html#bivariate-distributions",
    "href": "w06/slides.html#bivariate-distributions",
    "title": "Week 6: Moments and Covariance",
    "section": "Bivariate Distributions",
    "text": "Bivariate Distributions\n(degroot_probability_2013?) | DSPS Sec. 3.4 \n\nWe generalize the concept of the distribution of a random variable to the joint distribution of two random variables.\nIn doing so, we introduce the joint pmf for two discrete random variables, the joint pdf for two continuous variables, and the joint CDF for any two random variables."
  },
  {
    "objectID": "w06/slides.html#sec-hadamard",
    "href": "w06/slides.html#sec-hadamard",
    "title": "Week 6: Moments and Covariance",
    "section": "Appendix A: The Hadamard Product",
    "text": "Appendix A: The Hadamard Product\n\n\n\nUsed in nearly all neural NLP algorithms, as the basis of LSTM (see LSTM equations on the right)\nThe subscripts for the harmonic mean \\(M_{-1}\\), geometric mean \\(M_0\\), and arithmetic mean \\(M_1\\) come from the definition of the generalized mean:\n\n\\[\nM_p(V) = \\left( \\frac{1}{n} \\sum_{i=1}^n v_i^p \\right)^{1/p}\n\\]\n\n\\[\n\\begin{align*}\nf_t &= \\sigma(W_f [h_{t - 1}, x_t] + b_f) \\\\\ni_t &= \\sigma(W_i [h_{t - 1}, x_t] + b_i) \\\\\n\\tilde{C}_t &= \\tanh(W_C [h_{t - 1}, x_t] + b_C) \\\\\nC_t &= f_t \\odot C_{t - 1} + i_t \\odot \\tilde{C}_t \\\\\no_t &= \\sigma(W_o [h_{t - 1}, x_t] + b_o) \\\\\nh_t &= o_t \\odot \\tanh(C_t) \\\\\n\\hat{y} &= \\text{softmax}(W_y h_t + b_y)\n\\end{align*}\n\\]\n\n\nIf you‚Äôre a dork like me, you can read about generalized means, Fr√©chet means, or Stata‚Äôs trimmean function, all of which bring together seemingly-unrelated functions used throughout Machine Learning!"
  },
  {
    "objectID": "w06/slides.html#sec-continuous-support",
    "href": "w06/slides.html#sec-continuous-support",
    "title": "Week 6: Moments and Covariance",
    "section": "Appendix B: Continuous RV Support",
    "text": "Appendix B: Continuous RV Support\nIn most cases, for continuous RVs, the definition\n\\[\n\\mathcal{R}_X = \\{x \\in \\mathsf{Domain}(f_X) \\given f_X(x) &gt; 0\\}\n\\]\nworks fine. But, to fully capture all possible continuous RVs, the following formal definition is necessary:\n\\[\n\\mathcal{R}_X = \\left\\{x \\in \\mathbb{R} \\given \\forall r &gt; 0 \\left[ f_X(B(x,r)) &gt; 0 \\right] \\right\\},\n\\]\nwhere \\(B(x,r)\\) is a ‚Äúband‚Äù1 around \\(x\\) with radius \\(r\\).\n\n\n\n\nDSAN 5100-03 W06: Moments and Covariance\n\n\n\nFor a full explanation, see this StackExchange discussion.\nIn one dimension, this would be an interval; in two dimensions, a circle; in three dimensions, a sphere; etc."
  },
  {
    "objectID": "cheatsheet-math.html",
    "href": "cheatsheet-math.html",
    "title": "DSAN 5100 Math Cheatsheet",
    "section": "",
    "text": "Proposition \\(p\\): A true-false statement like ‚Äú1 + 1 = 2‚Äù or ‚Äú\\(x\\) is greater than 5‚Äù. The latter would be written as \\(p(x)\\), since its true/false value depends on a given value of \\(x\\).\n\\(\\wedge\\): Logical ‚Äúand‚Äù. \\(p \\wedge q\\) is true only if both \\(p\\) and \\(q\\) are true.\n\\(\\vee\\): Logical ‚Äúor‚Äù. \\(p \\vee q\\) is true if \\(p\\) is true or \\(q\\) is true, or both are true.\n\\(\\neg\\): Logical negation: If \\(p\\) is true, \\(\\neg p\\) is false. If \\(p\\) is false, \\(\\neg p\\) is true.\nDeMorgan‚Äôs Laws: Logical identities which illustrate how the negation operator gets ‚Äúdistributed‚Äù in a logical statement, allowing conversion of ‚Äúor‚Äù statements into ‚Äúand‚Äù statements, and vice-versa: \\(\\neg(p \\wedge q) = \\neg(\\neg p \\vee \\neg q)\\)\n\\(\\implies\\): ‚ÄúImplies‚Äù. \\(a \\implies b\\) is true if, whenever \\(a\\) is true, \\(b\\) is also true.\n\\(\\iff\\): ‚ÄúIf and only if‚Äù. \\(a \\iff b\\) is true if, \\(a\\) is only true when \\(b\\) is true, and \\(a\\) is only false when \\(b\\) is false.\n\\(\\exists\\): ‚ÄúThere exists‚Äù. In the course this will be written as \\(\\exists x \\in S [p(x)]\\), which means that there exists some element \\(x\\) in the set \\(S\\) such that \\(p(x)\\) is true. Also called the ‚Äúexistential quantifier‚Äù.\n\\(\\forall\\): ‚ÄúFor all‚Äù. In the course this will be written as \\(\\forall x \\in S [p(x)]\\), which means that for every element in a set \\(S\\) (with \\(x\\) representing some element arbitrarily taken from \\(S\\)), the proposition \\(p(x)\\) is true. Also called the ‚Äúuniversal quantifier‚Äù.\n\nNote that the universal and existential quantifiers are closely related by a negation law (just like \\(\\wedge\\) and \\(\\vee\\) and their connection via DeMorgan‚Äôs Laws): \\(\\neg \\left( \\forall x \\in S[p(x)] \\right) \\iff \\exists x \\in S [\\neg p(x)]\\). The negation on the outside of the quantified proposition has moved inside of it, with the quantifier flipped.\nThe same holds true in reverse: \\(\\neg \\left( \\exists x \\in S [p(x)] \\right) \\iff \\forall x \\in S [\\neg p(x)]\\)\n\n\n\n\n\n\nA set \\(S\\) (denoted by a capital letter when possible) is a collection of elements (denoted by a lowercase letter when possible).\n\nFor example, if \\(S = \\{0,1,2,3\\}\\), then \\(0\\) is an element of \\(S\\).\n\n\\(a \\in S\\): The proposition that \\(a\\) is an element of the set \\(S\\).\n\nIf \\(S = \\{0,1,2,3\\}\\), then \\(2 \\in S\\) but \\(5 \\notin S\\).\n\n\\(A \\subseteq S\\): The proposition that \\(A\\) is a subset of the set \\(S\\).\n\nIf \\(S = \\{0, 1, 2, 3\\}\\), then \\(\\{1,3\\} \\subseteq S\\) but \\(\\{1,4\\} \\not\\subseteq S\\). Note that sets are defined to be subsets of themselves, so that \\(S \\subseteq S\\).\n\n\\(A \\subset S\\): The proposition that \\(A\\) is a proper subset of \\(S\\), meaning that \\(A \\subseteq S\\) but \\(A \\neq S\\).\n\nWhile sets are subsets of themselves, sets are not proper subsets of themselves, so that if \\(S = \\{0, 1, 2, 3\\}\\), then \\(\\{1,2,3\\} \\subset S\\) but \\(\\{0, 1, 2, 3\\} \\not\\subset S\\).\n\n\\(|S|\\): The cardinality of, or number of elements in, a set \\(S\\).\n\nIf \\(S = \\{1, 2, 3\\}\\), \\(|S| = 3\\).\nIf the set \\(S\\) has infinite cardinality, we can distinguish between two cases:\n\nIf elements of \\(S\\) can be put into one-to-one correspondence with the natural numbers \\(\\mathbb{N}\\), we say that \\(S\\) is countably infinite and has cardinality \\(\\aleph_0\\) (pronounced ‚Äúaleph-null‚Äù): \\(|S| = \\aleph_0\\).\nIf elements of \\(S\\) cannot be put into one-to-one correspondence with the natural numbers \\(\\mathbb{N}\\), we say that \\(S\\) is uncountably infinite and has cardinality greater than \\(\\aleph_0\\): \\(|S| &gt; \\aleph_0\\).\n\n\n\\(\\mathcal{P}(S)\\): The power set of a set \\(S\\), which is the set of all possible subsets of \\(S\\).\n\nFor example, if \\(S = \\{1, 2, 3\\}\\), \\(\\mathcal{P}(S) = \\{\\varnothing, \\{1\\}, \\{2\\}, \\{3\\}, \\{1,2\\}, \\{1,3\\}, \\{2,3\\}, \\{1,2,3\\}\\}\\). Notice that \\(|\\mathcal{P}(S)| = 2^{|S|}\\), which is always true of the power set.\n\n\n\n\n\n\n\\(\\mathbb{N}\\): The set of all natural numbers, sometimes called the ‚Äúcounting numbers‚Äù: \\(\\{0, 1, 2, 3, \\ldots \\}\\) (This set is countably infinite).\n\\(\\mathbb{Z}\\): The set of all integers, which includes all of the natural numbers along with their negatives: \\(\\{\\ldots, -2, -1, 0, 1, 2, \\ldots\\}\\) (This set is also countably infinite)\n\\(\\mathbb{Q}\\): The set of all rational numbers, i.e., well-defined ratios of two integers. \\(x \\in \\mathbb{Q} \\iff x = \\frac{p}{q}\\) for two integers \\(p\\) and \\(q\\), and \\(q \\neq 0\\). (This set is, surprisingly, also countably infinite)\n\\(\\mathbb{R}\\): The set of all real numbers, which includes all integers as well as numbers such as \\(\\pi\\), \\(2.356\\), or \\(\\sqrt{2}\\) (This set is uncountably infinite).\nScalar: A single number from some set of numbers, like \\(-2.1 \\in \\mathbb{R}\\)\nVector: A \\(d\\)-dimensional vector \\(\\mathbf{v}\\) is a collection of \\(d\\) scalars in \\(\\mathbb{R}\\), \\(\\mathbf{v} = (v_1, v_2, \\ldots, v_d)^\\top\\), which we can interpret as an arrow pointing \\(v_i\\) units in each dimension \\(i\\). For example, if \\(\\mathbf{v} = (3,5)\\), we can interpret \\(\\mathbf{v}\\) as representing an arrow pointing \\(3\\) units in the \\(x\\) direction and \\(5\\) units in the \\(y\\) direction.\n\nAs indicated above, however, we will assume that vectors are column vectors unless otherwise specified, though they will be written row-wise with a transpose symbol at the end. This means that, although it will be written like \\(\\mathbf{v} = (v_1, v_2, \\ldots, v_n)^\\top\\), you should apply the transpose in your head: \\[\n\\mathbf{v} = (v_1, v_2, \\ldots, v_n)^\\top = \\begin{bmatrix}v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n\\end{bmatrix}\n\\]\n\nMatrix: An \\(m \\times n\\) matrix \\(\\mathbf{M}_{[m \\times n]}\\) is an \\(m\\)-by-\\(n\\) grid of scalars, where the scalar in the \\(i\\)th row and \\(j\\)th column is denoted \\(m_{i,j}\\). In the class, we will be careful to add a subscript like \\(\\mathbf{M}_{[m \\times n]}\\) to indicate the number of rows (\\(m\\)) and columns (\\(n\\)) in the matrix, since operations like multiplication are only defined for matrices with particular dimensions.\nMatrix multiplication: For two matrices \\(\\mathbf{X}_{[a \\times b]}\\) and \\(\\mathbf{Y}_{[c \\times d]}\\), matrix multiplication is defined if \\(b = c\\), and produces the following \\(a \\times d\\) matrix \\(\\mathbf{XY}_{[a \\times d]}\\):\n\\[\n  \\mathbf{XY}_{[a \\times d]} = \\begin{bmatrix}\n  x_{1,1}y_{1,1} & \\cdots & x_{m,1}y_{1,n} \\\\\n  \\vdots & \\ddots & \\vdots \\\\\n  x_{1,n}y_{m,1} & \\cdots & x_{m,n}y_{m,n}\n  \\end{bmatrix}\n  \\]\n\\(\\sum_{i=1}^n f(i)\\): \\(\\Sigma\\) is the capitalized Greek letter ‚ÄúSigma‚Äù, and stands for ‚ÄúSum‚Äù in this case. This notation means: ‚Äúthe sum of \\(f(i)\\) from \\(i = 1\\) to \\(i = n\\)‚Äù. For example, \\(\\sum_{i=1}^3 i^2 = 1^2 + 2^2 + 3^2 = 14\\).\n\\(\\prod_{i=1}^n f(i)\\): \\(\\Pi\\) is the capitalized Greek letter ‚ÄúPi‚Äù, and stands for ‚ÄúProduct‚Äù in this case. This notation means: ‚Äúthe product of \\(f(i)\\) from \\(i = 1\\) to \\(i = n\\)‚Äù. For example, \\(\\prod_{i=1}^3 i^2 = 1^2 \\cdot 2^2 \\cdot 3^2 = 36\\).\n\n\n\n\n\n\\([a,b] \\in \\mathbb{R}\\): The closed interval between \\(a\\) and \\(b\\). That is, the subset of \\(\\mathbb{R}\\) containing all numbers between \\(a\\) and \\(b\\), including \\(a\\) and \\(b\\) themselves.\n\\((a,b) \\in \\mathbb{R}\\): The open interval between \\(a\\) and \\(b\\). That is, the subset of \\(\\mathbb{R}\\) containing all numbers between \\(a\\) and \\(b\\), excluding \\(a\\) and \\(b\\) themselves.\n\\([a, b)\\), \\((a, b]\\): The half-open interval between \\(a\\) and \\(b\\). In the first case, we include \\(a\\) but exclude \\(b\\), while in the second we exclude \\(a\\) but include \\(b\\).\n\\(\\int_{a}^b f(x)dx\\): The integral of the function \\(f(x)\\) between points \\(a\\) and \\(b\\). In this course, you just need to remember that this produces the area under the curve of \\(f(x)\\) between these points.\n\\(\\frac{d}{dx} \\left[ f(x) \\right]\\): The derivative of the function \\(f(x)\\). For this class, you just need to remember that the derivative is what transforms a Cumulative Density Function (CDF) into a Probability Density Function (PDF): if \\(F_X(v)\\) is the CDF of a random variable \\(X\\), then \\(\\frac{d}{dx}\\left[ F_X(v) \\right] = f_X(v)\\), the PDF of \\(X\\).\n\nFor functions of multiple variables, like the joint pdf \\(f_{X,Y}(v_X, v_Y)\\), we use the \\(\\partial\\) symbol instead of \\(d\\) to denote partial derivatives: for example, the change in \\(F_{X,Y}(v_X, v_Y)\\) as \\(v_X\\) changes is denoted \\(\\frac{\\partial}{\\partial v_X}\\left[ F_{X,Y}(v_X, v_Y) \\right]\\), while the change in \\(F_{X,Y}(v_X, v_Y)\\) as \\(v_Y\\) changes is denoted \\(\\frac{\\partial}{\\partial v_Y}\\left[ F_{X,Y}(v_X, v_Y) \\right]\\).",
    "crumbs": [
      "Math Cheatsheet"
    ]
  },
  {
    "objectID": "cheatsheet-math.html#math-preliminaries",
    "href": "cheatsheet-math.html#math-preliminaries",
    "title": "DSAN 5100 Math Cheatsheet",
    "section": "",
    "text": "Proposition \\(p\\): A true-false statement like ‚Äú1 + 1 = 2‚Äù or ‚Äú\\(x\\) is greater than 5‚Äù. The latter would be written as \\(p(x)\\), since its true/false value depends on a given value of \\(x\\).\n\\(\\wedge\\): Logical ‚Äúand‚Äù. \\(p \\wedge q\\) is true only if both \\(p\\) and \\(q\\) are true.\n\\(\\vee\\): Logical ‚Äúor‚Äù. \\(p \\vee q\\) is true if \\(p\\) is true or \\(q\\) is true, or both are true.\n\\(\\neg\\): Logical negation: If \\(p\\) is true, \\(\\neg p\\) is false. If \\(p\\) is false, \\(\\neg p\\) is true.\nDeMorgan‚Äôs Laws: Logical identities which illustrate how the negation operator gets ‚Äúdistributed‚Äù in a logical statement, allowing conversion of ‚Äúor‚Äù statements into ‚Äúand‚Äù statements, and vice-versa: \\(\\neg(p \\wedge q) = \\neg(\\neg p \\vee \\neg q)\\)\n\\(\\implies\\): ‚ÄúImplies‚Äù. \\(a \\implies b\\) is true if, whenever \\(a\\) is true, \\(b\\) is also true.\n\\(\\iff\\): ‚ÄúIf and only if‚Äù. \\(a \\iff b\\) is true if, \\(a\\) is only true when \\(b\\) is true, and \\(a\\) is only false when \\(b\\) is false.\n\\(\\exists\\): ‚ÄúThere exists‚Äù. In the course this will be written as \\(\\exists x \\in S [p(x)]\\), which means that there exists some element \\(x\\) in the set \\(S\\) such that \\(p(x)\\) is true. Also called the ‚Äúexistential quantifier‚Äù.\n\\(\\forall\\): ‚ÄúFor all‚Äù. In the course this will be written as \\(\\forall x \\in S [p(x)]\\), which means that for every element in a set \\(S\\) (with \\(x\\) representing some element arbitrarily taken from \\(S\\)), the proposition \\(p(x)\\) is true. Also called the ‚Äúuniversal quantifier‚Äù.\n\nNote that the universal and existential quantifiers are closely related by a negation law (just like \\(\\wedge\\) and \\(\\vee\\) and their connection via DeMorgan‚Äôs Laws): \\(\\neg \\left( \\forall x \\in S[p(x)] \\right) \\iff \\exists x \\in S [\\neg p(x)]\\). The negation on the outside of the quantified proposition has moved inside of it, with the quantifier flipped.\nThe same holds true in reverse: \\(\\neg \\left( \\exists x \\in S [p(x)] \\right) \\iff \\forall x \\in S [\\neg p(x)]\\)\n\n\n\n\n\n\nA set \\(S\\) (denoted by a capital letter when possible) is a collection of elements (denoted by a lowercase letter when possible).\n\nFor example, if \\(S = \\{0,1,2,3\\}\\), then \\(0\\) is an element of \\(S\\).\n\n\\(a \\in S\\): The proposition that \\(a\\) is an element of the set \\(S\\).\n\nIf \\(S = \\{0,1,2,3\\}\\), then \\(2 \\in S\\) but \\(5 \\notin S\\).\n\n\\(A \\subseteq S\\): The proposition that \\(A\\) is a subset of the set \\(S\\).\n\nIf \\(S = \\{0, 1, 2, 3\\}\\), then \\(\\{1,3\\} \\subseteq S\\) but \\(\\{1,4\\} \\not\\subseteq S\\). Note that sets are defined to be subsets of themselves, so that \\(S \\subseteq S\\).\n\n\\(A \\subset S\\): The proposition that \\(A\\) is a proper subset of \\(S\\), meaning that \\(A \\subseteq S\\) but \\(A \\neq S\\).\n\nWhile sets are subsets of themselves, sets are not proper subsets of themselves, so that if \\(S = \\{0, 1, 2, 3\\}\\), then \\(\\{1,2,3\\} \\subset S\\) but \\(\\{0, 1, 2, 3\\} \\not\\subset S\\).\n\n\\(|S|\\): The cardinality of, or number of elements in, a set \\(S\\).\n\nIf \\(S = \\{1, 2, 3\\}\\), \\(|S| = 3\\).\nIf the set \\(S\\) has infinite cardinality, we can distinguish between two cases:\n\nIf elements of \\(S\\) can be put into one-to-one correspondence with the natural numbers \\(\\mathbb{N}\\), we say that \\(S\\) is countably infinite and has cardinality \\(\\aleph_0\\) (pronounced ‚Äúaleph-null‚Äù): \\(|S| = \\aleph_0\\).\nIf elements of \\(S\\) cannot be put into one-to-one correspondence with the natural numbers \\(\\mathbb{N}\\), we say that \\(S\\) is uncountably infinite and has cardinality greater than \\(\\aleph_0\\): \\(|S| &gt; \\aleph_0\\).\n\n\n\\(\\mathcal{P}(S)\\): The power set of a set \\(S\\), which is the set of all possible subsets of \\(S\\).\n\nFor example, if \\(S = \\{1, 2, 3\\}\\), \\(\\mathcal{P}(S) = \\{\\varnothing, \\{1\\}, \\{2\\}, \\{3\\}, \\{1,2\\}, \\{1,3\\}, \\{2,3\\}, \\{1,2,3\\}\\}\\). Notice that \\(|\\mathcal{P}(S)| = 2^{|S|}\\), which is always true of the power set.\n\n\n\n\n\n\n\\(\\mathbb{N}\\): The set of all natural numbers, sometimes called the ‚Äúcounting numbers‚Äù: \\(\\{0, 1, 2, 3, \\ldots \\}\\) (This set is countably infinite).\n\\(\\mathbb{Z}\\): The set of all integers, which includes all of the natural numbers along with their negatives: \\(\\{\\ldots, -2, -1, 0, 1, 2, \\ldots\\}\\) (This set is also countably infinite)\n\\(\\mathbb{Q}\\): The set of all rational numbers, i.e., well-defined ratios of two integers. \\(x \\in \\mathbb{Q} \\iff x = \\frac{p}{q}\\) for two integers \\(p\\) and \\(q\\), and \\(q \\neq 0\\). (This set is, surprisingly, also countably infinite)\n\\(\\mathbb{R}\\): The set of all real numbers, which includes all integers as well as numbers such as \\(\\pi\\), \\(2.356\\), or \\(\\sqrt{2}\\) (This set is uncountably infinite).\nScalar: A single number from some set of numbers, like \\(-2.1 \\in \\mathbb{R}\\)\nVector: A \\(d\\)-dimensional vector \\(\\mathbf{v}\\) is a collection of \\(d\\) scalars in \\(\\mathbb{R}\\), \\(\\mathbf{v} = (v_1, v_2, \\ldots, v_d)^\\top\\), which we can interpret as an arrow pointing \\(v_i\\) units in each dimension \\(i\\). For example, if \\(\\mathbf{v} = (3,5)\\), we can interpret \\(\\mathbf{v}\\) as representing an arrow pointing \\(3\\) units in the \\(x\\) direction and \\(5\\) units in the \\(y\\) direction.\n\nAs indicated above, however, we will assume that vectors are column vectors unless otherwise specified, though they will be written row-wise with a transpose symbol at the end. This means that, although it will be written like \\(\\mathbf{v} = (v_1, v_2, \\ldots, v_n)^\\top\\), you should apply the transpose in your head: \\[\n\\mathbf{v} = (v_1, v_2, \\ldots, v_n)^\\top = \\begin{bmatrix}v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n\\end{bmatrix}\n\\]\n\nMatrix: An \\(m \\times n\\) matrix \\(\\mathbf{M}_{[m \\times n]}\\) is an \\(m\\)-by-\\(n\\) grid of scalars, where the scalar in the \\(i\\)th row and \\(j\\)th column is denoted \\(m_{i,j}\\). In the class, we will be careful to add a subscript like \\(\\mathbf{M}_{[m \\times n]}\\) to indicate the number of rows (\\(m\\)) and columns (\\(n\\)) in the matrix, since operations like multiplication are only defined for matrices with particular dimensions.\nMatrix multiplication: For two matrices \\(\\mathbf{X}_{[a \\times b]}\\) and \\(\\mathbf{Y}_{[c \\times d]}\\), matrix multiplication is defined if \\(b = c\\), and produces the following \\(a \\times d\\) matrix \\(\\mathbf{XY}_{[a \\times d]}\\):\n\\[\n  \\mathbf{XY}_{[a \\times d]} = \\begin{bmatrix}\n  x_{1,1}y_{1,1} & \\cdots & x_{m,1}y_{1,n} \\\\\n  \\vdots & \\ddots & \\vdots \\\\\n  x_{1,n}y_{m,1} & \\cdots & x_{m,n}y_{m,n}\n  \\end{bmatrix}\n  \\]\n\\(\\sum_{i=1}^n f(i)\\): \\(\\Sigma\\) is the capitalized Greek letter ‚ÄúSigma‚Äù, and stands for ‚ÄúSum‚Äù in this case. This notation means: ‚Äúthe sum of \\(f(i)\\) from \\(i = 1\\) to \\(i = n\\)‚Äù. For example, \\(\\sum_{i=1}^3 i^2 = 1^2 + 2^2 + 3^2 = 14\\).\n\\(\\prod_{i=1}^n f(i)\\): \\(\\Pi\\) is the capitalized Greek letter ‚ÄúPi‚Äù, and stands for ‚ÄúProduct‚Äù in this case. This notation means: ‚Äúthe product of \\(f(i)\\) from \\(i = 1\\) to \\(i = n\\)‚Äù. For example, \\(\\prod_{i=1}^3 i^2 = 1^2 \\cdot 2^2 \\cdot 3^2 = 36\\).\n\n\n\n\n\n\\([a,b] \\in \\mathbb{R}\\): The closed interval between \\(a\\) and \\(b\\). That is, the subset of \\(\\mathbb{R}\\) containing all numbers between \\(a\\) and \\(b\\), including \\(a\\) and \\(b\\) themselves.\n\\((a,b) \\in \\mathbb{R}\\): The open interval between \\(a\\) and \\(b\\). That is, the subset of \\(\\mathbb{R}\\) containing all numbers between \\(a\\) and \\(b\\), excluding \\(a\\) and \\(b\\) themselves.\n\\([a, b)\\), \\((a, b]\\): The half-open interval between \\(a\\) and \\(b\\). In the first case, we include \\(a\\) but exclude \\(b\\), while in the second we exclude \\(a\\) but include \\(b\\).\n\\(\\int_{a}^b f(x)dx\\): The integral of the function \\(f(x)\\) between points \\(a\\) and \\(b\\). In this course, you just need to remember that this produces the area under the curve of \\(f(x)\\) between these points.\n\\(\\frac{d}{dx} \\left[ f(x) \\right]\\): The derivative of the function \\(f(x)\\). For this class, you just need to remember that the derivative is what transforms a Cumulative Density Function (CDF) into a Probability Density Function (PDF): if \\(F_X(v)\\) is the CDF of a random variable \\(X\\), then \\(\\frac{d}{dx}\\left[ F_X(v) \\right] = f_X(v)\\), the PDF of \\(X\\).\n\nFor functions of multiple variables, like the joint pdf \\(f_{X,Y}(v_X, v_Y)\\), we use the \\(\\partial\\) symbol instead of \\(d\\) to denote partial derivatives: for example, the change in \\(F_{X,Y}(v_X, v_Y)\\) as \\(v_X\\) changes is denoted \\(\\frac{\\partial}{\\partial v_X}\\left[ F_{X,Y}(v_X, v_Y) \\right]\\), while the change in \\(F_{X,Y}(v_X, v_Y)\\) as \\(v_Y\\) changes is denoted \\(\\frac{\\partial}{\\partial v_Y}\\left[ F_{X,Y}(v_X, v_Y) \\right]\\).",
    "crumbs": [
      "Math Cheatsheet"
    ]
  },
  {
    "objectID": "cheatsheet-math.html#conditional-probability",
    "href": "cheatsheet-math.html#conditional-probability",
    "title": "DSAN 5100 Math Cheatsheet",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\nProbability Fundamentals\n\n\\(\\Omega\\): The set of all possible outcomes in a probability setting\n\\(\\mathcal{P}(\\Omega) = \\{ e \\mid e \\subseteq \\Omega\\}\\): The set of all subsets of \\(\\Omega\\), each of which is an event\n\n\n\nRandom Variables\n\n\\(X\\) is a random variable if it maps each element of \\(\\Omega\\) to a real number \\(o \\in \\mathbb{R}\\).\n\nFor example, if we‚Äôre rolling a die, we can create a random variable \\(X\\) which maps \\(\\text{roll a one}\\) to \\(1\\), \\(\\text{roll a two}\\) to \\(2\\), and so on. (Allows us to do math with probability spaces!)\n\n\\(X\\) is a discrete random variable if it maps outcomes to countable set of numbers, whether this means a finite set like \\(\\{1,2,3\\}\\) or a countably infinite set like \\(\\mathbb{N}\\).\n\\(X\\) is a continuous random variable if it maps outcomes to a non-countable set of numbers, typically \\(\\mathbb{R}\\).\n\\(\\mathcal{R}_X\\), the support of a random variable \\(X\\), is the set of all possible values that the random variable can map onto. For example, if \\(X\\) represents a dice roll, then \\(\\mathcal{R}_X = \\{1, 2, 3, 4, 5, 6\\}\\).\nCumulative Density Function (CDF): Given a random variable \\(X\\) (whether discrete or continuous), \\(F_X(v) = P(X \\leq v)\\) is its cumulative density function, which tells us the probability that \\(X\\) is realized as a number less than or equal to some value \\(v\\).\nProbability Mass Function (PMF): Given a discrete random variable \\(X\\), \\(p_X(v) = P(X = v)\\) is its probability mass function, which tells us the probability that \\(X\\) is realized as the value \\(v\\).\nProbability Density Function (PDF): Given a continuous random variable \\(X\\), \\(f_X(v)\\) is the unique function which allows us to determine, using integration, the probability that \\(X\\) is in some range \\([a,b]\\). That is, it is the unique function satisfying \\(P(X \\in [a,b]) = \\int_a^b f_X(x)dx\\).\n\nRemember: unlike in the discrete case where \\(p_X(v) = P(X = v)\\), \\(f_X(v)\\) is not the probability that \\(X\\) is realized as the value \\(v\\). \\(f_X(v) \\neq P(X = v)\\).",
    "crumbs": [
      "Math Cheatsheet"
    ]
  },
  {
    "objectID": "cheatsheet-math.html#expectation-variance-moments",
    "href": "cheatsheet-math.html#expectation-variance-moments",
    "title": "DSAN 5100 Math Cheatsheet",
    "section": "Expectation, Variance, Moments",
    "text": "Expectation, Variance, Moments\n\n\\(M_1(V)\\): The (‚Äúregular‚Äù) arithmetic mean of a set of values \\(V = \\{v_1, v_2, \\ldots, v_n\\}\\): \\(M_1(V) = (v_1 + v_2 + \\cdots + v_n)\\frac{1}{n} = \\left( \\sum_{i=1}^n v_i \\right)\\frac{1}{n}\\).\n\\(M_0(V)\\): The geometric mean of a set of values \\(V = \\{v_1, v_2, \\ldots, v_n\\}\\): \\(M_0(V) = (v_1\\cdot v_2 \\cdot \\cdots \\cdot v_n)^{\\frac{1}{n}} = \\left( \\prod_{i=1}^n v_i \\right)^{\\frac{1}{n}}\\)\n\\(M_{-1}(V)\\): The harmonic mean of a set of values \\(V = \\{v_1, v_2, \\ldots, v_n\\}\\): \\(M_{-1}(V) = \\frac{n}{\\frac{1}{v_1} + \\frac{1}{v_2} + \\cdots + \\frac{1}{v_n}} = \\left( \\frac{\\sum_{i=1}^n v_i^{-1}}{n} \\right)^{-1}\\)\n\\(\\odot\\): The Hadamard product of matrices. For two matrices \\(\\mathbf{X}_{[m \\times n]}\\) and \\(\\mathbf{Y}_{[m \\times n]}\\) with equal dimensions:\n\\[\n  X_{[m \\times n]} = \\begin{bmatrix}\n      x_{1,1} & \\cdots & x_{1,n} \\\\\n      \\vdots & \\ddots & \\vdots \\\\\n      x_{m,1} & \\cdots & x_{m,n}\n  \\end{bmatrix}, Y_{[m \\times n]} = \\begin{bmatrix}\n      y_{1,1} & \\cdots & y_{1,n} \\\\\n      \\vdots & \\ddots & \\vdots \\\\\n      y_{m,1} & \\cdots & y_{m,n}\n  \\end{bmatrix}\n  \\]\nTheir Hadamard product \\(\\mathbf{X} \\odot \\mathbf{Y}\\) is another \\(m \\times n\\) matrix\n\\[\n  (\\mathbf{X} \\odot \\mathbf{Y})_{[m \\times n]} = \\begin{bmatrix}\n      x_{1,1}y_{1,1} & \\cdots & x_{1,n}y_{1,n} \\\\\n      \\vdots & \\ddots & \\vdots \\\\\n      x_{m,1}y_{m,1} & \\cdots & x_{m,n}y_{m,n}\n  \\end{bmatrix}\n  \\]",
    "crumbs": [
      "Math Cheatsheet"
    ]
  }
]